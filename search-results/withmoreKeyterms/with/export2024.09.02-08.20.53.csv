"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Algorithm Analysis of Sparse Matrix Multiplication","H. Ren; H. Ma; J. Kang; Y. Liu; L. Wang; X. Zheng",Beijing Institute of Astronautical Systems Engineering; Beijing Institute of Astronautical Systems Engineering; Beijing Institute of Astronautical Systems Engineering; Beijing Institute of Astronautical Systems Engineering; Beijing Institute of Astronautical Systems Engineering; Beijing Institute of Astronautical Systems Engineering,"2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)","1 Apr 2022","2021","","","912","917","Matrix is widely used in telecommunication, cryptography, computer science and other field. Especially in wireless sensor network data processing, it is important and necessary to keep data transmitting reliable and resilient. In channel coding and secure communication, matrix is used to realize the coding of transmission information and source information in the channel, which not only reduces the bit error rate of wireless communication, but also realizes the confidentiality of communication. The development of effective algorithms for matrix calculation has been an interesting subject for several centuries and an expanding research field. For some widely used and special matrices, such as sparse matrix and quasi diagonal matrix, there are specific fast algorithms. This paper briefly describes and explains our design of serial algorithms which implementing the sparse matrix multiplication by parallel programming, and also to provide benchmark results to justify the correctness and performance of our design.","2693-9371","978-1-6654-7836-6","10.1109/QRS-C55045.2021.00138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9741870","sparse;matrix;multiplication;parallel","Wireless communication;Wireless sensor networks;Computer network reliability;Bit error rate;Benchmark testing;Communications technology;Software reliability","","","","2","IEEE","1 Apr 2022","","","IEEE","IEEE Conferences"
"The unique aspects of simulation verification and validation","D. Thomas; A. Joiner; W. Lin; M. Lowry; T. Pressburger","AEgis Technologies Group, Inc., Huntsville, AL, USA; AEgis Technologies Group, Inc., Huntsville, AL, USA; NASA Ames Research Center, Moffett Field, CA, USA; NASA Ames Research Center, Moffett Field, CA, USA; NASA Ames Research Center, Moffett Field, CA, USA",2010 IEEE Aerospace Conference,"15 Apr 2010","2010","","","1","7","Models and simulations (M&S) will be employed to support important design decisions and verification of system requirements in the development of NASA's Orion Crew Exploration Vehicle. Most simulations are implemented in software. For developed software, NASA's software engineering procedural guideline NPR 7150.2 and safety standard NASA-STD-8719.13B apply. Recognizing the need for critical M&S to be validated to be credible for their intended uses, NASA developed a Modeling and Simulation Standard, NASA-STD-7009. This paper analyzes the requirements specified by these standards and their role in test, validation and certification of modeling and simulation software. It discusses simulation validation as a distinct instance of software validation with corresponding unique requirements. Simulation-specific validation concerns include fit to intended use, validation against experimental data, uncertainty quantification, and sensitivity analysis. The paper also describes the Orion M&S verification, validation, and accreditation (VV&A) process.","1095-323X","978-1-4244-3887-7","10.1109/AERO.2010.5446785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5446785","","Software safety;Software standards;Standards development;Analytical models;Vehicles;Software engineering;Guidelines;NASA;Software testing;Certification","","3","","4","IEEE","15 Apr 2010","","","IEEE","IEEE Conferences"
"Research on Determination of Overloaded Function Uniqueness for Regression Testing Oriented","S. Qi; Y. -m. Mu; Z. -h. Zhang; K. -q. Peng","Open Computer System Laboratory, Beijing Information Science and Technology University, Beijing, China; Computer School, Beijing Information Science and Technology University, Beijing, China; Open Computer System Laboratory, Beijing Information Science and Technology University, Beijing, China; Computer School, Beijing Information Science and Technology University, Beijing, China",2010 2nd International Conference on Information Engineering and Computer Science,"30 Dec 2010","2010","","","1","4","Function call path testing is based on static analysis of source code. The relationship between the definitions of the overloaded function and the call points is uncertain in the static analysis, which will produce a great deal of redundant paths and increase the cost of the testing. In order to determine the paths of the actual process and get function call relation, firstly, we need to determine the uniqueness of the overloaded function. We analyze the form of the overloaded function call from several aspects, design the algorithm of DUOF(determining the uniqueness of the overloaded function), ultimately determine its unique, by analyzing the realization mechanism of overloaded functions and applying the theory of compile and object-oriented. The experiment's result shows that the result of its implementation is not only accurate but also can improve the efficiency of regression testing, efficiency of the algorithm is more significant especially when the amount of code is larger.","2156-7387","978-1-4244-7941-2","10.1109/ICIECS.2010.5678400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5678400","","Testing;Algorithm design and analysis;Data structures;Semantics;Shape;Information science;Software algorithms","","1","","9","IEEE","30 Dec 2010","","","IEEE","IEEE Conferences"
"Modified sparse distributed memory as transient episodic memory for cognitive software agents","U. Ramamaurthy; S. K. D'Mello; S. Franklin","Comput. Sci. Div., Memphis Univ., TN, USA; Computer Science Division and Institute for Intelligent Systems, The University of Memphis, Memphis, TN, USA; Computer Science Division and Institute for Intelligent Systems, The University of Memphis, Memphis, TN, USA","2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)","7 Mar 2005","2004","6","","5858","5863 vol.6","This paper presents a modified sparse distributed memory architecture for use in software agents with natural language processing capabilities. We have modified Kanerva's sparse distributed memory (SDM) into an architecture with a ternary memory space. This enables the memory to be used in IDA, the intelligent distribution agent built for the U.S. Navy. IDA implements Boars' global workspace theory, a psychological theory of consciousness. As a result, it can react to novel and problematic situations in a more flexible, more human-like way than traditional AI systems. IDA performs a function, namely billet assignment, therefore reserved for humans. We argue that such flexibility requires advanced memory systems such as transient episodic memory and autobiographical memory. Here, we present the architecture, tests and results of this modified SDM system which can be used as a transient episodic memory in suitable software agents.","1062-922X","0-7803-8566-7","10.1109/ICSMC.2004.1401130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1401130","","Software agents;Computer architecture;Memory architecture;Natural language processing;Intelligent agent;Psychology;Artificial intelligence;Billets;Humans;Software testing","","6","","14","IEEE","7 Mar 2005","","","IEEE","IEEE Conferences"
"CoMSS: Context based measure for semantic similarity between conceptual models","E. A. Kaundal; A. Kaur","Department of Computer Science Engineering, Chandigarh University, Gharuan, Punjab, India; Department of Computer Science Engineering, Chandigarh University, Gharuan, Punjab, India",2017 International Conference on Intelligent Computing and Control Systems (ICICCS),"11 Jan 2018","2017","","","1080","1088","Artifacts are defined as the tools which act as building block for developing a software or project. Artifacts are of several kinds like UML and BPMN. The overall connotation of the document in SDLC is combination of sensible or significant words represented in the form of different artifacts. In this approach main focus is on the precision of the documents or artifacts developed by requirement analysts. This phase is purely personal opinion oriented, later on which may cause rejection of the software during acceptance testing. Our aim is to preserve the overall meaning of the document that's why we compare the class diagram (conceptual model) with BPMN so that the meaning of the requirements provided by the stakeholders should be preserved in both forms of artifacts. The word specificity and word semantics plays vital role in assessing the semantic similarity between the two artifacts. In this paper the frequency (word specificity) is calculated between the vectors with the help of TF-IDF and the semantic similarity between the vectors is calculated with the help of WordNet algorithms. The proposed similarity measures are evaluated in divergent context, the benchmark dataset i.e SemEval (Semantic Evaluation) 2012 Semantic Textual Similarity test set, competition organized in 2012. Three standard case studies are used to evaluate the semantic similarity between the artifacts named as Rambaugh's ATM Model (Rambaugh et al. 1991), EFP (Kurt, 1995), Course Registration (IBM Corp, 2004).","","978-1-5386-2745-7","10.1109/ICCONS.2017.8250633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8250633","Natural language processing;Vector space model;WordNet;Sentence similarity;CoMSS;TF-IDF;Semantic similarity;Knowledge Based systems;Information Retrieval","Semantics;Computational modeling;Software;Analytical models;Unified modeling language;Online banking;Control systems","","","","18","IEEE","11 Jan 2018","","","IEEE","IEEE Conferences"
"A Quantitative Analysis Framework for Recurrent Neural Network","X. Du; X. Xie; Y. Li; L. Ma; Y. Liu; J. Zhao","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Kyushu University, Japan; Nanyang Technological University, Singapore; Kyushu University, Japan",2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE),"9 Jan 2020","2019","","","1062","1065","Recurrent neural network (RNN) has achieved great success in processing sequential inputs for applications such as automatic speech recognition, natural language processing and machine translation. However, quality and reliability issues of RNNs make them vulnerable to adversarial attacks and hinder their deployment in real-world applications. In this paper, we propose a quantitative analysis framework - DeepStellar - to pave the way for effective quality and security analysis of software systems powered by RNNs. DeepStellar is generic to handle various RNN architectures, including LSTM and GRU, scalable to work on industrial-grade RNN models, and extensible to develop customized analyzers and tools. We demonstrated that, with DeepStellar, users are able to design efficient test generation tools, and develop effective adversarial sample detectors. We tested the developed applications on three real RNN models, including speech recognition and image classification. DeepStellar outperforms existing approaches three hundred times in generating defect-triggering tests and achieves 97% accuracy in detecting adversarial attacks. A video demonstration which shows the main features of DeepStellar is available at: https://sites.google.com/view/deepstellar/tool-demo.","2643-1572","978-1-7281-2508-4","10.1109/ASE.2019.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952565","recurrent neural netwrod;model abstraction;quantitative analysis;similarity metrics;coverage criteria","Testing;Tools;Training data;Statistical analysis;Recurrent neural networks;Security;Computer architecture","","5","","18","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"An empirical study on reliability modeling for diverse software systems","Xia Cai; M. R. Lyu","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, China",15th International Symposium on Software Reliability Engineering,"24 Jan 2005","2004","","","125","136","Reliability and fault correlation are two main concerns for design diversity, yet empirical data are limited in investigating these two. In previous work, we conducted a software project with real-world application for investigation on software testing and fault tolerance for design diversity. Mutants were generated by injecting one single real fault recorded in the software development phase to the final versions. In this paper, we perform more analysis and experiments on these mutants to evaluate and investigate the reliability features in diverse software systems. We apply our project data on two different reliability models and estimate the reliability bounds for evaluation purpose. We also parameterize fault correlations to predict the reliability of various combinations of versions, and compare three different fault-tolerant software architectures.","1071-9458","0-7695-2215-7","10.1109/ISSRE.2004.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383112","","Software systems;Fault tolerance;Application software;Reliability engineering;Software testing;Aerospace electronics;Computer science;Data engineering;Design engineering;Programming","","3","","21","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"Learning from Open-Source Projects: An Empirical Study on Defect Prediction","Z. He; F. Peters; T. Menzies; Y. Yang","University of Chinese Academy of Sciences, Beijing, China; Lane Department of CS & EE, West Virginia University, Morgantown, USA; Lane Department of CS & EE, West Virginia University, Morgantown, USA; Lab for Internet Software Technology, Institute of Software Chinese Academy of Sciences, Beijing, China",2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement,"12 Dec 2013","2013","","","45","54","The fundamental issue in cross project defect prediction is selecting the most appropriate training data for creating quality defect predictors. Another concern is whether historical data of open-source projects can be used to create quality predictors for proprietary projects from a practical point-of-view. Current studies have proposed statistical approaches to finding these training data, however, thus far no apparent effort has been made to study their success on proprietary data. Also these methods apply brute force techniques which are computationally expensive. In this work we introduce a novel data selection procedure which takes into account the similarities between the distribution of the test and potential training data. Additionally we use feature subset selection to increase the similarity between the test and training sets. Our procedure provides a comparable and scalable means of solving the cross project defect prediction problem for creating quality defect predictors. To evaluate our procedure we conducted empirical studies with comparisons to the within company defect prediction and a relevancy filtering method. We found that our proposed method performs relatively better than the filtering method in terms of both computation cost and prediction performance.","1949-3789","978-0-7695-5056-5","10.1109/ESEM.2013.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681337","software defect prediction;cross-project;instance selection;feature subset selection;data similarity","Open source software;Training data;Predictive models;Data models;Training;Filtering","","89","","33","IEEE","12 Dec 2013","","","IEEE","IEEE Conferences"
"ASSD: Arabic Semantic Similarity Dataset","B. Dahy; M. Farouk; K. Fathy","Department of Computer Science, Faculty of Computers and Information (of Assiut University), Assiut, Egypt; Department of Computer Science, Faculty of Computers and Information (of Assiut University), Assiut, Egypt; Department of Computer Science, Faculty of Computers and Information (of Assiut University), Assiut, Egypt","2021 9th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC)","3 Feb 2022","2021","","","130","134","Finding semantic similarity between sentences is very useful in many NLP applications, such as information retrieval, plagiarism detection, information extraction, and machine translation. Limitations in Arabic language resources have led to a poor level of research in Arabic sentence similarity. This challenge makes identifying semantically similar sentences in Arabic even more difficult. This paper presents a new Arabic dataset for the sentence similarity task. This dataset can be used to help develop sentence similarity approaches. In addition, the main purpose of the created dataset is to evaluate the sentence similarity approach. The dataset has been collected from Wikipedia, an intermediate lexicon, and other WWW resources. This paper gives more details about the processes of collecting data, filtering, preprocessing the pairs of sentences and some statistics about the dataset, for building a benchmark for semantic textual similarity. The dataset is available for future research in this field. The experiment shows that the created dataset is an efficient tool for evaluating semantic similarity approaches for the Arabic language.","","978-1-6654-8292-9","10.1109/JAC-ECC54461.2021.9691424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9691424","Arabic Dataset;Arabic Semantic Similarity;Arabic Sentences Similarity;Arabic Word Similarity","Filtering;Plagiarism;Semantics;Buildings;Encyclopedias;Benchmark testing;Internet","","1","","44","IEEE","3 Feb 2022","","","IEEE","IEEE Conferences"
"Classification of Non-Functional Requirements Using Fuzzy Similarity KNN Based on ISO / IEC 25010","I. M. S. Raharja; D. O. Siahaan","Informatics Department, Institut Teknologi Sepuluh Nopember, Indonesia; Informatics Department, Institut Teknologi Sepuluh Nopember, Indonesia",2019 12th International Conference on Information & Communication Technology and System (ICTS),"30 Sep 2019","2019","","","264","269","In developing software, one of the important role is non-functional requirements. They are often forgotten by the developer, so that it causes adverse effects. For this reason, a non-functional requirement classification method is needed to make it easier for software developers to classify non-functional requirements from requirement document. Most of studies in this area are focusing on single label classification. However, a non-functional requirement sentence can be classified to more than one class. Therefore, a classification technique that support multi-labels was needed. This research proposes a model for classifying non-functional requirements into quality aspects based on ISO/IEe 25010. It uses Fuzzy Similarity KNN (FSKNN) for building the sentence-based classification model. Six difference dataset which is contain 1432 sentence is used in the test. Best accuracy, precision and recall value from classification using FSKNN respectively is 42.8%, 68.1%, and 55.9%.","","978-1-7281-2133-8","10.1109/ICTS.2019.8850944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8850944","Non-Functional Requirements;Classification;FSKNN;ISO /IEC 25010","ISO Standards;Software quality;IEC Standards;Training data;Mathematical model","","9","","17","IEEE","30 Sep 2019","","","IEEE","IEEE Conferences"
"A lightweight software control system for cyber awareness and security","M. Co; C. L. Coleman; J. W. Davidson; S. Ghosh; J. D. Hiser; J. C. Knight; A. Nguyen-Tuong","Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA",2009 2nd International Symposium on Resilient Control Systems,"18 Sep 2009","2009","","","19","24","Designing and building software that is free of defects that can be exploited by malicious adversaries is a difficult task. Despite extensive efforts via the application of formal methods, use of automated software engineering tools, and performing extensive pre-deployment testing, exploitable errors still appear in software. The problem of cyber resilience is further compounded by the growing sophistication of adversaries who can marshal substantial resources to compromise systems. This paper describes a novel, promising approach to improving the resilience of software. The approach is to impose a process-level software control system that continuously monitors an application for signs of attack or failure and responds accordingly. The system uses software dynamic translation to seamlessly insert arbitrary sensors and actuators into an executing binary. The control system employs the sensors to detect attacks and the actuators to effect an appropriate response. Using this approach, several novel monitoring and response systems have been developed. The paper describes our light-weight process-level software control system, our experience using it to increase the resilience of systems, and discusses future research directions for extending and enhancing this powerful approach to achieving cyber awareness and resilience.","","978-1-4244-4853-1","10.1109/ISRCS.2009.5251353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5251353","Virtual Execution;Software Dynamic Translation;Cyber Security;Cyber Awareness;Diversity;Randomization","Software systems;Lighting control;Control systems;Computer security;Resilience;Application software;Process control;Sensor systems;Actuators;Automatic control","","1","","15","IEEE","18 Sep 2009","","","IEEE","IEEE Conferences"
"A semantic similarity retrieval model based on Lucene","Y. Zhou; X. Wu; R. Wang","School of Computer Science and Engineering, Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Engineering, Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Engineering, Guilin University of Electronic Technology, Guilin, China",2014 IEEE 5th International Conference on Software Engineering and Service Science,"23 Oct 2014","2014","","","854","858","In recent years, more and more users hope the search results can meet human's demand when they use a search engine. On the basis of analysis and study on the open source Lucene system architecture, a semantic search system is designed based on the special XML data sources in this paper. What's more, we use the word item location and word semantic to improve the Lucene's search results and conduct experiments to test and verify the retrieval performance, the accuracy of similarity search, the space efficiency of index and the time-efficiency of supporting inquiry: And finally by deploying the Tomcat server to implement our implement system. The experiment results prove that compared with the original Lucene indexing system, our system can improve the indexing efficiency, query efficiency and accuracy.","2327-0594","978-1-4799-3279-5","10.1109/ICSESS.2014.6933700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933700","Lucene;similarity;lexical item location;semantic;XML","Semantics;XML;Search engines;Algorithm design and analysis;Accuracy;Indexing","","2","","9","IEEE","23 Oct 2014","","","IEEE","IEEE Conferences"
"An experimental evaluation of the assumption of independence in multiversion programming","J. C. Knight; N. G. Leveson","Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of California, Irvine, CA, USA",IEEE Transactions on Software Engineering,"26 Sep 2012","1986","SE-12","1","96","109","N-version programming has been proposed as a method of incorporating fault tolerance into software. Multiple versions of a program (i.e. `N') are prepared and executed in parallel. Their outputs are collected and examined by a voter, and, if they are not identical, it is assumed that the majority is correct. This method depends for its reliability improvement on the assumption that programs that have been developed independently will fail independently. An experiment is described in which the fundamental axiom is tested. In all, 27 versions of a program were prepared independently from the same specification at two universities and then subjected to one million tests. The results of the tests revealed that the programs were individually extremely reliable but that the number of tests in which more than one program failed was substantially more than expected. The results of these tests are presented along with an analysis of some of the faults that were found in the programs. Background information on the programmers used is also summarized.","1939-3520","","10.1109/TSE.1986.6312924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6312924","Design diversity;fault-tolerant software;multiversion programming;N-version programming;software reliability","Programming;Software;Educational institutions;Software reliability;NASA","","495","1","","IEEE","26 Sep 2012","","","IEEE","IEEE Journals"
"An experiment in software redundancy with diverse methodologies","J. M. Adams; A. Taha","Department of Computer Science, New Mexico State University, USA; Department of Computer Science, New Mexico State University, USA",Proceedings of the Twenty-Fifth Hawaii International Conference on System Sciences,"6 Aug 2002","1992","ii","","83","90 vol.2","The goal of this experiment was to study the possibility of achieving highly reliable software using an approach to software redundancy with diverse methodologies. The experiment was similar to an experiment done by Knight and Leveson (1986) except that two different programming methodologies were used. Data from the experiment were analyzed using the simple statistical model for multiversion programming developed by Knight and Leveson and the more sophisticated statistical model of Eckhardt and Lee (1985), to see if results were consistent with the previous results for a single methodology. A still more sophisticated statistical model due to Littlewood and Miller (1989) was used to assess the effectiveness of using diverse methodologies.<>","","0-8186-2420-5","10.1109/HICSS.1992.183280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=183280","","Redundancy;Software safety;Computer languages;Software algorithms;Logic programming;Programming profession;Testing;Reflection;Computer science;Algorithm design and analysis","","4","","7","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Polarization angle diversity and new digital software radio architecture","M. Aono; K. Takei","Department of Energy management system, Hitachi Research Laboratory, Hitachi-shi, Ibaraki-ken, Japan; Department of Energy management system, Hitachi Research Laboratory, Hitachi-shi, Ibaraki-ken, Japan","2015 International Conference on Circuits, Power and Computing Technologies [ICCPCT-2015]","16 Jul 2015","2015","","","1","3","We are developing new radio architecture for applying a wireless communication system to controlling and monitoring systems in industrial infrastructure systems. Using polarization angle diversity, we can achieve reliable communication in a non line-of-sight situation. To realize polarization angle diversity, we use a rotating polarized radio wave. When we use polarization angle diversity, we need to control radio frequencies more easily. New software radio architecture create radio frequency in a digital circuit directly. It has a possibility to control a rotating polarization radio wave. And by experiment, I show a result of basic communication test and confirm its functions.","","978-1-4799-7075-9","10.1109/ICCPCT.2015.7159299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7159299","M2M radio;block coding;polarization diversity","Computer architecture;Wireless communication;Digital circuits;Software radio;Hardware;Field programmable gate arrays;Mixers","","2","","3","IEEE","16 Jul 2015","","","IEEE","IEEE Conferences"
"Bug Detection Using Particle Swarm Optimization with Search Space Reduction","A. Reungsinkonkarn; P. Apirukvorapinit","Department of Computer Information System, Assumption University; Faculty of Information Technology, Thai-Nichi Institute of Technology","2015 6th International Conference on Intelligent Systems, Modelling and Simulation","29 Oct 2015","2015","","","53","57","A bug detection tool is an important tool in software engineering development. Many research papers have proposed techniques for detecting software bug, but there are certain semantic bugs that are not easy to detect. In our views, a bug can occur from incorrect logics that when a program is executed with a particular input, the program will behave in unexpected ways. In this paper, we propose a method and tool for software bugs detection by finding such input that causes an unexpected output guided by the fitness function. The method uses a Hierarchical Similarity Measurement Model (HSM) to help create the fitness function to examine a program behavior. Its tool uses Particle Swarm Optimization (PSO) with Search Space Reduction (SSR) to manipulate input by contracting and eliminating unfavorable areas of input search space. The programs under experiment were selected from four different domains such as financial, decision support system, algorithms and machine learning. The experimental result shows a significant percentage of success rate up to 93% in bug detection, compared to an estimated success rate of 28% without SSR.","2166-0670","978-1-4799-8258-5","10.1109/ISMS.2015.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7311209","Bug Detection;Fitness Function;Hierarchical Similarity Measurement Model (HSM);Particle Swarm Optimization (PSO);Optimization","Computer bugs;Software;Complexity theory;Particle swarm optimization;Computational modeling;Atmospheric measurements;Particle measurements","","6","","15","IEEE","29 Oct 2015","","","IEEE","IEEE Conferences"
"The unique reference NCSLOC metric","S. D. Crouch; D. B. Simmons","Texas A and M University, USA; Texas A and M University, USA",Proceedings. Twenty-Third Annual International Computer Software and Applications Conference (Cat. No.99CB37032),"6 Aug 2002","1999","","","316","317","We propose that by utilizing certain metrics and gathering operating system information it can be determined if a file is a version or duplicate of another file on the system. In a software development environment, knowing what files are versions of other files would be beneficial in many areas. It would help a manager estimate the amount of code that needs to be modified in a reengineering project. When comparing files to a software reuse library, the amount of reuse can be measured. If a survey is being done on the entire contents of the computer's file system, then all code for a variety of programming languages can be located and the amount of new and reused code can be quantified. The authors present a description of the metrics, how they are collected, and the results of processing a large number of files using the metrics.","0730-3157","0-7695-0368-3","10.1109/CMPSAC.1999.812726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=812726","","Computer networks;Distributed computing;Software performance;Operating systems;Project management;Libraries;File systems;Computer languages;White spaces;Testing","","","","2","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"A Source Code Similarity System for Plagiarism Detection","Z. Đurić; D. Gašević",NA; NA,The Computer Journal,"18 Jan 2018","2013","56","1","70","86","Source code plagiarism is an easy to do task, but very difficult to detect without proper tool support. Various source code similarity detection systems have been developed to help detect source code plagiarism. Those systems need to recognize a number of lexical and structural source code modifications. For example, by some structural modifications (e.g. modification of control structures, modification of data structures or structural redesign of source code) the source code can be changed in such a way that it almost looks genuine. Most of the existing source code similarity detection systems can be confused when these structural modifications have been applied to the original source code. To be considered effective, a source code similarity detection system must address these issues. To address them, we designed and developed the source code similarity system for plagiarism detection. To demonstrate that the proposed system has the desired effectiveness, we performed a well-known conformism test. The proposed system showed promising results as compared with the JPlag system in detecting source code similarity when various lexical or structural modifications are applied to plagiarized code. As a confirmation of these results, an independent samples t-test revealed that there was a statistically significant difference between average values of F-measures for the test sets that we used and for the experiments that we have done in the practically usable range of cut-off threshold values of 35–70%.","1460-2067","","10.1093/comjnl/bxs018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8226597","algorithms;plagiarism;similarity detection;software;source code","","","21","","","","18 Jan 2018","","","OUP","OUP Journals"
"Forecasting e-Journal Unique Visitors using Smoothed Long Short-Term Memory","A. P. Wibawa; R. R. Ula; A. B. P. Utama; M. Y. Chuttur; A. Pranolo; Haviluddin","Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Software and Information Systems, University of Mauritius, Reduit, Mauritius; Department of Informatics, Universitas Ahmad Dahlan, Yogyakarta, Indonesia; Department of Computer Science, Universitas Mulawarman, Samarinda, Indonesia","2021 7th International Conference on Electrical, Electronics and Information Engineering (ICEEIE)","30 Nov 2021","2021","","","609","613","The number of unique visitors every day can be used as a benchmark to assess the success of an electronic journal. Unique visitors are visitors who use one IP in a certain period. With an increasing number of unique visitors every day, it can be inferred that scientific periodicals are increasingly in demand by the wider community, affecting the breadth of distribution and speeding up the journal accreditation system. Therefore, a model that can predict the number of unique visitors in electronic journals in the future can be beneficial for journal administrators. This paper evaluates Long Short-Term Memory (LSTM) performance when predicting the next day’s (T+1) time series for the number of unique visitors to an e-Journal website. The unique visitor data sample used was from January 1, 2018, to December 31, 2018. The distribution of data testing and training used was 80% and 20%. The data quality has been improved by smoothing the input data using exponential, mean, and median smoothing. The evaluation results show that the architecture with the best performance is model 2, namely the model mean + LSTM architecture 1-5-1 with a learning rate of 0.2 and a MAPE value of 0.08098. Therefore, we conclude that data smoothing with mean smoothing can improve Long Short-Term Memory performance for unique website visitor forecasting.","","978-1-6654-3232-0","10.1109/ICEEIE52663.2021.9616628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616628","forecasting;unique visitors;e-journal;long short-term memory;data smoothing","Training;Smoothing methods;Data integrity;Time series analysis;Neural networks;Predictive models;Benchmark testing","","","","25","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Automated software diversity for hardware fault detection","G. Gaiswinkler; A. Gerstinger","Elektrobit Austria GmbH, Vienna, Austria; Institute of Computer Technology, University of Technology, Vienna, Vienna, Austria",2009 IEEE Conference on Emerging Technologies & Factory Automation,"4 Dec 2009","2009","","","1","7","Software in dependable systems must be able to tolerate or detect faults in the underlying infrastructure, such as the hardware. This paper presents a cost efficient automated method how register faults in the microprocessor can be detected during execution. This is done with the help of using compiler options to generate diverse binaries. The efficacy of this approach has been analyzed with the help of a CPU emulator, which was modified exactly for this purpose. The promising results show, that by using this approach, it is possible to automatically detect the vast majority of the injected register faults. In our simulations, two diverse versions have-despite of experiencing the same fault during execution - never delivered the same incorrect result, so we could detect all injected faults.","1946-0759","978-1-4244-2727-7","10.1109/ETFA.2009.5347167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5347167","","Hardware;Fault detection;Testing;Program processors;Application software;Microprocessors;Registers;Optimizing compilers;Optimization methods;Software systems","","10","","10","IEEE","4 Dec 2009","","","IEEE","IEEE Conferences"
"Alternatives to achieve software diversity in common channel signaling networks","N. L. Hung; A. R. Jacob; S. E. Makris","Bellcores Raritan River Software, USA; Bellcores Navesink Research and Engineering Center, Red Bank, NJ, USA; Bellcores Navesink Research and Engineering Center, Red Bank, NJ, USA",IEEE Journal on Selected Areas in Communications,"6 Aug 2002","1994","12","3","533","538","With the increasing amount of software deployed in the common channel signaling networks (CCSNs) and its increasing complexity, software and its failure effects on the CCSNs have become a major concern. The software error contributing to the 1991 CCSN outages, which affected a large number of customer lines, has underscored the vulnerability of the CCSNs to software failures. The current mated pair signaling transfer point (STP) implementations in the CCSNs, with both STPs from the same supplier having the same software, make this architecture susceptible to common-cause software failure modes that might result in failures of both STPs simultaneously. To address these concerns, ways have been considered to achieve software diversity in the CCSNs by ensuring software failure mode independence among network nodes. Four potential alternatives are identified here: (i) multiple software developments in STPs; (ii) different software generics for backup; (iii) mixed-supplier STP pairs; and (iv) E-link sets to different supplier STPs. The advantages and disadvantages of these alternatives to ensure software diversity are examined in this paper and should be weighed by individual telecommunications network providers. concerns expressed in this paper are not exhaustive listings, but rather catalysts for further studies and discussions.<>","1558-0008","","10.1109/49.285295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285295","","Intelligent networks;Software testing;Fault tolerance;Software reliability;Jacobian matrices;Computer architecture;Programming;Telecommunication services;Software engineering;Guidelines","","4","1","8","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"$\Delta$ΔBreakpad: Diversified Binary Crash Reporting","B. Abrath; B. Coppens; M. Mishra; J. Van den Broeck; B. De Sutter","Computer Systems Lab, Ghent University, Ghent, Belgium; Computer Systems Lab, Ghent University, Ghent, Belgium; Computer Systems Lab, Ghent University, Ghent, Belgium; Computer Systems Lab, Ghent University, Ghent, Belgium; Electronics and Information Systems, Ghent University, Gent, Belgium",IEEE Transactions on Dependable and Secure Computing,"1 Jul 2020","2020","17","4","841","856","This paper introduces ΔBreakpad. It extends the Breakpad crash reporting system to handle software diversity effectively and efficiently by replicating and patching the debug information of diversified software versions. Simple adaptations to existing open source compiler tools are presented that on the one hand introduce significant amounts of diversification in the code and stack layout of ARMv7 binaries to mitigate the widespread deployment of code injection and code reuse attacks, while on the other hand still supporting accurate crash reporting. An evaluation on SPEC2006 benchmarks demonstrates that the corresponding computational, storage, and communication overheads are small.","1941-0018","","10.1109/TDSC.2018.2823751","Innovation by Science and Technology in Flanders(grant numbers:3G013013); European Union Seventh Framework Programme(grant numbers:609734); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8332984","Software security;software diversity;crash reporting","Computer crashes;Software;Servers;Tools;Benchmark testing;Google;Registers","","1","","23","IEEE","6 Apr 2018","","","IEEE","IEEE Journals"
"A scalable method to measure similarity between two EDA-generated timing graphs","J. L. M. Lee","Software Engineering, Altera Corporation Malaysia, Penang, Malaysia 11900","2015 International Conference on Computer, Communications, and Control Technology (I4CT)","27 Aug 2015","2015","","","44","48","This is a case study of the use of graph similarity to correlate the timing models obtained from two electronic design automation (EDA) static timing analysis tools (Altera's Quartus II software versus Synopsys PrimeTime). Timing models are data modelled from the post-layout netlist and parasitics extraction. The field programmable gate array's (FPGA) timing model is used by customers to optimize their designs. As mask designs are constantly revisioned, new timing models are generated and thus the Quartus II software must constantly be updated with the new models. A verification needs to be carried out at every new iteration of timing models to ensure the regression testing of timing models is stable and reliable. This case study discusses one such verification methodology. A timing graph consists of nodes and edges. Edges have weights attached to them that can denote some characteristic, such as timing arc delays in this case. Out of the many graph similarity algorithms in the field, the most cited are edit distance similarity, neighbourhood matching, spectral matching and belief propagation. Neighbourhood matching, which was used in this study, is a point-to-point matching of a node's similarity score based on its neighbourhood's similarity score. The timing graph from the Quartus II software was generated with an in-house Tcl scripting language applications programming interface. The timing graph from PrimeTime was generated from its timing reports. An algorithm was postulated to calculate graph similarity based on edge weights of the graphs. The algorithm compared both graphs and produced a matrix of graph similarity scores for all paired nodes. The algorithm was tested on five data paths taken from the two EDA tools under evaluation. Our results showed good correlation between intuitive similarity measure and our algorithmic calculation.","","978-1-4799-7952-3","10.1109/I4CT.2015.7219534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219534","timing graph;point-to-point matching;graph similarity;FPGA timing model","Delays;Field programmable gate arrays;Software;Data models;Symmetric matrices;Software algorithms","","","","10","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Network Intrusion Detection Using Diversity-Based Centroid Mechanism","M. S. Gondal; A. J. Malik; F. A. Khan","Department of Computer Science, National University of Computer and Emerging Sciences, Islamabad, Pakistan; Department of Software Engineering, Foundation University, Rawalpindi, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Islamabad, Pakistan",2015 12th International Conference on Information Technology - New Generations,"1 Jun 2015","2015","","","224","228","Threats to computer networks are numerous and potentially devastating. Intrusion detection techniques provide protection to our data and track unauthorized access. Many algorithms and techniques have been proposed to improve the accuracy and minimize the false positive rate of the intrusion detection system (IDS). Statistical techniques, evolutionary techniques, and data mining techniques have also been used for this purpose. In this paper, we use a centroid-based technique for network intrusion detection in which the centroid is constructed on the basis of diversity. Diversity of a point is the sum of the distances from a point to all other points in a cluster. The point having minimum diversity is chosen as a centroid. The performance of diversity-based centroid shows significant improvement in the classification of intrusions. Experimental results on the KDDCup99 dataset demonstrate that the proposed method shows excellent performance in terms of accuracy, detection rate, and false positive rate.","","978-1-4799-8828-0","10.1109/ITNG.2015.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113477","Intrusion Detection System (IDS);Centroid;Diversity;Classification","Intrusion detection;Accuracy;Probes;Testing;Training;Classification algorithms","","8","","17","IEEE","1 Jun 2015","","","IEEE","IEEE Conferences"
"Generic Side-channel Distinguisher Based on Kolmogorov-Smirnov Test: Explicit Construction and Practical Evaluation","L. Jiye; Z. Yongbin; Y. Shuguo; F. Dengguo","State Key Laboratory of Information Security, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Software, Chinese Academy of Sciences, Beijing, China",Chinese Journal of Electronics,"31 Jul 2023","2012","21","3","547","553","Construction and evaluation of efficient distinguishers with broad generality is one fundamental problem in the area of side-channel cryptanalysis. Due to their capabilities to deal with general correlations, MIA-like distinguishers have received wide attention from academia. In this paper, we conduct a comprehensive comparison investigation of existing MIA-like distinguishers, and then propose a new generic side-channel distinguisher based on partial Kolmogorov-Smirnov test, namely PKS distinguisher. Theoretical analysis and experimental attacks unanimously justify that PKS distinguisher works remarkably well with both linear and non-linear leakage models. Specifically, PKS distinguisher has obvious advantages over existing MIA-like distinguishers in terms of both success rate and guessing entropy. Additionally, lower computational complexity of PKS distinguisher further shows its better applicability than MIA-like distinguishers.","2075-5597","","","National Natural Science Foundation of China(grant numbers:61073178); Natural Science Foundation of Beijing(grant numbers:4112064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197402","Side-channel cryptanalysis;Power analysis attack;Distinguisher;Distribution similarity;Kolmogorov-Smirnov test","Analytical models;Costs;Correlation;Computational modeling;Entropy;Computational complexity;Sorting","","","","16","","31 Jul 2023","","","CIE","CIE Journals"
"Diversity-by-Design for Dependable and Secure Cyber-Physical Systems: A Survey","Q. Zhang; A. Z. Mohammed; Z. Wan; J. -H. Cho; T. J. Moore","Department of Computer Science, Virginia Tech, Falls Church, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA, USA; Department of Computer Science, Virginia Tech, Falls Church, VA, USA; Department of Computer Science, Virginia Tech, Falls Church, VA, USA; Network Science Division, U.S. Army Research Laboratory, Adelphi, MD, USA",IEEE Transactions on Network and Service Management,"10 Mar 2022","2022","19","1","706","728","Diversity-based security approaches have been studied for several decades since the 1970s. The concept of diversity-by-design emerged in the 1980s. Since then, diversity-based system design research has been explored to provide more secure and dependable services in cyber-physical systems (CPSs). In this work, we are particularly interested in providing an in-depth, comprehensive survey of existing diversity-based approaches, their insights, and associated future work directions for building secure and dependable CPSs. This will allow us to provide promising ways of providing quality network and services based on key diversity-by-design principles for those who want to conduct research on developing secure and dependable CPSs using diversity as a system design feature. This survey paper mainly provides: (i) The common concept of diversity based on its multidisciplinary nature along with the historical evolution of the concept of diversity-by-design for providing secure and dependable services; (ii) the key diversity-by-design principles; (iii) the key benefits and caveats of using the diversity-by-design; (iv) the main concerns of CPS environments utilizing the diversity-by-design; (v) an extensive survey and discussions of existing diversity-based approaches based on five different classifications; (vi) the types of attacks considered by diversity-based approaches; (vii) the overall trends of evaluation methodologies used for diversity-based approaches, in terms of metrics, datasets, and testbeds; and (viii) the insights, lessons, and gaps identified from this extensive survey and future work directions.","1932-4537","","10.1109/TNSM.2021.3091391","Army Research Office(grant numbers:W91NF-20-2-0140); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462505","Diversity-by-design;software diversity;heterogeneity;security;dependability;cyber-physical systems","Security;Software;Measurement;Viruses (medical);Software as a service;Programming;Hardware","","","","182","IEEE","22 Jun 2021","","","IEEE","IEEE Journals"
"Sentence similarity detection in Malayalam language using cosine similarity","P. P. Gokul; B. K. Akhil; K. K. M. Shiva","Maryland Power Electronics Laboratory, Electrical and Computer Engineering Department, Institute for Systems Research, University of Maryland, College Park, MD, USA; Maryland Power Electronics Laboratory, Electrical and Computer Engineering Department, Institute for Systems Research, University of Maryland, College Park, MD, USA; NA","2017 2nd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","15 Jan 2018","2017","","","221","225","Identifying paraphrase in Malayalam language is difficult task because it is a highly agglutinative language and the linguistic structure in Malayalam language is complex compared to other languages. Here we use individual words synonyms to find the similarity between two sentences. In this paper, cosine similarity method is used to find the paraphrases in Malayalam language. In this paper we present the observations on sentence similarity between two Malayalam sentences using cosine similarity method, we used test data of 900 and 1400 sentence pairs of FIRE 2016 Malayalam corpus that used in two iterations to present and obtained an accuracy of 0.8 and 0.59.","","978-1-5090-3704-9","10.1109/RTEICT.2017.8256590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8256590","Natural Language processing;Paraphrase detection;Semantic similarity;Cosine Similarity;jaccard Similarity","Tagging;Semantics;Conferences;Market research;Communications technology;Training","","15","","12","IEEE","15 Jan 2018","","","IEEE","IEEE Conferences"
"Challenges of the Dynamic Detection of Functionally Similar Code Fragments","F. Deissenboeck; L. Heinemann; B. Hummel; S. Wagner","Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; University of Stuttgart, Germany",2012 16th European Conference on Software Maintenance and Reengineering,"5 Apr 2012","2012","","","299","308","Classic clone detection approaches are hardly capable of finding redundant code that has been developed independently, i.e., is not the result of copy&paste. To automatically detect such functionally similar code of independent origin, we experimented with a dynamic detection approach that applies random testing to selected chunks of code similar to Jiang&Su's approach. We found that such an approach faces several limitations in its application to diverse Java systems. This paper details on our insights regarding these challenges of dynamic detection of functionally similar code fragments. Our findings support a substantiated discussion on detection approaches and serve as a starting point for future research.","1534-5351","978-0-7695-4666-7","10.1109/CSMR.2012.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178896","dynamic analysis;functional similarity","Cloning;Java;Pipelines;Software systems;Measurement;Testing;Detectors","","20","","10","IEEE","5 Apr 2012","","","IEEE","IEEE Conferences"
"Towards Developer-Centered Secure Coding Training","V. Pikulin; D. Kubo; K. Nissanka; S. Bandara; M. A. Shamsiemon; A. Yasmin; A. Jayatilaka; A. Madugalla; T. Kanij","Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Centre for Research on Engineering Software Technologies (CREST), The University of Adelaide, Adelaide, Australia; Department of Software Systems and Cybersecurity, Monash University, Melbourne, Australia; Department of Software Systems and Cybersecurity, Monash University, Melbourne, Australia",2023 38th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW),"2 Nov 2023","2023","","","24","31","Software security continues to be a matter of concern for both end-users and developers, with the cost of potential lapses expected to become larger as software plays a larger role in society. Despite investments in secure coding training programmes, organisations are not achieving the expected success rate. An often overlooked reason for this among many others is that current training programmes are not tailored to consider the diversity among software developers as it relates to human aspects. In this research, data was gathered from software developers of various backgrounds on their perceptions of secure coding training, their expectations from and challenges with such a training program. The findings suggest that developers with personality traits of agreeableness tend to ignore secure coding standards. Additionally, developers with higher work experience tend to demand storage management, responsible use of privileges, security and privacy laws and testing topics to be included in the secure coding training. Furthermore, in terms of training structure, developers with higher openness tend to demand hands-on training to be included. The study's findings seek to inform future researchers and organisations on factors to consider when designing adaptive secure coding programs that would address the needs of developers from different backgrounds.","2151-0849","979-8-3503-3032-8","10.1109/ASEW60602.2023.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298735","Secure Coding;Programming;Cybersecurity;Training;Developers;Diversity;Human Aspects","Training;Privacy;Storage management;Encoding;Software;Security;Standards","","1","","21","IEEE","2 Nov 2023","","","IEEE","IEEE Conferences"
"Using Program Data-State Diversity in Test Data Search","M. Alshraideh; L. Bottaci","Department of Computer Science, University of Hull, Hull, UK; Department of Computer Science, University of Hull, Hull, UK",Testing: Academic & Industrial Conference - Practice And Research Techniques (TAIC PART'06),"16 Oct 2006","2006","","","107","114","Search-based automatic software test data generation for structural testing depends on the instrumentation of the test goal to construct a many-valued function which is then optimised. The method encounters difficulty when the search is in a region in which the function is not able to discriminate between different candidate test cases because it returns a constant value. A typical example of this problem arises in the instrumentation of branch predicates that depend on the value of a boolean-valued (flag) variable. Existing transformation techniques can solve many cases of the problem but there are situations for which transformation techniques are inadequate. This paper presents a technique for directing the search when the function that instruments the test goal is not able to discriminate candidate test inputs. The new technique depends on introducing program data-state diversity as an additional search goal. The search is guided by a new evaluation (cost) function made up of two parts, one depends on the conventional instrumentation of the test goal, the other depends on the diversity of the data-states produced during execution of the program under test. The method is demonstrated for a number of example programs for which existing methods are inadequate.","","0-7695-2672-1","10.1109/TAIC-PART.2006.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1691676","","Automatic testing;Instruments;Cost function;Software testing;Computer science;Search methods;Genetic algorithms","","1","","18","IEEE","16 Oct 2006","","","IEEE","IEEE Conferences"
"Cloned Buggy Code Detection in Practice Using Normalized Compression Distance","T. Ishio; N. Maeda; K. Shibuya; K. Inoue","Nara Institute of Science and Technology, Nara, Japan; NEC Corporation, Tokyo, Japan; NEC Corporation, Tokyo, Japan; Osaka University, Osaka, Japan",2018 IEEE International Conference on Software Maintenance and Evolution (ICSME),"11 Nov 2018","2018","","","591","594","Software developers often write similar source code fragments in a software product. Since such code fragments may include the same mistake, developers have to inspect code clones if they found a bug in their code. In this study, we developed a tool to detect clones of a faulty code fragment for a software company, since existing code clone detection tools do not fit the requirements of the company. The tool employs Normalized Compression Distance for source code comparison, because its definition is understandable for developers, and also it is easy to support multiple programming languages. We conducted two experiments using an existing research dataset and actual examples. Based on the evidence, the tool has been deployed in several projects in the company.","2576-3148","978-1-5386-7870-1","10.1109/ICSME.2018.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530071","Code clone detection;Source code similarity;Source code search;Bug fix;Development tool","Tools;Cloning;Companies;Computer bugs;Benchmark testing;Microsoft Windows","","7","","18","IEEE","11 Nov 2018","","","IEEE","IEEE Conferences"
"Sparse Measurement Algorithm Execution Time Prediction on Heterogeneous Edge Devices for Early Stage Software-Hardware Matching","B. Rupprecht; B. Vogel-Heuser; J. Möhrle; D. Hujo; Y. Wang","Institute of Automation and Information Systems, School of Engineering and Design Technical, Technical University of Munich; Institute of Automation and Information Systems, School of Engineering and Design Technical, Technical University of Munich; Institute of Automation and Information Systems, School of Engineering and Design Technical, Technical University of Munich; Institute of Automation and Information Systems, School of Engineering and Design Technical, Technical University of Munich; Institute of Automation and Information Systems, School of Engineering and Design Technical, Technical University of Munich",2024 IEEE 7th International Conference on Industrial Cyber-Physical Systems (ICPS),"26 Aug 2024","2024","","","1","8","The design and implementation of edge computing solutions needs elaborate knowledge about the inter-dependencies of software and hardware, which are also often developed parallel to meet performance requirements like time constraints. However, the suitability of hardware to execute a given algorithm and vice versa is often assessed by time-consuming trial-and-error approaches. For algorithm assessment, the execution time is crucial. However, existing execution time estimation approaches usually rely on either thorough timing models for the underlying hardware or vast amounts of measurements. Consequently, these approaches are not feasible for an early design stage, where an assessment with limited effort is crucial. Thus, this paper tries to overcome those limitations by comparing a parametric and a non-parametric execution time prediction approach suitable for an early design stage. The evaluation with four edge devices out of heterogeneous categories using measured data is a first attempt at generalizability. A selection of four different algorithms applicable in smart manufacturing and benchmarking ensures the approaches’ broad applicability. The parametric and non-parametric model comparison shows the trade-off between source code analysis and performing measurements.","2769-3899","979-8-3503-6301-2","10.1109/ICPS59941.2024.10640034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10640034","Execution time modeling;execution time prediction;performance benchmarking;software-hardware matching;edge devices","Source coding;Software algorithms;Benchmark testing;Predictive models;Prediction algorithms;Hardware;Software","","","","20","IEEE","26 Aug 2024","","","IEEE","IEEE Conferences"
"Best Parameter Selection Of Rabin-Karp Algorithm In Detecting Document Similarity","A. D. Hartanto; A. Syaputra; Y. Pristyanto","Faculty of Computer Science, Universitas Amikom Yogyakarta, Yogyakarta, Indonesia; Faculty of Computer Science, Universitas Amikom Yogyakarta, Yogyakarta, Indonesia; Faculty of Computer Science, Universitas Amikom Yogyakarta, Yogyakarta, Indonesia",2019 International Conference on Information and Communications Technology (ICOIACT),"23 Dec 2019","2019","","","457","461","Text mining is usually used to detect document similarities and plagiarism. The field of education is one area that is prone to plagiarism. Plagiarism can kill someone's creativity because this action does not require energy and does not have to think hard. Therefore, the act of plagiarism must be prevented from causing harm to various parties. By using matching strings on documents, it can be used to detect plagiarism. One method that can be used is Rabin-Karp Algorithm, but in several studies that have been done the researchers did not test the k-gram value and database value, in theory, this would affect the performance of the Rabin-Karp Algorithm. Therefore in this study, the selection of k-gram values and prime bases was conducted to determine the effect on the performance of the Rabin-Karp Algorithm. The results showed that the selection of gram values and prime bases affected the processing time in testing the data and the similarity values of the documents being tested. In this study the value of k = 5 on k-gram has the fastest time for the testing process, both testing with multiple data 25 and testing the data for all amounts of data the number is 300.","","978-1-7281-1655-6","10.1109/ICOIACT46704.2019.8938458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938458","Text Mining;Rabin-Karp;Parameter Selection;Document Similarity","Plagiarism;Testing;Computer science;Text mining;Information and communication technology;Flowcharts;Filtering","","6","","15","IEEE","23 Dec 2019","","","IEEE","IEEE Conferences"
"Collaborative Filtering Method with the use of Production Rules","A. S. Mohammed; Y. Meleshko; S. Balaji B; S. Serhii","Dept of Computer Engineering, Lebanese French University, Salahaddin University, Erbil, KR-Iraq; Dept of Cyber Security & Software, Central Ukrainian National Technical University, Kropyvnytskyi, Ukraine; Dept of Information Technology, Lebanese French University, Erbil, KR-Iraq; Dept of Computer Science and Programming, National Technical University (Kharkiv Polytechnic Institute), Ukraine",2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE),"20 Feb 2020","2019","","","387","391","this paper proposes a new collaborative filtering method with the calculation of unknown similarity coefficients between users via the application of production rules, which aims to improve the work quality of recommendation systems, to develop of production rules for the developed system. The methods used are: graph theory, the theory of algorithms, mathematical statistics, object-oriented programming, and fuzzy logic. The developed systems are new collaborative filtering method with the definition of unknown similarity coefficients between users through the application of production rules was developed, software for the implementation and testing of this method was developed, experiments on the developed software was conducted. The production rules to determine unknown similarity coefficients in recommendation systems was proposed. The new method of collaborative filtering with the application of production rules has been developed to find unknown similarity coefficients between users that may be possibly used to improve the work quality of the recommendation system. The conducted experiments showed that the developed method enhances the quality indicators of the recommendation system, such as item space coverage and the total number of predicted preferences of users.","","978-1-7281-3778-0","10.1109/ICCIKE47802.2019.9004257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004257","recommendation systems;production rules;collaborative filtering;similarity coefficients","Collaboration;Production;Information filters;Computational intelligence;Software","","1","","13","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"Building software engineering teams that work: The impact of dominance on group conflict and Performance outcomes","T. L. Lewis; W. J. Smith",Radford University; Virginia Technology,2008 38th Annual Frontiers in Education Conference,"22 Dec 2008","2008","","","S3H-1","S3H-6","This project is designed to build on theories of team composition and proposes an innovative way of assigning students to teams. Currently, professors are using a variety of team assignment techniques to form software engineering teams. This research believes that a contributing factor to the undesired outcomes (i.e., low performing teams and high levels of conflict) of software engineering teams is that the teams were not formed using ldquorelevant and salientrdquo criteria. To address the relevance issue, we test the impact of problem solving preferences (a sub-set of the MBTI scale) on group conflict and performance. We then test the extent to which the numerical dominance (i.e., salience) of problem solving styles influences conflict and performance. It was found that dominance of problem solving styles is related to negative team outcomes. We conclude by discussing ways in which instructors and team members may minimize negative team outcomes when there is no choice other than forming a team with one dominant problem solving preference.","2377-634X","978-1-4244-1969-2","10.1109/FIE.2008.4720498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4720498","MBTI;Numerical Dominance;Problem Solving Style;Team Diversity;Team Dynamics","Software engineering;Problem-solving;Testing;Demography;Buildings;Teamwork;Programming;Software design;Information technology;Technological innovation","","7","","25","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"DistSim - Scalable Distributed in-Memory Semantic Similarity Estimation for RDF Knowledge Graphs","C. F. Draschner; J. Lehmann; H. Jabeen","University of Bonn, Bonn, Germany; University of Bonn, Bonn, Germany; University of Cologne, Cologne, Germany",2021 IEEE 15th International Conference on Semantic Computing (ICSC),"3 Mar 2021","2021","","","333","336","In this paper, we present DistSim, a Scalable Distributed in-Memory Semantic Similarity Estimation framework for Knowledge Graphs. DistSim provides a multitude of state-of-the-art similarity estimators. We have developed the Similarity Estimation Pipeline by combining generic software modules. For large scale RDF data, DistSim proposes MinHash with locality sensitivity hashing to achieve better scalability over all-pair similarity estimations. The modules of DistSim can be set up using a multitude of (hyper)-parameters allowing to adjust the tradeoff between information taken into account, and processing time. Furthermore, the output of the Similarity Estimation Pipeline is native RDF. DistSim is integrated into the SANSA stack, documented in scala-docs, and covered by unit tests. Additionally, the variables and provided methods follow the Apache Spark MLlib name-space conventions. The performance of DistSim was tested over a distributed cluster, for the dimensions of data set size and processing power versus processing time, which shows the scalability of DistSim w.r.t. increasing data set sizes and processing power. DistSim is already in use for solving several RDF data analytics related use cases. Additionally, DistSim is available and integrated into the open-source GitHub project SANSA.","2325-6516","978-1-7281-8899-7","10.1109/ICSC50631.2021.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364473","Distributed RDF Analytics;Scalable Semantic Similarity Estimation;Knowledge Graph Data Analytics Pipeline;SANSA","Scalability;Semantics;Pipelines;Estimation;Distributed databases;Resource description framework;Software development management","","3","","21","IEEE","3 Mar 2021","","","IEEE","IEEE Conferences"
"Superpixel-level sparse representation-based classification for hyperspectral imagery","S. Jia; B. Deng; X. Jia","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong, CN; Coll. of Comput. Sci. & Software Eng., Shenzhen University, Shenzhen, Guangdong, CN; College of Computer Science and Software Engineering, Shenzhen University, Sydney, NSW, AU",2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS),"3 Nov 2016","2016","","","3302","3305","Sparse representation-based classification (SRC) assigns a test sample to the class with minimal representation error via a sparse linear combination of all the training samples, which has successfully been applied to hyperspectral imagery (HSI). Meanwhile, spatial information, that means the adjacent pixels belong to the same class with a high probability, is a valuable complement to the spectral information. In this paper, we propose an efficient method for HSI classification by using superpixel based sparse representation-based classification (SP-SRC). One superpixel can be regarded as a small region consisting of a number of pixels with similar spectral characteristics. The novel method utilizes superpixel to exploit spatial information which can greatly improve classification accuracy. Specifically, SRC is firstly used to classifier the HSI. Then an efficient segmentation algorithm is adopted to divide the HSI into disjoint superpixels. Finally, each superpixel is used to fuse the results of the SRC classifier. Experimental results on the widely-used Indian Pines hyperspectral imagery have shown that the proposed SP-SRC approach could achieve better performance than the pixel-wise SRC method.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729854","Hyperspectral imagery;superpixel;sparse representation-based classification","Hyperspectral imaging;Training;Image segmentation;Erbium;Algorithm design and analysis;Feature extraction","","5","","15","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"Incremental sparse linear regression algorithms for face recognition","X. Liu; J. Liu; X. Liu; Z. Kong; X. Yang","School of Mathematics, South China University of Technology, Guangzhou, P.R. China; The AutoNavi Alibaba Group, Beijing, P.R. China; State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, P.R. China; Department of Software Engineering, South China University of Technology, Panyu, P.R. China; Department of Software Engineering, South China University of Technology, Panyu, P.R. China",2018 Tenth International Conference on Advanced Computational Intelligence (ICACI),"11 Jun 2018","2018","","","69","74","Recently, a face identification algorithm naming Linear Regression Classification(LRC) is proposed, which uses a basic idea that data from the same class lie on a linear subspace and achieves better performance compared to the benchmark algorithms. However, solution of LRC involves computing the inverse matrix which is a time consuming thing for larger datasets. To overcome this limitation, in this study, considering that sparsity has good discriminative nature for classifying, we first propose an incremental sparse linear regression classification algorithm (ISLRC) for face recognition. When dealing with larger datasets by incremental learning, with the new training samples coming, ISLRC has a simple analytical solution only involving matrix multiplication and leads to a high running efficiency. Then, motivated by the facts that face images are naturally tensors and a compact and meaningful representations of tensor data can be obtained by multilinear principle component analysis (MPCA), we extend ISLRC to tensor patterns and propose an MPCA based ISLRC algorithm (MPCA-ISLRC). Experimental results on face recognition show that in most cases, ISLRC and MPCA-ISLRC are superior to the benchmark methods in test accuracy and training time for larger face image datasets.","","978-1-5386-4362-4","10.1109/ICACI.2018.8377583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377583","Linear Regression Classification;Sparse Representation;Incremental Learning;Face Recognition;Tensor","Classification algorithms;Tensile stress;Training;Face;Linear regression;Face recognition;Training data","","2","","17","IEEE","11 Jun 2018","","","IEEE","IEEE Conferences"
"Impact Analysis of Syntactic and Semantic Similarities on Patch Prioritization in Automated Program Repair","M. Asad; K. K. Ganguly; K. Sakib","Institute of Information Technology University of Dhaka, Dhaka, Bangladesh; Institute of Information Technology University of Dhaka, Dhaka, Bangladesh; Institute of Information Technology University of Dhaka, Dhaka, Bangladesh",2019 IEEE International Conference on Software Maintenance and Evolution (ICSME),"5 Dec 2019","2019","","","328","332","Patch prioritization means sorting candidate patches based on probability of correctness. It helps to minimize the bug fixing time and maximize the precision of an automated program repairing technique. Approaches in the literature use either syntactic or semantic similarity between faulty code and fixing element to prioritize patches. Unlike others, this paper aims at analyzing the impact of combining syntactic and semantic similarities on patch prioritization. As a pilot study, it uses genealogical and variable similarity to measure semantic similarity, and normalized longest common subsequence to capture syntactic similarity. For evaluating the approach, 22 replacement mutation bugs from IntroClassJava benchmark were used. The approach repairs all the 22 bugs and achieves a precision of 100%.","2576-3148","978-1-7281-3094-1","10.1109/ICSME.2019.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918958","patch prioritization;semantic similarity;syntactic similarity;automated program repair","Computer bugs;Syntactics;Semantics;Maintenance engineering;Measurement;Benchmark testing;Information technology","","8","","17","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
"One-Dimensional Soft-Demapping Algorithms for Rotated QAM and Software Implementation on DSP","K. Kim; N. Basutkar; K. Bae; P. Xue; H. Yang","Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea; Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea; Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea; Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea; Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea",IEEE Transactions on Signal Processing,"10 Jul 2013","2013","61","15","3918","3930","To improve detection performance of quadrature amplitude modulation (QAM), signal space diversity (SSD) has been exploited and adopted for the second generation of digital video broadcasting (DVB-T2) system. Maximum-likelihood detection (MLD) to get full SSD is avoided because of enormous computational complexity. Its max-log approximated detection (full search algorithm) and subregion based soft-demappers are also too complex to be implemented due to their two-dimensional (2D) Euclidean distance calculation. In particular, the complexity becomes the main burden for the software implementation, which is attractive for multistandard broadcasting receivers. To tackle the main bottleneck, we propose one-dimensional (1D) soft-demappers. By reformulating a rotated QAM signal as two layered pulse amplitude modulation (PAM) signals, the full search algorithm is simplified to an MMSE decorrelation followed by 1D soft-demapping, where Gaussian approximation is used for the interferences. Additional interference cancellation is considered to further suppress its residual interference. For 256-QAM with 4/5 code rate in memoryless Rayleigh channels with/without erasures, the performance gap to the full search is within 0.15 dB at 10-3 bit error rate (BER), while the complexity is less than 8%. Due to the significant complexity reduction of the proposed algorithms, the software implementation of a DVB-T2 receiver on DSP is feasible with 73% less computations than the one with the full-search-based soft-demapper.","1941-0476","","10.1109/TSP.2013.2262681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6515394","Coarse-grained reconfigurable array (CGRA) architecture;digital signal processor (DSP);interference cancellation (IC);log likelihood ratio (LLR);minimum mean square error (MMSE);rotated QAM;signal space diversity (SSD);soft-demapping;software defined radio (SDR)","Quadrature amplitude modulation;Complexity theory;Software algorithms;Signal processing algorithms;Approximation algorithms;Decorrelation;Software","","12","1","29","IEEE","13 May 2013","","","IEEE","IEEE Journals"
"Compressive Sensing based Software Defined GPR for Subsurface Imaging","Y. Zhang; D. Orfeo; D. Huston; T. Xia","School of Engineering, University of Vermont, Burlington, VT, USA; School of Engineering, University of Vermont, Burlington, VT, USA; School of Engineering, University of Vermont, Burlington, VT, USA; School of Engineering, University of Vermont, Burlington, VT, USA",2021 IEEE Radar Conference (RadarConf21),"18 Jun 2021","2021","","","1","6","This paper presents the design of a new ground penetrating radar (GPR) integrating software defined radio (SDR) and compressive sensing (CS) technologies. In recent literature, SDR has been explored for designing GPR in the way of stepped-frequency continuous wave (SFCW) radar. In the operation, the software defined GPR (SD GPR) radiates a series of sinusoidal signals of evenly spaced frequencies at each scan position. The reflection signals of all frequency tones are received and their amplitude and phase responses are measured and characterized. As each individual frequency tone needs to be generated, transmitted and received in sequence, it results in a slow scan speed. In this study, compressive sensing is explored to expedite SD GPR operation speed. For SD GPR subsurface survey, when the target area is spatially sparse, i.e. the buried objects are sparsely distributed, In addition, we develop a CS based signal processing algorithm specifically for improving image quality and reducing the clutter. To reconstruct the image correctly, an automatic parameter selection algorithm based on the structural similarity index measure (SSIM) is proposed. For validation, a laboratory test was conducted. The experimental results demonstrate that the CS imaging algorithm produces less clutter comparing with the traditional GPR image algorithms, such as the time domain back projection (BPA) method.","2375-5318","978-1-7281-7609-3","10.1109/RadarConf2147009.2021.9455291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455291","Software Defined GPR;Subsurface Imaging;Compressive Sensing;Structural Similarity Index Measure (SSIM)","Ground penetrating radar;Software algorithms;Signal processing algorithms;Radar imaging;Software;Frequency measurement;Indexes","","4","","21","IEEE","18 Jun 2021","","","IEEE","IEEE Conferences"
"Tibetan Few-Shot Learning Model Based on Matching Networks","Z. Zhang; G. Xiong; Y. Yu; X. Wang; X. Feng; N. Tashi","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information Science and Technology, Tibet University, Lhasa, China",2023 International Conference on Neuromorphic Computing (ICNC),"19 Mar 2024","2023","","","446","451","This paper highlights the low-resource Tibetan few-shot learning model and establishes accuracy benchmarks utilizing Matching Networks (MN). Addressing the issues of low quality and limited usability in the existing Tibetan-Chinese parallel corpus, this paper constructs a small-scale and high-quality Tibetan-Chinese parallel corpus containing 110,000 sentence pairs using data filtering, deduplication, deletion of blank lines, and special symbol processing. Based on full context embeddings, Softmax-based attention mechanisms, and similarity metrics, the Tibetan few-shot learning model based on MN is proposed to help the model learn logical Tibetan knowledge rapidly from few-shot data. Different distance metrics on Cosine, Euclidean, Poincare, and Minkowski distances are used to test the accuracy of the Tibetan k-shot learning model, which provides a unified and reliable benchmark for the Tibetan few-shot learning tasks. This research provides substantial assistance in solving the issues of machine learning performing poorly in low-resource settings. The experiment results demonstrate that the accuracy of all metrics is improved with the number of shots increased, and Euclidean distance performs well in 5-way 1-shot learning, cosine performs well in 5-way 2-shot learning, and Minkowski distance $(\mathrm{p}=3)$ shows excellent accuracy in 5-way 3-shot learning. Notably, we used our own Tibetan data set and succeeded in enhancing accuracy by a noteworthy 1.6% in a 5-way 3-shot setup.","","979-8-3503-1688-9","10.1109/ICNC59488.2023.10462784","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10462784","Tibetan;few-shot learning;matching networks;machine learning;similarity metrics","Measurement;Training;Symbols;Benchmark testing;Solids;Data models;Usability","","","","20","IEEE","19 Mar 2024","","","IEEE","IEEE Conferences"
"Adaptive Multi-Hash Similarity Fusion for Remote Sensing Image Retrieval","J. Yu; H. Li; Y. Ge; H. Shao; J. Xiong","Software School, Nanchang Hongkong University, Nanchang, Jiangxi, China; School of Arts, Media and Computers, Jiangxi Tourism and Commerce Vocational College, Nanchang, Jiangxi, China; Software School, Nanchang Hongkong University, Nanchang, Jiangxi, China; Software School, Nanchang Hongkong University, Nanchang, Jiangxi, China; Software School, Nanchang Hongkong University, Nanchang, Jiangxi, China","2024 5th International Conference on Geology, Mapping and Remote Sensing (ICGMRS)","9 Jul 2024","2024","","","117","121","With the exponential growth of remote sensing (RS) images, content-based remote sensing image retrieval (CBRSIR) has become an effective method to retrieve target images from RS data. However, existing CBRSIR methods often rely on a single feature, which fails to fully capture the rich and complex visual content. To address this limitation, we propose an adaptive multi-hash similarity fusion method for RSIR. Firstly, deep features and manual features are extracted to provide varying perspectives on the image. Secondly, in order to enhance retrieval efficiency, these features are transformed into low-dimensional hash codes through the probability ordinal-preserving semantic hashing method. Finally, various hash similarities are fused to capitalize on the complementarity of different views and narrow the semantic gap. Given that different hash similarities contribute disparately to the final retrieval result during fusion, determining the weight distribution is critical for enhancing the fusion effect. Therefore, the mean average precision results are utilized to adaptively determine fusion weights. Experiments on two benchmark datasets demonstrate that the proposed method outperforms other RSIR methods. Comparative experiments with exhaustive weighting reveal the simplicity and effectiveness of our adaptive weight allocation method.","","979-8-3503-6571-9","10.1109/ICGMRS62107.2024.10581361","China National Science Foundation(grant numbers:42261070,41801288); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10581361","Remote sensing image retrieval;Hashing similarity fusion;Adaptive weight assignment;Deep features;Manual features","Visualization;Codes;Geology;Semantics;Image retrieval;Manuals;Benchmark testing","","","","17","IEEE","9 Jul 2024","","","IEEE","IEEE Conferences"
"Assessment of Data Diversity Methods for Software Fault Tolerance Based on Mutation Analysis","G. Gallardo; J. May; J. C. Gallardo","University of Bristol, UK; Safety Systems Research Centre (SSRC), University of Bristol, UK; SSRC, UK",Second Workshop on Mutation Analysis (Mutation 2006 - ISSRE Workshops 2006),"2 Apr 2007","2006","","","6","6","One of the main concerns in safety-critical software is to ensure sufficient reliability because proof of the absence of systematic failures has proved to be an unrealistic goal. fault-tolerance (FT) is one method for improving reliability claims. It is reasonable to assume that some software FT techniques offer more protection than others, but the relative effectiveness of different software FT schemes remains unclear. We present the principles of a method to assess the effectiveness of FT using mutation analysis. The aim of this approach is to observe the power of FT directly and use this empirical process to evolve more powerful forms of FT. We also investigate an approach to FT that integrates data diversity (DD) assertions and TA. This work is part of a longer term goal to use FT in quantitative safety arguments for safety critical systems.","","0-7695-2897-X","10.1109/MUTATION.2006.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4144725","","Diversity methods;Fault tolerance;Genetic mutations;Software safety;Redundancy;Software testing;Fault tolerant systems;Software systems;Failure analysis;System testing","","","","17","IEEE","2 Apr 2007","","","IEEE","IEEE Conferences"
"BEDIVFUZZ: Integrating Behavioral Diversity into Generator-based Fuzzing","H. L. Nguyen; L. Grunske","Humboldt-Universität zu Berlin, Germany; Humboldt-Universität zu Berlin, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","249","261","A popular metric to evaluate the performance of fuzzers is branch coverage. However, we argue that focusing solely on covering many different branches (i.e., the richness) is not sufficient since the majority of the covered branches may have been exercised only once, which does not inspire a high confidence in the reliability of the covered code. Instead, the distribution of the executed branches (i.e., the evenness) should also be considered. That is, behavioral diversity is only given if the generated inputs not only trigger many different branches, but also trigger them evenly often with diverse inputs. We introduce BEDIVFUZZ, a feedback-driven fuzzing technique for generator-based fuzzers. BEDIVFUZZ distinguishes between structure-preserving and structure-changing mutations in the space of syntactically valid inputs, and biases its mutation strategy towards validity and behavioral diversity based on the received program feedback. We have evaluated BEDIVFUZZ on Ant, Maven, Rhino, Closure, Nashorn, and Tomcat. The results show that BE-DIVFUZZ achieves better behavioral diversity than the state of the art, measured by established biodiversity metrics, namely the Hill numbers, from the field of ecology.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793964","Structure-aware fuzzing;behavioral diversity;random testing","Measurement;Codes;Focusing;Fuzzing;Ecology;Behavioral sciences;Reliability","","7","","54","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Empirical study of post-envelope detection receive diversity combining for passive UHF RFID tags","L. B. B. Paet; J. J. S. Marciano","Electrical and Electronics Engineering Institute, University of Philippines, Quezon, Philippines; Electrical and Electronics Engineering Institute, University of Philippines, Quezon, Philippines",TENCON 2011 - 2011 IEEE Region 10 Conference,"12 Jan 2012","2011","","","773","777","The concept of incorporating receive diversity combining schemes into UHF RFID tags is presented in this work. The inclusion of the said schemes into RFID tags is employed as a possible solution to the effects of multipath propagation on the reader-to-tag (R→T) wireless link which reduce the read range and degrade the read reliability of current passive RFID systems. To explore this concept, the authors constructed reader and tag emulation platforms using National Instruments PXI hardware modules and LabVIEW software programs for modeling the R→T communications link. The reader emulation platform was used to model the transmit section of an RFID reader and is capable of transmitting user-predetermined sequences of RFID commands. The tag emulation platform was used to model the receive section of a single-or multi-antenna RFID tag. These two platforms were utilized as a testbed for developing and testing the following 2-channel diversity combining schemes for UHF RFID tags: (1) selection diversity combining (SDC), (2) post-detection direct additive combining (DACP), and (3) post-detection ratio squared combining (RSCP). Experiments were conducted to determine the read range and read reliability performance. Results of these experiments show that a maximum of 26.67% improvement in the read range and a maximum of 16.64% improvement in the read reliability of UHF RFID systems can be obtained by integrating receive diversity schemes into RFID tags. Improvements were recorded even for tag antenna spacings as low as 0.05?.","2159-3450","978-1-4577-0255-6","10.1109/TENCON.2011.6129215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129215","spatial diversity;multi-antenna signal processing;passive UHF RFID;EPC Gen 2 RFID","Diversity reception;Antennas;Reliability;Emulation;Passive RFID tags;Hardware","","1","","13","IEEE","12 Jan 2012","","","IEEE","IEEE Conferences"
"Generation of High-Quality Relevant Judgments through Document Similarity and Document Pooling for the Evaluation of Information Retrieval Systems","M. H. Joseph; S. D. Ravana","Department of Information Systems, Faculty of Computer Science & Information Technology, University of Malaya, Malaysia; Department of Information Systems, Faculty of Computer Science & Information Technology, University of Malaya, Malaysia","2022 14th International Conference on Software, Knowledge, Information Management and Applications (SKIMA)","6 Feb 2023","2022","","","261","265","The Information Retrieval System Evaluation have carried out through Cranfield-paradigm in which the test collections provide the foundation of the evaluation process. The test collections consist of document corpus, topics, and a set of relevance judgements. The relevant judgements are the documents which retrieved from the test collections based on the topics. The precision of the evaluation process is based on the number of relevant documents in the relevant judgement list called qrels. This paper presents a study on how methodologies like pooling and document similarity helps to generate more relevant documents into the relevance judgments set in order to increase the accuracy of the evaluation process. The initial results have shown that combination of pooling with document similarity performs better compared to base clustering or classification.","2573-3214","978-1-6654-9334-5","10.1109/SKIMA57145.2022.10029459","Ministry of Higher Education(grant numbers:FRGS/1/2020/1CT06/UM/02/1); Universiti Malaya(grant numbers:RMFI521-2021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10029459","Information retrieval;Evaluation;Pooling;Document similarity;Information Systems","Information retrieval;Software;Information management","","","","15","IEEE","6 Feb 2023","","","IEEE","IEEE Conferences"
"Software Side Channel Vulnerability Detection Based on Similarity Calculation and Deep Learning","W. Sun; Z. Yan; X. Xu; W. Ding; L. Gao","School of Cyber Engineering Xidian University, Xi’an, China; School of Cyber Engineering Xidian University, Xi’an, China; School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; School of Cyber Engineering Xidian University, Xi’an, China; School of Cyber Engineering Xidian University, Xi’an, China","2022 IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","20 Mar 2023","2022","","","800","809","Software Side Channel Vulnerabilities (SSCVs) cause serious security threats, which introduces a big challenge to software development. With the sustaining growth of software complexity and scale, SSCV detection has become a tedious work. Existing methods suffer from efficiency, accuracy and generality problems, and ignore the detection of vulnerability variants. Applying machine learning is promising due to high efficiency and automation, but training an effective model is still an open issue due to the lack of side-channel vulnerability data. In this paper, we propose a novel two-stage SSCV detection method based on similarity calculation and deep learning. We target three types of vulnerability variants that have different degrees of similarity to original ones. The first detection stage applies Deterministic Finite Automata (DFA) and Trie tree to regularize software codes for detecting vulnerability Variants 1 and 2 through similarity calculation. The second stage uses Long Short-Term Memory and Neural Network Classifier (LSTM-NNClassifier) to discover vulnerability Variant 3. In addition, we offer a code augmentation method to construct a sufficient dataset to train the LSTM-NNClassifier for overcoming the problem of lacking training data. Extensive experiments based on real world data show the efficiency and accuracy of our detection method.","2324-9013","978-1-6654-9425-0","10.1109/TrustCom56396.2022.00112","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10063617","Side Channel Attack;Vulnerability Detection;Deep Learning;Similarity Calculation","Deep learning;Training;Privacy;Codes;Learning automata;Neural networks;Training data","","","","34","IEEE","20 Mar 2023","","","IEEE","IEEE Conferences"
"Indoor antenna diversity testbed","K. Bialkowski; S. Zagriatski; A. Postula; M. E. Bialkowski","School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD, Australia; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD, Australia; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD, Australia; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD, Australia",2005 IEEE Antennas and Propagation Society International Symposium,"12 Dec 2005","2005","2B","","759","762 vol. 2B","This paper presents a high precision testbed for evaluating antenna diversity techniques in an indoor environment. Details concerning mechanical, electrical and electronics hardware and associated measurement software are described. Initial measurement results for two Bluetooth modules operating with co-polar and cross-polar monopole antennas in the ISM 2.4 GHz band are given.","1947-1491","0-7803-8883-6","10.1109/APS.2005.1552127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1552127","","Testing;Polarization;Antenna measurements;Transmitting antennas;MIMO;Gears;Coaxial cables;Software measurement;Receiving antennas;Transmitters","","4","","3","IEEE","12 Dec 2005","","","IEEE","IEEE Conferences"
"A Semantics-Based Hybrid Approach on Binary Code Similarity Comparison","Y. Hu; H. Wang; Y. Zhang; B. Li; D. Gu","Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Software Engineering,"11 Jun 2021","2021","47","6","1241","1258","Binary code similarity comparison is a methodology for identifying similar or identical code fragments in binary programs. It is indispensable in fields of software engineering and security, which has many important applications (e.g., plagiarism detection, bug detection). With the widespread of smart and Internet of Things (IoT) devices, an increasing number of programs are ported to multiple architectures (e.g., ARM, MIPS). It becomes necessary to detect similar binary code across architectures as well. The main challenge of this topic lies in the semantics-equivalent code transformation resulting from different compilation settings, code obfuscation, and varied instruction set architectures. Another challenge is the trade-off between comparison accuracy and coverage. Unfortunately, existing methods still heavily rely on semantics-less code features which are susceptible to the code transformation. Additionally, they perform the comparison merely either in a static or in a dynamic manner, which cannot achieve high accuracy and coverage simultaneously. In this paper, we propose a semantics-based hybrid method to compare binary function similarity. We execute the reference function with test cases, then emulate the execution of every target function with the runtime information migrated from the reference function. Semantic signatures are extracted during the execution as well as the emulation. Lastly, similarity scores are calculated from the signatures to measure the likeness of functions. We have implemented the method in a prototype system designated as BinMatch which performs binary code similarity comparison across architectures of x86, ARM and MIPS on the Linux platform. We evaluate BinMatch with nine real-word projects compiled with different compilation settings, on variant architectures, and with commonly-used obfuscation methods, totally performing over 100 million pairs of function comparison. The experimental results show that BinMatch is resilient to the semantics-equivalent code transformation. Besides, it not only covers all target functions for similarity comparison, but also improves the accuracy comparing to the state-of-the-art solutions.","1939-3520","","10.1109/TSE.2019.2918326","National Natural Science Foundation of China(grant numbers:U1636217); National Key Research and Development Program of China(grant numbers:2016YFB0801201,2016QY071401); Ministry of Industry and Information Technology of the People's Republic of China(grant numbers:[2018] 282); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721093","Binary code similarity comparison;reverse engineering;program analysis;code clone","Binary codes;Semantics;Computer architecture;Runtime;Computer science;Feature extraction;Internet of Things","","8","","65","IEEE","23 May 2019","","","IEEE","IEEE Journals"
"Development of Class Diagrams Based on Use Case, and Sequence Diagrams Using a Text Mining Approach in SRS Penguin","N. F. Setiyawan; Y. Priyadi; W. Astuti","Department of Informatics, Telkom University, Bandung, Indonesia; Department of Software Engineering, Telkom University, Bandung, Indonesia; Department of Informatics, Telkom University, Bandung, Indonesia",2023 IEEE World AI IoT Congress (AIIoT),"13 Jul 2023","2023","","","0070","0076","Software requirement specification is a document that can be used as a guide for developers to develop applications. This study uses SRS from the Penguin application to help determine the development of class diagrams based on use case and sequence diagrams using the text mining method. The results of this process will be calculated for similarity, after which validation and testing will be carried out using Gwet’s AC1 and Cohen Kappa. Based on the results and discussion, three artifacts were formed, namely actors from use case diagrams (AUC), objects from sequence diagrams (OSD), and class names from class diagrams (NCD). The three artifacts produce two comparisons in the formation of class diagrams. The first comparison is between AUC and NCD, with the highest cosine similarity score of 0.666. From this score, the resulting construction of class diagram component names is seller and customer. The first comparison also resulted in a score of 0.088 for Cohen Kappa and 0.756 for Gwet’s AC1. Furthermore, for the second comparison, between OSD and NCD, two results were obtained with the same score, namely 0.9. This score resulted in the formation of class component names such as seller, transaction page, revenue page, expenditure page, and penguin app system. And the second comparison has a Cohen kappa score of 0.112 and 0.926 for Gwet’s AC1 score. The results of the Cohen Kappa score, and Gwet’s AC1 can be used as recommendations for improving class names that match the actors names in use case diagram, and object names in the sequence diagram.","","979-8-3503-3761-7","10.1109/AIIoT58121.2023.10174287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174287","software requirement specification;class diagram;use case diagram;text mining;similarities;validation","Text mining;Software;Artificial intelligence;Testing","","1","","27","IEEE","13 Jul 2023","","","IEEE","IEEE Conferences"
"Human activity recognition from basic actions using graph similarity measurement","N. Noorit; N. Suvonvorn","Department of Computer Engineering, Prince of Songkla University, Songkhla, Thailand; Department of Computer Engineering, Prince of Songkla University, Songkhla, Thailand",2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE),"27 Aug 2015","2015","","","7","11","Human activity recognition has an important role for the automatic anomaly event detection and recognition application such as surveillance system and patient monitoring system. In this paper, we propose a human activity recognition method based on graph similarity measurement technique (GSM). The basic actions with their movements for each person in the interested area are extracted and calculated. The action sequence with movement features of labelled dataset are used as basis data to establish the statistical activity graph model that used to calculate similarity between graphs. The system performs good results, (sensitivity and specificity are about 80% for first testing activity and about 90% for second testing activity).","","978-1-4799-1966-6","10.1109/JCSSE.2015.7219761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219761","human activity recognition;directed graph;graph similarity measurement","Joints;Conferences;Computer science;Software engineering","","1","","13","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos","H. Liu; Y. Teng; T. Lu; H. Wang; L. Wang","State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University",2023 IEEE/CVF International Conference on Computer Vision (ICCV),"15 Jan 2024","2023","","","18534","18544","Camera-based 3D object detection in BEV (Bird’s Eye View) space has drawn great attention over the past few years. Dense detectors typically follow a two-stage pipeline by first constructing a dense BEV feature and then performing object detection in BEV space, which suffers from complex view transformations and high computation cost. On the other side, sparse detectors follow a query-based paradigm without explicit dense BEV feature construction, but achieve worse performance than the dense counterparts. In this paper, we find that the key to mitigate this performance gap is the adaptability of the detector in both BEV and image space. To achieve this goal, we propose SparseBEV, a fully sparse 3D object detector that outperforms the dense counterparts. SparseBEV contains three key designs, which are (1) scale-adaptive self attention to aggregate features with adaptive receptive field in BEV space, (2) adaptive spatio-temporal sampling to generate sampling locations under the guidance of queries, and (3) adaptive mixing to decode the sampled features with dynamic weights from the queries. On the test split of nuScenes, SparseBEV achieves the state-of-the-art performance of 67.5 NDS. On the val split, SparseBEV achieves 55.8 NDS while maintaining a real-time inference speed of 23.5 FPS. Code is available at https://github.com/MCG-NJU/SparseBEV.","2380-7504","979-8-3503-0718-4","10.1109/ICCV51070.2023.01703","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10377285","","Three-dimensional displays;Costs;Navigation;Pipelines;Detectors;Object detection;Feature extraction","","4","","60","IEEE","15 Jan 2024","","","IEEE","IEEE Conferences"
"Optimizing Spaced $k$-mer Neighbors for Efficient Filtration in Protein Similarity Search","W. Li; B. Ma; K. Zhang","Department of Computer Science, University of Western Ontario, London, ON, Canada; School of Computer Science, University of Waterloo, Waterloo, Canada; Department of Computer Science, University of Western Ontario, London, ON, Canada",IEEE/ACM Transactions on Computational Biology and Bioinformatics,"21 May 2014","2014","11","2","398","406","Large-scale comparison or similarity search of genomic DNA and protein sequence is of fundamental importance in modern molecular biology. To perform DNA and protein sequence similarity search efficiently, seeding (or filtration) method has been widely used where only sequences sharing a common pattern or “seed” are subject to detailed comparison. Therefore these methods trade search sensitivity with search speed. In this paper, we introduce a new seeding method, called spaced $k$-mer neighbors, which provides a better tradeoff between the sensitivity and speed in protein sequence similarity search. With the method of spaced $k$-mer neighbors, for each spaced $k$-mer, a set of spaced $k$-mers is selected as its neighbors. These pre-selected spaced $k$-mer neighbors are then used to detect hits between query sequence and database sequences. We propose an efficient heuristic algorithm for the spaced neighbor selection. Our computational experimental results demonstrate that the method of spaced $k$-mer neighbors can improve the overall tradeoff efficiency over existing seeding methods.","1557-9964","","10.1109/TCBB.2014.2306831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6744614","Spaced seeds;homology search;similarity search","Sensitivity;Proteins;Amino acids;Databases;DNA;Bioinformatics;Frequency modulation","Algorithms;Animals;Computational Biology;Drosophila;Humans;Mice;Proteins;Sequence Analysis, Protein;Sequence Homology, Amino Acid;Software","4","","23","IEEE","19 Feb 2014","","","IEEE","IEEE Journals"
"Measuring semantic similarity by contextualword connections in Chinese news story segmentation","X. Nie; W. Feng; L. Wan; L. Xie","School of Computer Science and Technology, School of Computer Software, School of Computer Software, Tianjin University, Tianjin, China; Tianjin University, Tianjin, Tianjin, CN; Tianjin University, Tianjin, Tianjin, CN; School of Computer Science, Northwestern Polytechnical University, Xian, China","2013 IEEE International Conference on Acoustics, Speech and Signal Processing","21 Oct 2013","2013","","","8312","8316","A lot of recent work in story segmentation focuses on developing better partitioning criteria to segment news transcripts into sequences of topically coherent stories, while simply relying on the repetition based hard word-level similarities and ignoring the semantic correlations between different words. In this paper, we propose a purely data-driven approach to measuring soft semantic word- and sentence-level similarity from a given corpus, without the guidance of linguistic knowledge, ground-truth topic labeling or story boundaries. We show that contextual word connections can help to produce semantically meaningful similarity measurement between any pair of Chinese words. Based on this, we further use a parallel all-pair SimRank algorithm to propagate such contextual similarities throughout the whole vocabulary. The resultant word semantic similarity matrix is then used to refine the classical cosine similarity measurement of sentences. Experiments on benchmark Chinese news corpora show that, story segmentation using the proposed soft semantic similarity measurement can always produce better segmentation accuracy than using the hard similarity. Specifically, we can achieve 3%-10% average F1-measure improvement to state-of-the-art NCuts based story segmentation.","2379-190X","978-1-4799-0356-6","10.1109/ICASSP.2013.6639286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6639286","Semantic similarity;contextual word connections;similarity propagation;story segmentation","Semantics;Educational institutions;Vocabulary;Measurement;Benchmark testing;Accuracy;Correlation","","5","","12","IEEE","21 Oct 2013","","","IEEE","IEEE Conferences"
"Time- and Space-Efficient Evaluation of Sparse Boolean Functions in Embedded Software","V. Dvorak","Brno University of Technology, Czech Republic",14th Annual IEEE International Conference and Workshops on the Engineering of Computer-Based Systems (ECBS'07),"10 Apr 2007","2007","","","178","185","The paper addresses software implementation of large sparse systems of Boolean functions. Fast evaluation of such functions with the smallest memory consumption is often required in embedded systems. A new heuristic method of obtaining compact representation of sparse Boolean functions in a form of linked tables is described that can be used for BDD minimization as well. Evaluation of Boolean functions reduces to multiple indirect memory accesses. The method is compared to other techniques like a walk through a BDD or a list search and is illustrated on examples. The presented method is flexible in making trade-offs between performance and memory consumption and may be thus useful for embedded microprocessor or microcontroller software.","","0-7695-2772-8","10.1109/ECBS.2007.72","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4148932","","Boolean functions;Embedded software;Binary decision diagrams;Data structures;Zirconium;Embedded system;Programmable control;Testing;Upper bound;Paper technology","","","","9","IEEE","10 Apr 2007","","","IEEE","IEEE Conferences"
"Finding Causally Different Tests for an Industrial Control System","C. M. Poskitt; Y. Chen; J. Sun; Y. Jiang","Singapore Management University, Singapore; ShanghaiTech University, China; Singapore Management University, Singapore; Tsinghua University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2578","2590","Industrial control systems (ICSs) are types of cyber-physical systems in which programs, written in languages such as ladder logic or structured text, control industrial processes through sensing and actuating. Given the use of ICSs in critical infrastructure, it is important to test their resilience against manipulations of sensor/actuator inputs. Unfortunately, existing methods fail to test them comprehensively, as they typically focus on finding the simplest-to-craft manipulations for a testing goal, and are also unable to determine when a test is simply a minor permutation of another, i.e. based on the same causal events. In this work, we propose a guided fuzzing approach for finding 'meaningfully different’ tests for an ICS via a general formalisation of sensor/actuator-manipulation strategies. Our algorithm identifies the causal events in a test, generalises them to an equivalence class, and then updates the fuzzing strategy so as to find new tests that are causally different from those already identified. An evaluation of our approach on a real-world water treatment system shows that it is able to find 106% more causally different tests than the most comparable fuzzer. While we focus on diversifying the test suite of an ICS, our formalisation may be useful for other fuzzers that intercept communication channels.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172721","Cyber-physical systems;fuzzing;test diversity;equivalence classes;causality","Integrated circuits;Process control;Communication channels;Fuzzing;Model checking;Mathematical models;Sensors","","1","","47","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Data Fusion Algorithm Based on Fuzzy Similarity Weighted Least Square for Positioning with the Global Positioning System","A. E. Abdalla; B. Shetar; M. S. Abdelwahab","Electrical Engineering Department, Miltary Technical College, Cairo, Egypt; Electrical Engineering Department, Miltary Technical College, Cairo, Egypt; Electrical Engineering Department, Miltary Technical College, Cairo, Egypt",2020 12th International Conference on Electrical Engineering (ICEENG),"27 Aug 2020","2020","","","467","470","The Global Positioning System, GPS customs solutions to determine the coordinates of the GPS receiver location and the receiver clock offset from data extracted from at least four pseudoranges. The constancy and accuracy are essential requirements in positioning calculation. The Least Squares, LS estimate has been widely used for solving GPS positioning problems. Aside its valuable properties, the LS estimate can be affected by outliers which reflect to its performance in terms of accuracy. In this paper, a new approach is applied to LS estimate to increase its accuracy and reliability. Assuming six or more satellites are observed. First, several sets of measurements are formed by making all possible combinations of observed satellites at least five satellites in each set. Second, the LS estimate approach is applied for each set of measurement to estimate the receiver position. A cluster of each set of measurements is obtained and its statistical properties mean and standard deviation are computed. Grubbs’s outlier algorithm is applied to all clusters to find the outlier measurements. The fusion of position data set is based on the fuzzy similarity between the sets of cluster position where the importance weight of each set of data is extracted. According to the proposed algorithm, software is developed using MATLAB. The proposed algorithm is tested, and the position accuracy is improved. Moreover, it reflects the efficiency and feasibility to real-time data processing and monitoring","","978-1-7281-3052-1","10.1109/ICEENG45378.2020.9171714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171714","Fusion data;Weighted least square method;GPS;Data fusion;Fuzzy Similarity;Grubbs’s Statistic;Outlier;Mean and Standard Deviation","Weight measurement;Satellites;Software algorithms;Measurement uncertainty;Clustering algorithms;Data integration;Receivers","","3","","10","IEEE","27 Aug 2020","","","IEEE","IEEE Conferences"
"VulMiningBGS: Detection of overflow vulnerabilities based on graph similarity","Z. Yu; J. Xue; X. Sun; W. Wang; Y. Song; L. Chen; Z. Qin","School of Cyber Science and Engineering Southeast University, Nanjing, China; School of Cyber Science and Engineering Southeast University, Nanjing, China; Internet Technology Center, State Grid Zhejiang Electric Power Co., Ltd. Research Institute, Hangzhou, China; Internet Department, State Grid Zhejiang Electric Power Co., Ltd., Hangzhou, China; School of Cyber Science and Engineering Southeast University, Nanjing, China; School of Cyber Science and Engineering Southeast University, Nanjing, China; School of Cyber Science and Engineering Southeast University, Nanjing, China",2022 18th International Conference on Computational Intelligence and Security (CIS),"7 Apr 2023","2022","","","386","390","The increasing number of software vulnerabilities pose serious security attacks and lead to system compromise, information leakage or denial of service. It is a challenge to further improve the vulnerability detection technique. Nowadays most applications are implemented using C/C++. In this paper we focus on the detection of overflow vulnerabilities in C/C++ source code. A novel scheme named VulMiningBGS (Vulnerability Mining Based on Graph Similarity) is proposed. We convert the source code into Top N-Weighted Range Sum Feature Graph (TN-WRSFG), and graph similarity comparisons based on source code level can be effectively carried on to detect possible vulnerabilities. Three categories of vulnerabilities in the Juliet test suite are used, i.e., CWE121, CWE122 and CWE190, with four indicators for performance evaluation (precision, recall, accuracy and F1_score). Experimental results show that our scheme outperforms the traditional methods, and is effective in the overflow vulnerability detection for C/C++ source code.","","979-8-3503-4627-5","10.1109/CIS58238.2022.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10091381","vulnerability detection;graph similarity comparison;weighted range sum feature graph","Performance evaluation;Deep learning;Source coding;Feature extraction;Software;Security;Computational intelligence","","1","","15","IEEE","7 Apr 2023","","","IEEE","IEEE Conferences"
"Study of Concept Similarity Algorithm between Steel Ontologies","Y. Hu; W. Li; S. Liu","School of Computer Science and Technology Tianjin University, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China",2012 Third World Congress on Software Engineering,"10 Jan 2013","2012","","","19","22","Concepts similarity calculation is the basis for ontology mapping. Vocabulary, meaning of the word, property and instance of concepts are the important facts when calculating concepts similarity. All the facts above are combined and a composite method is proposed to calculate concepts similarity in this paper. In order to keep the effectiveness and comprehensiveness of the method, we combine concepts vocabularies matching algorithm, synonyms basing on Word Net matching algorithm, concepts properties and instances similarities. By calculating test data, the experiment result shows that the method can calculate concepts similarity effectively between two steel ontologies.","","978-1-4673-4546-0","10.1109/WCSE.2012.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6394917","ontology;semantic distance;concept similarity","Ontologies;Vocabulary;Semantics;Educational institutions;Steel;Semantic Web","","","","7","IEEE","10 Jan 2013","","","IEEE","IEEE Conferences"
"Document clustering and topic discovery based on semantic similarity in scientific literature","J. Jayabharathy; S. Kanmani; A. A. Parveen","Department of Computer Science & Engineering, Pondicherry Engineering College, Pondicherry, India; Department of Information Technology, Pondicherry Engineering College, Pondicherry, India; Department of Computer Science & Engineering, Pondicherry Engineering College, Pondicherry, India",2011 IEEE 3rd International Conference on Communication Software and Networks,"8 Sep 2011","2011","","","425","429","Unlabeled document collections are becoming increasingly common and mining such databases becomes a major challenge. It is a major issue to retrieve relevant documents from the larger document collection. By clustering the text documents, the documents sharing similar topics are grouped together. Incorporating semantic features will improve the accuracy of document clustering methods. In order to determine at a sight whether the content of a cluster are of user interest or not, topic discovery methods are required to tag each clusters identifying distinct and representative topic of each cluster. Most of the existing topic discovery methods often assign labels to clusters based on the terms that the clustered documents contain. In this paper a modified semantic-based model is proposed where related terms are extracted as concepts for concept-based document clustering by bisecting k-means algorithm and topic detection method for discovering meaningful labels for the document clusters based on semantic similarity by Testor theory. The proposed method is compared to the Topic Detection by Clustering Keywords method using F-measure and purity as evaluation metrics. Experimental results prove that the proposed semantic-based model outperforms the existing work.","","978-1-61284-486-2","10.1109/ICCSN.2011.6014600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6014600","Document clustering;Topic discovery;Semantic similarity;Concept;Testor theory","Internet;Data mining;Information retrieval;Information services;Electronic publishing","","11","2","13","IEEE","8 Sep 2011","","","IEEE","IEEE Conferences"
"Coexistence of SCTP and TCP variants under self-similar network","L. Charoenwatana; S. Rattanabung","Department of Mathematics, Statistics, and Computer, Ubon Ratchathani University, Ubon Ratchathani, Thailand; Ubon Rajathanee University, Ubon Ratchathani, TH",2011 Eighth International Joint Conference on Computer Science and Software Engineering (JCSSE),"23 Jun 2011","2011","","","17","22","SCTP will co-exist with TCP on the Internet in a near future as its maturity progresses. Self-similarity is long known as an inherent characteristic of the IP network in which performance of SCTP under such environment is yet to be investigated. This paper reports behaviors and throughput of SCTP and TCP streams when co-existed together in the same channel under self-similar traffic environment. Simulation tests on several TCP variants including New-Reno, Reno, Tahoe, Vegas, and SACK using ns2 simulator are conducted. Results reveal that SCTP acquires averagely only 50% throughput when competing with TCP. Although found that self-similarity does not extensively distort SCTP-TCP performance, it, nevertheless, offers indirect advantage to SCTP in gaining throughput proportion against TCP.","","978-1-4577-0687-5","10.1109/JCSSE.2011.5930082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5930082","Network Protocol;TCP;SCTP;Self-Similarity","","","2","","17","IEEE","23 Jun 2011","","","IEEE","IEEE Conferences"
"A concept similarity computation based on multi-property ontology","Y. Xiquan; C. Xin; J. Na","Department of Computer Science and Technology, College of Humanities & Sciences, Northeast Normal University, Changchun, Jilin, China; School of Computer Science and Information Technology, Northeast Normal University, Changchun, Jilin, China; School of Computer Science and Information Technology, Northeast Normal University, Changchun, Jilin, China",The 2nd International Conference on Software Engineering and Data Mining,"9 Aug 2010","2010","","","538","543","In this paper, we propose a method of concept similarity calculation based on multi-property ontology, in which the relationship among properties is established under the evolutionary and taxonomy theory. In order to test the accuracy of our concept similarity calculation, we build a model of the multi-property tea ontology at first. Then, to study the tea ontology properties evolution method, we provide property weight priority algorithms. Finally by comparing our calculating result with that in the other three methods, we safely conclude that our calculating accuracy is extremely high, and the result agree with opinions of tea experts.","","978-89-88678-22-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5542864","concept similarity measure;multi-property feature;tea ontology","Ontologies;Computer science;Taxonomy;Information technology;Educational institutions;Testing;Accuracy;Computer architecture;Grid computing;Semantic Web","","","2","14","","9 Aug 2010","","","IEEE","IEEE Conferences"
"Integrating Personality and Learning Profiles of Students in Formative Course Evaluation System for Gaining Insights on Diversity and Improving Learner Experience Analytics Dashboard","J. Wu; M. S. Khalid","Department of Computer Science, Technical University of Denmark, Copenhagen, Denmark; Department of Computer Science, Technical University of Denmark, Copenhagen, Denmark","2024 International Conference on Advances in Computing, Communication, Electrical, and Smart Systems (iCACCESS)","22 Apr 2024","2024","","","1","8","The study address the scarcity of empirical design research on personalized feedback analytics in higher education. It focuses on the redesign and testing of a prototype, aiming to tackle the design dilemmas associated with personality profiles and personalized analytics for both teachers and stu-dents. Building upon the existing Wyblo App, the click-through prototype integrates VARK and MBTI models for learning preferences and personality analysis. Employing a design thinking methodology and a mixed-methods approach, the research defined requirements through interviews, surveys, and existing literature. The prototype's interfaces provided teachers with personality and learning preferences-based feedback analysis, aiding in pedagogical decisions. For students, the analytics offered personalized insights and recommendations compared to peers. The positive feedback from initial testing served as anecdotal evidence, emphasizing the need for broader, authentic testing for reliable generalization. The study envisions inspiring learning technology designers to incorporate personalized insights into course evaluation analytics, fostering reflective practices for both students and teachers based on individualized learning preferences and teaching approaches.","","979-8-3503-5028-9","10.1109/iCACCESS61735.2024.10499505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10499505","Formative evaluation;Personalized feedback;Learning preference;Personality test;Analytics dashboard","Surveys;Analytical models;Education;Buildings;Prototypes;Reliability;Interviews","","","","43","IEEE","22 Apr 2024","","","IEEE","IEEE Conferences"
"The Application of Levenshtein Algorithm in the Examination of the Question Bank Similarity","M. -M. Shao; D. -M. Qian","TianShi Coll., Tianjin, China; TianShi Coll., Tianjin, China",2016 International Conference on Robots & Intelligent System (ICRIS),"5 Dec 2016","2016","","","422","424","The question database similarity detection is a test that can quickly in the huge, find the similarity is very high, which questions repeated also need screening. General use Excel API JAVA program with the distance editing algorithm, to achieve a direct access to the excel question bank. In designing a question bank repeated questions detection algorithm, we have found that based on the Levenshtein algorithm often appear memory overrun and unable to output, to improve exam similarity detection efficiency brings great negative effect. Through the actual operation of the study, using the string segmentation and increase the control statement can be very good to improve the problem, to improve the test efficiency is very favorable.","","978-1-5090-4155-8","10.1109/ICRIS.2016.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7757159","Levenshtein Algorithm;Item Bank;Similarity Measure","Robots;Intelligent systems","","5","","6","IEEE","5 Dec 2016","","","IEEE","IEEE Conferences"
"Automatically Identifying Shared Root Causes of Test Breakages in SAP HANA","G. An; J. Yoon; J. Sohn; J. Hong; D. Hwang; S. Yoo","School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; SnT, University of Luxembourg, Luxembourg; SAP Labs Korea, Seoul, Republic of Korea; SAP Labs Korea, Seoul, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),"17 Jun 2022","2022","","","65","74","Continuous Integration (CI) of a largescale software system such as SAP HANA can produce a non-trivial number of test breakages. Each breakage that newly occurs from daily runs needs to be manually inspected, triaged, and eventually assigned to developers for debugging. However, not all new breakages are unique, as some test breakages would share the same root cause; in addition, human errors can produce duplicate bug tickets for the same root cause. An automated identification of breakages with shared root causes will be able to significantly reduce the cost of the (typically manual) post-breakage steps. This paper investigates multiple similarity functions between test breakages to assist and automate the identification of test breakages that are caused by the same root cause. We consider multiple information sources, such as static (i.e., the code itself), historical (i.e., whether the test results have changed in a similar way in the past), as well as dynamic (i.e., whether the coverage of test cases are similar to each other), for the purpose of such automation. We evaluate a total of 27 individual similarity functions, using realworld CI data of SAP HANA from a six-month period. Further, using these individual similarity functions as in-put features, we construct a classification model that can predict whether two test breakages share the same root cause or not. When trained using ground truth labels extracted from the issue tracker of SAP HANA, our model achieves an F1 score of 0.743 when evaluated using a set of unseen test breakages collected over three months. Our results show that a classification model based on test similarity functions can successfully support the bug triage stage of a CI pipeline.","","978-1-6654-9590-5","10.1145/3510457.3513051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793878","Continuous Integration;Test Similarity;Root Cause Analysis","Root cause analysis;Pipelines;Computer bugs;Debugging;Manuals;Predictive models;Feature extraction","","1","","44","","17 Jun 2022","","","IEEE","IEEE Conferences"
"NiCad+: Speeding the Detecting Process of NiCad","C. Feng; T. Wang; J. Liu; Y. Zhang; K. Xu; Y. Wang","National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China",2020 IEEE International Conference on Service Oriented Systems Engineering (SOSE),"1 Sep 2020","2020","","","103","110","With the development of the Internet and the construction of open source software communities, there has been a surge in open source software. Code Reuse—copy-past and modify open source code, which becomes a convenient choice for developers to save time and reduce labor costs. So there are more and more similar code fragments, code clones, in code project as a popular phenomenon. The code clone may import uncertainties into the program, which is a hot spot for urgent exploration. This paper summarized code clone detection tools and techniques in four categories at present and introduced one detection tool, NiCad, with high recall and precision. However, NiCad is not perfect for large-scale code clone detection scenarios, because NiCad is slow when dealing with large-scale of codes. Therefore, we speeded the detection process of NiCad, and and named the improved tool NiCad+. We greatly improved the efficiency of NiCad without effecting its recall and precision. The time-cost of detecting code clone was remarkable shortened by reducing the matching times. When testing with BigCloneEval, it only takes 28.43% time-cost as original NiCad. When testing with varying input sizes, the speeded detection process performs better than the original one from 10 KLoC (lines of code) to 5 MLoC.","2642-6587","978-1-7281-6972-9","10.1109/SOSE49046.2020.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183401","code clone detection, NiCad, large scale, similarity, open source software","Cloning;Tools;Open source software;Semantics;Syntactics;Heuristic algorithms","","3","","30","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Evaluation of Diversity in Movie Recommendation Systems","R. Chintya; D. S. Kusumo; A. Gandhi","School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia",2024 2nd International Conference on Software Engineering and Information Technology (ICoSEIT),"16 Apr 2024","2024","","","64","69","There are many movie streaming applications today, such as Netflix, Disney Hotstar, Viu, WeTV, iQiYi, and others. The application offers a variety of movies that users can watch, thus confusing users. Each user has a different interest in the content provided. Thus, it is important to use a recommendation system on platforms that provide services to users to provide satisfaction through recommendations so that users feel satisfied. Several studies have focused more on measuring the accuracy aspect of the recommendation system. In comparison, there is an aspect of the recommendation system besides accuracy, namely diversity. Diversity is an aspect that plays a role in providing various recommendations based on users and content on the platform. Evaluation of the diversity aspect of the recommendation system is carried out by implementing the K-means clustering and cosine similarity algorithms using a film dataset. Then, measure it using the Intra-list diversity metric and get a result of 0.65. Tests on users were also carried out regarding user satisfaction with the list of films using a questionnaire so that the median value was 4, and the mode value was between 4 and 5. From the results of the evaluation, it was found that the recommendations provided were diverse and satisfactory for users.","","979-8-3503-1750-3","10.1109/ICoSEIT60086.2024.10497505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10497505","recommendation system;diversity;user satisfaction","Measurement;Clustering algorithms;Motion pictures;Real-time systems;Information technology;Recommender systems;Testing","","","","20","IEEE","16 Apr 2024","","","IEEE","IEEE Conferences"
"Feature Selection with Structural Sparse Mode for Text Categorization","W. Zheng; D. Tang; H. Zhang; H. Tang","College of Software Engineering, Chengdu University of Information Technology, Chengdu, P.R. China; College of Software Engineering, Chengdu University of Information Technology, Chengdu, P.R. China; College of Software Engineering, Chengdu University of Information Technology, Chengdu, P.R. China; College of Metrology & Measurement Engineering, China Jiliang University, Hangzhou, P.R. China",2017 9th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC),"21 Sep 2017","2017","1","","359","362","The grouped structure has successfully been embedded in sparse models for feature selection; however, some groups generated by clustering method might be difficult to interpret their semantic information if the number of words in the group is very large. This paper proposes a novel approach in which a group structure is constructed and its corresponding sparse model is used to select features for text categorization. After variable preselection, an algorithm is developed to generate groups, such that each group only contains two or three closely related words, which can reflect more essential semantic meaningful. Finally, structural sparse mode is used to select feature in wrapper way. The experimental results demonstrate that the proposed method achieves comparable precision and improves the sparsity considerably, which means that the model has better interpretability.","","978-1-5386-3022-8","10.1109/IHMSC.2017.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8047647","Text Categorization;Feature Selection;Structure;Group;Sparse","Text categorization;Semantics;Training;Benchmark testing;Clustering algorithms;Correlation","","","","18","IEEE","21 Sep 2017","","","IEEE","IEEE Conferences"
"Enhanced Sparse based Discriminative Topic Representation for Text Categorization","W. Zheng; W. Zhang; X. Yue; Y. Gao; H. Tang","Software Automatic Generation and Intelligent Service Key Laboratory of SiChuan Province, Chengdu, China; College of Software Engineering, Chengdu University of Information Technology, Chengdu, China; College of Software Engineering, Chengdu University of Information Technology, Chengdu, China; College of Software Engineering, Chengdu University of Information Technology, Chengdu, China; College of Engineering, Sichuan Normal University, Chengdu, China",2019 6th International Conference on Systems and Informatics (ICSAI),"27 Feb 2020","2019","","","404","408","This paper presents an enhanced sparse based discriminative topic representation method for text categorization. By constructing category center vectors and combining with the latent Dirichlet allocation model, a more discriminative dictionary is obtained, which can describe the relationship between topic and word well. Furthermore, an enhanced sparse representation of documents can be generated with a L1/2 regularization in order to achive a good relationship between document and topic. The experimental results show that our proposed approach achieves more stable classification performance and obtains more high sparse degree.","","978-1-7281-5256-1","10.1109/ICSAI48974.2019.9010289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010289","Text Categorization;Enhanced Sparse;Topic;Representation","Semantics;Dictionaries;Open systems;Text categorization;Training;Sparse matrices;Large scale integration","","","","19","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Research on the parallel algorithm for self-similar network traffic simulation","H. Zhang; J. Xu; J. Tian","Institute of Machine Intelligence, Nankai University, Tianjin, China; Institute of Machine Intelligence, Nankai University, Tianjin, China; Institute of Machine Intelligence, Nankai University, Tianjin, China",2009 2nd IEEE International Conference on Computer Science and Information Technology,"11 Sep 2009","2009","","","355","359","As the Web application is world wide used, system' s performance, especially reliability, becomes more significant. Traditional performance testing tools such as QA Load and LoadRunner will generate the stress data with the fixed scale. But in the real time, network traffic is model-based. We focus on generating test data to simulate network traffic accurately for Web application reliability testing. The statistical results of network traffic show that the property of the self-similarity is ubiquitous in Web environment. So generating self-similar network traffic is demanded. But nowadays, there is a bottleneck in generating network traffic by single computer. We need a parallel method to solve this problem. In this paper we propose a distributed system based on a parallel algorithm to generate self-similar traffic using the Fraction Gaussian Noise (FGN) model. The experiment results show that the network traffic generated by the distributed system has self-similar property.","","978-1-4244-4519-6","10.1109/ICCSIT.2009.5234666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234666","Parallel Algorithm;Distributed System;Generating Network Traffic;Self-similar Model","Parallel algorithms;Telecommunication traffic;Traffic control;Testing;Stress;Computational modeling;Application software;Computer network reliability;Computer networks;Pervasive computing","","1","","6","IEEE","11 Sep 2009","","","IEEE","IEEE Conferences"
"Exploiting Wireless Links Diversity in Software-Defined IEEE 802.11 Enterprise Wlan","M. F. Monir; F. Granelli","Dept. of Computer Science and Engineering, Independent University, Bangladesh Dhaka, Bangladesh; Dept. of Information Engineering and Computer Science, University of Trento (UniTrento), Trento, Italy",GLOBECOM 2020 - 2020 IEEE Global Communications Conference,"25 Jan 2021","2020","","","1","6","Adoption of wireless technologies is rising dramatically. As traffic load is continuously rising with the rapid growth of user scale and mobile services, today's Wireless Local Area Network (WLAN) enterprise is facing a series of crucial challenges such as packet loss, interference, poor bandwidth etc. This is because of the inherent design of the IEEE 802.11 architecture. Enabling Software Defined Networking (SDN) in Wi-Fi enterprise would solve the puzzle of current WLAN technology limitations and ensure high scalability and performance. While standardization is focusing on performance enhancement by evolving the Wi-Fi MAC/PHY protocols, in this work we focus on bandwidth optimization in IEEE S02.11 by using Software Defined Networking (SDN). We analyze various programming abstractions for WLANs and exploit the wireless link diversity in Software Defined Enterprise-WLAN with the support of the 5GEMPOWERSDN platform. A multiple uplink mechanism between user devices and Access Points (APs) is proposed that allows a remarkable performance improvement in the network in terms of throughput and packet delivery ratio.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9322469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9322469","Software Defined Networking (SDN);Software Defined Wireless Networks (SDWN);WLANs;network performance;programming abstractions","Uplink;Wireless fidelity;Wireless communication;Wireless networks;Programming;IEEE 802.11 Standard;Throughput","","2","","14","IEEE","25 Jan 2021","","","IEEE","IEEE Conferences"
"A methodology for using edges to measure structural and semantic similarity of XML documents","Hong-Jun Qiu; Wen-Jing Yu","School of Engineering, Shantou University, Shantou, China; South China Institute of Software Engineering, GZU, Guangzhou, China",2009 International Conference on Machine Learning and Cybernetics,"25 Aug 2009","2009","3","","1653","1658","XML is a standard data representation format that comes with its own structure and semantics. The similarity measurement of XML should include data, structure and semantics, but the semantic measurement has not yet received strong attention. Aiming at the product structure domain, a methodology for using edges to measure structural and semantic similarity of XML is presented in this paper. Based on the semantics of product structure described in XML, the edge constraint is used to improve the structural similarity efficiency. An effective weight mechanism interrelated with XML model hiberarchy is adopted to address the semantics problem, to enhance the similarity precision. The implement pseudocode is presented. The experimental tests demonstrate that the proposed method can efficiently measure the structural and semantic similarity of product structures described in XML.","2160-1348","978-1-4244-3702-3","10.1109/ICMLC.2009.5212295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5212295","XML;Product structure;Structural and semantic similarity;Measurement","XML;Machine learning algorithms;Machine learning;Cybernetics;Data engineering;Computational complexity;Assembly;Software measurement;Measurement standards;Software standards","","","","8","IEEE","25 Aug 2009","","","IEEE","IEEE Conferences"
"Unique applications of reverberation techniques","K. A. Brezinski; D. R. Kempf","Aircraft Division, Naval Air Warfare Center, Patuxent River, MD, USA; Aircraft Division, Naval Air Warfare Center, Patuxent River, MD, USA",2001 IEEE EMC International Symposium. Symposium Record. International Symposium on Electromagnetic Compatibility (Cat. No.01CH37161),"7 Aug 2002","2001","2","","732","733 vol.2","Box level radiated susceptibility was required on a large, highly interconnected avionics system. Traditional laboratory testing compliance needed to be demonstrated, however, the complexity of the system and necessary support equipment prohibited normal approaches in a laboratory environment. This paper discusses the testing performed using reverberation techniques inside the aircraft and also outside the aircraft in a shielded hangar. The paper also discusses the innovative testing techniques and departures from traditional rules and paradigms of the trade.","","0-7803-6569-0","10.1109/ISEMC.2001.950464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=950464","","Reverberation;Aircraft;Frequency;Aerospace electronics;Tuners;System testing;Performance evaluation;Software testing;Rivers;Wiring","","","","","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Diversity TMR: Proof of concept in a mixed-signal case","G. de M. Borges; L. F. Gonçalves; T. R. Balen; M. Lubaszewski","Departamento de Engenharia Elétrica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil; Departamento de Engenharia Elétrica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil; Departamento de Engenharia Elétrica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil; Departamento de Engenharia Elétrica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil",2010 11th Latin American Test Workshop,"19 Aug 2010","2010","","","1","6","In this paper a design diversity fault tolerance technique is applied to a mixed-signal (MS) system. Three different implementations of a second order low-pass filter (which perform the same transfer function) associated to a majority voter are used to build the TMR scheme. The whole system is prototyped by using a programmable mixed-signal device. Some functional faults are injected into the circuit blocks and practical measurements are made on the prototyped system. Results show that the design diversity TMR is a feasible technique that can increase reliability of some classes of state-of-art MS circuits.","2373-0862","978-1-4244-7785-2","10.1109/LATW.2010.5550343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5550343","fault tolerance;mixed-signal;redundancy;design diversity","Low pass filters;Tunneling magnetoresistance;Software;Circuit faults;Hardware;Finite impulse response filter","","4","","17","IEEE","19 Aug 2010","","","IEEE","IEEE Conferences"
"Dual downlink signals level balancing methodology for LTE user equipment test conformance","G. S. Lau; R. B. Ahmad","School of Computer & Communication Engineering, University Malaysia Perlis, Arau, Perlis, Malaysia; School of Computer & Communication Engineering, University Malaysia Perlis, Arau, Perlis, Malaysia","2016 International Conference on Robotics, Automation and Sciences (ICORAS)","9 Mar 2017","2016","","","1","5","Receiver diversity related conformance tests of 2G/3G cellular devices either with multipath propagation or not typically would utilize RF channel emulator (or RF fader) to balance the dual downlink signal levels before reception by dual receiver antennas of device. The RF fader has capability to close loop output power level, so it allows user to set the desired output level. With this capability, dual downlink signal inputs into the fader can be level adjusted in order to get the balance and similar output level of both signals from fader. For receiver diversity tests with only static propagation which is default to LTE device, since it is in static propagation, fader would be underutilized for only diversity purpose. To be cost save, such balancing approach could be alternatively replaced with discrete components and software algorithm. A new setup is designed with this approach to balance the dual downlink levels in order to comply the receiver test conformance. This paper will describe about the methodology.","","978-1-5090-6205-8","10.1109/ICORAS.2016.7872613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872613","LTE;Dual Downlink;Balancing;User equipment;Receiver diversity","Attenuators;Receivers;Downlink;Attenuation;Radio frequency;Switches;Software","","","","5","IEEE","9 Mar 2017","","","IEEE","IEEE Conferences"
"Data diverse fault tolerant architecture for component based systems","A. Sil; O. Bandyopadhyay; N. Chaki","National Institute of Technical Teacher''s Training and Research, Kolkata, India; National Institute of Technical Teacher''s Training and Research, Kolkata, India; University of Calcutta, Kolkata, India",2009 World Congress on Nature & Biologically Inspired Computing (NaBIC),"22 Jan 2010","2009","","","942","946","Of late, component based software design has become a major focus in software engineering research and computing practice. These software components are used in a wide range of applications some of which may have mission critical requirements. In order to achieve required level of reliability, these component-based designs have to incorporate special measures to cope up with software faults. This paper presents a fault tolerant component based data driven architecture that is based on C2 architectural framework and implements data diverse fault tolerance strategies. The proposed design makes a trade-off between platform flexibility, reliability and efficiency at run time and exhibits its ability to tolerate faults in a cost effective manner. Application of proposed design is exhibited with a case study.","","978-1-4244-5053-4","10.1109/NABIC.2009.5393876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5393876","","Fault tolerant systems;Connectors;Fault tolerance;Mission critical systems;Computer architecture;Software design;Costs;Testing;Software engineering;Application software","","1","","15","IEEE","22 Jan 2010","","","IEEE","IEEE Conferences"
"The Impact of Diversity on Online Ensemble Learning in the Presence of Concept Drift","L. L. Minku; A. P. White; X. Yao","Centre of Excellence of Research in Computational Intelligence and Applications (CERCIA), School of Computer Science, University of Binningham, Birmingham, UK; School of Mathematics and Statistics, University of Binningham, Birmingham, UK; Centre of Excellence of Research in Computational Intelligence and Applications (CERCIA), School of Computer Science, University of Binningham, Birmingham, UK",IEEE Transactions on Knowledge and Data Engineering,"18 Mar 2010","2010","22","5","730","742","Online learning algorithms often have to operate in the presence of concept drift (i.e., the concepts to be learned can change with time). This paper presents a new categorization for concept drift, separating drifts according to different criteria into mutually exclusive and nonheterogeneous categories. Moreover, although ensembles of learning machines have been used to learn in the presence of concept drift, there has been no deep study of why they can be helpful for that and which of their features can contribute or not for that. As diversity is one of these features, we present a diversity analysis in the presence of different types of drifts. We show that, before the drift, ensembles with less diversity obtain lower test errors. On the other hand, it is a good strategy to maintain highly diverse ensembles to obtain lower test errors shortly after the drift independent on the type of drift, even though high diversity is more important for more severe drifts. Longer after the drift, high diversity becomes less important. Diversity by itself can help to reduce the initial increase in error caused by a drift, but does not provide the faster recovery from drifts in long-term.","1558-2191","","10.1109/TKDE.2009.156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5156502","Concept drift;online learning;neural network ensembles;diversity.","Machine learning;Testing;Application software;Training data;Information filtering;Industrial training;Neural networks;Time factors;Computer industry;Industrial control","","325","","51","IEEE","6 Jul 2009","","","IEEE","IEEE Journals"
"Feedback-directed exploration of web applications to derive test models","A. M. Fard; A. Mesbah","University of British Columbia Vancouver, BC, Canada; University of British Columbia Vancouver, BC, Canada",2013 IEEE 24th International Symposium on Software Reliability Engineering (ISSRE),"2 Jan 2014","2013","","","278","287","Dynamic exploration techniques play a significant role in automated web application testing and analysis. However, a general web application crawler that exhaustively explores the states can become mired in limited specific regions of the web application, yielding poor functionality coverage. In this paper, we propose a feedback-directed web application exploration technique to derive test models. While exploring, our approach dynamically measures and applies a combination of code coverage impact, navigational diversity, and structural diversity, to decide a-priori (1) which state should be expanded, and (2) which event should be exercised next to maximize the overall coverage, while minimizing the size of the test model. Our approach is implemented in a tool called FEEDEx. We have empirically evaluated the efficacy of FEEDEx using six web applications. The results show that our technique is successful in yielding higher coverage while reducing the size of the test model, compared to classical exhaustive techniques such as depth-first, breadth-first, and random exploration.","2332-6549","978-1-4799-2366-3","10.1109/ISSRE.2013.6698880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698880","model generation;web app;coverage;testing;diversity","Portable document format;IEEE Xplore","","22","1","","IEEE","2 Jan 2014","","","IEEE","IEEE Conferences"
"Analysis of Automated Evaluation for Multi-document Summarization Using Content-Based Similarity","L. -Q. Qiu; B. Pang","State Key Laboratory of Software Development Environment, Beihang University, China; State Key Laboratory of Software Development Environment, Beihang University, China",Second International Conference on the Digital Society,"25 Feb 2008","2008","","","60","63","We introduce an automated evaluation method based on content similarity, and construct a vector space of words, on which we compute cosine similarity of automated summaries and human summaries. The method is tested on DUC 2005 data, and produces acceptable results, which may avoid some shortcomings of n-gram. We also test the effects of stopwords and stemming.","","978-0-7695-3087-1","10.1109/ICDS.2008.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4456020","automated evaluation;multi-document summarization;content -based similarity","Humans;Testing;NIST;Functional analysis;Programming;Vocabulary;Natural languages;Performance evaluation;Costs;Large-scale systems","","","","5","IEEE","25 Feb 2008","","","IEEE","IEEE Conferences"
"Harfu Jar Detection System In Al-Quran Using Pierce Similarity Algorithm as a Basic Learning Media of Arabic Language","M. Jannah; A. A. Nababan","Software Engineering, STMIK Pelita Nusantara Medan, Indonesia; Software Engineering, STMIK Pelita Nusantara Medan, Indonesia","2020 3rd International Conference on Mechanical, Electronics, Computer, and Industrial Technology (MECnIT)","14 Aug 2020","2020","","","349","354","Arabic language has a very broad language structure, we need to know the most dominant Arabic language found in the Al-Quran, so to know the interpretation (Tafsir) of the Al-Quran, we must learn Arabic language. One of the basic parts of Arabic language is nahwu science, nahwu is the study of laying row in Arabic such as the kasra, dhamma and fatta. Jar letters is one of basic part in nahwu science. In this research, a detection system about Jar patterns will be developed with image processing approach. This system was built using Delphi XE with 7 sample of Jar letters where it will be used in the training process. The process of detecting Jar patterns is using a method that will find the distance value from training and testing process on the Al-Quran image. Training process stage begins with the bitmap extension file of the original image,then change the size to gray scale level and convolution edge detection so that it will produce a vector value for each Jar pattern. Testing process will be use the Pierce Similarity Algorithm to measure the distance value of the Jar pattern to be recognized. The percentage of system detection results obtained, the pierce similarity method is able to recognize a Jar pattern of 60-80%.","","978-1-7281-7403-7","10.1109/MECnIT48290.2020.9166632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166632","Image Processing;Pattern Recognition;Pierce Similarity;Jar Letter","","","","","16","IEEE","14 Aug 2020","","","IEEE","IEEE Conferences"
"Hyperspectral image classification using Fisher criterion-based Gabor cube selection and multi-task joint sparse representation","S. Jia; Y. Xie; L. Shen; L. Deng","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Information Engineering, Shenzhen University, Shenzhen, China",2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS),"23 Oct 2017","2015","","","1","4","Recently, Gabor wavelet transformation has been introduced for feature extraction of hyperspectral imagery. Due to the discriminative power of obtained Gabor features, high classification performance has been achieved. However, thousands of Gabor features cause too much burden for onboard computation, limiting the efficiency of the method. In fact, not all features have a positive effect on classification. In this paper, we have proposed a Gabor cube selection-based Multi-task Joint Sparse Representation framework, abbreviated as MT-SG, for hyperspectral imagery classification. Firstly, based on the Fisher discrimination criterion, the most representative Gabor cubes for each class have been picked out. Next, under multi-task joint sparse representation framework, a coefficient vector can be obtained for each test sample with the selected cube features, which can be applied for the following residual-based classification. Experimental results on real hyperspectral data have demonstrated the feasibility and efficiency of the proposed method.","2158-6276","978-1-4673-9015-6","10.1109/WHISPERS.2015.8075364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8075364","Hyperspectral imagery;Gabor wavelet;multi-task joint sparse representation","Training;Hyperspectral imaging;Feature extraction;Three-dimensional displays;Transforms;Limiting","","2","","10","IEEE","23 Oct 2017","","","IEEE","IEEE Conferences"
"Automated Repair of Java Programs with Random Search via Code Similarity","H. Cao; F. Liu; J. Shi; Y. Chu; M. Deng","College of Information Science and Engineering, Henan University of Technology, zhengzhou; College of Information Science and Engineering, Henan University of Technology, zhengzhou; College of Information Science and Engineering, Henan University of Technology, zhengzhou; College of Information Science and Engineering, Henan University of Technology, zhengzhou; College of Information Science and Engineering, Henan University of Technology, zhengzhou","2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)","1 Apr 2022","2021","","","470","477","Automatic program repair is a cutting-edge research direction in software engineering in recent years. The existing program repair techniques based on genetic programming suffer from requiring verification of a large number of candidate patches, which consume a lot of computational resources. We instead propose Random search via Code Similarity based automate program Repair (RCSRepair). First, we use test filtering and test case prioritization techniques in fault localization to reduce and restructure test cases. Second, a combination of random search and code similarity is used to generate patches. Finally, overfitting detection is performed on the patches that pass the test cases to improve the quality of the patch. The experimental results show that our approach can successfully fix 54 bugs of 224 real-world bugs in Defects4J and has outperform the compared approaches.","2693-9371","978-1-6654-7836-6","10.1109/QRS-C55045.2021.00075","National Natural Science Foundation of China(grant numbers:61602154,61340037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9742203","program repair;random search;test case prioritization;patch overfitted","Java;Software maintenance;Codes;Filtering;Computer bugs;Software quality;Maintenance engineering","","1","","19","IEEE","1 Apr 2022","","","IEEE","IEEE Conferences"
"Researches of Sentence Similarity Computation Method Based on the Enhanced Petri Net","F. Chen; W. Chen","Computer Teaching and Experiment Center, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Computer Teaching and Experiment Center, Xi'an Jiaotong University, Xi'an, Shaanxi, China",2009 International Conference on Computational Intelligence and Software Engineering,"28 Dec 2009","2009","","","1","5","In the field of natural language processing (NPL), sentence similarity computation has a wide application. The key of sentence similarity computation is to grasp the characteristics and the meaning of the sentence quickly and accurately. In this paper, we present a new and advanced sentence similarity computation model based on the enhanced Petri net, which is mainly for the Chinese sentence. The basic idea of this model is utilizing semantic properties to expand the Petri net and reconstruct Petri net to an opening structure. The deduction method of this model is equation of state, which make the judgment of sentence similarity closer to the process of human thought. Moreover, we have tested the sentence similarity computation methods and algorithms. It proves that this method covers most aspects of sentence similarity computation and has a superior performance during experiments.","","978-1-4244-4507-3","10.1109/CISE.2009.5363839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363839","","Humans;Education;Equations;Uncertainty;Abstracts;Natural language processing;Application software;Computational modeling;Testing;Statistics","","","","8","IEEE","28 Dec 2009","","","IEEE","IEEE Conferences"
"An Application of Multicriteria Weighted Graph Similarity Method to Social Networks Analyzing","Z. Tarapata; R. Kasprzyk","Faculty of Cybernetics, Military University of Technology, Warsaw, Poland; Faculty of Cybernetics, Military University of Technology, Warsaw, Poland",2009 International Conference on Advances in Social Network Analysis and Mining,"4 Sep 2009","2009","","","366","368","In the paper a concept of multicriteria weighted graphs similarity (MWGSP) method and its application to examine some properties of social networks is considered. The approach extends known approaches based on the graph similarity with two features: (1) the similarity is calculated as structural and non-structural (quantitative) in weighted graph, (2) choice of the most similar graph (subgraph) to graph (subgraph) representing examined objects is based on multicriteria decision. We test our similarity measures on email network for which the expected results are known, and on the terrorist net that prepared and executed September 11, 2001 attacks.","","978-0-7695-3689-7","10.1109/ASONAM.2009.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231827","social networks;weighted graph similarity;multicriteria optimization;early warning system","Social network services;Terrorism;Chemical analysis;Paper technology;Cybernetics;Electronic mail;Testing;Computer errors;Histograms;Application software","","8","","7","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"An Approach of Semantic Similarity Measure between Ontology Concepts Based on Multi Expression Programming","S. Xia; Z. Hu; Q. Niu","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China",2009 Sixth Web Information Systems and Applications Conference,"31 Dec 2009","2009","","","184","188","To improve accuracy of semantic similarity measure between ontology concepts, four main factors that impact on semantic similarity measure is taken into account. They are semantic distance, semantic depth, semantic coincidence and semantic density. Firstly, they were preprocessed to obtain four basic methods for calculating semantic similarity. And then Multi Expression Programming algorithm was adopted to combine and optimize the four basic methods. Thus, an approach of semantic similarity measure between ontology concepts based on Multi Expression Programming is proposed. At last, the approach is tested using dataset extracted from WordNet. The experiment result shows that the approach can be able to exclude the influence of non-key factor and enhance accuracy of semantic similarity measure.","","978-0-7695-3874-7","10.1109/WISA.2009.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368079","Ontology;hierarchical structure;semantic similarity;Multi Expression Programming (MEP)","Ontologies;Evolutionary computation;Information retrieval;Information systems;Application software;Computer science;Optimization methods;Testing;Genetic programming;Information technology","","4","1","10","IEEE","31 Dec 2009","","","IEEE","IEEE Conferences"
"Two Level Question Classification Based on SVM and Question Semantic Similarity","J. Fu; Y. Qu; Z. Wang","School of Computer Science & Technology, Beijing Institute of Technology, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Mathematics and Computer Science, Harbin University, Harbin, China",2009 International Conference on Electronic Computer Technology,"27 Feb 2009","2009","","","366","370","Question classification is very important in question answering system. This paper presents our research about question classification in a real-world on-line interactive question answering system in computer service & support domain. In the domain, questions are divided into 15 cursory categories and 220 sub-categories. The difference of this system is that standard question sentences represent the subcategories rather than only classification criterion. For the special situation, the two level question classification method is present in the paper. Support vector machine method is adopted to train a classifier on coarse categories; question semantic similarity model is used to classify the question into sub-categories. The lexical feature and domain ontology concept hierarchy is constructed and exploited to enhance the expression capacity of the feature characteristic for both feature selection for SVM and question semantic similarity computing. When trained and tested on the 11000 question instances in the domain, our approach reaches an accuracy up to 91.5%, which outperforms the result of the baseline.","","978-0-7695-3559-3","10.1109/ICECT.2009.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4795985","question classification;SVM;question semantic similarity","Support vector machines;Support vector machine classification;Computer science;Ontologies;Information technology;Mathematics;Testing;Application software;Intelligent robots;Machine learning","","2","","6","IEEE","27 Feb 2009","","","IEEE","IEEE Conferences"
"When Does ""Diversity""' in Development Reduce Common Failures? Insights from Probabilistic Modeling","K. Salako; L. Strigini","Centre for Software Reliability, City University, London, United Kingdom; Centre for Software Reliability, City University, London, United Kingdom",IEEE Transactions on Dependable and Secure Computing,"9 Apr 2014","2014","11","2","193","206","Fault tolerance via diverse redundancy, with multiple ""versions""' of a system in a redundant configuration, is an attractive defence against design faults. To reduce the probability of common failures, development and procurement practices pursue ""diversity""' between the ways the different versions are developed. But difficult questions remain open about which practices are more effective to this aim. About these questions, probabilistic models have helped by exposing fallacies in ""common sense"" judgements. However, most make very restrictive assumptions. They model well scenarios in which diverse versions are developed in rigorous isolation from each other: A condition that many think desirable, but is unlikely in practice. We extend these models to cover nonindependent development processes for diverse versions. This gives us a rigorous way of framing claims and open questions about how best to pursue diversity, and about the effects--negative and positive--of commonalities between developments, from specification corrections to the choice of test cases. We obtain three theorems that, under specific scenarios, identify preferences between alternative ways of seeking diversity. We also discuss nonintuitive issues, including how expected system reliability may be improved by creating intentional ""negative""' dependences between the developments of different versions.","1941-0018","","10.1109/TDSC.2013.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6579596","Common-mode failure;software diversity;fault tolerance;multiversion software;probability of failure on demand;reliability","Phase frequency detector;Software;Reliability;Random variables;Computational modeling;Correlation;Probabilistic logic","","9","","24","IEEE","15 Aug 2013","","","IEEE","IEEE Journals"
"Detecting functionally similar code within the same project","R. Tajima; M. Nagura; S. Takada","Keio Gijuku Daigaku, Minato-ku, Tokyo, JP; Nihon Daigaku, Chiyoda-ku, Tokyo, JP; Keio Gijuku Daigaku, Minato-ku, Tokyo, JP",2018 IEEE 12th International Workshop on Software Clones (IWSC),"29 Mar 2018","2018","","","51","57","Multiple developers often take part in a software development project. Although these developers are collaborating towards the development within the same project, each developer creates code on their own. This may lead to duplicate or similar code appearing in different parts of the software. Such code should be removed to improve maintainability. This paper proposes an approach to automatically detect such code, which we shall call functionally similar code. The unit of detection is at the method level, and we focus on input/output and the method structure using program dependence graph. We show the results of applying our approach on open source software.","2572-6587","978-1-5386-6430-8","10.1109/IWSC.2018.8327319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327319","Functionally similar code detection;Random testing;Program dependence graph","Cloning;Testing;Databases;Software;Semantics;Data mining;Java","","5","","","IEEE","29 Mar 2018","","","IEEE","IEEE Conferences"
"A Simple and Efficient Merge of Two Sparse 3D Models with Overlapped Images","H. Lim; S. -h. Jung; J. Seo","Immersive Media Research Section, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; Immersive Media Research Section, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea; Immersive Media Research Section, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea",2019 International Conference on Information and Communication Technology Convergence (ICTC),"27 Dec 2019","2019","","","1474","1476","One of the efficient approaches to generate a sparse 3D model is to incrementally merge the separately reconstructed 3D sub-models. This paper presents a simple and efficient method to merge two sparse 3D models having overlapped images. In the proposed method, first, a global similarity transform matrix between the two model is computed from the 3D points reprojected from the overlapped images. After that, the camera parameters of the overlapped images and the reprojected 3D points in one model are refined using the obtained global similarity transform matrix. A precise similarity transform matrix between the two 3D models is then estimated from the inlier 2D-3D correspondences to accurately align and merge the two 3D models. Experimental results show that the proposed method merge the two models more accurately compared to the existing merge method embedded in the state-of-the-art incremental Structure from Motion open software.","2162-1233","978-1-7281-0893-3","10.1109/ICTC46691.2019.8939592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939592","3D model merge;Sparse 3D reconstruction;Similarity transform matrix","Three-dimensional displays;Solid modeling;Transforms;Computational modeling;Sparse matrices;Cameras;Computer vision","","2","","9","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"Human action recognition based on sparse representation induced by L1/L2 regulations","Z. Gao; A. -a. Liu; H. Zhang; G. -p. Xu; Y. -b. Xue","Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Department of Electronic Information Engineering, Tianjin University, Tianjin, China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Key Laboratory of Computer Vision and System, Ministry of Education, Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China",Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012),"14 Feb 2013","2012","","","1868","1871","Sparse representation based classification (SRC) has been widely used for face recognition (FR). Although SRC algorithm is also adopted in human action recognition, the evaluations of different regular terms have not been given. In this paper, we will discuss and evaluate the role of different regular terms of SRC in human action recognition, after that, we propose human action recognition algorithm based on sparse representation induced by L1 and L2 regulations - called SR-L12. Experiments on well known KTH action dataset show that SR-L12 is much better than that of nearest neighbor (NN), nearest subspace (NS), full-space (NF), SRC and collaborative representation classification (CRC). Moreover, the proposed method is comparable to most of state-of-the-art algorithms for human action recognition.","1051-4651","978-4-9906441-0-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6460518","","Humans;Accuracy;Noise measurement;Testing;Training;Classification algorithms;Feature extraction","","","","14","","14 Feb 2013","","","IEEE","IEEE Conferences"
"A Weighted Raw Reputation Generating Approach Based on Similarity","J. Zhang; X. Zhang; J. Zhu; J. Xu","Dept. of Comput. Sci., Nankai Univ., Tianjin, China; Dept. of Comput. Sci., Nankai Univ., Tianjin, China; Dept. of Comput. Sci., Nankai Univ., Tianjin, China; Dept. of Comput. Sci., Nankai Univ., Tianjin, China",2010 Second International Conference on Communication Software and Networks,"25 Mar 2010","2010","","","136","140","In the anti-spam field, raw reputation is the current mailing behavior of one email server. Meanwhile, it is the foundation of the distributed spam processing technology based on reputation mechanism. In this paper, the advantages and disadvantages of the existing several raw reputation generating approaches are analyzed, and a new method: MSGuard is proposed. MSGuard is a weighted raw reputation generating approach based on similarity. Simulation results demonstrate that: in the scenario which the malicious nodes provide inauthentic evaluations, the average differences between the expectations and the raw reputations calculated by TrustGuard and MSRep are 0.4 and 0.5 respectively. And the difference of either EigenTrust or MSGuard is only approximate 0.05. In the scenario which the collusive and disguised malicious nodes exist, the difference between the expectation and the raw reputation calculated by EigenTrust is 0.25, and it is less than 0.1 by MSGuard. MSGuard can reflect nodes' actual mailing situations more accurately.","","978-1-4244-5727-4","10.1109/ICCSN.2010.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5437617","spam;raw reputation;similarity;inauthentic evaluation;weighting factor","Internet;Computer science;Network servers;Testing;Algorithm design and analysis;Arithmetic;Search engines;Protection;Feedback","","","","12","IEEE","25 Mar 2010","","","IEEE","IEEE Conferences"
"Enhancing a Keyword Search Using Segmentation and Similarity Measure Algorithms: A Case Study of Phuket Attractions","K. Chochiang; W. Khuanwilai","College of Computing, Prince of Songkla University, Phuket, Thailand; College of Computing, Prince of Songkla University, Phuket, Thailand",2019 16th International Joint Conference on Computer Science and Software Engineering (JCSSE),"14 Oct 2019","2019","","","26","31","A system to support an incorrectly typed input keyword search in Thai language is proposed in this work. Segmentation and similarity measure algorithms are employed to enhance the traditional keyword search engine. The average of six similarity measure algorithms including Levenshtein, Overlap (bi-gram), Overlap (tri-gram), Jaccard, Dice (bi-gram), and Dice (tri-gram). The prototype is tested by 93 subjects including both native and non-native Phuket subjects. Top twenty-five Phuket attraction names are used as the data set. The experimental results show that the proposed system can improve the efficiency of the original search from 54.4% to 91.6% while the execution time of the extra steps can be negligible. Moreover, Bi-gram algorithms seem to outperform their Tri-gram counterpaths in this experiment and Jaccard seems to be outperformed by other similarity measure algorithms.","2642-6579","978-1-7281-0719-6","10.1109/JCSSE.2019.8864176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864176","Search engine;Incorrect keyword;Dice;Overlap;Levenshtein;Jaccard","Keyword search;Sea measurements;Engines;Current measurement;Testing;Prototypes;Search engines","","","","12","IEEE","14 Oct 2019","","","IEEE","IEEE Conferences"
"A Divide and Conquer Approach to All Solutions Satisfiability Problem","X. Ren; W. Guo; Z. Mo; W. Tian","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China",2018 IEEE 4th International Conference on Computer and Communications (ICCC),"1 Aug 2019","2018","","","2590","2595","SAT, is one of the fundamental topics in computer science, which has a long history in AI. As a variant of SAT, the all solutions satisfiability problem(AllSAT) is widely used in the field of electronic design automation. It is to generate all or part solutions of a given SAT instance. The computational complexity of AllSAT is higher than general SAT, which leads to less research related and poor performance of existing AllSAT solvers. In this paper, we propose to solve AllSAT by a divide-and-conquer-based approach called DIV2, which solve more instances within the time limit. Besides, we present a segmentation strategy for DIV2, called Jaccard similarity segmentation, which improves the efficiency of DIV2. The experimental result shows that the method proposed in this paper, has a better performance than the state-of-the-art algorithms, with regarding to the number of instances solved and the total number of solutions found for SAT 2014 competition benchmark.","","978-1-5386-8339-2","10.1109/CompComm.2018.8780746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780746","Satisfiability problem;AllSAT solvers;Divide and Conquer;Similarity Segmentation;Jaccard similarity coefficient","Computational complexity;IEEE Sections;Software engineering;Computer science;Design automation;Benchmark testing","","3","","22","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"A software tool for compressive sensing based time-frequency analysis","A. Draganie; M. Brajović; I. Orović; S. Stanković","Univerzitet Crne Gore, Podgorica, ME; Faculty of Electrical Engineering, University of Montenegro, Podgorica, Montenegro; Faculty of Electrical Engineering, University of Montenegro, Podgorica, Montenegro; Faculty of Electrical Engineering, University of Montenegro, Podgorica, Montenegro",2015 57th International Symposium ELMAR (ELMAR),"23 Nov 2015","2015","","","45","48","A software tool that implements Compressive sensing based time-frequency analysis and performs instantaneous frequency estimation, is proposed and described in the paper. A focus is made on the signals with fast varying instantaneous frequency (IF), which can be accurately estimated using complex-time distribution. Therefore, the proposed tool offers different possibilities to adjust parameters of complex-lag distributions in order to comply with fast-varying IF laws. Moreover, beside the standard implementation based on the full set of samples, a compressive sensing based time-frequency approach is included in order to obtain sparse time-frequency representation. Sparse time-frequency representation is reconstructed from very few ambiguity domain observations. The tool performance is tested on real and synthetic signals.","","978-953-184-209-9","10.1109/ELMAR.2015.7334492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334492","Compressive Sensing;Complex-time Distribution;Ambiguity Domain;Instantaneous Frequency estimation;Sparse Representation","Time-frequency analysis;Estimation;Software tools;Compressed sensing;Standards;Kernel","","2","","20","","23 Nov 2015","","","IEEE","IEEE Conferences"
"Handwritten Bangla digit recognition using Sparse Representation Classifier","H. A. Khan; A. A. Helal; K. I. Ahmed","Department of Electrical and Electronic Engineering, United International University, Dhaka, Bangladesh; Department of Electrical and Electronic Engineering, United International University, Dhaka, Bangladesh; Department of Electrical and Electronic Engineering, United International University, Dhaka, Bangladesh","2014 International Conference on Informatics, Electronics & Vision (ICIEV)","10 Jul 2014","2014","","","1","6","We present a framework for handwritten Bangla digit recognition using Sparse Representation Classifier. The classifier assumes that a test sample can be represented as a linear combination of the train samples from its native class. Hence, a test sample can be represented using a dictionary constructed from the train samples. The most sparse linear representation of the test sample in terms of this dictionary can be efficiently computed through ℓ1-minimization, and can be exploited to classify the test sample. We applied Sparse Representation Classifier on the image zone density, an image domain statistical feature extracted from the character image, to classify the Bangla numerals. This is a novel approach for Bangla Optical Character Recognition, and demonstrates an excellent accuracy of 94% on the off-line handwritten Bangla numeral database CMATERdb 3.1.1. This result is promising, and should be investigated further.","","978-1-4799-5180-2","10.1109/ICIEV.2014.6850817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6850817","Sparse Representation Classifier;Bangla Optical Character Recognition;Handwritten character recognition;Digit recognition","Feature extraction;Accuracy;Vectors;Training;Optical character recognition software;Character recognition;Image segmentation","","34","","15","IEEE","10 Jul 2014","","","IEEE","IEEE Conferences"
"Improved OMP selecting sparse representation used with face recognition","J. Zhang; K. Yan; Z. He","Bio-computing Research Center, Harbin Institute of Technology, Shenzhen, P.R. China; Bio-computing Research Center, Harbin Institute of Technology, Shenzhen, P.R. China; Key Laboratory of Network Oriented Intelligent Computation, Shenzhen, P.R. China",2014 IEEE 5th International Conference on Software Engineering and Service Science,"23 Oct 2014","2014","","","589","592","With the worldwide strengthening of anti-terrorism and other identity verification, the products based on face recognition are used in real life more and more. The recognition as an important ways has become the focus of academic research in the world. Face recognition accuracy can be improved by increasing the number of training samples, but increasing number will result in a large computing complexity. In recent years, the sparse representation becomes hot in face recognition. In this paper, we propose an energy constraint orthogonal matching pursuit (ECOMP) algorithm for sparse representation in face recognition. It selects a few training samples and hierarchical structure for face recognition. In this method, we re-select training samples by ECOMP, calculate the weight of all the selected training samples and find the sparse training samples which can recover the test sample. While the AR and the ORL database experimental results show that this method has better performance than other identification methods.","2327-0594","978-1-4799-3279-5","10.1109/ICSESS.2014.6933637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933637","orthogonal matching pursuit;sparse representation;image classification","Training;Face recognition;Databases;Matching pursuit algorithms;Error analysis;Algorithm design and analysis","","3","","17","IEEE","23 Oct 2014","","","IEEE","IEEE Conferences"
"COSMOS — An innovative nodal architecture for controlling large numbers of small satellites and other diverse assets","T. Sorensen; E. Pilger; M. Nunes","Interstel Technologies, Inc., Honolulu, HI, USA; Interstel Technologies, Inc., Honolulu, HI, USA; Interstel Technologies, Inc., Honolulu, HI, USA",2015 7th International Conference on Recent Advances in Space Technologies (RAST),"20 Aug 2015","2015","","","385","389","The Hawaii Space Flight Laboratory (HSFL) at the University of Hawaii at Manoa developed the Comprehensive Open-architecture Solution for Mission Operations Systems (COSMOS) under a three-year NASA grant. This innovative suite of software and hardware was initially designed for supporting the operations of multiple small satellites, but during its development, it evolved into a comprehensive system of systems that is capable of providing nearly all operations functions to support an integrated system of objects to be monitored and controlled, called nodes. These nodes are not limited to spacecraft, but can be almost any type of vehicle or electronic entity that has communication connectivity with the distributed COSMOS system. Even the vehicles themselves can operate COSMOS as their onboard controlling software. HSFL built a 55-kg satellite called Hiakasat that is due to launch on the ORS-4 mission in 2015. This satellite uses COSMOS for its onboard flight software, which integrates seamlessly with the COSMOS system that is being used to operate the mission on the ground. COSMOS is currently being used to monitor research ship gathering data, and even controlling rovers on simulated lunar missions. This innovative nodal architecture will allow a fully integrated system that can combine satellites with UAVs, submersible, ships, and other robotic craft.","","978-1-4799-7697-3","10.1109/RAST.2015.7208374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7208374","mission operations;spacecraft software;system of systems;nodal architecture","Satellites;Software;Monitoring;Space vehicles;Computer architecture;Space missions","","","","8","IEEE","20 Aug 2015","","","IEEE","IEEE Conferences"
"The Behavioral Diversity of Java JSON Libraries","N. Harrand; T. Durieux; D. Broman; B. Baudry","EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden; EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden; EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden; EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden",2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE),"11 Feb 2022","2021","","","412","422","JSON is an essential file and data format in domains that span scientific computing, web APIs or configuration management. Its popularity has motivated significant software development effort to build multiple libraries to process JSON data. Previous studies focus on performance comparison among these libraries and lack a software engineering perspective. We present the first systematic analysis and comparison of the input / output behavior of 20 JSON libraries, in a single software ecosystem: Java/Maven. We assess behavior diversity by running each library against a curated set of 473 JSON files, including both well-formed and ill-formed files. The main design differences, which influence the behavior of the libraries, relate to the choice of data structure to represent JSON objects and to the encoding of numbers. We observe a remarkable behavioral diversity with ill-formed files, or corner cases such as large numbers or duplicate data. Our unique behavioral assessment of JSON libraries paves the way for a robust processing of ill-formed files, through a multi-version architecture.","2332-6549","978-1-6654-2587-2","10.1109/ISSRE52982.2021.00050","Swedish Foundation for Strategic Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700248","JSON;Java;Behavioral Diversity","Java;Systematics;Scientific computing;Data structures;Libraries;Software;Software reliability","","2","","44","IEEE","11 Feb 2022","","","IEEE","IEEE Conferences"
"Skin beautification detection using sparse coding","T. Sun; X. Hui; Z. Wang; S. Zhang","Harbin Institute of Technology, Weihai, China; Harbin Institute of Technology, Weihai, China; Harbin Institute of Technology, Weihai, China; Harbin Institute of Technology, Weihai, China",2017 Fifteenth IAPR International Conference on Machine Vision Applications (MVA),"20 Jul 2017","2017","","","526","529","In the past years, skin beautifying softwares have been widely used in portable devices for social activities, which have the functionalities of turning one's skin into flawless complexion. With a huge number of photos uploaded to social media, it is useful for users to distinguish whether a photo is beautified or not. To address this problem, in this paper, we propose a skin beautification detection method by mining and distinguishing the intrinsic features of original photos and the corresponding beautified photos. To this aim, we propose to use sparse coding to learn two sets of basis functions using densely sampled patches from the original photos and the beautified photos, respectively. To detect whether a test photo is beautified, we represent the sampled patches from the photo using the learned basis functions and then see which set of basis functions produces more sparse coefficients. To our knowledge, our effort is the first one to detect skin beautification. To validate the effectiveness of the proposed method, we collected about 1000 photos including both the original photos and the photos beautified by a software. Our experimental results indicate the proposed method achieved a desired detection accuracy of over 80%.","","978-4-9011-2216-0","10.23919/MVA.2017.7986916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7986916","","Dictionaries;Skin;Training;Encoding;Software;Testing;Roads","","","","7","","20 Jul 2017","","","IEEE","IEEE Conferences"
