"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Similarities of Testing Programmed and Learnt Software","F. Dobslaw; R. Feldt","Dept. of Communication, Quality Mngmt. and Inf. Systems, Mid Sweden University, Östersund, Sweden; Dept. of Computer Science and Engineering, Chalmers University of Technology, Gothenburg, Sweden","2023 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","29 May 2023","2023","","","78","81","This study examines to what extent the testing of traditional software components and machine learning (ML) models fundamentally differs or not. While some researchers argue that ML software requires new concepts and perspectives for testing, our analysis highlights that, at a fundamental level, the specification and testing of a software component are not dependent on the development process used or on implementation details. Although the software engineering/computer science (SE/CS) and Data Science/ML (DS/ML) communities have developed different expectations, unique perspectives, and varying testing methods, they share clear commonalities that can be leveraged. We argue that both areas can learn from each other, and a non-dual perspective could provide novel insights not only for testing ML but also for testing traditional software. Therefore, we call upon researchers from both communities to collaborate more closely and develop testing methods and tools that can address both traditional and ML software components. While acknowledging their differences has merits, we believe there is great potential in working on unified methods and tools that can address both types of software.","2159-4848","979-8-3503-3335-0","10.1109/ICSTW58534.2023.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10132221","Software Testing;Software Engineering;Machine Learning;Non-Duality;Software Boundaries","Software testing;Conferences;Machine learning;Software;Testing","","","","12","IEEE","29 May 2023","","","IEEE","IEEE Conferences"
"Boosted Exploratory Test Architecture: Coaching Test Engineers with Word Similarity","Y. Nishi; Y. Shibasaki","Dept. of Informatics, The University of Electro-Communications, Tokyo, Japan; Dept. of Informatics, The University of Electro-Communications, Tokyo, Japan","2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","28 May 2021","2021","","","173","174","Testing software using machine learning and neural network is difficult due to non-linearity. This paper proposes Boosted Exploratory Test architecture to support creativity of test engineers by using a non-linear test generator. This paper also shows experimental results Boosted Exploratory Test architecture with Word2Vec is better for a smart speaker.","","978-1-6654-4456-9","10.1109/ICSTW52544.2021.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440172","software testing;test architecture;Boosted Exploratory Test;Word2Vec;smart speaker","Software testing;Conferences;Neural networks;Computer architecture;Machine learning;Software;Generators","","","","8","IEEE","28 May 2021","","","IEEE","IEEE Conferences"
"A Preliminary Empirical Assessment of Similarity for Combinatorial Iteraction Testing of Software Product Lines","S. Fischer; R. E. Lopez-Herrejon; R. Ramler; A. Egyed","Johannes Kepler University, Linz, Austria; Johannes Kepler University, Linz, Austria; Software Competence Center, Hagenberg, Austria; Johannes Kepler University, Linz, Austria",2016 IEEE/ACM 9th International Workshop on Search-Based Software Testing (SBST),"9 Jan 2017","2016","","","15","18","Extensive work on Search-Based Software Testing for Software Product Lines has been published in the last few years. Salient among them is the use of similarity as a surrogate metric for t-wise coverage whenever higher strengths are needed or whenever the size of the test suites is infeasible because of technological or budget limitations. Though promising, this metric has not been assessed with real fault data. In this paper, we address this limitation by using Drupal, a widely used open source web content management system, as an industry-strength case study for which both variability information and fault data have been recently made available. Our preliminary assessment corroborates some of the previous findings but also raises issues on some assumptions and claims made. We hope our work encourages further empirical evaluations of Combinatorial Interaction Testing approaches for Software Product Lines.","","978-1-4503-4166-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7810700","Software Product Line;Combinatorial Interaction Testing;Product Similarity;Documented Faults;Empirical;Drupal","Testing;Computational modeling;Measurement;Fault detection;Software product lines;Data models;Feature extraction","","","","21","","9 Jan 2017","","","IEEE","IEEE Conferences"
"Research on Excavation Technology of Software Implied Testing Requirements","Y. Yang; K. Li; Q. Zhang; Y. Wang","Beijing Research Institute of the Beijing Flight Communications Computing, Beijing, China; Beijing Research Institute of the Beijing Flight Communications Computing, Beijing, China; Beijing Research Institute of the Beijing Flight Communications Computing, Beijing, China; Beijing Research Institute of the Beijing Flight Communications Computing, Beijing, China",2021 2nd International Conference on Computer Science and Management Technology (ICCSMT),"8 Jun 2022","2021","","","92","96","Aiming at the problems of inappropriate decomposition of software testing requirements and inexperienced testers in the software testing process, the paper proposes a software implicit testing requirements excavation method based on failure modes. Failure modes are obtained by analyzing historical failure data with the fault tree analysis method, according to which the testing guidelines corresponding to them are established afterwards. Implicit test requirements are testing requirements that are not mentioned in the software development requirements document but have occurred in other software with similar testing requests. The extraction of implied testing requirements relies on matching the semantic similarity between the development requirements document and the testing guidelines. The testing requirements that are not described in the development requirements document are complemented by the testing guidelines. The excavation of implied testing requirements complements the testing outline formed by the original decomposition of testing requirements according to the development requirement document and reduces the probability of the same problem occurring in the software. The experimental results show that it provides sufficient support for the improvement of testing requirements in the test of software and guarantees the reliability and security of the software efficiently.","","978-1-6654-2063-1","10.1109/ICCSMT54525.2021.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9786960","component;testing requirements;failure mode;semantic similarity analysis;fault tree;software test","Software testing;Computer science;Semantics;Excavation;Software;Software reliability;Security","","","","12","IEEE","8 Jun 2022","","","IEEE","IEEE Conferences"
"Assessing Software Product Line Testing Via Model-Based Mutation: An Application to Similarity Testing","C. Henard; M. Papadakis; G. Perrouin; J. Klein; Y. L. Traon","Interdisciplinary Centre for Security, University of Luxembourg, Luxembourg, Luxembourg; Interdisciplinary Centre for Security, University of Luxembourg, Luxembourg, Luxembourg; Precise Research Center In Software Engineering (PReCISE), University of Namur, Namur, Belgium; Interdisciplinary Centre for Security, University of Luxembourg, Luxembourg, Luxembourg; Interdisciplinary Centre for Security, University of Luxembourg, Luxembourg, Luxembourg","2013 IEEE Sixth International Conference on Software Testing, Verification and Validation Workshops","1 Aug 2013","2013","","","188","197","Needs for mass customization and economies of scale have pushed engineers to develop Software Product Lines (SPLs). SPLs are families of products sharing commonalities and exhibiting differences, built by reusing software assets abstractly represented by features. Feature models describe the constraints that link the features and allow the configuration of tailored software products. Common SPLs involve hundreds, even thousands of features, leading to billions of possible software products. As a result, testing a product line is challenging due to the enormous size of the possible products. Existing techniques focus on testing based on the product line's feature model by selecting a limited set of products to test. Being created manually or reverse-engineered, feature models are prone to errors impacting the generated test suites. In this paper, we examine ability of test suites to detect such errors. In particular, we propose two mutation operators to derive erroneous feature models (mutants) from an original feature model and assess the capability of the generated original test suite to kill the mutants. Experimentation on real feature models demonstrate that dissimilar tests suites have a higher mutant detection ability than similar ones, thus validating the relevance of similarity-driven product line testing.","","978-0-7695-4993-4","10.1109/ICSTW.2013.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6571629","Mutation;Testing;Feature Models;Software Product Lines;Similarity","Frequency modulation;Testing;Software;Context;Mobile handsets;Biological system modeling;Analytical models","","41","","36","IEEE","1 Aug 2013","","","IEEE","IEEE Conferences"
"PHANTA: Diversified Test Code Quality Measurement for Modern Software Development","S. Tokumoto; K. Takayama","Fujitsu Laboratories Ltd., Japan; Fujitsu Laboratories Ltd., Japan",2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE),"9 Jan 2020","2019","","","1206","1207","Test code is becoming more essential to the modern software development process. However, practitioners often pay inadequate attention to key aspects of test code quality, such as bug detectability, maintainability and speed. Existing tools also typically report a single test code quality measure, such as code coverage, rather than a diversified set of metrics. To measure and visualize quality of test code in a comprehensive fashion, we developed an integrated test code analysis tool called Phanta. In this show case, we posit that the enhancement of test code quality is key to modernizing software development, and show how Phanta's techniques measure the quality using mutation analysis, test code clone detection, and so on. Further, we present an industrial case study where Phanta was applied to analyze test code in a real Fujitsu project, and share lessons learned from the case study.","2643-1572","978-1-7281-2508-4","10.1109/ASE.2019.00138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952538","Software Testing;Test Code;Mutation Testing","Tools;Measurement;Cloning;Software;Testing;Computer bugs;Software engineering","","","","6","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Test Set Diameter: Quantifying the Diversity of Sets of Test Cases","R. Feldt; S. Poulding; D. Clark; S. Yoo","Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Sweden; Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Sweden; Department of Computer Science, University College London, London, UK; School of Computing KAIST, Daejeon, Republic of Korea","2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)","21 Jul 2016","2016","","","223","233","A common and natural intuition among software testers is that test cases need to differ if a software system is to be tested properly and its quality ensured. Consequently, much research has gone into formulating distance measures for how test cases, their inputs and/or their outputs differ. However, common to these proposals is that they are data type specific and/or calculate the diversity only between pairs of test inputs, traces or outputs. We propose a new metric to measure the diversity of sets of tests: the test set diameter (TSDm). It extends our earlier, pairwise test diversity metrics based on recent advances in information theory regarding the calculation of the normalized compression distance (NCD) for multisets. A key advantage is that TSDm is a universal measure of diversity and so can be applied to any test set regardless of data type of the test inputs (and, moreover, to other test-related data such as execution traces). But this universality comes at the cost of greater computational effort compared to competing approaches. Our experiments on four different systems show that the test set diameter can help select test sets with higher structural and fault coverage than random selection even when only applied to test inputs. This can enable early test design and selection, prior to even having a software system to test, and complement other types of test automation and analysis. We argue that this quantification of test set diversity creates a number of opportunities to better understand software quality and provides practical ways to increase it.","","978-1-5090-1827-7","10.1109/ICST.2016.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515474","Software testing;Information theory;Test selection;Empirical study","Measurement;Complexity theory;Software testing;Electronic mail;Software systems","","69","","41","IEEE","21 Jul 2016","","","IEEE","IEEE Conferences"
"Random Border Mirror Transform: A Diversity Based Approach to an Effective and Efficient Mirror Adaptive Random Testing","M. Omari; J. Chen; P. Kwaku Kudjo; H. Ackah-Arthur; R. Huang","School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China","2019 IEEE 19th International Conference on Software Quality, Reliability and Security (QRS)","3 Oct 2019","2019","","","54","61","Mirror Adaptive random testing (MART) is an overhead reduction strategy for adaptive random testing methods. Theoretically speaking, MART's advantage over ordinary ARTs is determined by the mirroring scheme selected. Incidentally, an inherent problem with MART relates to the difficulty in the choice of a scheme for any testing task. This is because a higher scheme (larger mirror domains) does not necessarily guarantee efficient utilization of testing resources due to lack of diversity of mirror generated test cases. The culprit has been identified as the mapping functions used as substitutes to complex ART methods. In this paper, we present a new method for generating diversified mirror test cases by randomly displacing the mirror partitions upon which the mapping functions of MART operates. The result of simulations and experiments conducted shows remarkable improvement over MART's effectiveness and efficiency across MART schemes, especially where program failures are unrelated to one or more input parameters.","","978-1-7281-3927-2","10.1109/QRS.2019.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854699","Adaptive random testing;software testing;mirror adaptive random testing;test case diversity","Mirrors;Subspace constraints;Software;Power capacitors;Software testing;Software reliability","","1","","24","IEEE","3 Oct 2019","","","IEEE","IEEE Conferences"
"Looking For Novelty in Search-Based Software Product Line Testing","Y. Xiang; H. Huang; M. Li; S. Li; X. Yang","School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China; Centre of Excellence for Research in Computational Intelligence and Applications, School of Computer Science, University of Birmingham, Birmingham, U.K.; School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China",IEEE Transactions on Software Engineering,"15 Jul 2022","2022","48","7","2317","2338","Testing software product lines (SPLs) is difficult due to a huge number of possible products to be tested. Recently, there has been a growing interest in similarity-based testing of SPLs, where similarity is used as a surrogate metric for the $t$t-wise coverage. In this context, one of the primary goals is to sample, by optimizing similarity metrics using search-based algorithms, a small subset of test cases (i.e., products) as dissimilar as possible, thus potentially making more $t$t-wise combinations covered. Prior work has shown, by means of empirical studies, the great potential of current similarity-based testing approaches. However, the rationale of this testing technique deserves a more rigorous exploration. To this end, we perform correlation analyses to investigate how similarity metrics are correlated with the $t$t-wise coverage. We find that similarity metrics generally have significantly positive correlations with the $t$t-wise coverage. This well explains why similarity-based testing works, as the improvement on similarity metrics will potentially increase the $t$t-wise coverage. Moreover, we explore, for the first time, the use of the novelty search (NS) algorithm for similarity-based SPL testing. The algorithm rewards “novel” individuals, i.e., those being different from individuals discovered previously, and this well matches the goal of similarity-based SPL testing. We find that the novelty score used in NS has (much) stronger positive correlations with the $t$t-wise coverage than previous approaches relying on a genetic algorithm (GA) with a similarity-based fitness function. Experimental results on 31 software product lines validate the superiority of NS over GA, as well as other state-of-the-art approaches, concerning both $t$t-wise coverage and fault detection capacity. Finally, we investigate whether it is useful to combine two satisfiability solvers when generating new individuals in NS, and how the performance of NS is affected by its key parameters. In summary, looking for novelty provides a promising way of sampling diverse test cases for SPLs.","1939-3520","","10.1109/TSE.2021.3057853","National Natural Science Foundation of China(grant numbers:61906069,61773410,61876207); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2019A1515011411,2019A1515011700); Science and Technology Program of Guangzhou(grant numbers:202002030355,201802010007); Project Funded by China Postdoctoral Science Foundation(grant numbers:2019M662912); Guangdong Province Key Area R&D Program(grant numbers:2018B010109003); Fundamental Research Funds for the Central Universities(grant numbers:2019MS088,2020ZYGXZR014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350184","Software product line testing;product sampling;novelty search;similarity-based testing;  $t$   t     -wise coverage;correlation analysis","Testing;Frequency modulation;Measurement;Software;Correlation;Software product lines;Fault detection","","6","","90","IEEE","8 Feb 2021","","","IEEE","IEEE Journals"
"Teaching software testing methods based on diversity principles","Z. Chen; J. Zhang; B. Luo","Software Institute, Nanjing University, Nanjing, China; Nanjing University, Nanjing, Jiangsu, CN; Nanjing University, Nanjing, Jiangsu, CN",2011 24th IEEE-CS Conference on Software Engineering Education and Training (CSEE&T),"16 Jun 2011","2011","","","391","395","Software testing is the primary approach to support software quality assurance. Many novel software testing methods have been proposed to achieve various tasks in recent years. It is a challenge to teach these new testing methods and classical testing methods within limited time. This paper reports our work in progress on the new teaching approach to software testing methods based on diversity principles.","2377-570X","978-1-4577-0348-5","10.1109/CSEET.2011.5876111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5876111","","Software testing;Education;Software;Subspace constraints;Industries;Diversity methods","","5","","15","IEEE","16 Jun 2011","","","IEEE","IEEE Conferences"
"DDF: Diversity Dragonfly Algorithm for cost-aware test suite minimization approach for software testing","S. R. Sugave; S. H. Patil; B. E. Reddy","MIT College of Engineering, Pune, MH, India; Bharati Vidyapeeth University College of Engineering, Pune, MH, India; JNTUA College of Engineering, Kalikiri, Chittor District, AP, India",2017 International Conference on Intelligent Computing and Control Systems (ICICCS),"11 Jan 2018","2017","","","701","707","The test suite minimization approach is a major research topic that it requires huge attention from the researchers as the traditional methods used for performing the test suite minimization is concentrated on the cost of regression testing but the requirements were not satisfied. To solve the problem of satisfying requirements, researchers proposed greedy algorithms, optimization algorithms, and so on. In this paper, a novel optimization algorithm is proposed termed as the Diversity Dragonfly Algorithm (DDF) algorithm that concentrates on the cost and quality of the test suite. The diversification included in the standard Dragonfly algorithm forms the DDF that uses three bitwise operators for diversification. The DDF algorithm determines the best suite based on the hunting mechanism of the dragonfly using a minimum objective function such that the selected test suite satisfies all the requirements. The experiment is carried out using five subject programs and the performance analysis of the proposed DDF is carried out and compared with the existing methods. It is found that the reduction capability of the DDF is better than existing methods and the cost of the proposed DDF is low ensuring a quality test suite reduction.","","978-1-5386-2745-7","10.1109/ICCONS.2017.8250554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8250554","Test suite reduction;DDF optimization algorithm;cost constraint;Software testing;Diversity function","Software;Minimization;Optimization;Software algorithms;Software testing;Linear programming","","10","","15","IEEE","11 Jan 2018","","","IEEE","IEEE Conferences"
"A safety-critical software development strategy based on theory of diverse design","S. Lee; X. Bao; T. Zhao","School of Reliability and Systems Engineering, Beihang University, Beijing, China; School of Reliability and Systems Engineering, Beihang University, Beijing, China; School of Reliability and Systems Engineering, Beihang University, Beijing, China","The Proceedings of 2011 9th International Conference on Reliability, Maintainability and Safety","11 Aug 2011","2011","","","694","699","As an effective method to improve software reliability and safety, diverse design has been widely used in safety-critical software development in the aviation, aerospace and rail transportation areas. Since N-version programming costs a lot and automatic code generation tools have been widely used nowadays, a safety-critical software development strategy based on theory of diverse design, which is combined with automatic code generation tools, is proposed in this paper. Qualitative analysis on the diversity and cost of software developed through this strategy is also completed in this paper to show that this strategy can effectively avoid common-cause failures and improve the safety of safety-critical software. At last, safety-critical software development process based on this strategy is proposed.","","978-1-61284-666-8","10.1109/ICRMS.2011.5979354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5979354","Diverse design;software safety;safety-critical software;software development;automatic code generation tools","Safety;Software;Programming;Testing;Algorithm design and analysis;Data models;Analytical models","","1","","12","IEEE","11 Aug 2011","","","IEEE","IEEE Conferences"
"Invasive Software Testing: Mutating Target Programs to Diversify Test Exploration for High Test Coverage","Y. Kim; S. Hong; B. Ko; D. L. Phan; M. Kim","School of Computing, KAIST, South Korea; School of CSEE, Handong Global University, South Korea; School of Computing, KAIST, South Korea; School of Computing, KAIST, South Korea; School of Computing, KAIST, South Korea","2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)","28 May 2018","2018","","","239","249","Software testing techniques have advanced significantly over several decades; however, most of current techniques still test a target program as it is, and fail to utilize valuable information of diverse test executions on many variants of the original program in test generation. This paper proposes a new direction for software testing - Invasive Software Testing (IST). IST first generates a set of target program variants m1, ⋯, mn from an original target program p by applying mutation operations 1, ⋯, μn. Second, given a test suite T, IST executes m1, ⋯, mn with T and records the test runs which increase test coverage compared to p with T. Based on the recorded information, IST generates guideposts for automated test generation on p toward high test coverage. Finally, IST generates test inputs on p with the guideposts and achieves higher test coverage. We developed DEMINER which implements IST for C programs through software mutation and concolic testing. Further, we showed the effectiveness of DEMINER on three real-world target programs Busybox-ls, Busybox-printf, and GNU-find. The experiment results show that the amount of the improved branch coverage by DEMINER is 24.7% relatively larger than those of the conventional concolic testing techniques on average.","","978-1-5386-5012-7","10.1109/ICST.2018.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367052","Mutation analysis;Practical mutation tool;C programs","Test pattern generators;Manganese;Software testing;Invasive software;Computer crashes","","12","","32","IEEE","28 May 2018","","","IEEE","IEEE Conferences"
"Instance Generator and Problem Representation to Improve Object Oriented Code Coverage","A. Sakti; G. Pesant; Y. -G. Guéhéneuc","Department of Computer and Software Engineering, École Polytechnique de Montral, Montral, QC, Canada; Department of Computer and Software Engineering, École Polytechnique de Montral, Montral, QC, Canada; Department of Computer and Software Engineering, École Polytechnique de Montral, Montral, QC, Canada",IEEE Transactions on Software Engineering,"11 Mar 2015","2015","41","3","294","313","Search-based approaches have been extensively applied to solve the problem of software test-data generation. Yet, test-data generation for object-oriented programming (OOP) is challenging due to the features of OOP, e.g., abstraction, encapsulation, and visibility that prevent direct access to some parts of the source code. To address this problem we present a new automated search-based software test-data generation approach that achieves high code coverage for unit-class testing. We first describe how we structure the test-data generation problem for unit-class testing to generate relevant sequences of method calls. Through a static analysis, we consider only methods or constructors changing the state of the class-under-test or that may reach a test target. Then we introduce a generator of instances of classes that is based on a family of means-of-instantiation including subclasses and external factory methods. It also uses a seeding strategy and a diversification strategy to increase the likelihood to reach a test target. Using a search heuristic to reach all test targets at the same time, we implement our approach in a tool, JTExpert, that we evaluate on more than a hundred Java classes from different open-source libraries. JTExpert gives better results in terms of search time and code coverage than the state of the art, EvoSuite, which uses traditional techniques.","1939-3520","","10.1109/TSE.2014.2363479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6926828","Automatic Test Data Generation;Search Based Software Testing;Unit Class Testing;Seeding Strategy;Diversification Strategy;Java Testing;Automatic test data generation;search based software testing;unit class testing;seeding strategy;diversification strategy;Java testing","Testing;Complexity theory;Generators;Search problems;Java;Production facilities;Libraries","","64","","53","IEEE","16 Oct 2014","","","IEEE","IEEE Journals"
"A Preliminary Study on Factors Affecting Software Testing Team Performance","T. Kanij; R. Merkel; J. Grundy","Swinburne University of Technology, Hawthorn, VIC, Australia; Monash University, Clayton, VIC, Australia; Swinburne University of Technology, Hawthorn, VIC, Australia",2011 International Symposium on Empirical Software Engineering and Measurement,"1 Dec 2011","2011","","","359","362","With the growth of the software testing industry, many in-house testing groups and outsourcing testing companies have been established. Underlying the success of these testing groups and companies are team(s) of testers. This research investigates the importance of different factors, diversity and experience on building a successful testing team. We collected the opinions of testing practitioners on these factors via a survey. The outcome strongly indicates the relative importance of different factors and that diversity is helpful for a testing team. The results also support the importance of suitable team experience.","1949-3789","978-1-4577-2203-5","10.1109/ESEM.2011.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6092588","testing team;rank;diversity;experience","Software measurement;Software engineering","","10","","11","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Test Case Reuse based on ESIM Model","X. Chen; J. Wang; S. Zhou; P. Xue; J. Jia","Chinese Academy of Sciences, University of Chinese Academy of Sciences Technology and Engineering Center for Space Utilization, Beijing, China; Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, Beijing, China; Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, Beijing, China; Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, Beijing, China; Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, Beijing, China",2021 8th International Conference on Dependable Systems and Their Applications (DSA),"1 Dec 2021","2021","","","700","705","Software testing is crucial to guarantee the reliability of software, and test case plays an important role in software testing. Test cases are mainly written by testers, which not only consumes a lot of time, but the quality of test cases depends heavily on the designer’s technical capability. Test case reuse technology can reuse historically executed test cases, which are written by experts and stored in the knowledge base. Different from the test case reuse based on modeling and other methods, we propose a test case reuse technology based on the similarity of requirements documents, and use the model ESIM (Enhanced Sequential Inference Model), which performs well in the field of text matching. when employing this method, testers do not have to possess rich experiences and high-level expertise, in this way, the issue of the stability of design quality caused by difference of designer’s technical capability is solved.","2767-6684","978-1-6654-4391-3","10.1109/DSA52907.2021.00101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623005","software test;test case reuse;text similarity;NLP","Software testing;Knowledge based systems;Software;Stability analysis;Software reliability;Indexes","","1","","16","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"Modified ACO to maintain diversity in regression test optimization","S. Kumar; P. Ranjan; R. Rajesh","Department of computer science, Central University of South Bihar; Department of computer science, Central University of South Bihar; Department of computer science, Central University of South Bihar, India",2016 3rd International Conference on Recent Advances in Information Technology (RAIT),"9 Jul 2016","2016","","","619","625","Regression testing is unavoidable maintenance activity that is performed several times in software development life cycle. Optimization of regression test case is required to minimize the test case (which will in-turn reduce the time and cost of testing) and to find the fault in early testing activity. The two widely used regression test case optimization techniques, namely, selection and prioritization are recently found to be integrated with different metaheuristic algorithms for fruitful regression test cases. Among the various meta-heuristic algorithms, Ant colony optimization (ACO) algorithm is most popularly used. ACO will try to find the smallest path out all the test cases and it is not sufficient because it will not cover all the test cases which are needed. In this paper we have proposed a modified ant colony optimization to solve test cases in huge search space. The modified algorithm selects the best test cases that find the maximum fault in minimum time.","","978-1-4799-8579-1","10.1109/RAIT.2016.7507970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7507970","Regresssion testing;Soft computing;Multi-objective optimization;Test case optimization;Nature Based Optimization","Optimization;Software;Ant colony optimization;Software algorithms;Software testing;Maintenance engineering","","3","","24","IEEE","9 Jul 2016","","","IEEE","IEEE Conferences"
"Fundamentals of test case selection: Diversity, diversity, diversity","T. Y. Chen","Centre of Software Analysis and Testing, Swinburne University of Technology, Hawthorn, VIC, Australia",The 2nd International Conference on Software Engineering and Data Mining,"9 Aug 2010","2010","","","723","724","Our recent investigations in software testing reveal that diversity constitutes the underlying foundation in many test case selection strategies. This talk attempts to provide an overview of the concept of diversity in test case selection through two families of test case selection strategies, namely, random testing and partition testing. We also present some areas of software testing where the application of data mining techniques shows great potential in identifying key aspects of diversity in various forms.","","978-89-88678-22-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5542825","Adaptive Random Testing;Partition Testing;Proportional Sampling Strategy;Software Testing","Testing;Entropy;Game theory;Counting circuits;Fuzzy sets;Mechatronics;Data analysis;Decision theory;Uncertainty;Fuzzy systems","","","","7","","9 Aug 2010","","","IEEE","IEEE Conferences"
"Code Coverage Similarity Measurement Using Machine Learning for Test Cases Minimization","M. C. Saputra; T. Katayama","Interdisciplinary Graduate School of Agriculture and Engineering, University of Miyazaki, 1-1 Gakuen-Kibanadai Nishi, Miyazaki, Japan; Interdisciplinary Graduate School of Agriculture and Engineering, University of Miyazaki, 1-1 Gakuen-Kibanadai Nishi, Miyazaki, Japan",2020 IEEE 9th Global Conference on Consumer Electronics (GCCE),"21 Dec 2020","2020","","","287","291","Machine learning approach for minimizing the number of test cases on the test suite is an interesting research area on software testing. The research tries to minimize the number of test cases on the test suite by minimizing redundant test cases based on similarity classification. The Support Vector Machine, K-Nearest Neighbour, and Decision tree classify similar test cases by comparing the lines executed by test cases. The result has shown that the support vector machine is the highest score on accuracy and the lowest score on error rate comparing with K-Nearest Neighbour, and Decision tree. Minimize the redundant test cases increase the quality of the test cases, and reducing time on the testing process.","2378-8143","978-1-7281-9802-6","10.1109/GCCE50665.2020.9291990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291990","Similarity;Test Case;Support Vector Machine;K-Nearest Neighbour Decision Tree","Software testing;Machine learning algorithms;Error analysis;Support vector machine classification;Machine learning;Minimization;Decision trees","","1","","16","IEEE","21 Dec 2020","","","IEEE","IEEE Conferences"
"Scoring Mechanism of Defect Report Based on Text Similarity","M. Zhu; J. Sun; X. Li; L. Xiao","School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, China; School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, China; School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, China; Engineering Research Center for Software Testing and Evaluation of Fujian Province, Xiamen, China",2019 10th International Conference on Information Technology in Medicine and Education (ITME),"23 Jan 2020","2019","","","182","185","With the rapid development of the software industry in recent years, the demand for software testing talents in the society is also growing. Therefore, more and more colleges and universities set up ""software testing technology"" courses in related majors. Finding defects is a basic skill of software testing technology training. Some defects are difficult to find and some defects are easy to find. How to give reasonable evaluation according to the difficulty and quantity of defects in the defect report submitted by students often requires much of teacher's time and effort. This paper proposes a defect repetitive detection method based on the combination of TF-IDF and cosine similarity and proposes a defect report scoring mechanism based on the difficulty level and number of defects found by students. Comparing the manually scores of the defect reports by the teachers, the scoring mechanism is reasonable and effective, and greatly improves the work efficiency of the teachers.","2474-3828","978-1-7281-3918-0","10.1109/ITME.2019.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964978","software testing;TF-IDF;cosine similarity;scoring mechanism","Software;Feature extraction;Software testing;Libraries;Mathematical model;Information science;Classification algorithms","","","","4","IEEE","23 Jan 2020","","","IEEE","IEEE Conferences"
"On the similarities and differences between program documentation and test documentation","S. Tilley; T. Parveen",Florida Institute of Technology; Independent Consultant,2012 IEEE International Professional Communication Conference,"10 Jan 2013","2012","","","1","2","Program documentation is a vital source of information for software engineers charged with making changes to complex applications. Test documentation can be used to help future stakeholders understand the rationale behind the testing effort. This panel will discuss some of the similar features and salient differences between program documentation and test documentation. Although both types of documentation are usually written by and for different groups of people (for reasonable-sized projects), there is enough overlap that each could be improved by studying the communication strategies of the other.","2158-1002","978-1-4577-2126-7","10.1109/IPCC.2012.6408643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6408643","Communication;program documentation;test documentation","Documentation;Software;Software engineering;Software testing;IEEE standards","","","","5","IEEE","10 Jan 2013","","","IEEE","IEEE Conferences"
"An Industrial Study on the Challenges and Effects of Diversity-Based Testing in Continuous Integration","A. Ahmad; F. G. d. O. Neto; E. P. Enoiu; K. Sandahl; O. Leifler","Ericsson AB, Linköping, Sweden; Gothenburg University, Gothenburg, Sweden; Mälardalens University, Mälardalens, Sweden; Linköping University, Linköping, Sweden; Linköping University, Linköping, Sweden","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)","25 Dec 2023","2023","","","337","347","Many test prioritisation techniques have been proposed in order to improve test effectiveness of Continuous Integration (CI) pipelines. Particularly, diversity-based testing (DBT) has shown promising and competitive results to improve test effectiveness. However, the technical and practical challenges of introducing test prioritisation in CI pipelines are rarely discussed, thus hindering the applicability and adoption of those proposed techniques. This research builds on our prior work in which we evaluated diversity-based techniques in an industrial setting. This work investigates the factors that influence the adoption of DBT both in connection to improvements in test cost-effectiveness, as well as the process and human related challenges to transfer and use DBT prioritisation in CI pipelines. We report on a case study considering the CI pipeline of Axis Communications in Sweden. We performed a thematic analysis of a focus group interview with senior practitioners at the company to identify the challenges and perceived benefits of using test prioritisation in their test process. Our thematic analysis reveals a list of ten challenges and seven perceived effects of introducing test prioritisation in CI cycles. For instance, our participants emphasized the importance of introducing comprehensible and transparent techniques that instill trust in its users. Moreover, practitioners prefer techniques compatible with their current test infrastructure (e.g., test framework and environments) in order to reduce instrumentation efforts and avoid disrupting their current setup. In conclusion, we have identified tradeoffs between different test prioritisation techniques pertaining to the technical, process and human aspects of regression testing in CI. We summarize those findings in a list of seven advantages that refer to specific stakeholder interests and describe the effects of adopting DBT in CI pipelines.","2693-9177","979-8-3503-1958-3","10.1109/QRS60937.2023.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366588","diversity based testing;test suite minimisation;emprirical study;continuous integration;regression testing","Industries;Instruments;Pipelines;Software quality;Companies;Software reliability;Stakeholders","","1","","37","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"Black-Box Test Case Prioritization Using Log Analysis and Test Case Diversity","X. Yu; K. Jia; W. Hu; J. Tian; J. Xiang","School of Computer Science and Artificial Intelligence, Wuhan University of Technology, Wuhan, China; School of Computer Science and Artificial Intelligence, Wuhan University of Technology, Wuhan, China; School of Computer Science and Artificial Intelligence, Wuhan University of Technology, Wuhan, China; School of Computer Science and Artificial Intelligence, Wuhan University of Technology, Wuhan, China; School of Computer Science and Artificial Intelligence, Wuhan University of Technology, Wuhan, China",2023 IEEE 34th International Symposium on Software Reliability Engineering Workshops (ISSREW),"2 Nov 2023","2023","","","186","191","Regression testing is a software testing type that examines whether updates made in the software impact the existing functionality of the application. Depressingly, the long testing time and high testing costs make regression testing very expensive. Test case prioritization (TCP) stands out as one of the extensively researched regression testing techniques. It prioritizes test cases to optimize their execution order, aiming to maximize the prioritization goals and reveal faults earlier to provide feedback to testers. The TCP technique based on log analysis (LogTCP) designs the prioritization strategy using logs generated during test case execution. However, LogTCP’s performance is limited by its inability to incorporate the diversity of test cases for sorting. To overcome these concerns, we propose a method to implement TCP using k-means clustering and log analysis(called KL-TCP), that takes into account both log information and test case diversity. We examine the effectiveness of this strategy in ten open source Java projects on GitHub. The experimental results show that our proposed method outperforms LogTCP method by detecting a higher average percentage of faults. The best average performance of the ten project experiments reached 0.77(APFD).","","979-8-3503-1956-9","10.1109/ISSREW60843.2023.00072","Research and Development; Natural Science Foundation of Chongqing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10301343","test case prioritization;test case diversity;log parsing","Software testing;Java;Fault detection;Semantics;Feature extraction;Software reliability;History","","","","27","IEEE","2 Nov 2023","","","IEEE","IEEE Conferences"
"Identifying Similar Test Cases That Are Specified in Natural Language","M. Viggiato; D. Paas; C. Buzon; C. -P. Bezemer","Analytics of Software, Games and Repository Data (ASGAARD) Lab, University of Alberta, Edmonton, AB, Canada; Prodigy Education, Toronto, ON, Canada; Prodigy Education, Toronto, ON, Canada; Analytics of Software, Games and Repository Data (ASGAARD) Lab, University of Alberta, Edmonton, AB, Canada",IEEE Transactions on Software Engineering,"14 Mar 2023","2023","49","3","1027","1043","Software testing is still a manual process in many industries, despite the recent improvements in automated testing techniques. As a result, test cases (which consist of one or more test steps that need to be executed manually by the tester) are often specified in natural language by different employees and many redundant test cases might exist in the test suite. This increases the (already high) cost of test execution. Manually identifying similar test cases is a time-consuming and error-prone task. Therefore, in this paper, we propose an unsupervised approach to identify similar test cases. Our approach uses a combination of text embedding, text similarity and clustering techniques to identify similar test cases. We evaluate five different text embedding techniques, two text similarity metrics, and two clustering techniques to cluster similar test steps and three techniques to identify similar test cases from the test step clusters. Through an evaluation in an industrial setting, we showed that our approach achieves a high performance to cluster test steps (an F-score of 87.39%) and identify similar test cases (an F-score of 86.13%). Furthermore, a validation with developers indicates several different practical usages of our approach (such as identifying redundant test cases), which help to reduce the testing manual effort and time.","1939-3520","","10.1109/TSE.2022.3170272","Prodigy Education; Natural Sciences and Engineering Research Council of Canada(grant numbers:ALLRP 550309); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9763328","Software testing;test case similarity;clustering","Bit error rate;Natural languages;Testing;Task analysis;Manuals;Games;Codes","","7","","61","IEEE","26 Apr 2022","","","IEEE","IEEE Journals"
"A Linear Regression Approach to Modeling Software Characteristics for Classifying Similar Software","H. -I. Lim","Dept. of Computer Engineering, Kyungnam University, Gyeongsangnam-do, South Korea",2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC),"9 Jul 2019","2019","1","","942","943","Linear regression is one approach among various machine learning methods that are applied to solve problems by constructing a model from training with previously known data. Machine learning can be applied to various areas, especially on complex problems which have no clear computational rule or solution for the problems. In this paper, we present a linear regression approach to solve in area of software analysis for identifying similar software. In the experimental results, we show the evaluation results of applying linear regression on classification of similar software.","0730-3157","978-1-7281-2607-4","10.1109/COMPSAC.2019.00152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754066","linear regression;software analysis;machine learning;software classification;code vector","Software;Linear regression;Data models;Machine learning;Training data;Training;Predictive models","","10","","6","IEEE","9 Jul 2019","","","IEEE","IEEE Conferences"
"Fostering the Diversity of Exploratory Testing in Web Applications","J. Leveau; X. Blanc; L. Réveillère; J. -R. Falleri; R. Rouvoy","Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI, Talence, France; Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI, Talence, France; Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI, Talence, France; Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI, Talence, France; Univ. Lille / Inria, France","2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)","5 Aug 2020","2020","","","164","174","Exploratory testing (ET) is a software testing approach that complements automated testing by leveraging business expertise. It has gained momentum over the last decades as it appeals testers to exploit their business knowledge to stress the system under test (SUT). Exploratory tests, unlike automated tests, are defined and executed on-the-fly by testers. Testers who perform exploratory tests may be biased by their past experience and therefore may miss anomalies or unusual interactions proposed by the SUT. This is even more complex in the context of web applications, which typically expose a huge number of interaction paths to their users. As testers of these applications cannot remember all the sequences of interactions they performed, they may fail to deeply explore the application scope. This paper therefore introduces a new approach to assist testers in widely exploring any web application. In particular, our approach monitors the online interactions performed by the testers to suggest in real-time the probabilities of performing next interactions. Looking at these probabilities, we claim that the testers who favour interactions that have a low probability (because they were rarely performed), will increase the diversity of their explorations. Our approach defines a prediction model, based on ${n}$-grams, that encodes the history of past interactions and that supports the estimation of the probabilities. Integrated within a web browser extension, it automatically and transparently injects feedback within the application itself. We conduct a controlled experiment and a qualitative study to assess our approach. Results show that it prevents testers to be trapped in already tested loops, and succeeds to assist them in performing deeper explorations of the SUT.","2159-4848","978-1-7281-5778-8","10.1109/ICST46399.2020.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159101","test;Exploratory test;n-gram;web applications","Predictive models;Computational modeling;Monitoring;Software testing;Buildings;Context modeling","","","","26","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Bypassing the Combinatorial Explosion: Using Similarity to Generate and Prioritize T-Wise Test Configurations for Software Product Lines","C. Henard; M. Papadakis; G. Perrouin; J. Klein; P. Heymans; Y. Le Traon","Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg",IEEE Transactions on Software Engineering,"8 Jul 2014","2014","40","7","650","670","Large Software Product Lines (SPLs) are common in industry, thus introducing the need of practical solutions to test them. To this end, $t$-wise can help to drastically reduce the number of product configurations to test. Current $t$-wise approaches for SPLs are restricted to small values of $t$. In addition, these techniques fail at providing means to finely control the configuration process. In view of this, means for automatically generating and prioritizing product configurations for large SPLs are required. This paper proposes (a) a search-based approach capable of generating product configurations for large SPLs, forming a scalable and flexible alternative to current techniques and (b) prioritization algorithms for any set of product configurations. Both these techniques employ a similarity heuristic. The ability of the proposed techniques is assessed in an empirical study through a comparison with state of the art tools. The comparison focuses on both the product configuration generation and the prioritization aspects. The results demonstrate that existing  $t$-wise tools and prioritization techniques fail to handle large SPLs. On the contrary, the proposed techniques are both effective and scalable. Additionally, the experiments show that the similarity heuristic can be used as a viable alternative to $t$ -wise.","1939-3520","","10.1109/TSE.2014.2327020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823132","Software product lines;testing;T-wise Interactions;search-based approaches;prioritization;similarity","Testing;Frequency modulation;Context;Scalability;Software;Linux;Arrays","","146","","64","IEEE","29 May 2014","","","IEEE","IEEE Journals"
"Cluster-Based Parallel Testing Using Semantic Analysis","C. Landing; S. Tahvili; H. Haggren; M. Langkvis; A. Muhammad; A. Loufi","School of Science and Technology, Örebro University, Örebro, Sweden; Global Artificial Intelligence Accelerator (GAIA), Ericsson AB, Stockholm, Sweden; Global Artificial Intelligence Accelerator (GAIA), Ericsson AB, Stockholm, Sweden; School of Science and Technology, Örebro University, Örebro, Sweden; Global Artificial Intelligence Accelerator (GAIA), Ericsson AB, Stockholm, Sweden; School of Science and Technology, Örebro University, Örebro, Sweden",2020 IEEE International Conference On Artificial Intelligence Testing (AITest),"25 Aug 2020","2020","","","99","106","Finding a balance between testing goals and testing resources can be considered as a most challenging issue, therefore test optimization plays a vital role in the area of software testing. Several parameters such as the objectives of the tests, test cases similarities and dependencies between test cases need to be considered, before attempting any optimization approach. However, analyzing corresponding testing artifacts (e.g. requirement specification, test cases) for capturing the mentioned parameters is a complicated task especially in a manual testing procedure, where the test cases are documented as a natural text written by a human. Thus, utilizing artificial intelligence techniques in the process of analyzing complex and sometimes ambiguous test data, is considered to be working in different industries. Test scheduling is one of the most popular and practical ways to optimize the testing process. Having a group of test cases which are required the same system setup, installation or testing the same functionality can lead to a more efficient testing process. In this paper, we propose, apply and evaluate a natural language processing-based approach that derives test cases' similarities directly from their test specification. The proposed approach utilizes the Levenshtein distance and converts each test case into a string. Test cases are then grouped into several clusters based on their similarities. Finally, a set of cluster-based parallel test scheduling strategies are proposed for execution. The feasibility of the proposed approach is studied by an empirical evaluation that has been performed on a Telecom use-case at Ericsson in Sweden and indicates promising results.","","978-1-7281-6984-2","10.1109/AITEST49225.2020.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9176809","Software Testing;Natural Language Processing;Test Optimization;Semantic Similarity;Clustering","Testing;Optimization;Job shop scheduling;Semantics;Manuals;Standards;Software","","3","","51","IEEE","25 Aug 2020","","","IEEE","IEEE Conferences"
"GUI Test Case Prioritization by State-Coverage Criterion","Z. -W. He; C. -G. Bai","Department of Automatic Control, Beijing University of Aeronautics and Astronautics, Beijing, China; Department of Automatic Control, Beijing University of Aeronautics and Astronautics, Beijing, China",2015 IEEE/ACM 10th International Workshop on Automation of Software Test,"27 Jul 2015","2015","","","18","22","Graphical User Interface (GUI) application is a kind of typical event-driven software (EDS) that transforms state according to input events invoked through a user interface. It is time consuming to test a GUI application since there are a large number of possible event sequences generated by the permutations and combinations of user operations. Although some GUI test case prioritization techniques have been proposed to determine ""which test case to execute next"" for early fault detection, most of them use random ordering to break tie cases, which has been proved to be ineffective. Recent research presents the opinion that using hybrid criteria can be an effective way for tie-breaking, but few studies focus on seeking a new criterion cooperating well with other criteria when breaking tie cases. In this paper, we propose a state-distance-based method using state coverage as a new criterion to prioritize GUI test cases. An empirical study on three GUI programs reveals that the state-distance-based method is really suitable for GUI test case prioritization and can cooperate well with the (additional) event length criterion.","","978-1-4673-7022-6","10.1109/AST.2015.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7166260","GUI testing;event-driven software;test case prioritization;GUI state similarity","Graphical user interfaces;Testing;Software;Fault detection;Software engineering;Measurement;Conferences","","5","1","11","IEEE","27 Jul 2015","","","IEEE","IEEE Conferences"
"Syntax-Tree Similarity for Test-Case Derivability in Software Requirements","S. Masuda; T. Matsuodani; K. Tsuda","IBM Research, Chuou-ku, Tokyo, Japan; Debug Engineering Research Laboratory, Tama-shi, Tokyo, Japan; University of Tsukuba, Bunkyo-ku, Tokyo, Japan","2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","28 May 2021","2021","","","162","172","Software testing has been important for software engineering to contribute to developing high-quality software. Decision table testing is a general technique to derive test cases with information on conditions and actions from software requirements. Deriving conditions and actions from requirements is key for efficient decision table testing. This paper proposes and evaluates a syntax-tree similarity method for test-case derivability in software requirements. We define the syntax-tree similarity technique used in our method as selecting test-case-derivable sentences from requirements at pre-processing. The syntax tree is defined as divided into sub-trees that consist of a root to each leaf. The syntax-tree similarity technique calculates the similarity between each sentence in the requirements and test-case-derivable sentence. The method involves natural language processing to select test-case-derivable sentences from the requirements on the basis of syntax-tree similarity then determines conditions and actions through dependency and case analyses. After selecting requirements by syntax-tree similarity, our method derives conditions and actions from the requirements by the deriving rules we define. Experiments revealed that the F-measure of the accuracy of the derived conditions and actions increased 16% from that reported in prior work. The results from case studies further indicate the effectiveness of our method.","","978-1-6654-4456-9","10.1109/ICSTW52544.2021.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440190","derive test cases;syntax-tree similarity;software requirements","Software testing;Conferences;Prototypes;Manuals;Syntactics;Software;Natural language processing","","","","47","IEEE","28 May 2021","","","IEEE","IEEE Conferences"
"A Similarity Metric for the Inputs of OO Programs and Its Application in Adaptive Random Testing","J. Chen; F. -C. Kuo; T. Y. Chen; D. Towey; C. Su; R. Huang","School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, VIC, Australia; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, VIC, Australia; School of Computer Science, University of Nottingham Ningbo China, Ningbo, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China",IEEE Transactions on Reliability,"2 Jun 2017","2017","66","2","373","402","Random testing (RT) has been identified as one of the most popular testing techniques, due to its simplicity and ease of automation. Adaptive random testing (ART) has been proposed as an enhancement to RT, improving its fault-detection effectiveness by evenly spreading random test inputs across the input domain. To achieve the even spreading, ART makes use of distance measurements between consecutive inputs. However, due to the nature of object-oriented software (OOS), its distance measurement can be particularly challenging: Each input may involve multiple classes, and interaction of objects through method invocations. Two previous studies have reported on how to test OOS at a single-class level using ART. In this study, we propose a new similarity metric to enable multiclass level testing using ART. When generating test inputs (for multiple classes, a series of objects, and a sequence of method invocations), we use the similarity metric to calculate the distance between two series of objects, and between two sequences of method invocations. We integrate this metric with ART and apply it to a set of open-source OO programs, with the empirical results showing that our approach outperforms other RT and ART approaches in OOS testing.","1558-1721","","10.1109/TR.2016.2628759","National Natural Science Foundation of China(grant numbers:61202110,61502205); Postdoctoral Science Foundation of China(grant numbers:2015M571687,2015M581739); Australian Research Council(grant numbers:DP 120104773); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7790883","Adaptive random testing (ART);method invocation;object distance;object-oriented software (OOS) testing;test input distance","Subspace constraints;Measurement;Software;Power capacitors;Software testing;Computer science","","24","","49","IEEE","19 Dec 2016","","","IEEE","IEEE Journals"
"Evaluating String Distance Metrics for Reducing Automatically Generated Test Suites","I. T. Elgendy; R. M. Hierons; P. McMinn","University of Sheffield, Sheffield, UK; University of Sheffield, Sheffield, UK; University of Sheffield, Sheffield, UK",2024 IEEE/ACM International Conference on Automation of Software Test (AST),"18 Jun 2024","2024","","","171","181","Regression test suites can have a large number of test cases, especially automatically generated ones, and tend to grow in size making it costly to run the entire test suite. Test suite reduction aims to eliminate some test cases to reduce the test suite size and therefore reduce the cost of running it. In this paper, string distances on the text of the test cases are used as measures of similarity for reduction. A practical benefit of using string distance is that there is no need to run the test cases: the test suite source code is the only requirement, making the approach fast. We reduce test suites generated from Randoop and EvoSuite; two well-known test generation tools of Java programs. We implemented a string-based similarity reduction and compared it against random reduction. In the experiments, mutation scores using reduced test suites based on maximising string dissimilarity of test cases were higher than those for random reduction in over 70% of the test suites generated Also, the results showed that test suites generated by Randoop can be drastically reduced in one case by 99% using the string-based similarity reduction approach while maintaining the fault-finding capabilities of the original test suite. Finally, on average, the normalised compression distance was found to be the best similarity metric choice in terms of fault-detection. CCS CONCEPTS • Software and its engineering $\rightarrow$ Software testing and debugging; Empirical software validation.","2833-9061","979-8-4007-0588-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556457","Test suite reduction;Similarity-based testing;Diversity-based testing;Automatically generated tests","Measurement;Software testing;Java;Costs;Automation;Source coding;Debugging","","","","37","","18 Jun 2024","","","IEEE","IEEE Conferences"
"Software Vulnerability Detection Based on Code Coverage and Test Cost","B. Shuai; H. Li; L. Zhang; Q. Zhang; C. Tang","School of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, P. R. China; School of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, China; School of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, China; School of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, China; School of Electronic Science and Engineering, National University of Defense Technology, Changsha, Hunan, China",2015 11th International Conference on Computational Intelligence and Security (CIS),"4 Feb 2016","2015","","","317","321","In order to solve the problems of traditional Fuzzing technique for software vulnerability detection, a novel method based on code coverage and test cost is proposed. Firstly, static analysis is applied to calculate the code coverage information, including basic block coverage and new block coverage. In addition, test path diversity information is introduced to elevate path coverage, which is achieved based on the sequence alignment algorithm. Secondly, test cost is analyzed respectively from running time and loop structure. The loop structure is simplified using finite expansion manner. Thirdly, the genetic algorithm fitness function is constructed based on the code coverage and test cost to guide the test case generation. Experiments on realistic binary software show that the method could obtain higher vulnerability detection accuracy and efficiency than the traditional Fuzzing technique.","","978-1-4673-8660-9","10.1109/CIS.2015.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7397098","code coverage;test cost;test path diversity;genetic algorithm","Software;Genetic algorithms;Security;Algorithm design and analysis;Software algorithms;Optimization;Search problems","","3","1","30","IEEE","4 Feb 2016","","","IEEE","IEEE Conferences"
"Mining Similar Methods for Test Adaptation","D. Sondhi; M. Jobanputra; D. Rani; S. Purandare; S. Sharma; R. Purandare","Department of Computer Science and Engineering, Indraprastha Institute of Information Technology Delhi, New Delhi, Delhi, India; IIT Madras, Chennai, Tamil Nadu, India; Department of Computer Science and Engineering, GITA Bhubaneswar, Bhubaneswar, Odisha, India; Department of Computer Science and Engineering, Indraprastha Institute of Information Technology Delhi, New Delhi, Delhi, India; Department of Computer Science and Engineering, IIIT Bhubaneswar, Bhubaneswar, Odisha, India; Department of Computer Science and Engineering, Indraprastha Institute of Information Technology Delhi, New Delhi, Delhi, India",IEEE Transactions on Software Engineering,"15 Jul 2022","2022","48","7","2262","2276","Developers may choose to implement a library despite the existence of similar libraries, considering factors such as computational performance, language or platform dependency, accuracy, convenience, and completeness of an API. As a result, GitHub hosts several library projects that have overlaps in their functionalities. These overlaps have been of interest to developers from the perspective of code reuse or the preference of one implementation over the other. Through an empirical study, we explore the extent and nature of existence of these similarities in the library functions. We have further studied whether the similarity of functions across different libraries and their associated test suites can be leveraged to reveal defects in one another. We see scope for effectively using the mining of test suites from the perspective of revealing defects in a program or its documentation. Another noteworthy observation made in the study is that similar functions may exist across libraries implemented in the same language as well as in different languages. Identifying the challenges that lie in building a testing tool, we automate the entire process in Metallicus, a test mining and recommendation tool. Metallicus returns a test suite for the given input of a query function and a template for its test suite. On a dataset of query functions taken from libraries implemented in Java or Python, Metallicus revealed 46 defects.","1939-3520","","10.1109/TSE.2021.3057163","Department of Science and Technology (DST) (India); Science and Engineering Research Board; Confederation of Indian Industry; Microsoft Research; Infosys Center for AI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347715","Test suites;mining;software testing;function similarity","Libraries;Testing;Tools;Software development management;Python;Documentation;Open source software","","1","","48","IEEE","4 Feb 2021","","","IEEE","IEEE Journals"
"Test Case Update Detection Using Graph Similarity of UML State Machine in Early Development Process","A. N. Ponco Bimantoro; S. Rochimah; S. Arifiani","Departement of Informatics Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Departement of Informatics Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Departement of Informatics Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2021 8th International Conference on Information Technology, Computer and Electrical Engineering (ICITACEE)","3 Dec 2021","2021","","","143","148","Test case and its data test are part of software testing, which is a crucial phase of software development. Usually, testing is commonly done by explanatory testing and test case-based testing. However, both testing can be very costly and take most of the development time. Moreover, the test case data generated in the early step of development processes could be invalid as its designed algorithm or software might be revised. Therefore, in this study, we proposed a graph similarity of transformed UML State Machine Diagram to justify whether a feature's algorithm data test needs an update or not. We conducted the test on East Java's student admission portal namely PPDB 2017, 2018, and 2019. From the experiment conducted, we found that our proposed method shows promising results with high precision (up to 100%) and 95.6% recall. Thus, our proposed method can be very useful in the early step of development processes because it can save both time and cost since we can detect which features need a new test case data.","","978-1-6654-3998-5","10.1109/ICITACEE53184.2021.9617486","ITS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9617486","Data test;graph similarity;state machine diagram;UML","Software testing;Electrical engineering;Java;Costs;Unified modeling language;Software algorithms;Feature extraction","","1","","12","IEEE","3 Dec 2021","","","IEEE","IEEE Conferences"
"Test Generation and Test Prioritization for Simulink Models with Dynamic Behavior","R. Matinnejad; S. Nejati; L. C. Briand; T. Bruckmann","SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; Delphi Automotive Systems, Luxembourg",IEEE Transactions on Software Engineering,"17 Sep 2019","2019","45","9","919","944","All engineering disciplines are founded and rely on models, although they may differ on purposes and usages of modeling. Among the different disciplines, the engineering of Cyber Physical Systems (CPSs) particularly relies on models with dynamic behaviors (i.e., models that exhibit time-varying changes). The Simulink modeling platform greatly appeals to CPS engineers since it captures dynamic behavior models. It further provides seamless support for two indispensable engineering activities: (1) automated verification of abstract system models via model simulation, and (2) automated generation of system implementation via code generation. We identify three main challenges in the verification and testing of Simulink models with dynamic behavior, namely incompatibility, oracle and scalability challenges. We propose a Simulink testing approach that attempts to address these challenges. Specifically, we propose a black-box test generation approach, implemented based on meta-heuristic search, that aims to maximize diversity in test output signals generated by Simulink models. We argue that in the CPS domain test oracles are likely to be manual and therefore the main cost driver of testing. In order to lower the cost of manual test oracles, we propose a test prioritization algorithm to automatically rank test cases generated by our test generation algorithm according to their likelihood to reveal a fault. Engineers can then select, according to their test budget, a subset of the most highly ranked test cases. To demonstrate scalability, we evaluate our testing approach using industrial Simulink models. Our evaluation shows that our test generation and test prioritization approaches outperform baseline techniques that rely on random testing and structural coverage.","1939-3520","","10.1109/TSE.2018.2811489","H2020 European Research Council(grant numbers:694277); Delphi Automotive Systems, Luxembourg; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8305644","Simulink models;search-based software testing;test generation;test prioritization;test oracle;output diversity;signal features;structural coverage","Software packages;Testing;Tools;Computational modeling;Vehicle dynamics;Scalability","","52","","124","IEEE","1 Mar 2018","","","IEEE","IEEE Journals"
"Comparing and Combining File-based Selection and Similarity-based Prioritization towards Regression Test Orchestration","R. Greca; B. Miranda; M. Gligoric; A. Bertolino","Gran Sasso Science Institute, Federal University of Pernambuco, The University of Texas at Austin, ISTI-CNR Italy, Brazil, USA, Italy; Gran Sasso Science Institute, Federal University of Pernambuco, The University of Texas at Austin, ISTI-CNR Italy, Brazil, USA, Italy; Gran Sasso Science Institute, Federal University of Pernambuco, The University of Texas at Austin, ISTI-CNR Italy, Brazil, USA, Italy; Gran Sasso Science Institute, Federal University of Pernambuco, The University of Texas at Austin, ISTI-CNR Italy, Brazil, USA, Italy",2022 IEEE/ACM International Conference on Automation of Software Test (AST),"17 Jun 2022","2022","","","115","125","Test case selection (TCS) and test case prioritization (TCP) techniques can reduce time to detect the first test failure. Although these techniques have been extensively studied in combination and isolation, they have not been compared one against the other. In this paper, we perform an empirical study directly comparing TCS and TCP approaches, represented by the tools Ekstazi and FAST, respectively. Furthermore, we develop the first combination, named Fastazi, of file-based TCS and similarity-based TCP and evaluate its benefit and cost against each individual technique. We performed our experiments using 12 Java-based open-source projects. Our results show that, in the median case, the combined approach detects the first failure nearly two times faster than either Ekstazi alone (with random test ordering) or FAST alone (without TCS). Statistical analysis shows that the effectiveness of Fastazi is higher than that of Ekstazi, which in turn is higher than that of FAST. On the other hand, FAST adds the least overhead to testing time, while the difference between the additional time needed by Ekstazi and Fastazi is negligible. Fastazi can also improve failure detection in scenarios where the time available for testing is restricted. CCS CONCEPTS • Software and its engineering →Software testing and debugging.","","978-1-4503-9286-0","10.1145/3524481.3527223","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796413","regression testing;test case selection;test case prioritization;test orchestration;Fastazi","Costs;Automation;Statistical analysis;Diversity reception;Debugging;Open source software;Testing","","4","","37","","17 Jun 2022","","","IEEE","IEEE Conferences"
"Boundary Value Exploration for Software Analysis","F. Dobslaw; F. G. de Oliveira Neto; R. Feldt","Dept. of Computer Science and Engineering, Chalmers and the University of Gothenburg, Gothenburg, Sweden; Dept. of Computer Science and Engineering, Chalmers and the University of Gothenburg, Gothenburg, Sweden; Dept. of Computer Science and Engineering, Chalmers and the University of Gothenburg, Gothenburg, Sweden","2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2020","2020","","","346","353","For software to be reliable and resilient, it is widely accepted that tests must be created and maintained alongside the software itself. One safeguard from vulnerabilities and failures in code is to ensure correct behavior on the boundaries between subdomains of the input space. So-called boundary value analysis (BVA) and boundary value testing (BVT) techniques aim to exercise those boundaries and increase test effectiveness. However, the concepts of BVA and BVT themselves are not generally well defined, and it is not clear how to identify relevant sub-domains, and thus the boundaries delineating them, given a specification. This has limited adoption and hindered automation. We clarify BVA and BVT and introduce Boundary Value Exploration (BVE) to describe techniques that support them by helping to detect and identify boundary inputs. Additionally, we propose two concrete BVE techniques based on information-theoretic distance functions: (i) an algorithm for boundary detection and (ii) the usage of software visualization to explore the behavior of the software under test and identify its boundary behavior. As an initial evaluation, we apply these techniques on a much used and well-tested date handling library. Our results reveal questionable behavior at boundaries highlighted by our techniques. In conclusion, we argue that the boundary value exploration that our techniques enable is a step towards automated boundary value analysis and testing, which can foster their wider use and improve test effectiveness and efficiency.","","978-1-7281-1075-2","10.1109/ICSTW50294.2020.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155629","boundary value analysis;boundary value testing;test diversity","Software;Tools;Software testing;Visualization;Measurement;Heating systems","","8","","28","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"Searching for Cognitively Diverse Tests: Towards Universal Test Diversity Metrics","R. Feldt; R. Torkar; T. Gorschek; W. Afzal","Department of Systems and Software Engineering, Blekinge Institute of Technology, Ronneby, Sweden; Department of Systems and Software Engineering, Blekinge Institute of Technology, Ronneby, Sweden; Department of Systems and Software Engineering, Blekinge Institute of Technology, Ronneby, Sweden; Department of Systems and Software Engineering, Blekinge Institute of Technology, Ronneby, Sweden",2008 IEEE International Conference on Software Testing Verification and Validation Workshop,"16 Jul 2008","2008","","","178","186","Search-based software testing (SBST) has shown a potential to decrease cost and increase quality of testing- related software development activities. Research in SBST has so far mainly focused on the search for isolated tests that are optimal according to a fitness function that guides the search. In this paper we make the case for fitness functions that measure test fitness in relation to existing or previously found tests; a test is good if it is diverse from other tests. We present a model for test variability and propose the use of a theoretically optimal diversity metric at variation points in the model. We then describe how to apply a practically useful approximation to the theoretically optimal metric. The metric is simple and powerful and can be adapted to a multitude of different test diversity measurement scenarios. We present initial results from an experiment to compare how similar to human subjects, the metric can cluster a set of test cases. To carry out the experiment we have extended an existing framework for test automation in an object-oriented, dynamic programming language.","","978-0-7695-3388-9","10.1109/ICSTW.2008.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4567005","","Software testing;System testing;Humans;Object oriented modeling;Automatic testing;Software measurement;Software engineering;Isolation technology;Costs;Programming","","43","","22","IEEE","16 Jul 2008","","","IEEE","IEEE Conferences"
"Measurement of Similarity between Use Case Description and Sequence Diagram in Software Requirement Specification using Text Analysis for Dtrain Application","R. Z. I. Yanis; Y. Priyadi; S. Y. Puspitasari","Department of Informatics, Telkom University, Bandung, Indonesia; Department of Software Engineering, Telkom University, Bandung, Indonesia; Department of Software Engineering, Telkom University, Bandung, Indonesia",2022 2nd International Conference on Electronic and Electrical Engineering and Intelligent System (ICE3IS),"16 Jan 2023","2022","","","328","333","Dtrain application is built by implementing software documents, one of which is the Software Requirement Specification (SRS). In compiling software documents, there is a mismatch between one document element with other elements. Therefore, this study will measure the similarity between the Use Case Description (UCD) on the SRS case study Dtrain with Sequence Diagrams (SD) to determine how similar or compatible the two SRS elements are. This study aims to measure the similarity of UML artifacts between UCD and SD contained in a software development document. The suitability of the two artifacts can be done by analyzing the text in the description (UCD) and object (SD) sections. Based on the results and discussion, this study resulted in the following. First, a study that finds level of similarity between UCD and the SD by comparing the step results performed an extraction on the UCD and the extraction of messages and actors on the SD. Second, there are five use cases in the Dtrain application, so the UCD and SD are each 5. Third, the highest similarity value results are found in SD 1 and SD 5, with a similarity value of 0.712. Fourth, the results of the validation value using algorithm code to get a kappa score of 0.331. Fifth, the results of the validation obtained from results of the expert questionnaire got a value of 0.8905.","","978-1-6654-6541-0","10.1109/ICE3IS56585.2022.10010259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10010259","Similarity;Software Requirement Specification;Validity;Text Analysis;Use Case","Electrical engineering;Text analysis;Codes;Unified modeling language;Software algorithms;Electric variables measurement;Software","","10","","24","IEEE","16 Jan 2023","","","IEEE","IEEE Conferences"
"Using mutation testing to measure behavioural test diversity","F. G. d. O. Neto; F. Dobslaw; R. Feldt","Dept. of Computer Science and Engineering, Chalmers and the University of Gothenburg, Gothenburg, Sweden; Dept. of Computer Science and Engineering, Chalmers and the University of Gothenburg, Gothenburg, Sweden; Dept. of Computer Science and Engineering, Chalmers and the University of Gothenburg, Gothenburg, Sweden","2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2020","2020","","","254","263","Diversity has been proposed as a key criterion to improve testing effectiveness and efficiency. It can be used to optimise large test repositories but also to visualise test maintenance issues and raise practitioners' awareness about waste in test artefacts and processes. Even though these diversitybased testing techniques aim to exercise diverse behavior in the system under test (SUT), the diversity has mainly been measured on and between artefacts (e.g., inputs, outputs or test scripts). Here, we introduce a family of measures to capture behavioural diversity (b-div) of test cases by comparing their executions and failure outcomes. Using failure information to capture the SUT behaviour has been shown to improve effectiveness of history-based test prioritisation approaches. However, historybased techniques require reliable test execution logs which are often not available or can be difficult to obtain due to flaky tests, scarcity of test executions, etc. To be generally applicable we instead propose to use mutation testing to measure behavioral diversity by running the set of test cases on various mutated versions of the SUT. Concretely, we propose two specific b-div measures (based on accuracy and Matthew's correlation coefficient, respectively) and compare them with artefact-based diversity (a-div) for prioritising the test suites of 6 different open-source projects. Our results show that our b-div measures outperform a-div and random selection in all of the studied projects. The improvement is substantial with an average increase in average percentage of faults detected (APFD) of between 19% to 31% depending on the size of the subset of prioritised tests.","","978-1-7281-1075-2","10.1109/ICSTW50294.2020.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155915","diversity-based testing;test prioritisation;test selection;empirical study","Testing;Fault detection;Reliability;Optimization;Atmospheric measurements;Particle measurements;Diversity reception","","4","","31","IEEE","4 Aug 2020","","","IEEE","IEEE Conferences"
"History-Guided Configuration Diversification for Compiler Test-Program Generation","J. Chen; G. Wang; D. Hao; Y. Xiong; H. Zhang; L. Zhang","College of Intelligence and Computing, Tianjin University, Tianjin, China; Key Laboratory of High Confidence Software Technologies, Peking University), MoE; Key Laboratory of High Confidence Software Technologies, Peking University), MoE; Key Laboratory of High Confidence Software Technologies, Peking University), MoE; The University of Newcastle, NSW, Australia; Key Laboratory of High Confidence Software Technologies, Peking University), MoE",2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE),"9 Jan 2020","2019","","","305","316","Compilers, like other software systems, contain bugs, and compiler testing is the most widely-used way to assure compiler quality. A critical task of compiler testing is to generate test programs that could effectively and efficiently discover bugs. Though we can configure test generators such as Csmith to control the features of the generated programs, it is not clear what test configuration is effective. In particular, an effective test configuration needs to generate test programs that are bug-revealing, i.e., likely to trigger bugs, and diverse, i.e., able to discover different types of bugs. It is not easy to satisfy both properties. In this paper, we propose a novel test-program generation approach, called HiCOND, which utilizes historical data for configuration diversification to solve this challenge. HiCOND first infers the range for each option in a test configuration where bug-revealing test programs are more likely to be generated based on historical data. Then, it identifies a set of test configurations that can lead to diverse test programs through a search method (particle swarm optimization). Finally, based on the set of test configurations for compiler testing, HiCOND generates test programs, which are likely to be bug-revealing and diverse. We have conducted experiments on two popular compilers GCC and LLVM, and the results confirm the effectiveness of our approach. For example, HiCOND detects 75.00%, 133.33%, and 145.00% more bugs than the three existing approaches, respectively. Moreover, HiCOND has been successfully applied to actual compiler testing in a global IT company and detected 11 bugs during the practical evaluation.","2643-1572","978-1-7281-2508-4","10.1109/ASE.2019.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952321","Compiler Testing;Configuration;History;Search","Computer bugs;Testing;Program processors;Generators;Companies;Software systems","","29","","58","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Robust comparison of similarity measures in analogy based software effort estimation","P. Phannachitta","College of Arts, Media and Technology, Chiang Mai University, Thailand","2017 11th International Conference on Software, Knowledge, Information Management and Applications (SKIMA)","19 Feb 2018","2017","","","1","7","Analogy-based software effort estimation (ABE) is a widely-adopted method because of the accuracy it offered as well as its intuitiveness. ABE derives an estimated effort value for a new software project by adapting to the effort values of its similar past projects. Accurately measuring the level of similarity between software project cases is an important process of ABE in regards to whether the retrieved past similar projects are analogous to the new project. However, no one to the best of our knowledge has systematically evaluated and compared the similarity measures for the ABE process. In the present study, 6 similarity measures that have been most commonly appeared in the literatures in a 5-year timeframe up to the time of writing are systematically compared. Based on a comprehensive empirical experiment using 12 industrial datasets consisting of 952 project cases, together with 5 robust performance measures, and subject to a robust statistical test method, we found that simple similarity measures such as Euclidean and Manhattan similarity measures generally offer accurate estimation for software effort estimation datasets. Despite studies in other fields frequently discourage the use of these simple similarity measures, the results of the present study are otherwise supporting them as a crucial part of an ABE model.","2573-3214","978-1-5386-4602-1","10.1109/SKIMA.2017.8294126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8294126","Software effort estimation;Analogy-based effort estimation;Similarity measure;Distance function;Empirical software engineering","Software;Estimation;Pollution measurement;Software measurement;Robustness;Euclidean distance;Bibliographies","","6","","43","IEEE","19 Feb 2018","","","IEEE","IEEE Conferences"
"The Role of Similarity in Detecting Feature Interaction in Software Product Lines","S. Khoshmanesh; R. R. Lutz","Department of Computer Science, Iowa State University, Ames, US; Department of Computer Science, Iowa State University, Ames, US",2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW),"18 Nov 2018","2018","","","286","292","As a software product line evolves, it typically introduces new features and includes new products over time. A known cause of software aging in product lines is the introduction of new features that interact in unplanned and even risky ways with the existing features. This can lead to failures, performance degradation, and hazardous states in a new product. Software product line developers currently identify new, unwanted feature interactions primarily in the testing of each new product. This incurs significant costs, comes late in development, and does not exploit the knowledge of prior feature interactions within a product line. The contribution of our paper is to leverage knowledge of prior feature interactions in a product line, together with similarity measures between the features in known feature interactions and the new features, in order to detect similar feature interactions in a new product much earlier in the development process. Results from application to a case study from the literature show that this approach accurately detected 73% of feature interactions. This small study suggests that using similarity measures at the feature level within a product line to detect problematic interactions involving a new feature can effectively reduce this cause of aging in a software product line.","","978-1-5386-9443-5","10.1109/ISSREW.2018.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539209","feature interaction;software aging;similarity metrics;software product lines","Feature extraction;Electronic mail;Software product lines;Cryptography;Testing;Software;Measurement","","3","","38","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"SimCoTest: A Test Suite Generation Tool for Simulink/Stateflow Controllers","R. Matinnejad; S. Nejati; L. C. Briand; T. Bruckmann","SnT Centre, University of Luxembourg, Luxembourg; SnT Centre, University of Luxembourg, Luxembourg; SnT Centre, University of Luxembourg, Luxembourg; Delphi Automotive Systems, Luxembourg",2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C),"23 Mar 2017","2016","","","585","588","We present SimCoTest, a tool to generate small test suites with high fault revealing ability for Simulink/Stateflow controllers. SimCoTest uses meta-heuristic search to (1) maximize the likelihood of presence of specific failure patterns in output signals (failure-based test generation), and to (2) maximize diversity of output signal shapes (output diversity test generation). SimCoTest has been evaluated on industrial Simulink models and has been systematically compared with Simuilnk Design Verifier (SLDV), an alternative commercial Simulink testing tool. Our results show that the fault revealing ability of SimCoTest outperforms that of SLDV. Further, in contrast to SLDV, SimCoTest is applicable to Simulink/Stateflow models in their entirety. A video describing the main features of SimCoTest is available at: https://youtu.be/YnXgveiGXEA.","","978-1-4503-4205-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883346","Simulink/Stateflow models;Software testing;Search-based software testing;Output diversity;Failure-based test generation;Simulink Design Verifier (SLDV)","Software packages;Mathematical model;Computational modeling;Testing;Data models;Adaptation models;Shape","","","","14","","23 Mar 2017","","","IEEE","IEEE Conferences"
"Techvar: Classification of Similarity in Software Detection Model using Deep Learning","P. H. Babu; P. Yalla","Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, AP; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Guntur, AP",2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS),"27 Apr 2022","2022","","","341","346","In Industry 4.0, Deep Learning techniques have become an important research tool in many area namely healthcare, automobiles, video analysis, audio analytics, software systems etc. In recent years, many research are performed in software analysis using modern technologies. CrosLSim, SimMax, and atrpos models are used to review the software similarity detection techniques for different software systems. The existing models for similarity detection are not efficient to be used in major software projects. In this paper, the Techvar-DNN system which performs enhanced Probability, maintainability, testability, and reusability has been proposed. When compared with other methods namely Random Forest and Support vector machines, the proposed system provides increased recall, a smaller function size, and more efficient computing. Moreover, the proposed model results show better F-measure, precision and recall to improve the software similarity detection in a more efficient manner.","","978-1-6654-7884-7","10.1109/ICSCDS53736.2022.9761003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761003","Deep Learning;Software Engineering;Similarity Detection;Classification","Deep learning;Support vector machines;Computational modeling;Taxonomy;Medical services;Software systems;Fourth Industrial Revolution","","","","20","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Reports Aggregation of Crowdsourcing Test Based on Feature Fusion","L. Cai; N. Wang; M. Chen; J. Wang; J. Wang; J. Gong","Development Center of Computer Software Technology, Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai, Shanghai, China; Development Center of Computer Software Technology, Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai, Shanghai, China; Development Center of Computer Software Technology, Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai, Shanghai, China; Development Center of Computer Software Technology, Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai, Shanghai, China; Development Center of Computer Software Technology, Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai, Shanghai, China; Development Center of Computer Software Technology, Shanghai Key Laboratory of Computer Software Testing & Evaluating, Shanghai, Shanghai, China","2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)","1 Apr 2022","2021","","","51","59","In recent years, a new testing method based on the concept of crowdsourcing has made great progress. Developers upload the project to the crowdsourcing test platform and recruit a large number of crowdsourcing workers for testing, so that the testing process has higher test adequacy, faster testing speed and lower testing cost. However, the test reports submitted after the test have serious problems such as large quantity and high similarity, resulting in the failure to achieve the expected results. Based on the method of feature fusion, this paper integrates the text description information, bug type information and screenshot information of crowdsourcing test reports, clusters crowdsourcing test reports through the calculation of similarity between reports, and finally achieves better results.","2693-9371","978-1-6654-7836-6","10.1109/QRS-C55045.2021.00018","National Key R&D Program of China(grant numbers:2018YFB1403400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9742039","crowdsourcing testing;similarity calculation;feature fusion","Crowdsourcing;Costs;Conferences;Machine learning;Software quality;Natural language processing;Mathematical models","","1","","32","IEEE","1 Apr 2022","","","IEEE","IEEE Conferences"
"Evaluation and Analysis of Spectrum-Based Fault Localization with Modified Similarity Coefficients for Software Debugging","Y. -S. You; C. -Y. Huang; K. -L. Peng; C. -J. Hsu","Institute of Information Systems and Applications, National Tsinghua University, Hsinchu, Taiwan; Inst. of Inf. Syst. & Applic., Nat. Tsinghua Univ., Hsinchu, Taiwan; Department of Computer Science; Department of Computer Science",2013 IEEE 37th Annual Computer Software and Applications Conference,"31 Oct 2013","2013","","","180","189","During the process of fault localization, the spectrum-based techniques are frequently used and widely studied since they can automatically and effectively localize the faults of software and be implemented easily. So far most of spectrum-based fault localization techniques have relied heavily on the use of similarity coefficients. However, we noticed that existing similarity coefficients for fault localization may lack measure(s) to properly reflect the relationship between failing and passing test cases. It also has to note that the failing test cases usually are expected to provide more information to the similarity coefficients than the passing test cases. In order to evaluate the importance of failing and passing test cases in the similarity coefficients, a number of modified similarity coefficients in fault localization are presented and discussed. The modified similarity coefficients which are assigned the weights of the failing and/or passing test cases will be studied and analyzed with the multi-coverage-combined techniques. Five open source programs and 75 faulty versions in total from Siemens suite, which have been widely used for software testing and comparison of fault localization techniques, were selected as experiment subjects. Detailed analysis of the results shows that assigning the weights of failing and passing test cases to the similarity coefficients would be able to localize the faults more effectively and accurately.","0730-3157","978-0-7695-4986-6","10.1109/COMPSAC.2013.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6649819","Fault Localization;Software Debugging;Software Testing;Similarity Coefficient","Computer bugs;Software testing;Fault diagnosis;Vectors;Software debugging","","11","","39","IEEE","31 Oct 2013","","","IEEE","IEEE Conferences"
"Black-Box Testing of Deep Neural Networks through Test Case Diversity","Z. Aghababaeyan; M. Abdellatif; L. Briand; R. S; M. Bagherzadeh","School of EECS, University of Ottawa, Ottawa, ON, Canada; Software and Information Technology Engineering Department, École de Technologie Supérieure, Montreal, QC, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada; Department of Research and Development, General Motors, Warren, MI, USA; School of EECS, University of Ottawa, Ottawa, ON, Canada",IEEE Transactions on Software Engineering,"15 May 2023","2023","49","5","3182","3204","Deep Neural Networks (DNNs) have been extensively used in many areas including image processing, medical diagnostics and autonomous driving. However, DNNs can exhibit erroneous behaviours that may lead to critical errors, especially when used in safety-critical systems. Inspired by testing techniques for traditional software systems, researchers have proposed neuron coverage criteria, as an analogy to source code coverage, to guide the testing of DNNs. Despite very active research on DNN coverage, several recent studies have questioned the usefulness of such criteria in guiding DNN testing. Further, from a practical standpoint, these criteria are white-box as they require access to the internals or training data of DNNs, which is often not feasible or convenient. Measuring such coverage requires executing DNNs with candidate inputs to guide testing, which is not an option in many practical contexts. In this paper, we investigate diversity metrics as an alternative to white-box coverage criteria. For the previously mentioned reasons, we require such metrics to be black-box and not rely on the execution and outputs of DNNs under test. To this end, we first select and adapt three diversity metrics and study, in a controlled manner, their capacity to measure actual diversity in input sets. We then analyze their statistical association with fault detection using four datasets and five DNNs. We further compare diversity with state-of-the-art white-box coverage criteria. As a mechanism to enable such analysis, we also propose a novel way to estimate fault detection in DNNs. Our experiments show that relying on the diversity of image features embedded in test input sets is a more reliable indicator than coverage criteria to effectively guide DNN testing. Indeed, we found that one of our selected black-box diversity metrics far outperforms existing coverage criteria in terms of fault-revealing capability and computational time. Results also confirm the suspicions that state-of-the-art coverage criteria are not adequate to guide the construction of test input sets to detect as many faults as possible using natural inputs.","1939-3520","","10.1109/TSE.2023.3243522","General Motors and Canada Research Chair; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041782","Coverage;deep neural network;diversity;faults;test","Measurement;Testing;Feature extraction;Closed box;Fault detection;Neurons;Computational modeling","","19","","93","CCBY","9 Feb 2023","","","IEEE","IEEE Journals"
"A similarity-based approach for test case prioritization using historical failure data","T. B. Noor; H. Hemmati","Department of Computer Science, University of Manitoba, Winnipeg, Canada; Department of Computer Science, University of Manitoba, Winnipeg, Canada",2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE),"14 Jan 2016","2015","","","58","68","Test case prioritization is a crucial element in software quality assurance in practice, specially, in the context of regression testing. Typically, test cases are prioritized in a way that they detect the potential faults earlier. The effectiveness of test cases, in terms of fault detection, is estimated using quality metrics, such as code coverage, size, and historical fault detection. Prior studies have shown that previously failing test cases are highly likely to fail again in the next releases, therefore, they are highly ranked, while prioritizing. However, in practice, a failing test case may not be exactly the same as a previously failed test case, but quite similar, e.g., when the new failing test is a slightly modified version of an old failing one to catch an undetected fault. In this paper, we define a class of metrics that estimate the test cases quality using their similarity to the previously failing test cases. We have conducted several experiments with five real world open source software systems, with real faults, to evaluate the effectiveness of these quality metrics. The results of our study show that our proposed similarity-based quality measure is significantly more effective for prioritizing test cases compared to existing test case quality measures.","","978-1-5090-0406-5","10.1109/ISSRE.2015.7381799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381799","Test case prioritization;Test quality metric;Similarity;Execution trace;Distance function;Historical data;Code coverage;Test size","Measurement;Testing;Fault detection;History;Context;Software quality","","49","1","32","IEEE","14 Jan 2016","","","IEEE","IEEE Conferences"
"Prefilter: A Fault Localization Method using Unlabelled Test Cases based on K-Means Clustering and Similarity","D. An; S. Wang; L. Zhu; X. Yang; X. Yan","School of Reliability and System Engineering, Beihang University, Beijing, China; School of Reliability and System Engineering, Beihang University, Beijing, China; School of Reliability and System Engineering, Beihang University, Beijing, China; School of Reliability and System Engineering, Beihang University, Beijing, China; Nanjing Research Institute of Electronic Engineering, Nanjing, China","2022 IEEE 22nd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)","30 Mar 2023","2022","","","263","269","Current research begins to apply unlabelled test cases to fault localization. However, in these methods, the labeled test cases randomly selected as the basis for fault localization cannot cover enough execution information, which will reduce fault localization efficiency. In this paper, a method based on K-Means clustering and similarity is proposed. At the beginning of the test, K-Means clustering is performed on the test case suite and the test cases filtered can cover more execution information. Next, for the test cases with failed execution results, the test cases with similar execution information are filtered to better highlight the fault information in the failed test cases. Experiments on Defects4J datasets show that the proposed method can be combined with other technologies to improve their efficiency, and the proposed method also has good compatibility with traditional software fault localization algorithms. The average improvement reached 13.37% in 8 scenarios.","2693-9371","979-8-3503-1991-0","10.1109/QRS-C57518.2022.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10076948","Fault localization;Software debugging;Unlabelled test cases;K-Means clustering;similarity;Test oracle","Location awareness;Software algorithms;Clustering algorithms;Software quality;Filtering algorithms;Information filters;Software reliability","","1","","16","IEEE","30 Mar 2023","","","IEEE","IEEE Conferences"
"A Theoretical and Empirical Study of Diversity-Aware Mutation Adequacy Criterion","D. Shin; S. Yoo; D. -H. Bae","School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",IEEE Transactions on Software Engineering,"14 Oct 2018","2018","44","10","914","931","Diversity has been widely studied in software testing as a guidance towards effective sampling of test inputs in the vast space of possible program behaviors. However, diversity has received relatively little attention in mutation testing. The traditional mutation adequacy criterion is a one-dimensional measure of the total number of killed mutants. We propose a novel, diversity-aware mutation adequacy criterion called distinguishing mutation adequacy criterion, which is fully satisfied when each of the considered mutants can be identified by the set of tests that kill it, thereby encouraging inclusion of more diverse range of tests. This paper presents the formal definition of the distinguishing mutation adequacy and its score. Subsequently, an empirical study investigates the relationship among distinguishing mutation score, fault detection capability, and test suite size. The results show that the distinguishing mutation adequacy criterion detects 1.33 times more unseen faults than the traditional mutation adequacy criterion, at the cost of a 1.56 times increase in test suite size, for adequate test suites that fully satisfies the criteria. The results show a better picture for inadequate test suites; on average, 8.63 times more unseen faults are detected at the cost of a 3.14 times increase in test suite size.","1939-3520","","10.1109/TSE.2017.2732347","Information & communications Technology Promotion (IITP); Korea government (MSIP)(grant numbers:R0126-17-1101); Software R&D for Model-based Analysis and Verification of Higher-order Large Complex System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7994647","Mutation testing;test adequacy criteria;diversity","Fault detection;Software engineering;Software testing;Correlation;Indexes;Subspace constraints","","24","","58","IEEE","27 Jul 2017","","","IEEE","IEEE Journals"
"Automatic Identification of High Impact Bug Report by Test Smells of Textual Similar Bug Reports","J. Ding; G. Fan; H. Yu; Z. Huang","Department of Computer Science and Engineering, East China University of Science and Technology; Department of Computer Science and Engineering, East China University of Science and Technology; Department of Computer Science and Engineering, East China University of Science and Technology; Department of Computer Science and Engineering, East China University of Science and Technology","2021 IEEE 21st International Conference on Software Quality, Reliability and Security (QRS)","10 Mar 2022","2021","","","446","457","Bug reports are written by the software stakeholders to track software defects and vulnerabilities. Since Software Quality Assurance (SQA) resources are limited, developers tend to resolve High-Impact Bugs (HIB) in advance. Prior research identified HIBs by analyzing the textual information in bug reports. However, they only consider textual information instead of the root cause of bugs, such as code quality. Since prior study revealed software test smells (i.e., sub-optimal test code implementation) are related to bug proneness, we intend to measure test smell distribution in textual similar bug reports to identify HIB reports. We first construct an effective model, which outperforms the baseline by 29.3% in terms of AUC-ROC. Secondly, we use SHAP to compute the importance of test smell features. Finally, we conduct an empirical survey to discuss the relationship between test smell and HIB reports. Result shows that Assertion Roulette and Conditional Test Logic test smell are important factors in distinguishing the types of bug reports.","2693-9177","978-1-6654-5813-9","10.1109/QRS54544.2021.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9724899","high impact bug report;test code smell;software quality assurance;empirical software engineering","Codes;Computer bugs;Software quality;Predictive models;Reliability engineering;Software reliability;Security","","1","","41","IEEE","10 Mar 2022","","","IEEE","IEEE Conferences"
"The Comparative Evaluation of Test Prioritization Approaches in an Industrial Study","A. Ahmad; F. G. d. O. Neto; E. P. Enoiu; K. Sandahl; O. Leifler","Ericsson AB, Linköping, Sweden; Gothenburg University, Gothenburg, Sweden; Mälardalens University, Mälardalens, Sweden; Linköping University, Linköping, Sweden; Linköping University, Linköping, Sweden","2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)","19 Feb 2024","2023","","","35","44","Many test prioritisation techniques have been proposed in order to improve test effectiveness of Continuous Integration (CI) pipelines. Particularly, diversity-based testing (DBT) has shown promising and competitive results to improve test effectiveness. We report on a case study considering the CI pipeline of Axis Communications in Sweden. We compared three different prioritisation approaches (i.e., diversity, failure history and time) in terms of their impact on coverage, failure detection rates and reduction on test execution time. Our results reveal that DBT is the best candidate to provide feature coverage, whereas failure rate prioritisation yields better failure coverage. Time-based prioritisation is not a reliable approach to provide cost-effective testing. Moreover, DBT would allow stakeholders to receive quick feedback on many combinations of integrated features to verify their code changes. Our participants report that developers are mainly interested in: (i) receiving quick feedback on a high combination of integrated features to verify their code changes, and (ii) associate their test suites to confidence scores representing the risk of missing failures given that fewer tests are executed.","2693-9371","979-8-3503-5939-8","10.1109/QRS-C60940.2023.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429997","diversity based testing;comparative evaluation;continuous integration;regression testing","Codes;Pipelines;Software quality;Software reliability;Stakeholders;Security;Testing","","","","64","IEEE","19 Feb 2024","","","IEEE","IEEE Conferences"
"From Diversity by Numbers to Diversity as Process: Supporting Inclusiveness in Software Development Teams with Brainstorming","A. Filippova; E. Trainer; J. D. Herbsleb","Institute for Software Research, Carnegie Mellon University, Pittsburgh, PA, USA; Institute for Software Research, Carnegie Mellon University, Pittsburgh, PA, USA; Institute for Software Research, Carnegie Mellon University, Pittsburgh, PA, USA",2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE),"20 Jul 2017","2017","","","152","163","Negative experiences in diverse software development teams have the potential to turn off minority participants from future team-based software development activity. We examine the use of brainstorming as one concrete team processes that may be used to improve the satisfaction of minority developers when working in a group. Situating our study in time-intensive hackathon-like environments where engagement of all team members is particularly crucial, we use a combination of survey and interview data to test our propositions. We find that brainstorming strategies are particularly effective for team members who identify as minorities, and support satisfaction with both the process and outcomes of teamwork through different mechanisms.","1558-1225","978-1-5386-3868-2","10.1109/ICSE.2017.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985658","Diversity;hackathons;teamwork;brainstorming;satisfaction;software engineering management","Software;Teamwork;Software engineering;Concrete;Cultural differences;Organizations","","39","","47","IEEE","20 Jul 2017","","","IEEE","IEEE Conferences"
"An Empirical Comparison of Similarity Measures for Abstract Test Case Prioritization","R. Huang; Y. Zhou; W. Zong; D. Towey; J. Chen","School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, P.R. China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, P.R. China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, P.R. China; T School of Computer Science, The University of Nottingham Ningbo China, Ningbo, P.R. China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, P.R. China",2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC),"11 Sep 2017","2017","1","","3","12","Test case prioritization (TCP) attempts to order test cases such that those which are more important, according to some criterion or measurement, are executed earlier. TCP has been applied in many testing situations, including, for example, regression testing. An abstract test case (also called a model input) is an important type of test case, and has been widely used in practice, such as in configurable systems and software product lines. Similarity-based test case prioritization (STCP) has been proven to be cost-effective for abstract test cases (ATCs), but because there are many similarity measures which could be used to evaluate ATCs and to support STCP, we face the following question: How can we choose the similarity measure(s) for prioritizing ATCs that will deliver the most effective results? To address this, we studied fourteen measures and two popular STCP algorithms - local STCP (LSTCP), and global STCP (GSTCP). We also conducted an empirical study of five realworld programs, and investigated the efficacy of each similarity measure, according to the interaction coverage rate and fault detection rate. The results of these studies show that GSTCP outperforms LSTCP - in 61% to 84% of the cases, in terms of interaction coverage rates; and in 76% to 78% of the cases with respect to fault detection rates. Our studies also show that Overlap, the simplest similarity measure examined in this study, could obtain the overall best performance for LSTCP; and that Goodall3 has the best performance for GSTCP.","0730-3157","978-1-5386-0367-3","10.1109/COMPSAC.2017.271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029584","Software testing;test case prioritization;abstract test case;similarity","Testing;Fault detection;Software;Computer science;Software product lines;Fault diagnosis;Algorithm design and analysis","","8","","25","IEEE","11 Sep 2017","","","IEEE","IEEE Conferences"
"Prioritization of Metamorphic Relations Based on Test Case Execution Properties","M. Srinivasan","Gianforte School of Computing, Montana State University, Bozeman, United States",2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW),"18 Nov 2018","2018","","","162","165","A test oracle is essential for software testing. In certain complex systems, it is hard to distinguish between correct and incorrect behavior. Metamorphic testing is one of the solution to solve the test oracle problem. In metamorphic testing, metamorphic relations (MRs) are derived based on the properties exhibited by the program under test (PUT). These MRs play a major role in the generation of test data for conducting MT. The effectiveness of MRs can be determined based on the ability to detect considerable faults for the given PUT. Many metamorphic relations with different fault finding capability can be used to test the PUT and it is important to identify and prioritize the MRs based on its fault finding effectiveness. In order to answer this challenge, we propose to prioritize the MRs based on the diversity in the execution path of the source and follow-up test cases of the MRs. We propose four metrics to capture different levels of diversity in the execution behavior of the test cases for each of the derived MRs. The total weight calculated for each of the MRs using the metrics is used to prioritize the MRs.","","978-1-5386-9443-5","10.1109/ISSREW.2018.000-5","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539189","Metamorphic Testing, Metamorphic Relations, Test case diversity, MR Prioritization","Measurement;Complexity theory;Indexes;Correlation;Tools;Software testing","","4","","13","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"Practical Software Diversification Tool Chain for Dissimilar Redundancy Architecture","G. Zhang; Z. Zhang; J. Wang; X. Ji","State key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; State key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; State key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; Information Engineering University, Zhengzhou, China",2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),"3 Feb 2021","2020","9","","1518","1521","With the rapid development of the information society, there are corresponding tool solutions for various daily problems. Aiming at the complex generation process and inconvenient operation of heterogeneous components in a security defense system constructed with dissimilar redundancy, in this paper, we propose a practical basic software application isomerization tool chain, which integrates a series of key technologies of heterogeneous structures. At the same time, corresponding automated tests are provided for users to conduct comprehensive evaluation. Experimental evaluation shows that the tool chain will be able to provide heterogeneous component support for security defense technologies based on dissimilarity redundancy construction and improve the security of software systems.","2693-2865","978-1-7281-5244-8","10.1109/ITAIC49862.2020.9338810","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9338810","software diversification;tool chain;dissimilar redundancy architecture;software system security","Redundancy;Computer architecture;Tools;Software;Hardware;Security;Testing","","1","","15","IEEE","3 Feb 2021","","","IEEE","IEEE Conferences"
"MAF: Method-Anchored Test Fragmentation for Test Code Plagiarism Detection","W. Sun; X. Wang; H. Wu; D. Duan; Z. Sun; Z. Chen","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET),"15 Aug 2019","2019","","","110","120","Software engineering education becomes popular due to the rapid development of the software industry. In order to reduce learning costs and improve learning efficiency, some online practice platforms have emerged. This paper proposes a novel test code plagiarism detection technology, namely MAF, by introducing bidirectional static slicing to anchor methods under test and extract fragments of test codes. Combined with similarity measures, MAF can achieve effective plagiarism detection by avoiding massive unrelated noisy test codes. The experiment is conducted on the dataset of Mooctest, which so far has supported hundreds of test activities around the world in the past 3 years. The experimental results show that MAF can effectively improve the performance (precision, recall and F1-measure) of similarity measures for test code plagiarism detection. We believe that MAF can further expand and promote software testing education, and it can also be extended to use in test recommendation, test reuse and other engineering applications.","","978-1-7281-1000-4","10.1109/ICSE-SEET.2019.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802113","Similarity measure, Plagiarism detection, Unit testing, Online training","","","3","","43","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Improving Multi-Objective Test Case Selection by Injecting Diversity in Genetic Algorithms","A. Panichella; R. Oliveto; M. D. Penta; A. De Lucia","Department of Mathematics and Computer Science, University of Salerno, Fisciano, Salerno, Italy; Department of Bioscience and Territory, University of Molise, Pesche, Isernia, Italy; Department of Engineering, University of Sannio, Benevento, Italy; Department of Mathematics and Computer Science, University of Salerno, Fisciano, Salerno, Italy",IEEE Transactions on Software Engineering,"14 Apr 2015","2015","41","4","358","383","A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem. However, previous studies have shown that there is no clear winner between greedy and MOGAs, and that their combination does not necessarily produce better results. In this paper we show that the optimality of MOGAs can be significantly improved by diversifying the solutions (sub-sets of the test suite) generated during the search process. Specifically, we introduce a new MOGA, coined as DIversity based Genetic Algorithm (DIV-GA), based on the mechanisms of orthogonal design and orthogonal evolution that increase diversity by injecting new orthogonal individuals during the search process. Results of an empirical study conducted on eleven programs show that DIV-GA outperforms both greedy algorithms and the traditional MOGAs from the optimality point of view. Moreover, the solutions (sub-sets of the test suite) provided by DIV-GA are able to detect more faults than the other algorithms, while keeping the same test execution cost.","1939-3520","","10.1109/TSE.2014.2364175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936894","Test Case Selection;Regression Testing;Orthogonal Design;Singular Value Decomposition;Genetic Algorithms;Empirical Studies;Test case selection;regression testing;orthogonal design;singular value decomposition;genetic algorithms;empirical studies","Optimization;Greedy algorithms;Testing;Linear programming;Genetic algorithms;Genetics;Sociology","","94","","76","IEEE","27 Oct 2014","","","IEEE","IEEE Journals"
"Empirical Investigation of the Effects of Test Suite Properties on Similarity-Based Test Case Selection","H. Hemmati; A. Arcuri; L. Briand","Department of Informatics, University of Oslo, Norway; Simula Research Laboratory, Norway; Department of Informatics, University of Oslo, Norway","2011 Fourth IEEE International Conference on Software Testing, Verification and Validation","19 May 2011","2011","","","327","336","Our experience with applying model-based testing on industrial systems showed that the generated test suites are often too large and costly to execute given project deadlines and the limited resources for system testing on real platforms. In such industrial contexts, it is often the case that only a small subset of test cases can be run. In previous work, we proposed novel test case selection techniques that minimize the similarities among selected test cases and outperforms other selection alternatives. In this paper, our goal is to gain insights into why and under which conditions similarity-based selection techniques, and in particular our approach, can be expected to work. We investigate the properties of test suites with respect to similarities among fault revealing test cases. We thus identify the ideal situation in which a similarity-based selection works best, which is useful for devising more effective similarity functions. We also address the specific situation in which a test suite contains outliers, that is a small group of very different test cases, and show that it decreases the effectiveness of similarity-based selection. We then propose, and successfully evaluate based on two industrial systems, a solution based on rank scaling to alleviate this problem.","2159-4848","978-1-61284-174-8","10.1109/ICST.2011.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5770622","Test Case Selection;Similarity Measure;Distance Function;Adaptive Random Testing;Genetic Algorithms;Model Based Testing","Testing;Unified modeling language;Subspace constraints;Fault detection;Gallium;Context;Encoding","","26","","19","IEEE","19 May 2011","","","IEEE","IEEE Conferences"
"Increasing Diversity in Coverage Test Suites Using Model Checking","G. Fraser; F. Wotawa","Institute for Software Technology, Graz University of Technology, Graz, Austria; Institute for Software Technology, Graz University of Technology, Graz, Austria",2009 Ninth International Conference on Quality Software,"15 Jan 2010","2009","","","211","218","Automated test case generation often results in test suites containing significant redundancy such as test cases that are duplicates, prefixes of other test cases, or cover the same test requirements. In this paper we consider the fact that items described by a coverage criterion can be covered in different ways. We introduce a technique where each created test case is guaranteed to cover a test requirement in a new way, even if it has previously been covered. This increases the diversity of how test objectives are satisfied, thus reducing the redundancy in test suites, improving their fault detection ability, and usually also decreasing the number of test cases generated. This approach is based in a scenario of specification based testing using model checkers as test case generation tools, and evaluation is performed on three different case study specifications.","2332-662X","978-1-4244-5913-1","10.1109/QSIC.2009.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5381459","test case generation;specification based testing;model checking;test coverage;test redundancy;test diversity","Logic testing;Automatic testing;Software testing;Redundancy;Fault detection;Software quality;Performance evaluation;Programming;Monitoring;Encoding","","2","","21","IEEE","15 Jan 2010","","","IEEE","IEEE Conferences"
"Regression Test cases selection using Natural Language Processing","S. Sutar; R. Kumar; S. Pai; S. BR","Siemens Technology & Services Private Ltd., Bangalore, India; Siemens Technology & Services Private Ltd., Bangalore, India; Siemens Technology & Services Private Ltd., Bangalore, India; Siemens Technology & Services Private Ltd., Bangalore, India",2020 International Conference on Intelligent Engineering and Management (ICIEM),"6 Aug 2020","2020","","","301","305","Regression Testing is one of the important phases to detect the effects of new development or modifications done in the already existing product. As the product grows, the number of regression test cases also increases to manifold. In an agile world, it is very important to extract test cases which are having very high potential to find defects to reduce the overall release cycle. In practice, there are many ways to select test cases based on different criteria. Many of them are based on historical defects in the product as historical defect clusters can be one of defect prone areas because of defect fixes. However, considering the high number of historical defects it becomes difficult to select test cases merely based on defect clusters or any other static techniques. In this paper, we propose our approach to find the high potential regression test cases from the master test suite using Natural Language Processing by selecting a test case based on its intent match with defects. The application developed from this solution has helped us in reducing the regression cycle and enhanced the exploratory productivity for our product. This method also opens the door for new concepts like generating test cases automatically based on its learnings from the product's historical defects, existing test cases, and new feature development.","","978-1-7281-4097-1","10.1109/ICIEM48762.2020.9160225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9160225","Natural Language Processing;Regression testing;Test efficiency;Text similarity;Test prioritization","Computer bugs;Natural language processing;Software testing;Artificial intelligence;History;Organizations","","7","","26","IEEE","6 Aug 2020","","","IEEE","IEEE Conferences"
"Adaptive Random Test Case Generation Based on Multi-objective Evolutionary Search","C. Mao; L. Wen; T. Y. Chen","School of Software and IoT Engineering, Jiangxi University of Finance and Economics, Nanchang, China; School of Software and IoT Engineering, Jiangxi University of Finance and Economics, Nanchang, China; Department of Computer Science and Software Engineering, Swinburne University of Technology, Melbourne, VIC, Australia","2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","9 Feb 2021","2020","","","46","53","Diversity is the key factor for test cases to detect program failures. Adaptive random testing (ART) is one of the effective methods to improve the diversity of test cases. Being an ART algorithm, the evolutionary adaptive random testing (eAR) only increases the distance between test cases to enhance its failure detection ability. This paper presents a new ART algorithm, MoesART, based on multi-objective evolutionary search. In this algorithm, in addition to the dispersion diversity, two other new diversities (or optimization objectives) are designed from the perspectives of the balance and proportionality of test cases. Then, the Pareto optimal solution returned by the NSGA-II framework is used as the next test case. In the experiments, the typical block failure pattern in the cases of two-dimensional and three-dimensional input domains is used to validate the effectiveness of the proposed MoesART algorithm. The experimental results show that MoesART exhibits better failure detection ability than both eAR and the fixed-sized-candidate-set ART (FSCS-ART), especially for the programs with three-dimensional input domain.","2324-9013","978-1-6654-0392-4","10.1109/TrustCom50675.2020.00020","NSFC(grant numbers:61762040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9343017","software testing;adaptive random testing;multi objective evolutionary search;test case;diversity","Privacy;Subspace constraints;Ear;Software;Power capacitors;Security;Testing","","3","","35","IEEE","9 Feb 2021","","","IEEE","IEEE Conferences"
"Visualizing Test Diversity to Support Test Optimisation","F. G. De Oliveira Neto; R. Feldt; L. Erlenhov; J. B. D. S. Nunes","Dept. of Computer Science and Engineering Chalmers, University of Gothenburg, Gothenburg, Sweden; Dept. of Computer Science and Engineering Chalmers, University of Gothenburg, Gothenburg, Sweden; Dept. of Computer Science and Engineering Chalmers, University of Gothenburg, Gothenburg, Sweden; Department of Computing Systems, Federal University of Campina Grande, Campina Grande, Brazil",2018 25th Asia-Pacific Software Engineering Conference (APSEC),"23 May 2019","2018","","","149","158","Diversity has been used as an effective criteria to optimise test suites for cost-effective testing. Particularly, diversity-based (alternatively referred to as similarity-based) techniques have the benefit of being generic and applicable across different Systems Under Test (SUT), and have been used to automatically select or prioritise large sets of test cases. However, there is a challenge in how to present diversity information to developers and testers since results are typically many-dimensional. Furthermore, the generality of diversity-based approaches makes it harder to choose when and where to apply them. In this paper we address these challenges by investigating: i) what are the trade-offs in using different sources of diversity (e.g., diversity of test requirements or test scripts) to optimise large test suites, and ii) how visualisation of test diversity data can assist testers for test optimisation and improvement. We perform a case study on three industrial projects and present quantitative results on the fault detection capabilities and redundancy levels of different sets of test cases. Our key result is that test similarity maps, based on pair-wise diversity calculations, helped industrial practitioners identify issues with their test repositories and decide on actions to improve. We conclude that the visualisation of diversity information can assist testers in their maintenance and optimisation activities.","2640-0715","978-1-7281-1970-0","10.1109/APSEC.2018.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719537","Software Testing;Diversity;Search based Software Testing;Empirical Study","Optimization;Testing;Indexes;Data visualization;Fault detection;Maintenance engineering;Subspace constraints","","7","","25","IEEE","23 May 2019","","","IEEE","IEEE Conferences"
"Selecting Test Cases based on Similarity of Runtime Information: A Case Study of an Industrial Simulator","K. Shimari; M. Tanaka; T. Ishio; M. Matsushita; K. Inoue; S. Takanezawa","Graduate School of Science and Technology, Nara Institute of Science and Technology, Nara, Japan; Graduate School of Information Science and Technology, Osaka University, Osaka, Japan; Graduate School of Science and Technology, Nara Institute of Science and Technology, Nara, Japan; Graduate School of Information Science and Technology, Osaka University, Osaka, Japan; Faculty of Science and Technology, Nanzan University, Aichi, Japan; Daikin Industries, Ltd, Osaka, Japan",2022 IEEE International Conference on Software Maintenance and Evolution (ICSME),"19 Dec 2022","2022","","","564","567","Regression testing is required to check the changes in behavior whenever developers make any changes to a software system. The cost of regression testing is a major problem because developers have to frequently update dependent components to minimize security risks and potential bugs. In this paper, we report a current practice in a company that maintains an industrial simulator as a critical component of their business. The simulator automatically records all the users’ requests and the simulation results in storage. The feature provides a huge number of test cases for regression testing to developers; however, their time budget for testing is limited (i.e., at most one night). Hence, the developers need to select a small number of test cases to confirm both the simulation result and execution performance are unaffected by an update of a dependent component. In other words, the test cases should achieve high coverage while keeping diversity of execution time. To solve the problem, we have developed a clustering-based method to select test cases, using the similarity of execution traces produced by them. The developers have used the method for a half year; they recognize that the method is better than the previous rule-based method used in the company.","2576-3148","978-1-6654-7956-1","10.1109/ICSME55016.2022.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978230","Test Selection;Dynamic Analysis;Software De-pendency;Clustering","Measurement;Software maintenance;Runtime;Costs;Simulation;Computer bugs;Companies","","1","","9","IEEE","19 Dec 2022","","","IEEE","IEEE Conferences"
"Improving Continuous Integration with Similarity-Based Test Case Selection","F. G. de Oliveira Neto; A. Ahmad; O. Leifler; K. Sandahl; E. Enoiu","Chalmers, University of Gothenburg, Gothenburg, Sweden; Linköping University, Linköping, Sweden; Linköping University, Linköping, Sweden; Linköping University, Linköping, Sweden; Mälardalen University, Västerås, Sweden",2018 IEEE/ACM 13th International Workshop on Automation of Software Test (AST),"15 Nov 2018","2018","","","39","45","Automated testing is an essential component of Continuous Integration (CI) and Delivery (CD), such as scheduling automated test sessions on overnight builds. That allows stakeholders to execute entire test suites and achieve exhaustive test coverage, since running all tests is often infeasible during work hours, i.e., in parallel to development activities. On the other hand, developers also need test feedback from CI servers when pushing changes, even if not all test cases are executed. In this paper we evaluate similarity-based test case selection (SBTCS) on integration-level tests executed on continuous integration pipelines of two companies. We select test cases that maximise diversity of test coverage and reduce feedback time to developers. Our results confirm existing evidence that SBTCS is a strong candidate for test optimisation, by reducing feedback time (up to 92% faster in our case studies) while achieving full test coverage using only information from test artefacts themselves.","","978-1-4503-5743-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8536348","Similarity based test case selection;Continuous integration;Automated testing","Testing;Companies;Pipelines;Optimization;Software;Servers;Instruments","","3","","21","","15 Nov 2018","","","IEEE","IEEE Conferences"
"Detecting Compiler Warning Defects Via Diversity-Guided Program Mutation","Y. Tang; H. Jiang; Z. Zhou; X. Li; Z. Ren; W. Kong","School of Software, Dalian University of Technology (DUT), Dalian, Liaoning, China; DUT Artificial Intelligence Institute, Dalian, Liaoning, China; School of Software, Dalian University of Technology (DUT), Dalian, Liaoning, China; SnT Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; School of Software, Dalian University of Technology (DUT), Dalian, Liaoning, China; School of Software, Dalian University of Technology (DUT), Dalian, Liaoning, China",IEEE Transactions on Software Engineering,"11 Nov 2022","2022","48","11","4411","4432","Compiler diagnostic warnings help developers identify potential programming mistakes during program compilation. However, these warnings could be erroneous due to the defects of compiler warning diagnostics. Although the existing technique (i.e., Epiphron) can automatically generate test programs for compiler warning defect detection, the effectiveness of Epiphron on defect-finding is still limited, due to the limitation for generating warning-sensitive test program structures. Therefore, in this paper, we propose a DIversity-guided PROgram Mutation approach, called DIPROM, to construct diverse warning-sensitive programs for effective compiler warning defect detection. Given a seed test program, DIPROM first removes its dead code to reduce false positive warning defects. Then, the abstract syntax tree (AST) of the test program is constructed; DIPROM iteratively mutates the structures of the AST to generate warning-sensitive program variants. To effectively construct diverse warning-sensitive structures, DIPROM applies a novel diversity-guided strategy to generate program variants in each iteration. With the generated program variants, differential testing is conducted to detect warning defects in different compilers. In the experiments, we evaluate DIPROM with two popular C compilers (i.e., GCC and Clang). Experimental results show that DIPROM significantly outperforms three state-of-the-art approaches (i.e., HiCOND, Epiphron, and Hermes) by up to 18.93%$\sim$∼76.74% in terms of the bug-finding capability on average. Meanwhile, DIPROM is efficient, which spends less time on finding the same average number of warning defects. We at last applied DIPROM to the latest development versions of GCC and Clang. After two months’ running, we reported 8 new warning defects; 5 of them have been confirmed/fixed by developers.","1939-3520","","10.1109/TSE.2021.3119186","National Natural Science Foundation of China(grant numbers:62032004,61772107,62072068); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566830","Compiler testing;differential testing;program mutation;test program generation","Program processors;Codes;Testing;Software;Programming;Feature extraction;Tools","","9","","53","IEEE","11 Oct 2021","","","IEEE","IEEE Journals"
"FAST Approaches to Scalable Similarity-Based Test Case Prioritization","B. Miranda; E. Cruciani; R. Verdecchia; A. Bertolino","Federal University of Pernambuco Recife, Brazil; Gran Sasso Science Institute, L’Aquila, Italy; Gran Sasso Science Institute, L’Aquila, Italy; ISTI - CNR, Pisa, Italy",2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE),"2 Sep 2018","2018","","","222","232","Many test case prioritization criteria have been proposed for speeding up fault detection. Among them, similarity-based approaches give priority to the test cases that are the most dissimilar from those already selected. However, the proposed criteria do not scale up to handle the many thousands or even some millions test suite sizes of modern industrial systems and simple heuristics are used instead. We introduce the FAST family of test case prioritization techniques that radically changes this landscape by borrowing algorithms commonly exploited in the big data domain to find similar items. FAST techniques provide scalable similarity-based test case prioritization in both white-box and black-box fashion. The results from experimentation on real world C and Java subjects show that the fastest members of the family outperform other black-box approaches in efficiency with no significant impact on effectiveness, and also outperform white-box approaches, including greedy ones, if preparation time is not counted. A simulation study of scalability shows that one FAST technique can prioritize a million test cases in less than 20 minutes.","1558-1225","978-1-4503-5638-1","10.1145/3180155.3180210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453081","locality sensitive hashing;minhashing;scalability;similarity;software testing;test case prioritization","Scalability;History;Fault detection;Big Data;Software testing;Data mining","","31","","34","","2 Sep 2018","","","IEEE","IEEE Conferences"
"Identifying Similar Software Datasets through Fuzzy Inference System","S. Anwar; Z. A. Rana; M. M. Awais","Department of Computer Science, Department of Computer Science(SSE), LUMS, Lahore, Pakistan; Department of Computer Science, Department of Computer Science(SSE), LUMS, Lahore, Pakistan; Department of Computer Science, Department of Computer Science(SSE), LUMS, Lahore, Pakistan",2012 10th International Conference on Frontiers of Information Technology,"31 Jan 2013","2012","","","181","187","Similar software have similar software measurements. Defect data from one software can be used to anticipate defects in a similar software. Although, not many defect datasets are made public in software engineering domain, PROMISE repository is a reasonable collection of software data. This paper presents a two step approach to identify similar software and applies the proposed technique to find similar datasets in PROMISE repository. As step 1, the approach generates associations rules for each dataset to determine dataset's behavior in terms of frequent patterns. As step 2, overlap between the association rules is calculated using Fuzzy Inference Systems (FIS). The FIS generated for the study have been expert-based as well as auto-generated. Similarity between 28 dataset pairs has been found KC2 and PC1 turned out to be most similar datasets with 86% similarity using Mamdani, 92% with Sugeno models. Results from expert-based and auto generated FIS have been comparable.","","978-0-7695-4927-9","10.1109/FIT.2012.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6424319","software similarity;dataset similarity;software measures;FIS;fuzzy system;association rules","Software;Association rules;Fuzzy logic;Software measurement;Pragmatics;Testing","","","","17","IEEE","31 Jan 2013","","","IEEE","IEEE Conferences"
"[Invited] Quality Assurance of Machine Learning Software","S. NAKAJIMA","National Institute of Informatics, Tokyo, Japan",2018 IEEE 7th Global Conference on Consumer Electronics (GCCE),"13 Dec 2018","2018","","","601","604","Functionalities of machine learning software are dependent on a set of data input to them; a slight change in a training dataset has much impact on learning parameter values and thus on inference results. ML-based systems bring about a new challenge to quality assurance methods. This paper reviews two traditional views of service and product qualities. Furthermore, it introduces a platform view, in which co-creation of value is a major concern.","2378-8143","978-1-5386-6309-7","10.1109/GCCE.2018.8574766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8574766","dataset diversity;metamorphic testing;service dominant logic;independent assessment","Machine learning;Training;Software;Quality assessment;Product design;Testing;Neural networks","","19","1","18","IEEE","13 Dec 2018","","","IEEE","IEEE Conferences"
"Test case analytics: Mining test case traces to improve risk-driven testing","T. B. Noor; H. Hemmati","Department of Computer Science, University of Manitoba, Winnipeg, Canada; Department of Computer Science, University of Manitoba, Winnipeg, Canada",2015 IEEE 1st International Workshop on Software Analytics (SWAN),"2 Apr 2015","2015","","","13","16","In risk-driven testing, test cases are generated and/or prioritized based on different risk measures. For example, the most basic risk measure would analyze the history of the software and assigns higher risk to the test cases that used to detect bugs in the past. However, in practice, a test case may not be exactly the same as a previously failed test, but quite similar. In this study, we define a new risk measure that assigns a risk factor to a test case, if it is similar to a failing test case from history. The similarity is defined based on the execution traces of the test cases, where we define each test case as a sequence of method calls. We have evaluated our new risk measure by comparing it to a traditional risk measure (where the risk measure would be increased only if the very same test case, not a similar one, failed in the past). The results of our study, in the context of test case prioritization, on two open source projects show that our new risk measure is by far more effective in identifying failing test cases compared to the traditional risk measure.","","978-1-4673-6923-7","10.1109/SWAN.2015.7070482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070482","Execution trace; Testing; Bug; Risk-driventesting; Similarity; Test case prioritization","Testing;History;Current measurement;Context;Software;Computer bugs;Databases","","13","","10","IEEE","2 Apr 2015","","","IEEE","IEEE Conferences"
"Research on automatic generation of test data for multi-path coverage","M. Zhang; H. Li","School of Computer & Information Technology, Research Center for Network Management, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Research Center for Network Management, Beijing Jiaotong University, Beijing, China","2021 4th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","19 Aug 2021","2021","","","1185","1188","Software testing is a complex and time-consuming task, especially in the part of test case design. Therefore, test automation can greatly reduce the consumption of manpower and material resources. The main work of this paper is as follows:1This article designs a total path similarity for the target path group of the code from the perspective of multi-path oriented. And relying on this to generate test data that meets multiple target paths at one time, so as to reduce the number of iterations and time spent.2This article is inspired by the fitness function design of genetic algorithm, and designs a fitness evaluation method for multi-path and single-path.3This paper selects the Beetle Antennae Search algorithm from existing intelligent optimization algorithms. Because it does not require too much information, it performs very well in low- dimensional problems, and only needs one longhorn beetle in the search process, which greatly reduces the amount of calculation. And it is applied to the triangle classification problem program, and compared with the traditional genetic algorithm at the same time. The experimental results verify the correctness of the method, and the Beetle Antennae Search algorithm is more efficient than the genetic algorithm.","","978-1-6654-1596-5","10.1109/AEMCSE51986.2021.00242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513033","Multi-path;Beetle Antennae Search algorithm;path similarity;genetic algorithm","Software testing;Software algorithms;Sociology;Search problems;Classification algorithms;Statistics;Task analysis","","1","","8","IEEE","19 Aug 2021","","","IEEE","IEEE Conferences"
"A Visualization of Specification Coverage Based on Document Similarity","H. Nakagawa; S. Matsui; T. Tsuchiya","Graduate School of Information Science and Technology, Osaka University, Osaka, Japan; Graduate School of Information Science and Technology, Osaka University, Osaka, Japan; Graduate School of Information Science and Technology, Osaka University, Osaka, Japan",2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C),"24 Aug 2017","2017","","","136","138","Code coverage is a metric used to represent how much code is tested when particular test cases are executed. As is code coverage, specification coverage is expected to help us to comprehend how much specification to be implemented is tested. In this study, we propose a visualization process for specification coverage. This process finds traceability links between specifications and test cases using a similarity metric and constructs two views for visualization. We develop a prototype tool for automatically executing the process and evaluate the process in a preliminary experiment on a web application development in industry. This extended abstract explains the overview of our study and the preliminary results.","","978-1-5386-1589-8","10.1109/ICSE-C.2017.117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965280","specification coverage;traceability;visualization;testing","Visualization;Software;Software engineering;Testing;Tools;HTML;Measurement","","2","","9","IEEE","24 Aug 2017","","","IEEE","IEEE Conferences"
"Software Defect Evaluation Methods for Embedded Real-Time Control System Based on Transfer Learning","X. Han; M. Bian; Z. Wu","China Electronic Product Reliability and Environmental Testing Research Institute, The fifth electronic research institute of MIIT, Guangzhou, China; China Electronic Product Reliability and Environmental Testing Research Institute, The fifth electronic research institute of MIIT, Guangzhou, China; China Electronic Product Reliability and Environmental Testing Research Institute, The fifth electronic research institute of MIIT, Guangzhou, China",2022 14th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA),"7 Mar 2022","2022","","","247","255","In order to reduce the impact of environmental changes on software defect evaluation, an embedded real-time control system software defect evaluation method based on transfer learning is proposed. Firstly, the defect software measurement index is selected. On this basis, the relevant index features are divided into the same cluster by using the feature clustering technology. According to the distribution similarity of the features between the two items, the relevant features are found and the features with large distribution differences are removed. Select high-quality features from the source project to build the training data set, and select better evaluation data from the source project through weight adjustment to realize the accurate evaluation of software defects. The mapping results have clear objectives, and the error rate of the evaluation results of the design method is within 8.7, which has a good evaluation effect.","2157-1481","978-1-6654-9978-1","10.1109/ICMTMA54903.2022.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723949","transfer learning;embedded real-time control system;defect assessment;measurement index;clustering technology;distribution similarity","Training;Software testing;Correlation;Error analysis;Transfer learning;Training data;Software","","","","20","IEEE","7 Mar 2022","","","IEEE","IEEE Conferences"
"Implementation of Semantic Textual Similarity between Requirement Specification and Use Case Description Using WUP Method (Case Study: Sipjabs Application)","E. J. Sari; Y. Priyadi; R. R. Riskiana","Department of Informatics, Telkom University, Bandung, Indonesia; Department of Software Engineering, Telkom University, Bandung, Indonesia; Department of Software Engineering, Telkom University, Bandung, Indonesia",2022 IEEE World AI IoT Congress (AIIoT),"13 Jul 2022","2022","","","681","687","The SRS used in this study is an application called “Sipjabs”. This application processes data regarding the position of human resources to meet the needs of a company. This research aims to implement semantic textual similarity in software requirements specification through functional requirements with use case diagrams using the Wu Palmer (WUP) method in finding semantics. This research method is presented in a flow chart consisting of three main activities: research object analysis, semantic textual similarity, and validity and reliability testing. In this research, an extraction process for the Requirement Specification has been produced, divided into five documents: FR01, FR02, FR03, FR04, FR05. Then the steps performed in the use case description are divided into UD01, UD02, UD03, UD04, UD05. The highest similarity value is found in documents UD03 and FR03, where the number of similarities is 0.626640. In addition, the highest score of the sentence that has been calculated using the Wu Palmer concept is 0.8000, which is found in the words “page” and “user”. The highest kappa value with Gwet's AC1 formula is 0.02547770700636931, which means “Fair Agreement”. For the results of the calculation of the questionnaire filled in by the expert, namely 0.82022, which means “Almost Perfect”.","","978-1-6654-8453-4","10.1109/AIIoT54504.2022.9817311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817311","Semantic Textual Similarity;Requirement Specification;Use Case Description","Semantics;Companies;Software;Software reliability;Artificial intelligence;Testing","","8","","26","IEEE","13 Jul 2022","","","IEEE","IEEE Conferences"
"A Test Suite Reduction Approach to Improving the Effectiveness of Fault Localization","W. Fu; H. Yu; G. Fan; X. Ji; X. Pei",Department of Computer Science and Engineering; Department of Computer Science and Engineering; Department of Computer Science and Engineering; Department of Computer Science and Engineering; The Third Research Institute of the Ministry of Public Security,"2017 International Conference on Software Analysis, Testing and Evolution (SATE)","23 Nov 2017","2017","","","10","19","In order to improve the effectiveness of fault localization, various test suite reduction techniques have been proposed. However, excessive or improper reduction of test cases may lose some testing information, thus causing a negative impact on fault localization. In this paper, we propose a new similarity-based test suite reduction approach to improving spectrum-based fault localization. Firstly, this approach extracts the high suspicious statements in the faulty program and removes the coincidental passed test cases for test suite selection. Then, it selects similar passed test cases for each different failed test case from the new passed test set based on the similar proportion of their execution traces, and determines the final composition of each similar test set based on the contribution of failed test cases to fault localization. By using the execution information of each similar test set with a spectrum-based fault localization approach, the ranks of statements can be obtained. Finally, synthesizing all ranks of statements in each rank list, we obtain the final rank list of statements. Several experiments show that our approach can help reduce the debugging effort in terms of the percentage of statements needed to be inspected when locating faults in both single-fault and multi-fault programs. Moreover, the results demonstrate that the value of similar proportion have nontrivial influence on the effectiveness of fault localization.","","978-1-5386-3687-9","10.1109/SATE.2017.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8118516","debugging;fault localization;test case reduction;similar test case","Testing;Software debugging;Heuristic algorithms;Tools;Optimization;Aggregates","","5","","34","IEEE","23 Nov 2017","","","IEEE","IEEE Conferences"
"How effective is GeoGebra Software in improving students learning similarities of geometrical shapes","A. Eid; T. J. Abdulla","Department of Mathematics, University of Bahrain, Sukheer, Bahrain; Department of Mathematics, University of Bahrain, Sukheer, Bahrain",2021 Sustainable Leadership and Academic Excellence International Conference (SLAE),"6 Jun 2022","2021","","","1","5","The teaching and learning of geometry are changing due to the wide range of software and mobile applications that instructors can incorporate into their classes. Some students struggle with visualizing geometric shapes and related concepts, which affects their performances. GeoGebra, which is an open-source dynamic mathematical software, can enhance students' visualization and hence their learning of geometrical concepts. This study investigated the impact of using GeoGebra in teaching geometry specifically, the similarities of triangles concept, to first-year Landscape Engineering students enrolled in the ""Mathematics for Built Environment"" course at the University of Bahrain. The study was conducted on 38 students enrolled in the course. The research data were obtained from students' pre and post test results. The collected data were analyzed, and the results showed that GeoGebra was an effective tool for enhancing students learning and understanding of similarities of triangles concepts.","","978-1-6654-0714-4","10.1109/SLAE54202.2021.9788090","University of Bahrain; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9788090","Analytic geometry;GeoGebra;dynamic mathematics software;Spatial Visualization;triangles similarities;mobile applications","Geometry;Leadership;Shape;Education;Mobile applications;Engineering students;Open source software","","","","20","IEEE","6 Jun 2022","","","IEEE","IEEE Conferences"
"Mobile Application GUI Similarity Comparison Based on Perceptual Hash for Automated Robot Testing","J. Cheng; W. Wang","School of Computer Science and Engineering, Xi'an Technological University, Shaanxi, China; School of Software, Northwestern Polytechnical University, Shaanxi, China","2021 International Conference on Intelligent Computing, Automation and Applications (ICAA)","30 Dec 2021","2021","","","245","251","Due to the rapid growth of mobile applications, the requirements for software testing speed are getting higher and higher. Therefore, automated testing is gradually replacing inefficient manual testing methods. However, most of the existing mobile applications are not open source code, and testing open source mobile applications is time-consuming and inefficient. Therefore, we propose automated robot testing based on black box testing. Firstly, YOLOV3 algorithm is used to obtain the information of mobile application interface components. Then, the perceptual hashing algorithm is used to identify the isomorphic GUI of mobile application, and the nodes that are the isomorphic GUI after the jump are merged to improve the test efficiency by simplifying the model. The experimental results show that the method can identify the isomorphic GUI quickly and accurately, and can better simplify the interface model and improve the test efficiency.","","978-1-6654-3730-1","10.1109/ICAA53760.2021.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9653505","","Software testing;Codes;Computational modeling;Software algorithms;Semantics;Manuals;Mobile applications","","3","","6","IEEE","30 Dec 2021","","","IEEE","IEEE Conferences"
"Micro-inequities and immigration backgrounds in the software industry","V. Markulj; K. Aslam; E. Guzmán",Vrije Universiteit Amsterdam; Vrije Universiteit Amsterdam; Vrije Universiteit Amsterdam,2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS),"18 Jun 2024","2024","","","23","33","Micro-inequities are subtle, repetitive, and often unintentional forms of negative messaging, that can account for a significant burden over time. Research shows that racial and gender minority groups are more likely to experience micro-inequities, and that micro-inequities have a significant negative effect on self-esteem, work performance and career advancement. However, research on micro-inequities among software practitioners, particularly with an immigration perspective, is non-existent. To bridge this gap, we investigate the experiences of software practitioners, regarding micro-inequities from an immigration perspective. We surveyed 135 immigrant and non-immigrant software practitioners working in technical roles about verbal, nonverbal and environmental micro-inequities. Our results show that immigrants experience nine out of 27 investigated forms of micro-inequities significantly more than non-immigrants. These include not being given credit for their work, feeling excluded from key social or networking opportunities and being assumed to be less competent, assertive or intelligent. Our study can serve as an incentive for practitioners to adopt (more) inclusive work practices and to raise awareness about micro-inequities in the community.Lay Abstract: Micro-inequities are subtle, repetitive, and often unintentional forms of negative messaging, that can account for a significant burden over time. While research shows that underrepresented groups are more likely to experience micro-inequities, they have not been extensively studied in the software industry. In our work we survey 135 software practitioners regarding their experiences with micro-inequities in the software industry from an immigration perspective. Our findings show that immigrants experience some forms of micro-inequities significantly more than non-immigrants.","2832-7616","979-8-4007-0499-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554791","micro-inequities;immigration;diversity;inclusion;software development teams;questionnaire-based survey","Industries;Surveys;Bridges;Engineering profession;Employment;Software;Software engineering","","","","49","CCBY","18 Jun 2024","","","IEEE","IEEE Conferences"
"MACS: Multi-Agent Adversarial Reinforcement Learning for Finding Diverse Critical Driving Scenarios","S. Kang; Q. Dong; Y. Xue; W. Yanjun","University of Chinese Academy of Sciences, Beijing, China; Institute of Software Chinese Academy of Sciences, Beijing, China; Institute of Software Chinese Academy of Sciences, Beijing, China; Institute of Software Chinese Academy of Sciences, Beijing, China","2024 IEEE Conference on Software Testing, Verification and Validation (ICST)","27 Aug 2024","2024","","","1","12","Critical scenario generation plays a crucial role in the autonomous driving test by efficiently and effectively identifying various hazardous scenarios to evaluate the multiagent system under test. The performance of existing solution models is hampered by sparse rewards resulting from long time-steps in driving scenarios. Moreover, they fail to guide the generation of more diverse scenarios because of the lack of a fine-grained design. To efficiently and effectively discover various critical scenarios, we propose the MACS method based on multiagent reinforcement learning to guide adversaries foiled the agent under test by replay buffer optimization and objective function design. By adopting the hindsight experience replay method, historical experiences are reused to address the challenge of sparse rewards and improve sample efficiency. Furthermore, we integrate the entropy term into the objective function to explore different driving strategies, thereby leading to the creation of diverse scenarios. We have achieved a new state-of-the-art performance in evaluating rule-based agents using an industrial-grade platform, SMARTS. The experimental results demonstrate that MACS can effectively generate diverse critical scenarios that lead to the failure of the agent under test. We also apply cluster methods, including DBSCAN and TRACLUS, to conduct diversity analysis of the generated scenarios. Besides, we evaluate and improve the reinforcement learning decision algorithm for the vehicle under test with our generated scenarios and give empirical conclusions about its robustness.","2159-4848","979-8-3503-0818-1","10.1109/ICST60714.2024.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10638588","Software Reliability;Search-based Test Generation;Reinforcement Learning;Critical Scenarios;Autonomous Driving","Software testing;Software algorithms;Reinforcement learning;Linear programming;Software;Robustness;Software reliability","","","","50","IEEE","27 Aug 2024","","","IEEE","IEEE Conferences"
"Testing for Fault Diversity in Reinforcement Learning","Q. Mazouni; H. Spieker; A. Gotlieb; M. Acher","Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Univ Rennes, Inria, INSA Rennes, CNRS, IRISA, Rennes, France",2024 IEEE/ACM International Conference on Automation of Software Test (AST),"18 Jun 2024","2024","","","136","146","Reinforcement Learning is the premier technique to approach sequential decision problems, including complex tasks such as driving cars and landing spacecraft. Among the software validation and verification practices, testing for functional fault detection is a convenient way to build trustworthiness in the learned decision model. While recent works seek to maximise the number of detected faults, none consider fault characterisation during the search for more diversity. We argue that policy testing should not find as many failures as possible (e.g., inputs that trigger similar car crashes) but rather aim at revealing as informative and diverse faults as possible in the model. In this paper, we explore the use of quality diversity optimisation to solve the problem of fault diversity in policy testing. Quality diversity (QD) optimisation is a type of evolutionary algorithm to solve hard combinatorial optimisation problems where high-quality diverse solutions are sought. We define and address the underlying challenges of adapting QD optimisation to the test of action policies. Furthermore, we compare classical QD optimisers to state-of-the-art frameworks dedicated to policy testing, both in terms of search efficiency and fault diversity. We show that QD optimisation, while being conceptually simple and generally applicable, finds effectively more diverse faults in the decision model, and conclude that QD-based policy testing is a promising approach.CCS CONCEPTS • Software and its engineering $\rightarrow$ Software verification and validation; • Computing methodologies $\rightarrow$ Reinforcement learning.","2833-9061","979-8-4007-0588-5","","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10556424","Software Testing;Reinforcement Learning;Quality Diversity","Space vehicles;Fault detection;Sociology;Reinforcement learning;Vehicle crash testing;Automobiles;Task analysis","","","","31","","18 Jun 2024","","","IEEE","IEEE Conferences"
"An Empirical Study of the Effectiveness of ""Forcing"" Diversity Based on a Large Population of Diverse Programs","P. Popov; V. Stankovic; L. Strigini","Centre for Software Reliability, City University London, London, UK; Centre for Software Reliability, City University London, London, UK; Centre for Software Reliability, City University London, London, UK",2012 IEEE 23rd International Symposium on Software Reliability Engineering,"4 Apr 2013","2012","","","41","50","Use of diverse software components is a viable defence against common-mode failures in redundant software-based systems. Various forms of ""Diversity-Seeking Decisions"" (""DSDs"") can be applied to the process of developing, or procuring, redundant components, to improve the chances of the resulting components not failing on the same demands. An open question is how effective these decisions, and their combinations, are for achieving large enough reliability gains. Using a large population of software programs, we studied experimentally the effectiveness of specific ""DSDs"" (and their combinations) mandating differences between redundant components. Some of these combinations produced much better improvements in system probability of failure per demand (PFD) than ""uncontrolled"" diversity did. Yet, our findings suggest that the gains from such ""DSDs"" vary significantly between them and between the application problems studied. The relationship between DSDs and system PFD is complex and does not allow for simple universal rules (e.g. ""the more diversity the better"") to apply.","2332-6549","978-1-4673-4638-2","10.1109/ISSRE.2012.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405403","design diversity;multiple version software;software fault tolerance;diversity-seeking decisions;reliability improvement;experimental study","Diversity reception;Software;Phase frequency detector;Java;Software reliability","","7","","24","IEEE","4 Apr 2013","","","IEEE","IEEE Conferences"
"The Diversity-Innovation Paradox in Open-Source Software","M. S. Yong; L. Paganini; H. S. Qiu; J. B. Santiago Calderón","School of Computer Science, Carnegie Mellon University; Centro de Informática, Federal University of Pernambuco, Brazil; School of Computer Science, Carnegie Mellon University; Biocomplexity Institute & Initiative, University of Virginia",2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR),"28 Jun 2021","2021","","","627","629","Prior studies have shown that, in open-source software (OSS), diversity is a positive indicator of productivity. Yet, code submissions from underrepresented groups are less successful. This mirrors the diversity-innovation paradox found in science—diverse groups produce more innovations, but historically underrepresented people have less successful careers in these groups. In this preliminary research, we want to investigate whether the effect of the diversity-innovation paradox is present in OSS. We define software innovation as a novel co-usage of two packages in the same project. Using World of Code, we identified JavaScript projects’ innovations from late 2008 to early 2014. We intend to calculate diversity measures for the authors who produced the innovations and build models to test the presence of the diversity-innovation paradox in OSS.","2574-3864","978-1-7281-8710-5","10.1109/MSR52588.2021.00089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463124","open-source;innovation;diversity","Productivity;Technological innovation;Engineering profession;Mirrors;Data mining;Open source software","","","","11","IEEE","28 Jun 2021","","","IEEE","IEEE Conferences"
"Output Sampling for Output Diversity in Automatic Unit Test Generation","H. D. Menendez; M. Boreale; D. Gorla; D. Clark","Department of Computer Science, Middlesex University London, London, U.K; University of Florence, Firenze, FI, Italy; Department of Computer Science, University of Rome “Sapienza”, Roma, Italy; Department of Computer Science, University College London, London, U.K.",IEEE Transactions on Software Engineering,"10 Jan 2022","2022","48","1","295","308","Diverse test sets are able to expose bugs that test sets generated with structural coverage techniques cannot discover. Input-diverse test set generators have been shown to be effective for this, but also have limitations: e.g., they need to be complemented with semantic information derived from the Software Under Test. We demonstrate how to drive the test set generation process with semantic information in the form of output diversity. We present the first totally automatic output sampling for output diversity unit test set generation tool, called OutGen. OutGen transforms a program into an SMT formula in bit-vector arithmetic. It then applies universal hashing in order to generate an output-based diverse set of inputs. The result offers significant diversity improvements when measured as a high output uniqueness count. It achieves this by ensuring that the test set’s output probability distribution is uniform, i.e., highly diverse. The use of output sampling, as opposed to any of input sampling, CBMC, CAVM, behaviour diversity or random testing improves mutation score and bug detection by up to 4150 and 963 percent respectively on programs drawn from three different corpora: the R-project, SIR and CodeFlaws. OutGen test sets achieve an average mutation score of up to 92 percent, and 70 percent of the test sets detect the defect. Moreover, OutGen is the only automatic unit test generation tool that is able to detect bugs on the real number C functions from the R-project.","1939-3520","","10.1109/TSE.2020.2987377","InfoTestSS(grant numbers:EP/P005888/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068446","Unit testing;output sampling;output diversity;SMT solver;OutGen","Computer bugs;Tools;Semantics;Generators;Software engineering;Test pattern generators","","5","","52","IEEE","15 Apr 2020","","","IEEE","IEEE Journals"
"Fault Localization Based on Multi-level Similarity of Execution Traces","X. Wang; Q. Gu; X. Zhang; X. Chen; D. Chen","State Key Laboratory of Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China",2009 16th Asia-Pacific Software Engineering Conference,"28 Dec 2009","2009","","","399","405","Since automated fault localization can improve the efficiency of both the testing and debugging process, it is an important technique for the development of reliable software. This paper proposes a novel fault localization approach based on multi-level similarity of execution traces, which is suitable for object-oriented software. It selects useful test cases at class level and computes code suspiciousness at block level. We develop a tool that implements the approach, and conduct empirical studies to evaluate its effectiveness. The experimental results show that our approach has the potential to be effective in localizing faults for object-oriented software.","1530-1362","978-0-7695-3909-6","10.1109/APSEC.2009.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358777","software testing;fault localization;object-oriented;execution trace;multi-level similarity","Software testing;Automatic testing;Programming profession;Software debugging;Software engineering;Laboratories;Computer science;Fault detection;Failure analysis;Information analysis","","2","","17","IEEE","28 Dec 2009","","","IEEE","IEEE Conferences"
"An Automated Framework for Cost Reduction of Mutation Testing Based on Program Similarity","G. F. Guarnieri; A. V. Pizzoleto; F. C. Ferrari","Federal University of São Carlos, Sorocaba, SP, Brazil; Federal University of São Carlos, São Carlos, SP, Brazil; Federal University of São Carlos, São Carlos, SP, Brazil","2022 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","8 Jun 2022","2022","","","179","188","This paper presents an implementation and assessment of a framework named SiMut. The framework was introduced in a previous paper with the objective of helping reducing the cost for testing a program based on groups of similar programs previously tested with mutation. The implementation presented in the paper handles Java programs and includes a set of variants that relate to three types of program abstraction (original source code, processed source code, and internal complexity metrics), three similarity calculation strategies (clustering, information diversity, and plagiarism), and one mutation cost reduction approach (inspired by the One-Op mutation technique). Our evaluation encompasses 20 variant combinations, also referred to as SiMut configurations, and 35 small Java programs. A cross-comparison involving the formed clusters and a comparison with randomly formed clusters points to configurations that tend to reach high effectiveness in foreseeing the best mutation operators for untested programs.","2159-4848","978-1-6654-9628-5","10.1109/ICSTW55395.2022.00041","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; Fundação de Amparo à Pesquisa do Estado de São Paulo; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9787949","mutation testing;cost reduction;program similarity","Software testing;Measurement;Java;Costs;Codes;Conferences;Plagiarism","","1","","31","IEEE","8 Jun 2022","","","IEEE","IEEE Conferences"
"Organizational Factors that Affect the Software Quality A Case Study at the Engineering Division of a Selected Software Development Organization in Sri Lanka","J. Harischandra; S. Hettiarachchi","Department of Computing, Informatics Institute of Technology in affiliation with University of Westminster, Colombo 06, Sri Lanka; International College of Business and Technology in affiliation with Cardiff Metropolitan University, Colombo 04, Sri Lanka",2020 IEEE 7th International Conference on Industrial Engineering and Applications (ICIEA),"27 May 2020","2020","","","984","988","The objective of this study is to identify the critical factors affecting the software quality at the engineering division of a selected software development organization in Sri Lanka. The purpose of the study is to identify the critical organizational factors that affect the software quality in the selected organization, determine the relationship and impact of those factors to software quality and provide recommendations and strategies to improve software quality. Having conducted a critical literature review, four independent variables have been identified which are staff training & development, coworker relationships, diversity of the team and knowledge sharing. A quantitative survey was carried out with a population of 110 and sample size of 86 senior engineers. The data analysis has been conducted using SPSS 19.0 tool and hypothesis validation was carried out using Pearson correlation, regression and significance values. The research findings showcase that, knowledge sharing has the strongest relationship towards software quality. Staff training and development and co-worker relationships also hold a relationship on software quality whereas diversity of the team does not claim a relationship on software quality. This research would help the software organizations to uplift the software quality by various strategies such as improving existing knowledge management systems with new features, introducing certification process for staff trainings and team building activities. This research could be further enhanced with a larger sample size with the use of other qualitative survey techniques.","","978-1-7281-6785-5","10.1109/ICIEA49774.2020.9101971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9101971","component;software quality;organizational factors;co-worker relationships;staff training and development;culture;diversity;knowledge","Software quality;Training;Companies;Industries;Correlation","","1","","19","IEEE","27 May 2020","","","IEEE","IEEE Conferences"
"Predictive data mining model for software bug estimation using average weighted similarity","N. K. Nagwani; S. Verma","Department of CS&E, NIT, Raipur; Department of CS&E, NIT, Raipur",2010 IEEE 2nd International Advance Computing Conference (IACC),"1 Mar 2010","2010","","","373","378","Software bug estimation is a very essential activity for effective and proper software project planning. All the software bug related data are kept in software bug repositories. Software bug (defect) repositories contains lot of useful information related to the development of a project. Data mining techniques can be applied on these repositories to discover useful interesting patterns. In this paper a prediction data mining technique is proposed to predict the software bug estimation from a software bug repository. A two step prediction model is proposed In the first step bug for which estimation is required, its summary and description is matched against the summary and description of bugs available in bug repositories. A weighted similarity model is suggested to match the summary and description for a pair of software bugs. In the second step the fix duration of all the similar bugs are calculated and stored and its average is calculated, which indicates the predicted estimation of a bug. The proposed model is implemented using open source technologies and is explained with the help of illustrative example.","","978-1-4244-4790-9","10.1109/IADCC.2010.5422923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5422923","Software bug repositories;Bug estimation;Weighted Similarity;Estimation Prediction","Data mining;Predictive models;Computer bugs;Open source software;Project management;Programming;Software testing;System testing;Software quality;Software development management","","12","","11","IEEE","1 Mar 2010","","","IEEE","IEEE Conferences"
"Localized open source software projects: Exploring realism and motivation","K. Buffardi","Computer Science Department, California State University, Chico, Chico, California, USA",2016 11th International Conference on Computer Science & Education (ICCSE),"6 Oct 2016","2016","","","382","387","To address a gap between traditional software engineering projects and professional software products and practices, we established an organization for student collaboration with local software professionals on open source projects. We explored how experiences with this local organization compared to different domains and approaches to improving software engineering project realism. Software engineering students worked in small teams on different types of projects that also included: internal products for a company in industry, humanitarian open source software, and entrepreneurial projects. We identified both strengths and weaknesses of each project type's realism. In addition, we explored students' motivations and discovered trends among underrepresented minorities' preferences.","","978-1-5090-2218-2","10.1109/ICCSE.2016.7581611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581611","Open source software;software engineering;computer science education;community engagement;industry collaboration;humanitarian free and open source software;diversity;underrepresented minorities","Software engineering;Hafnium compounds;Open source software;Collaboration;Programming","","10","","12","IEEE","6 Oct 2016","","","IEEE","IEEE Conferences"
"Implicit Gender Biases in Professional Software Development: An Empirical Study","Y. Wang; D. Redmiles","Department of Software Engineering, Rochester Institute of Technology; Department of Informatics, University of California, Irvine",2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS),"15 Aug 2019","2019","","","1","10","It has been well-known that the software development profession lacks gender diversity, particularly in the technical leadership positions. Researchers and practitioners have spent tremendous efforts on identifying the problems and finding solutions. However, most of the existing software engineering literature focuses on the explicit gender biases but ignores implicit gender biases. To fill this gap, the study sought to empirically investigate whether professional software engineers hold implicit gender biases related to women in the software development profession, and examine whether these implicit biases predict discriminatory decision-making. Using data from 142 professional software engineers in seven organizations, our study yields a rich set of concerning findings. First, we find that implicit biases were pervasive-both male and female software engineers implicitly associated software development professions, particular technical leadership roles, with men, not women, and also associated women with the home and family. Besides, people often cannot resist their implicit gender biases and make decisions in gender-neutral ways while they do well in resisting their explicit gender biases.","","978-1-7281-1762-1","10.1109/ICSE-SEIS.2019.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797640","Implicit gender biases;gender diversity in SE;decision making;implicit association test (IAT);empirical study","","","34","","66","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"A method for measuring similarity of software defect data","L. Wan; T. Yang; H. Liu","Department of Information Engineering, Academy of Armored Force Engineering, Beijing, China; Department of Information Engineering, Academy of Armored Force Engineering, Beijing, China; China Academy of Ordnance Science, Beijing, China","2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","2 Oct 2017","2017","","","1108","1112","The essence of the classification method is the similarity measure, which divides the objects with the same attributes into one class for analysis. In this paper, we first study the similarity measure method of mixed attributes of data mining, and introduce the attribute weight calculation method of defect data to take into account the influence of different attributes on the similarity measurement. It not only reflects the degree of similarity between the attributes of the defect data, but also reflects the distance between the attributes. In this paper, the defect data are analyzed and the results are measured. The experimental results show that the improved similarity measure has a certain degree of improvement in accuracy.","","978-1-4673-8979-2","10.1109/IAEAC.2017.8054185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8054185","fuzzy cluster;similarity;software defects","Manganese","","","","11","IEEE","2 Oct 2017","","","IEEE","IEEE Conferences"
"Crowdsourced Test Report Prioritization Based on Text Classification","Y. Yang; X. Chen","School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China",IEEE Access,"12 Sep 2022","2022","10","","92692","92705","In crowdsourced testing, crowd workers from different places help developers conduct testing and submit test reports for the observed abnormal behaviors. Developers manually inspect each test report and make an initial decision for the potential bug. However, due to the poor quality, test reports are handled extremely slowly. Meanwhile, due to the limitation of resources, some test reports are not handled at all. Therefore, some researchers attempt to resolve the problem of test report prioritization and have proposed many methods. However, these methods do not consider the impact of duplicate test reports. In this paper, we focus on the problem of test report prioritization and present a new method named DivClass by combining a diversity strategy and a classification strategy. First, we leverage Natural Language Processing (NLP) techniques to preprocess crowdsourced test reports. Then, we build a similarity matrix by introducing an asymmetric similarity computation strategy. Finally, we combine the diversity strategy and the classification strategy to determine the inspection order of test reports. To validate the effectiveness of DivClass, experiments are conducted on five crowdsourced test report datasets. Experimental results show that DivClass achieves 0.8887 in terms of APFD (Average Percentage of Fault Detected) and improves the state-of-the-art technique DivRisk by 14.12% on average. The asymmetric similarity computation strategy can improve DivClass by 4.82% in terms of APFD on average. In addition, empirical results show that DivClass can greatly reduce the number of inspected test reports.","2169-3536","","10.1109/ACCESS.2021.3128726","Science and Technology of Zhejiang Province(grant numbers:LY21F020020); National Natural Science Foundation of China(grant numbers:61902096); Key Project of Science and Technology of Zhejiang Province(grant numbers:2017C01010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9617598","Crowdsourced testing;test report prioritization;text classification;diversity strategy;asymmetric similarity","Computer bugs;Diversity reception;Software;Inspection;Task analysis;Software testing;Smart phones","","3","","43","CCBY","16 Nov 2021","","","IEEE","IEEE Journals"
"Hashing Fuzzing: Introducing Input Diversity to Improve Crash Detection","H. D. Menendez; D. Clark","Computer Science Department, Middlesex University London, London, U.K.; Computer Science Department, University College London, London, U.K.",IEEE Transactions on Software Engineering,"16 Sep 2022","2022","48","9","3540","3553","The utility of a test set of program inputs is strongly influenced by its diversity and its size. Syntax coverage has become a standard proxy for diversity. Although more sophisticated measures exist, such as proximity of a sample to a uniform distribution, methods to use them tend to be type dependent. We use r-wise hash functions to create a novel, semantics preserving, testability transformation for C programs that we call HashFuzz. Use of HashFuzz improves the diversity of test sets produced by instrumentation-based fuzzers. We evaluate the effect of the HashFuzz transformation on eight programs from the Google Fuzzer Test Suite using four state-of-the-art fuzzers that have been widely used in previous research. We demonstrate pronounced improvements in the performance of the test sets for the transformed programs across all the fuzzers that we used. These include strong improvements in diversity in every case, maintenance or small improvement in branch coverage – up to 4.8 perent improvement in the best case, and significant improvement in unique crash detection numbers – between 28 to 97 perent increases compared to test sets for untransformed programs.","1939-3520","","10.1109/TSE.2021.3100858","Nvidia; Engineering and Physical Sciences Research Council(grant numbers:InfoTestSS EP/P005888/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9502543","System testing;fuzz testing;HashFuzz;universal hashing","Instruments;Hash functions;Testing;Software;System testing;Fuzzing;Generators","","5","","60","IEEE","30 Jul 2021","","","IEEE","IEEE Journals"
"Inferring Relations Among Test Programs in Microservices Applications","E. De Angelis; G. De Angelis; A. Pellegrini; M. Proietti","IASI-CNR, Rome, Italy; IASI-CNR, Rome, Italy; IASI-CNR, Rome, Italy; IASI-CNR, Rome, Italy",2021 IEEE International Conference on Service-Oriented System Engineering (SOSE),"15 Oct 2021","2021","","","114","123","The emergence of the microservices-oriented architectural style calls for novel methodologies and technological frameworks that support the design, development, and main-tainance of applications structured according to this new style. In this paper, we consider the issue of designing suitable strategies for the governance and the automation of testing activities within the microservices paradigm. We focus on the problem of discovering relations between test programs that help avoiding to re-run all the available test suites each time one of its constituents evolves. We propose an analysis technique, based on symbolic execution of test programs, which is able to collect information about the invocations of local and remote APIs performed when running such programs. Symbolic execution enables the analysis of sets of executions corresponding to different input data, and hence it is also suitable for parametric test programs. The information extracted by symbolic execution is processed by a rule-based automated reasoning engine, which infers dependencies and similarities among test programs. In particular, test programs are considered similar if they involve the same microservice instance, or they connect to the same remote API, or they locally activate overlapping APIs, or they raise similar kinds of errors. We show the viability of our approach by presenting a case study within the context of a real-world microservice application that implements an open-source educational platform.","2642-6587","978-1-6654-3477-5","10.1109/SOSE52839.2021.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564098","software testing;microservices architecture;test program similarity;symbolic execution;automated reasoning","Automation;Service-oriented systems engineering;Conferences;Cognition;Data mining;Open source software;Engines","","2","","41","IEEE","15 Oct 2021","","","IEEE","IEEE Conferences"
"Weaving Context Sensitivity into Test Suite Construction","H. Wang; W. K. Chan","Department of Computer Science, University of Hong Kong, Hong Kong, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China",2009 IEEE/ACM International Conference on Automated Software Engineering,"18 Mar 2010","2009","","","610","614","Context-aware applications capture environmental changes as contexts and self-adapt their behaviors dynamically. Existing testing research has not explored context evolutions or their patterns inherent to individual test cases when constructing test suites. We propose the notation of context diversity as a metric to measure how many changes in contextual values of individual test cases. In this paper, we discuss how this notion can be incorporated in a test case generation process by pairing it with coverage-based test data selection criteria.","1938-4300","978-1-4244-5259-0","10.1109/ASE.2009.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5431725","context diversity;software testing;context-aware programe","Weaving;Software testing;Computer science;Application software;Software engineering;Automatic testing;Middleware;Physics computing;Working environment noise;Programming profession","","12","","15","IEEE","18 Mar 2010","","","IEEE","IEEE Conferences"
"Diversity of interaction in a quality assurance course","M. Ardis; C. Dugas","Department of Computer Science and Software Engineering, Rose Hulman Institute of Technology, USA; Department of Curriculum Instruction and Media Technology, Indiana State University, USA",Proceedings Frontiers in Education 35th Annual Conference,"3 Apr 2006","2005","","","F1G","13","All software engineering courses face a daunting task: how to recreate within the classroom the environment of software engineering as it is practiced. There are three major difficulties to overcome: providing the cultural environment of professional software engineering, providing opportunities for learning by observation and imitation, and providing opportunities for constructive feedback from teammates. Each of these difficulties can be addressed, but some creativity may be required to solve them within the traditional classroom setting","2377-634X","0-7803-9077-6","10.1109/FIE.2005.1612028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1612028","Quality assurance;situated learning;software engineering;usability testing;Vygotsky","Quality assurance;Software engineering;Software quality;Application software;Software testing;Automatic testing;System testing;Computer science;Software design;Software performance","","","","5","IEEE","3 Apr 2006","","","IEEE","IEEE Conferences"
"PODS — A project on diverse software","P. G. Bishop; D. G. Esp; M. Barnes; P. Humphreys; G. Dahll; J. Lahti","Central Electricity Research Laboratories, UK Central Electricity Generating Board, Surrey, UK; Central Electricity Research Laboratories, UK Central Electricity Generating Board, Surrey, UK; UK Atomic Energy Authority, UK; UK Atomic Energy Authority, UK; Institute for Energy, USA; Technical Research Centre of Finland (VTT), Finland",IEEE Transactions on Software Engineering,"26 Sep 2012","1986","SE-12","9","929","940","A review of the Project on Diverse Software (PODS), a collaborative software reliability research project, is presented. The purpose of the project was to determine the effect of a number of different software development techniques on software reliability. The main objectives were to evaluate the merits of using diverse software, evaluate the specification language X-SPEX, and compare the productivity and reliability associated with high-level and low-level languages. A secondary objective was to monitor the software development process, with particular reference to the creation and detection of software faults. To achieve these objectives, an experiment was performed which simulated a normal software development process to produce three diverse programs to the same requirement. The requirement was for a reactor over-power protection (trip) system. After careful independent development and testing, the three programs were tested against each other in a special test harness to locate residual faults. The conclusions drawn from this project are discussed.","1939-3520","","10.1109/TSE.1986.6313048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6313048","Fault classification;n-version programming;PODS;programming languages;reactor protection;software diversity;software faults;software reliability;specification languages;X","Software;Testing;Inductors;Specification languages;Software reliability;Documentation;Quality assurance","","64","","","IEEE","26 Sep 2012","","","IEEE","IEEE Journals"
"Including Everyone, Everywhere: Understanding Opportunities and Challenges of Geographic Gender-Inclusion in OSS","G. A. A. Prana; D. Ford; A. Rastogi; D. Lo; R. Purandare; N. Nagappan","School of Computing and Information Systems, Singapore Management University, Singapore, Singapore; Software Analysis and Intelligence, Microsoft Research, Redmond, WA, USA; Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; School of Computing and Information Systems, Singapore Management University, Singapore, Singapore; Computer Science and Engineering, Indraprastha Institute of Information Technology, New Delhi, Delhi, India; Testing, Verification and Measurement Research, Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,"16 Sep 2022","2022","48","9","3394","3409","The gender gap is a significant concern facing the software industry as the development becomes more geographically distributed. Widely shared reports indicate that gender differences may be specific to each region. However, how complete can these reports be with little to no research reflective of the Open Source Software (OSS) process and communities software is now commonly developed in? Our study presents a multi-region geographical analysis of gender inclusion on GitHub. This mixed-methods approach includes quantitatively investigating differences in gender inclusion in projects across geographic regions and investigate these trends over time using data from contributions to 21,456 project repositories. We also qualitatively understand the unique experiences of developers contributing to these projects through a survey that is strategically targeted to developers in various regions worldwide. Our findings indicate that gender diversity is low across all parts of the world, with no substantial difference across regions. However, there has been statistically significant improvement in diversity worldwide since 2014, with certain regions such as Africa improving at faster pace. We also find that most motivations and barriers to contributions (e.g., lack of resources to contribute and poor working environment) were shared across regions, however, some insightful differences, such as how to make projects more inclusive, did arise. From these findings, we derive and present implications for tools that can foster inclusion in open source software communities and empower contributions from everyone, everywhere.","1939-3520","","10.1109/TSE.2021.3092813","Research Lab for Intelligent Software Engineering; School of Computing and Information Systems; Singapore Management University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9466393","Inclusion;OSS;software engineering;empirical studies;GitHub;diversity;gender;geographic regions","Gender issues;Software development management;Open source software;Software engineering;Europe;Toy manufacturing industry;Industries","","19","","81","IEEE","28 Jun 2021","","","IEEE","IEEE Journals"
"Software Reliability Modeling and Analysis via Kernel-Based Approach","K. Okumura; H. Okamura; T. Dohi","Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, Japan; Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, Japan; Department of Information Engineering, Hiroshima University, Higashi-Hiroshima, Japan",2017 22nd International Conference on Engineering of Complex Computer Systems (ICECCS),"15 Feb 2018","2017","","","154","157","Traditional software reliability analysis utilizes only the fault count data observed in testing phase, and is done independently of the source code itself. Recently, it is known that utilization of software metrics in software reliability modeling and analysis can lead to more accurate reliability estimation and fault prediction through many empirical studies. However, such a metrics-based modeling also requires a careful selection of software metrics and their measurement, which are often troublesome and cost-consuming in practice. In this paper, we propose a kernel-based approach to estimate the quantitative software reliability, where two cases are considered; multiple software metrics are used and not. In the former case, we combine the kernel regression with the well-known non-homogeneous Poisson process-based software reliability growth model (SRGM), and propose a new metrics-based SRGM. In the latter case, we perform a similarity-based analysis through a source code transformation algorithm and try to estimate the quantitative software reliability from the source code directly without measuring multiple software metrics. Numerical examples with real application programs are presented to validate our kernel-based approach in the above two cases.","","978-1-5386-2431-9","10.1109/ICECCS.2017.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8292815","software reliability;software reliability growth model;kernel method;non-homogeneous Poisson process;similarity analysis;static source code analysis;statistical estimation;regularization;fault-free probability","Kernel;Software reliability;Software metrics;Estimation","","","","7","IEEE","15 Feb 2018","","","IEEE","IEEE Conferences"
