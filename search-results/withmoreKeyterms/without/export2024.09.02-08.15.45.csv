"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Test-Based Clone Detection: an Initial Try on Semantically Equivalent Methods","G. Li; H. Liu; Y. Jiang; J. Jin","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China",IEEE Access,"23 Dec 2018","2018","6","","77643","77655","Most code clone detection approaches identify clones via static source code analysis. Such approaches are effective and efficient in detecting lexically similar clones. However, they are less effective in detecting semantic clones that are similar in functionality but different in implementation. As an initial try to detect semantic clones, in this paper, we propose a test-based approach to detecting methods that are semantically equivalent to API methods. For a given method m, we generate its test cases automatically and search for semantically equivalent API methods by running the generated test cases. If two methods generate the same output on each of the test cases, they are taken as semantically equivalent methods. One of the weakness of test-based clone detection is that it is often time consuming. To reduce the time complexity, we take the following measures. First, we focus on methods instead of arbitrary fragments. Second, for a given method, we only compare it against such API methods whose signatures are highly similar to that of the given method. We evaluate the proposed approach on 10 well-known applications. Evaluation results suggest that it is efficient and accurate, and its precision is up to 98%.","2169-3536","","10.1109/ACCESS.2018.2883699","National Natural Science Foundation of China(grant numbers:61690205,61472034,61772071); National Key Research and Development Program of China(grant numbers:2016YFB1000801); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550632","Clone detection;semantic equivalence;test-driven;lexical similarity","Cloning;Semantics;Java;Time complexity;Open source software;Time measurement;Syntactics","","6","","84","OAPA","28 Nov 2018","","","IEEE","IEEE Journals"
"Looking for Lacunae in Bitcoin Core's Fuzzing Efforts","A. Groce; K. Jain; R. van Tonder; G. T. Kalburgi; C. L. Goues","Northern Arizona University, United States; Carnegie Mellon University, United States; Sourcegraph, Inc., United States; Northern Arizona University, United States; Carnegie Mellon University, United States",2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),"17 Jun 2022","2022","","","185","186","Bitcoin is one of the most prominent distributed software systems in the world. This paper describes an effort to investigate and enhance the effectiveness of the Bitcoin Core fuzzing effort. The effort initially began as a query about how to escape saturation in the fuzzing effort, but developed into a more general exploration. This paper summarizes the outcomes of a two-week focused effort. While the effort found no smoking guns indicating major test/fuzz weaknesses, it produced a large number of additional fuzz corpus entries, increased the set of fuzzers used for Bitcoin Core, and ran mutation analysis of Bitcoin Core fuzz targets, with a comparison to Bitcoin functional tests and other cryptocurrencies’ tests. Our conclusion is that for high quality fuzzing efforts, improvements to the oracle may be the best way to get more out of fuzzing.","","978-1-6654-9590-5","10.1145/3510457.3513072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794086","fuzzing;saturation;test diversity;mutation analysis;oracle strength","Bitcoin;Fuzzing;Software systems;Software engineering","","","","9","","17 Jun 2022","","","IEEE","IEEE Conferences"
"Syntactic Versus Semantic Similarity of Artificial and Real Faults in Mutation Testing Studies","M. Ojdanic; A. Garg; A. Khanfir; R. Degiovanni; M. Papadakis; Y. Le Traon","University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg",IEEE Transactions on Software Engineering,"17 Jul 2023","2023","49","7","3922","3938","Fault seeding is typically used in empirical studies to evaluate and compare test techniques. Central to these techniques lies the hypothesis that artificially seeded faults involve some form of realistic properties and thus provide realistic experimental results. In an attempt to strengthen realism, a recent line of research uses machine learning techniques, such as deep learning and Natural Language Processing, to seed faults that look like (syntactically) real ones, implying that fault realism is related to syntactic similarity. This raises the question of whether seeding syntactically similar faults indeed results in semantically similar faults and, more generally whether syntactically dissimilar faults are far away (semantically) from the real ones. We answer this question by employing 4 state-of-the-art fault-seeding techniques (PiTest - a popular mutation testing tool, IBIR - a tool with manually crafted fault patterns, DeepMutation - a learning-based fault seeded framework and $\mu$μBERT - a mutation testing tool based on the pre-trained language model CodeBERT) that operate in a fundamentally different way, and demonstrate that syntactic similarity does not reflect semantic similarity. We also show that 65.11%, 76.44%, 61.39% and 9.76% of the real faults of Defects4J V2 are semantically resembled by PiTest, IBIR, $\mu$μBERT and DeepMutation faults, respectively.","1939-3520","","10.1109/TSE.2023.3277564","Luxembourg National Research Fund(grant numbers:C19/IS/13646587/RASoRS,PayPal); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10136793","Fault injection;fault seeding;machine learning;mutation testing;semantic model;syntactic distance","Syntactics;Semantics;Testing;Measurement;Codes;Bit error rate;Pattern matching","","3","","57","CCBY","26 May 2023","","","IEEE","IEEE Journals"
"A validation method of complex product supportability simulation results based on image similarity","H. Jiayin; M. Lin; Z. Weitao; X. Boping; W. Naichao","School of Reliability and System Engineering, Beihang university, Beijing, China; School of Reliability and System Engineering, Beihang university, Beijing, China; School of Transportation Science and Engineering Beihang university, Beijing, China; School of Reliability and System Engineering, Beihang university, Beijing, China; School of Reliability and System Engineering, Beihang university, Beijing, China",2017 Prognostics and System Health Management Conference (PHM-Harbin),"23 Oct 2017","2017","","","1","5","Supportability simulation is widely used in the supportability analysis of complex products. The accuracy of the simulation results directly affects the quality of the support concept, which determines the performance of the product. In this paper, image similarity is introduced as a new criteria to the validation of complex product supportability simulation results. In the developed method, the simulation results, in the form of multivariate time series, are first preprocessed into gray image. A two-dimensional discrete wavelet transform is then used to filter out random errors. Finally, the image similarity is calculated to identify the quality of the simulation. The feasibility and applicability of the method are verified by the consistency test of the complex product supportability parameters.","2166-5656","978-1-5386-0370-3","10.1109/PHM.2017.8079123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8079123","simulation results test;image similarity;validation;supportability;multivariate time series","Simulation;Numerical models;Data models;Time series analysis;Wavelet transforms;Image reconstruction","","","","13","IEEE","23 Oct 2017","","","IEEE","IEEE Conferences"
"Combinatorial Approach for Automated Platform Diversity Testing","R. S. Sisodia; V. Channakeshava","Philips Research, Philips Healthcare, Bangalore, India; Philips Research, Philips Healthcare, Bangalore, India",2009 Fourth International Conference on Software Engineering Advances,"30 Oct 2009","2009","","","134","139","In recent years, product line engineering has been used effectively in many industrial setups to create a large variety of products. One key aspect of product line engineering is to develop re-usable assets often referred to as a platform. Such software platforms are inherently complex due to requirements of providing diverse functionalities, thereby leading to combinatorial test data explosion problem while validating these platforms. In this paper, we present a combinatorial approach for testing varied features and data diversity present within the platform. The proposed solution effectively takes care of complex interdependencies among diversity features and generates only valid combinations for test scenario. We also developed a prototype tool based on our proposed approaches to automate the platform testing. As part of our case study, we have used our prototype to validate a software platform widely being used across Philips Medical Systems (PMS) products. Initial results confirm that our approach significantly improves the overall platform testing process by reducing testing effort and improve the quality of the platform by detecting all interaction faults.","","978-1-4244-4779-4","10.1109/ICSEA.2009.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5298475","","Automatic testing;Taxonomy;Programming;Costs;Scheduling;Sorting;Databases;Uncertainty;Collaborative software;Project management","","1","","19","IEEE","30 Oct 2009","","","IEEE","IEEE Conferences"
"UWB Multicarrier Radar Target Scene Identification With 2-D Diversity Utilization and GLRT Refinement","D. Garmatyuk; M. Simms; S. Mudaliar","Department of Electrical and Computer Engineering, Miami University, Oxford, USA; Department of Electrical and Computer Engineering, Miami University, Oxford, USA; Sensors Directorate, Air Force Research Laboratory, Wright-Patterson Air Force Base, USA",IEEE Sensors Letters,"20 Dec 2019","2019","3","12","1","4","In this letter, we present a novel approach to target scene identification using ultrawideband software-defined radar system, which utilizes frequency-angle diversity and refines the decision via the numerically implemented generalized likelihood ratio test. The two stages of the method are discussed, as well as the Monte Carlo statistical simulation and its results. The experimental results are presented for two very similar target scenes, each of which had been successfully identified using training data available for five different scenarios. The proposed approach is tailored for use in multicarrier radar sensor systems; specifically, an orthogonal frequency division multiplexing system is considered in this letter.","2475-1472","","10.1109/LSENS.2019.2958013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926366","Sensor signal processing;frequency diversity;generalized likelihood ratio test (GLRT);multiple hypotheses testing (MHT);orthogonal frequency division multiplexing (OFDM) radar;target identification;ultrawideband (UWB) radar","OFDM;Sensors;Training data;Probability density function;Ultra wideband radar;Frequency diversity","","4","","19","IEEE","6 Dec 2019","","","IEEE","IEEE Journals"
"Cost of software design diversity an empirical evaluation","K. Kanoun","LAAS, CNRS, Toulouse, France",Proceedings 10th International Symposium on Software Reliability Engineering (Cat. No.PR00443),"6 Aug 2002","1999","","","242","247","This paper analyzes data related to working hours that have been recorded over seven years, during the development of a real-life software system. The software under consideration is composed of two diverse (dissimilar) units, called variants. The second variant is used for self-checking. The results of the two variants are compared: in case of agreement, the outputs of the principal variant are transmitted and in case of discrepancy an error is reported. For each development phase, we evaluate the cost overhead induced by the development of the second variant with respect to the cost of the principal variant, considered as a reference. The results show that the cost overhead varies from 25% to 134% according to the development phase.","1071-9458","0-7695-0443-4","10.1109/ISSRE.1999.809329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=809329","","Costs;Software design;Software systems;Data analysis;Fault tolerance;System testing;Air traffic control;Electronic switching systems;Air transportation;Fault tolerant systems","","2","","18","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Learning the semantic similarity of reusable software components","D. Merkl; A. M. Tjoa; G. Kappel","Department of Information Engineering, University of Technology, Vienna, Vienna, Austria; Department of Information Engineering, University of Technology, Vienna, Vienna, Austria; Department of Computer Science, University of Linz, Linz, Austria",Proceedings of 1994 3rd International Conference on Software Reuse,"6 Aug 2002","1994","","","33","41","Properly structured software libraries are crucial for the success of software reuse. Specifically, the structure of the software library ought to reflect the functional similarity of the stored software components in order to facilitate the retrieval process. We propose the application of artificial neural network technology to achieve such a structured library. In more detail, we utilize an artificial neural network adhering to the unsupervised learning paradigm. The distinctive feature of this very model is to make the semantic relationship between the stored software components geographically explicit. Thus, the actual user of the software library gets a notion of the semantic relationship between the components in terms of their geographical closeness.<>","","0-8186-6632-3","10.1109/ICSR.1994.365813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=365813","","Software reusability;Software libraries;Artificial neural networks;Application software;Unsupervised learning;Software quality;Computer science;Productivity;Software testing;Organizing","","9","","21","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"The Human Side of Software Engineering Teams: An Investigation of Contemporary Challenges","M. Hoffmann; D. Mendez; F. Fagerholm; A. Luckhardt","QualityMinds GmbH, Nürnberg, Germany; Blekinge Institute of Technology, Karlskrona, Sweden; Aalto University, Espoo, Finland; Technical University of Munich, München, Germany",IEEE Transactions on Software Engineering,"6 Jan 2023","2023","49","1","211","225","Context: There have been numerous recent calls for research on the human side of software engineering and its impact on various factors such as productivity, developer happiness and project success. An analysis of which challenges in software engineering teams are most frequent is still missing. As teams are more international, it is more frequent that their members have different human values as well as different communication habits. Additionally, virtual team setups (working geographically separated, remote communication using digital tools and frequently changing team members) are increasingly prevalent. Objective: We aim to provide a starting point for a theory about contemporary human challenges in teams and their causes in software engineering. To do so, we look to establish a reusable set of challenges and start out by investigating the effect of team virtualization. Virtual teams often use digital communication and consist of members with different nationalities that may have more divergent human values due to cultural differences compared to single nationality teams. Method: We designed a survey instrument and asked respondents to assess the frequency and criticality of a set of challenges, separated in context ”within teams” as well as ”between teams and clients”, compiled from previous empirical work, blog posts, and pilot survey feedback. For the team challenges, we asked if mitigation measures were already in place to tackle the challenge. Respondents were also asked to provide information about their team setup. The survey included the Personal Value Questionnaire to measure Schwartz human values. Finally, respondents were asked if there were additional challenges at their workplace. The survey was first piloted and then distributed to professionals working in software engineering teams via social networking sites and personal business networks. Result: In this article, we report on the results obtained from 192 respondents. We present a set of challenges that takes the survey feedback into account and introduce two categories of challenges; ”interpersonal” and ”intrapersonal”. We found no evidence for links between human values and challenges. We found some significant links between the number of distinct nationalities in a team and certain challenges, with less frequent and critical challenges occurring if 2-3 different nationalities were present compared to a team having members of just one nationality or more than three. A higher degree of virtualization seems to increase the frequency of some human challenges, which warrants further research about how to improve working processes when teams work from remote or in a distributed fashion. Conclusion: We present a set of human challenges in software engineering that can be used for further research on causes and mitigation measures, which serves as our starting point for a theory about causes of contemporary human challenges in software engineering teams. We report on evidence that a higher degree of virtualization of teams leads to an increase of certain challenges. This warrants further research to gather more evidence and test countermeasures, such as whether the employment of virtual reality software incorporating facial expressions and movements can help establish a less detached way of communication.","1939-3520","","10.1109/TSE.2022.3148539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706331","Software engineering;human challenges;virtual teams;human values;diversity;survey research","Software engineering;Software;Virtualization;Virtual groups;Cultural differences;Human factors;Productivity","","8","","56","IEEE","7 Feb 2022","","","IEEE","IEEE Journals"
"Clustering homogeneous XML documents using weighted similarities on XML attributes","N. K. Nagwani; A. Bhansali","Department of CS&E, National Institute of Technology, Raipur, India; Department of IT, OPJIT, Raigarh, India",2010 IEEE 2nd International Advance Computing Conference (IACC),"1 Mar 2010","2010","","","369","372","XML (eXtensible Markup Language) have been adopted by number of software vendors today, it became the standard for data interchange over the web and is platform and application independent also. A XML document is consists of number of attributes like document data, structure and style sheet etc. Clustering is method of creating groups of similar objects. In this paper a weighted similarity measurement approach for detecting the similarity between the homogeneous XML documents is suggested. Using this similarity measurement a new clustering technique is also proposed. The method of calculating similarity of document's structure and styling is given by number of researchers, mostly which are based on tree edit distances. And for calculating the distance between document's contents there are number of text and other similarity techniques like cosine, jaccord, tf-idf etc. In this paper both of the similarity techniques are combined to propose a new distance measurement technique for calculating the distance between a pair of homogeneous XML documents. The proposed clustering model is implemened using open source technology java and is validated experimentally. Given a collection of XML documents distances between documents is calculated and stored in the java collections, and then these distances are used to cluster the XML documents.","","978-1-4244-4790-9","10.1109/IADCC.2010.5422926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5422926","XML Clustering;Weighted Similarity;XML Documents Similarity","XML;Java;Clustering algorithms;Software standards;Application software;Weight measurement;Distance measurement;Software measurement;Software testing;Information retrieval","","10","","13","IEEE","1 Mar 2010","","","IEEE","IEEE Conferences"
"Runtime Diversity against Quasirandom Faults","A. Gerstinger","Institute of Computer Technology, University of Technology, Vienna, Austria",2009 Fourth International Conference on Systems,"26 May 2009","2009","","","145","148","Complex software based systems that have to be highly reliable, are increasingly confronted with fault types whose corresponding failures appear to be random, although they have a systematic cause. This paper introduces and defines these ""quasirandom"" faults. They have certain inconvenient common properties such as their difficulty to be reproduced, their strong state dependence and their likelihood to be found in operational systems after testing. However, these faults are also likely to be detected or tolerated with the help of diversity in software, and even low level diversity which can be achieved during runtime is a promising means against them. The result suggests, that runtime diversity can improve software reliability in complex systems.","","978-1-4244-3469-5","10.1109/ICONS.2009.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4976333","Fault Tolerance;Fault Detection;Diversity;Faults;Failures;Software Reliability","Runtime;Software systems;Hardware;Fault detection;System testing;Timing;Software reliability;Operating systems;Transistors;Input variables","","1","","5","IEEE","26 May 2009","","","IEEE","IEEE Conferences"
"Fuzz Testing Based on Seed Diversity Analysis","W. Lan; Z. Cui; J. Zhang; J. Yang; X. Gu","School of Computer Science, Beijing Information Science and Technology University, Beijing, China; School of Computer Science, Beijing Information Science and Technology University, Beijing, China; School of Computer Science, Beijing Information Science and Technology University, Beijing, China; School of Computer Science, Beijing Information Science and Technology University, Beijing, China; School of Computer Science, Beijing Information Science and Technology University, Beijing, China","2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","29 Jan 2024","2023","","","145","150","Fuzz testing is a widely used technique to detect software defects and vulnerabilities. Coverage-guided fuzzing aims to improve code coverage by generating offspring test cases through mutation, executing the program under test, and retaining interesting seeds for subsequent mutations using customized genetic algorithms. However, existing fuzzing tools rarely consider the similarity between seeds during mutation. Mutating similar seeds frequently generates similar offspring test cases, which results in similar coverage and reduces the efficiency of fuzz testing. To alleviate the impact of this problem on fuzz testing, this paper proposes a fuzz testing method based on seed diversity analysis, which focuses on the characteristics of seeds and uses byte sequences as a feature to measure the similarity between seeds. It collects seeds that can cover new edges and constructs a shorter seed queue with significant differences based on this feature, which replaces the original seed queue for mutation. Based on the proposed method, we implement the prototype tools AFL-Varied and Neuzz-Varied. Compared with AFL and Neuzz on six projects, the edge coverage and basic block coverage can be increased by 214.57% and 233.33 % at most, respectively.","2577-1655","979-8-3503-3702-0","10.1109/SMC53992.2023.10394486","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10394486","fuzz testing;coverage;seed diversity;clustering","Codes;Scalability;Refining;Prototypes;Fuzzing;Software;Genetic algorithms","","","","17","IEEE","29 Jan 2024","","","IEEE","IEEE Conferences"
"Configuration management strategy for distributed and diverse software development environments","U. V. Gumaste; Ti-Chung R. Hsueh; A. A. Nocera; Yiu Kwan Wo","AT&T Bell Labs., Holmdel, NJ, USA; AT and T Laboratories, Holmdel, NJ, USA; AT and T Laboratories, Middletown, NJ, USA; Lucent Technologies, Inc., Whippany, NJ, USA",Proceedings of the IEEE International Conference on Industrial Technology (ICIT'96),"6 Aug 2002","1996","","","42","46","This paper intends to provide an overview of management of software development environments having multiple operating systems and hardware platforms. The paper addresses issues related to system integration as well as independence while fulfilling the need of a seamless software development environment. The article examines the elements necessary to provide efficient software development, integration and test environments that supports distributed execution of software programs across different hardware platforms. The issues related to dissimilar operating systems and hardware platforms are also presented. Requirements for initial and future configuration management needs of such dissimilar environments are discussed.","","0-7803-3104-4","10.1109/ICIT.1996.601537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=601537","","Environmental management;Software development management;Programming;Hardware;Computer architecture;Software performance;Operating systems;Software testing;Productivity;Technology management","","","1","3","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"A Metamorphic Testing Framework and Toolkit for Modular Automated Driving Systems","R. Underwood; Q. -H. Luu; H. Liu","Department of Computing Technologies, Swinburne University of Technology, Melbourne, Australia; Department of Computing Technologies, Swinburne University of Technology, Melbourne, Australia; Department of Computing Technologies, Swinburne University of Technology, Melbourne, Australia",2023 IEEE/ACM 8th International Workshop on Metamorphic Testing (MET),"27 Jul 2023","2023","","","17","24","Autonomous vehicles (AV), at their highest potentials, will provide a greater mobility, an increased traffic efficiency and, more importantly, safer trips for millions of people every day. While assuring their safety and reliability is, thus, of great importance, it is also a huge challenge. Metamorphic testing (MT) has been shown to be one of the most successful testing techniques to validate automated driving systems (ADS) underpinning the AV. Having said that, there are still lots of rooms for further improving the ADS testing with MT. On one hand, the non-determinism in ADS’ behaviors poses great challenges for precisely judging their correctness. On the other hand, the testing scenarios used in the existing studies are still not very much complex for mimicking various realistic traffic conditions. In this study, we propose a new framework which takes into account the hypothesis testing to provide a more solid way for judging the non-deterministic behaviors of test outcomes. On top of that, we develop a new toolkit to implement more complex and realistic ADS testing scenarios. To demonstrate its practicability, we design complex traffic scenarios and pay attention to examine the ADS’ behaviors in non-collision cases which are often unable to be detected by conventional testing methods. It is then applied to test Autoware, a state-of-the-art modular ADS using the Carla simulator. An analysis of results with the Mann-Whitney-Wilcoxon test and Cohen’s d values reveals a large number of consistencies and reliability issues of Autoware. The findings highlight the flexibility and capability of our MT-based framework in validating the AV using a nondeterministic measure and realistic scenarios that can work in the absence of ground truth datasets.","","979-8-3503-0176-2","10.1109/MET59151.2023.00010","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10190416","Metamorphic testing;self-driving cars;autonomous vehicles;diversity of traffic scenarios","Art;Conferences;Buildings;Solids;Behavioral sciences;Safety;Reliability","","","","30","IEEE","27 Jul 2023","","","IEEE","IEEE Conferences"
"SCANTER 5000 and 6000 Solid State Radar: Utilisation of the SCANTER 5000 and 6000 series next generation solid state, coherent, frequency diversity and time diversity radar with software defined functionality for security applications","J. C. Pedersen","Product Portfolio & Innovation, Radar Systems, Terma AS, Lystrup, Denmark",2010 International WaterSide Security Conference,"14 Mar 2011","2010","","","1","8","Coherent, Solid State Radar technology has been available for decades, however, it did not penetrate into harbor surveillance, VTS and related applications for cost and technical reasons. Technically, the main challenge is that dynamic requirements to radar in littoral waters and build up regions are much higher than to other radar applications. Those challenges have now been met and combined with well-renowned advantages from the Terma SCANTER product range. Methods are further refined and implemented on a new technology platform. The result is a software-defined radar series, tailored to individual market segments, virtually unrestricted by dynamic constraints. The digital radar concept with software-defined functionality makes the set-up of the radar easy. Furthermore, Interference rejection against disturbance from radars on ships passing nearby the radar has also proven effective, and the dynamic range has proved to be sufficient to eliminate any artefacts from a high number of large buildings and other structures in an operational area. Operational tests have been performed with impressive results.","2166-1804","978-1-4244-8893-3","10.1109/WSSC.2010.5730272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5730272","Radar;Solid State;Coherece;Frequency Diversity;Time Diversity;Software-Defined Functionality;Security Applications;Radar Cross Section;Sector Power","Radar cross section;Radar antennas;Radar imaging;Solids;Antenna measurements","","","","2","IEEE","14 Mar 2011","","","IEEE","IEEE Conferences"
"Fuzzing with Sequence Diversity Inference for Sequential Decision-making Model Testing","K. Wang; Y. Wang; J. Wang; Q. Wang","State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China",2023 IEEE 34th International Symposium on Software Reliability Engineering (ISSRE),"2 Nov 2023","2023","","","706","717","Nowadays increasing AI techniques, e.g., reinforcement learning, imitation learning, etc., are applied to solve sequential decision-making problems by modeling them as Markov Decision Process (MDP), and achieve superior performance in areas, such as video games, robotics and autonomous driving etc. The reliability of such models is facing severe challenges especially in some safety-critical areas, where failures would bring intolerable disasters. Existing works testing episodic decision-making models are not workable, since they neglect the nature of sequentiality and interactivity in MDP. While other works testing sequential decision-making models are challenged by low testing efficiency because the interaction of MDP is time-consuming. In this paper, we propose an optimized fuzzing framework SeqDivFuzz which infers the sequence diversity during the MDP interaction process to effectively and efficiently test sequential decision-making models in blackbox settings. It adapts the existing fuzzing framework, including Seed Selection, Seed Mutation, Feedback Analysis and integrating a module of Diversity Inference to accelerate the fuzzing procedure. The module learns historical in-process information to check the diversity of test cases when running up to checkPoint in the course of MDP, and early terminating those non-diverse ones. We conduct experimental evaluation with four models involving three simulation environments. The results reflect that SeqDivFuzz exposes 12.3%~49.1% more crashes during a 12-hour testing procedure in four pairs of models and environments compared with the state-of-the-art fuzzing framework. The idea of in-process terminating can potentially boost other techniques for testing sequential decision-making models.","2332-6549","979-8-3503-1594-3","10.1109/ISSRE59848.2023.00041","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10301250","Fuzzing testing;Sequential decision-making;Markov decision process","Adaptation models;Video games;Decision making;Closed box;Life estimation;Fuzzing;Markov processes","","","","50","IEEE","2 Nov 2023","","","IEEE","IEEE Conferences"
"Using Fuzzy Set Similarity in Sentence Similarity Measures","V. Cross; V. Mokrenko; K. Crockett; N. Adel","Computer Science and Software Engineering, Miami University, Oxford, OH, USA; Computer Science and Software Engineering, Miami University, Oxford, OH, USA; Computational Intelligence Lab Manchester Metropolitan University, Manchester, UK; Department of Computing and Maths, Manchester Metropolitan University, Manchester, UK",2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),"26 Aug 2020","2020","","","1","8","Sentence similarity measures the similarity between two blocks of text. A semantic similarity measure between individual pairs of words, each taken from the two blocks of text, has been used in STASIS. Word similarity is measured based on the distance between the words in the WordNet ontology. If the vague words, referred to as fuzzy words, are not found in WordNet, their semantic similarity cannot be used in the sentence similarity measure. FAST and FUSE transform these vague words into fuzzy set representations, type-1 and type-2 respectively, to create ontological structures where the same semantic similarity measure used in WordNet can then be used. This paper investigates eliminating the process of building an ontology with the fuzzy words and instead directly using fuzzy set similarity measures between the fuzzy words in the task of sentence similarity measurement. Their performance is evaluated based on their correlation with human judgments of sentence similarity. In addition, statistical tests showed there is not any significant difference in the sentence similarity values produced using fuzzy set similarity measures between fuzzy sets representing fuzzy words and using FAST semantic similarity within ontologies representing fuzzy words.","1558-4739","978-1-7281-6932-3","10.1109/FUZZ48607.2020.9177836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177836","ontology;semantic similarity;fuzzy set similarity measures;human perception;sentence similarity measures","Fuzzy sets;Semantics;Ontologies;Fuses;Velocity measurement;Indexes;Software measurement","","7","","14","IEEE","26 Aug 2020","","","IEEE","IEEE Conferences"
"An Evaluation of Similarity Coefficients for Software Fault Localization","R. Abreu; P. Zoeteweij; A. J. c. Van Gemund","Software Technology Department, Faculty of Electrical Engineering,Mathematics,and Computer Science, Delft University of Technnology, Delft, Netherlands; Software Technology Department, Faculty of Electrical Engineering,Mathematics,and Computer Science, Delft University of Technnology, Delft, Netherlands; Software Technology Department, Faculty of Electrical Engineering,Mathematics,and Computer Science, Delft University of Technnology, Delft, Netherlands",2006 12th Pacific Rim International Symposium on Dependable Computing (PRDC'06),"26 Dec 2006","2006","","","39","46","Automated diagnosis of software faults can improve the efficiency of the debugging process, and is therefore an important technique for the development of dependable software. In this paper we study different similarity coefficients that are applied in the context of a program spectral approach to software fault localization (single programming mistakes). The coefficients studied are taken from the systems diagnosis/automated debugging tools Pinpoint, Tarantula, and AMPLE, and from the molecular biology domain (the Ochiai coefficient). We evaluate these coefficients on the Siemens Suite of benchmark faults, and assess their effectiveness in terms of the position of the actual fault in the probability ranking of fault candidates produced by the diagnosis technique. Our experiments indicate that the Ochiai coefficient consistently outperforms the coefficients currently used by the tools mentioned. In terms of the amount of code that needs to be inspected, this coefficient improves 5% on average over the next best technique, and up to 30% in specific cases","","0-7695-2724-8","10.1109/PRDC.2006.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4041886","","Fault diagnosis;Software debugging;Software reliability;Computer bugs;Embedded system;Software testing;System testing;Particle measurements;Mathematics;Computer science","","309","8","20","IEEE","26 Dec 2006","","","IEEE","IEEE Conferences"
"Collision resolution based on pulse shape diversity","X. Liu; S. Oymak; A. P. Petropulu; K. R. Dandekar","Electrical and Computer Engineering Department, Drexel University, Philadelphia, PA, USA; Electrical and Computer Engineering Department, Drexel University, Philadelphia, PA, USA; Electrical and Computer Engineering Department, Drexel University, Philadelphia, PA, USA; Electrical and Computer Engineering Department, Drexel University, Philadelphia, PA, USA",2009 IEEE 10th Workshop on Signal Processing Advances in Wireless Communications,"10 Jul 2009","2009","","","409","413","A two-user wireless uplink scenario is considered, in which the users transmit simultaneously over the same channel. In the networking literature the result of such transmission is referred to as collision. It has been recently shown that small user delays and carrier frequency offsets (CFO) between the users allow for blind collision resolution based on the measurements of a single receive antenna. This is achieved by oversampling the collision signal, and exploiting the information on the collided packets that is contained in the signal's polyphase components. In this paper, user pulse-shape diversity is investigated for separating collided users even when delays and CFOs are small. In particular, an iterative pulse shape design is proposed that enforces several desirable characteristics to each user's pulse shape function. The proposed approach is tested on a software defined radio testbed and also via simulations. Both simulations and testbed evaluation suggest that the proposed approach can be very successful in resolving the users under realistic signal-to-noise ratio scenarios. Resolving collisions can significantly improve throughput in wireless networks.","1948-3252","978-1-4244-3695-8","10.1109/SPAWC.2009.5161817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5161817","collision resolution;pulse shape diversity;blind user separation;successive interference cancelation;software defined radio.","Pulse shaping methods;Shape;Signal resolution;Delay;Software testing;Antenna measurements;Frequency measurement;Receiving antennas;Software radio;Signal to noise ratio","","3","","14","IEEE","10 Jul 2009","","","IEEE","IEEE Conferences"
"Effect of Newcomers' Supportive Strategies on Open Source Projects Socio-Technical Activities","S. Bayati","SOM Dept, Buisness School The University of Auckland, New Zealand",2019 IEEE/ACM 12th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE),"29 Aug 2019","2019","","","49","50","The success of open source software (OSS) projects are studied in previous research. This paper focused on the effect of newcomers supportive strategies in OSS projects on the success level of the project. This study analyzes the socio-technical commitment to the project as a proxy for success. Projects' data is collected from GitHub.com to empirically test the research model. Results show the importance of newcomers' supportive strategies on the different aspects of OSS projects success. Also, we have tested the effect of programming language diversity and project profile health on the success of a project. The outcome of this study has both managerial and practical implications.","2574-1837","978-1-7281-2239-7","10.1109/CHASE.2019.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816998","Open Source, Social Coding, Newcomers, Socio-Technical Success, Programming Language Diversity","Encoding;Computer languages;Open source software;Software engineering;Cultural differences;Measurement;Organizations","","6","","12","IEEE","29 Aug 2019","","","IEEE","IEEE Conferences"
"Search-based Diverse Sampling from Real-world Software Product Lines","Y. Xiang; H. Huang; Y. Zhou; S. Li; C. Luo; Q. Lin; M. Li; X. Yang","South China University of Technology, Guangzhou, China; South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-Sen University, Guangzhou, China; South China University of Technology, Guangzhou, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; University of Birmingham, Birmingham, UK; South China University of Technology, Guangzhou, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1945","1957","Real-world software product lines (SPLs) often encompass enormous valid configurations that are impossible to enumerate. To understand properties of the space formed by all valid configurations, a feasible way is to select a small and valid sample set. Even though a number of sampling strategies have been proposed, they either fail to produce diverse samples with respect to the number of selected features (an important property to characterize behaviors of configurations), or achieve diverse sampling but with limited scalability (the handleable configuration space size is limited to 1013). To resolve this dilemma, we propose a scalable diverse sampling strategy, which uses a distance metric in combination with the novelty search algorithm to produce diverse samples in an incremental way. The distance metric is carefully designed to measure similarities between configurations, and further diversity of a sample set. The novelty search incrementally improves diversity of samples through the search for novel configurations. We evaluate our sampling algorithm on 39 real-world SPLs. It is able to generate the required number of samples for all the SPLs, including those which cannot be counted by sharpSAT, a state-of-the-art model counting solver. Moreover, it performs better than or at least competitively to state-of-the-art samplers regarding diversity of the sample set. Experimental results suggest that only the proposed sampler (among all the tested ones) achieves scalable diverse sampling.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510053","National Natural Science Foundation of China(grant numbers:61906069,61876207); Science and Technology Program of Guangzhou(grant numbers:202002030355,201802010007); Fundamental Research Funds for the Central Universities(grant numbers:2020ZYGXZR014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794052","Software product lines;diverse sampling;novelty search;distance metric","Measurement;Scalability;Software algorithms;Search problems;Prediction algorithms;Software;Behavioral sciences","","1","","57","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Applying similar GIS Software Development Style to reservoir automatic supervision and control","Wang Chunlin; Song Jingqing","Kunming Shipbuilding Equipment Test and Research Center, Kunming, China; Kunming Shipbuilding Equipment Test and Research Center, Kunming, China",2008 27th Chinese Control Conference,"22 Aug 2008","2008","","","593","595","The GIS Software Development Styles are analyzed and compared. We bring forward a kind of Similar GIS Software Development Style which can satisfies requirement of Reservoir Automatic Supervision and Control and realizing mode is also introduced.","2161-2927","978-7-900719-70-6","10.1109/CHICC.2008.4604888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4604888","Automatic supervision and control;GIS development","Geographic information systems;Programming;Reservoirs","","","","2","","22 Aug 2008","","","IEEE","IEEE Conferences"
"A Diversity Model Based on Failure Distribution and its Application in Safety Cases","L. Chen; J. H. R. May","University of Bristol, Safety Systems Research Centre, Bristol, UK; University of Bristol, Safety Systems Research Centre, Bristol, UK",IEEE Transactions on Reliability,"30 Aug 2016","2016","65","3","1149","1162","This work develops a new basis for evaluating the reliability benefits of diverse software, based on fault injection testing. In particular, the work investigates new forms of argumentation that could in principle be used to justify diversity as a basis for the construction of safety claims. Failure distributions of two versions of diverse software under various fault conditions are revealed separately by fault injection methods, and then the common failure probability of the version-pair can be estimated. The approach is justified theoretically, and cross validated with other work. This method is also used to explain the fundamental influence of failure distributions on diversity. Furthermore, the unique capabilities of the method are demonstrated by implementation of the fault injection test on a program pair.","1558-1721","","10.1109/TR.2015.2503335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358170","Fault injection;multi-version;reliability;safety case;safety critical system;software diversity","Software;Safety;Software reliability;Sociology;Correlation","","3","","36","IEEE","17 Dec 2015","","","IEEE","IEEE Journals"
"Weighting Influence of User Behavior in Software Validation","A. Bertolino; E. Cartaxo; P. Machado; E. Marchetti","ISTI-CNR, Pisa, Italy; ISTI-CNR, Pisa, Italy; GMF-UFCG, Campina Grande, Brazil; GMF-UFCG, Campina Grande, Brazil",2008 19th International Workshop on Database and Expert Systems Applications,"12 Sep 2008","2008","","","495","500","Validation is an essential part of software development, and testing is a practical and widely used approach. The emerging methodology is model-based testing, in which test cases are derived from a model of software behaviour. In this paper we claim that also user behaviour should be taken into account for test planning purposes. We introduce a pragmatic approach called WSA, which derives the test cases from a state-based model, while also accounting for weights that consider relevance wrt user behaviour.","2378-3915","978-0-7695-3299-8","10.1109/DEXA.2008.75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4624765","usability;value based testing;weighted Similarity Approach","Testing;Software;Planning;Software engineering;Programming;Usability;Proposals","","1","","11","IEEE","12 Sep 2008","","","IEEE","IEEE Conferences"
"Empirical evidence of large-scale diversity in API usage of object-oriented software","D. Mendez; B. Baudry; M. Monperrus","Inria, University of Lille Nord de France, France; Inria, University of Lille Nord de France, France; Inria, University of Lille Nord de France, France",2013 IEEE 13th International Working Conference on Source Code Analysis and Manipulation (SCAM),"28 Oct 2013","2013","","","43","52","In this paper, we study how object-oriented classes are used across thousands of software packages. We concentrate on “usage diversity”, defined as the different statically observable combinations of methods called on the same object. We present empirical evidence that there is a significant usage diversity for many classes. For instance, we observe in our dataset that Java's String is used in 2460 manners. We discuss the reasons of this observed diversity and the consequences on software engineering knowledge and research.","","978-1-4673-5739-5","10.1109/SCAM.2013.6648183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648183","","Pipelines","","11","","23","IEEE","28 Oct 2013","","","IEEE","IEEE Conferences"
"Variant: a malware similarity testing framework","J. Upchurch; X. Zhou","Department of Computer Science, University of Colorado, Colorado Springs, USA; Department of Computer Science, University of Colorado, Colorado Springs, USA",2015 10th International Conference on Malicious and Unwanted Software (MALWARE),"25 Feb 2016","2015","","","31","39","This paper describes Variant, a testing framework for projects attempting to locate variants of malware families through similarity testing. The framework is a series of tests and data standards to evaluate recall and precision in tools that attempt to statically measure similarity in implementation of compiled software, specifically in determining code reuse in compiled software to identify malware variants. The paper offers a malware test dataset that has been manually analyzed to provide a gold standard dataset to be used in current and future malware variant detection works. This set provides a much needed resource in standardizing results across numerous works that have, so far, been tested against datasets that are either not reproducible, algorithmically derived, or both. The framework and dataset provided in this paper are used to test several malware detection approaches published in academic works or used in industry. Finally, the paper brings alignment of testing and reporting methods used in malware variant detection to those used in other statical testing methods used in industry and academia.","","978-1-5090-0319-8","10.1109/MALWARE.2015.7413682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7413682","","Malware;Testing;Standards;Software;Algorithm design and analysis;Gold;Industries","","15","","19","IEEE","25 Feb 2016","","","IEEE","IEEE Conferences"
"Efficiently represent diverse system field usage in reliability testing","P. J. M. Sonnemans; A. Balasubramanian; K. Kevrekedis; M. J. Newby","City University of London, UK; Eindhovan University of Technology, Netherlands; Eindhovan University of Technology, Netherlands; Eindhovan University of Technology, Netherlands",2008 Annual Reliability and Maintainability Symposium,"15 May 2009","2008","","","132","136","This paper addresses the problem how to represent diverse field usage of professional systems in an efficient way, so that field usage can be incorporated in reliability tests. With diverse we mean the variability in system use in the field. Operational Profiles are constructed from system field data to represent system field use. A clustering technique is introduced and applied in a strategic way to reduce the diversity in describing diverse system use in the field. In this way testing effort could be reduced by a factor 87 while maintaining 70 % similarity with the original system field data.","0149-144X","978-1-4244-1460-4","10.1109/RAMS.2008.4925783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4925783","reliability;testing;system use;operational profile;clustering;grouping;field performance","System testing;Biomedical imaging;Medical diagnostic imaging;Hospitals;Software testing;Maintenance;Reliability;Automotive engineering;Manufacturing;Medical services","","1","","10","IEEE","15 May 2009","","","IEEE","IEEE Conferences"
"An Efficient Automated Test Data Generation Method","H. Cui; L. Chen; B. Zhu; H. Kuang","Huazhong Normal Univ., Wuhan, China; Huazhong Normal Univ., Wuhan, China; Huazhong Normal Univ., Wuhan, China; Huazhong Normal Univ., Wuhan, China",2010 International Conference on Measuring Technology and Mechatronics Automation,"6 May 2010","2010","1","","453","456","How to shorten the time for test data generation is concerned about the main points of the current era. For this purpose, this paper brought forward an efficient automated test data generation method. In this paper first elaborated the basic particle swarm optimization algorithm and the improved particle swarm optimization algorithm, and as a search strategy, and then in this paper focused on the path of trajectory similarity calculation method. Experiments show that their combination of two methods can more efficiently generate test data.","2157-1481","978-1-4244-5739-7","10.1109/ICMTMA.2010.556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459797","Test data;particle swarm optimization algorithm;improved PSO;predicate function;path similarity calculation method","Automatic testing;Particle swarm optimization;Software testing;Genetic algorithms;Software quality;Programming;Costs;Current measurement;Time measurement;Mechatronics","","5","","8","IEEE","6 May 2010","","","IEEE","IEEE Conferences"
"Transcend Adversarial Examples: Diversified Adversarial Attacks to Test Deep Learning Model","W. Kong","National Key Laboratory of Science and Technology on Information System Security, Beijing, China",2023 IEEE 41st International Conference on Computer Design (ICCD),"22 Dec 2023","2023","","","13","20","Existing optimized adversarial attacks rely on the ability to search for perturbation within lp norm while keeping maximized loss for highly non-convex loss functions. Random initialization perturbation and the steepest gradient direction strategy are efficient techniques to prevent falling into local optima but compromise the capability of diversity exploration. Therefore, we introduce the Diversity-Driven Adversarial Attack (DAA), which incorporates Output Diversity Strategy (ODS) and diverse initialization gradient direction into the optimized adversarial attack algorithm, aiming to refine the inherent properties of the adversarial examples (AEs). More specifically, we design a diversity-promoting regularizer to penalize the insignificant distance between initialization gradient directions based on the version of ODS. Extensive experiments demonstrate that DAA can efficiently improve existing coverage criteria without sacrificing the performance of attack success rate, which implies that DAA can implicitly explore more internal model logic of DL model.","2576-6996","979-8-3503-4291-8","10.1109/ICCD58817.2023.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10360997","Adversarial Attack;Diversity;Robustness and Security;Test Deep Learning Model","Deep learning;Measurement;Perturbation methods;Computational modeling;Computer security;Testing","","","","31","IEEE","22 Dec 2023","","","IEEE","IEEE Conferences"
"Fuzzy similarity-based data fusion algorithm and its application to engine testing","Xiong Li; Zongchang Xu; Zhiming Dong","Department of Command and Administration, Academy of Armored Forces Engineering, Beijing, China; Department of Command and Administration, Academy of Technical Support Engineering, Beijing, China; Department of Command and Administration, Academy of Armored Forces Engineering, Beijing, China",2005 IEEE International Conference on Granular Computing,"5 Dec 2005","2005","2","","516","519 Vol. 2","According to the requirements of multisensor data fusion in real-time engine testing, a novel, fuzzy similarity-based data fusion algorithm is given in this paper. Based on fuzzy set theory, it calculates the fuzzy similarity between a certain sensor's measurement values and the multiple sensors' objective prediction values to determine the importance weigh of each sensor, and realize the multisensor testing parameter data fusion. According to the algorithm theory, its application software is also designed in the paper. The applied example proves that the algorithm can give priority to the high-stability and high-reliability sensors and it is laconic, efficient and feasible to real-time circumstance measure and data processing in engine condition monitoring and measurement.","","0-7803-9017-2","10.1109/GRC.2005.1547345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1547345","","Engines;Testing;Fuzzy set theory;Sensor fusion;Software algorithms;Application software;Software design;Algorithm design and analysis;Data processing;Condition monitoring","","1","1","14","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"TAF: a Tool for Diverse and Constrained Test Case Generation","C. Robert; J. Guiochet; H. Waeselynck; L. V. Sartori","LAAS-CNRS, Université de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Université de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Université de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Université de Toulouse, CNRS, Toulouse, France","2021 IEEE 21st International Conference on Software Quality, Reliability and Security (QRS)","10 Mar 2022","2021","","","311","321","The generation of test cases may have to accommodate size-varying data structures and semantic constraints between the data elements. This often requires the development of custom generators. In this paper, we introduce a novel generic tool to generate constrained and diverse test cases from a data model. First, the user defines the model using an XML-based domain-specific language. Then TAF generates diverse test cases by combining random sampling with the use of an SMT solver. The capabilities of the tool are demonstrated by four examples of models coming from various application domains: virtual crop fields for testing an agriculture robot, bitmap images with a graduated background, a population of taxpayers in a tax management system, and tree structures of diverse sizes and heights. We show how TAF performs in terms of data diversity and execution time. We also provide some comparison results with an UML-based tool using SMT solving.","2693-9177","978-1-6654-5813-9","10.1109/QRS54544.2021.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9724803","test;test input generation;fuzzing;autonomous robots;simulation","Three-dimensional displays;Unified modeling language;Diversity reception;Data structures;Data models;Test pattern generators;Usability","","6","","26","IEEE","10 Mar 2022","","","IEEE","IEEE Conferences"
"Fast Test Generation for Structurally Similar Circuits","J. Joe; N. Mukherjee; I. Pomeranz; J. Rajski","School of Electrical & Computer Engg., Purdue University, W. Lafayette, IN, USA; Siemens Digital Industries Software, Wilsonville, OR, USA; School of Electrical & Computer Engg., Purdue University, W. Lafayette, IN, USA; Siemens Digital Industries Software, Wilsonville, OR, USA",2022 IEEE 40th VLSI Test Symposium (VTS),"15 Jun 2022","2022","","","1","7","This paper describes a fast test generation process for digital circuits that exhibit extensive structural similarity. The property of structural similarity can be seen in circuits that are subjected to engineering change order (ECO), circuits that are modified during place and route, circuits subjected to retiming, and circuits with multiple similar cores. The goal of the paper is to determine the testability of a circuit (circuit2) given a test set for a structurally similar circuit (circuit1). This is achieved by transforming a test set generated for circuit1 into a test set for circuit2 as efficiently as possible, without repeating the entire test generation process. The process described in the paper starts with a structural analysis of circuit1 and circuit2 to obtain a mapping between their inputs and outputs. The mapping is used for transforming test patterns from circuit1 into test patterns for circuit2. The experiments conducted on industrial designs show an average of more than 10-fold reduction in runtime, compared with running the entire test generation process for circuit2.","2375-1053","978-1-6654-1060-1","10.1109/VTS52500.2021.9794232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794232","","Runtime;Very large scale integration;Test pattern generators;Digital circuits","","5","","25","IEEE","15 Jun 2022","","","IEEE","IEEE Conferences"
"An open-source software package to assess similarity measures that compare intuitionistic fuzzy sets","M. Loor; G. De Tre","Dept. of Electrical and Computer Engineering, ESPOL University, Guayaquil, Ecuador; Ghent University Dept. of Telecommunications and Information Processing, Ghent, Belgium",2017 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),"24 Aug 2017","2017","","","1","6","Since intuitionistic fuzzy sets (IFSs) have been applied to solve problems in topics like decision-making or pattern recognition, the study of similarity measures aiming to compare this kind of fuzzy sets has become a challenging research subject. When proposed, a similarity measure is usually tested to demonstrate its properties and advantages over the others. However, those tests are occasionally performed using a small number of examples that do not allow a researcher or practitioner to detect potential drawbacks. In this paper, an open-source software package whereby a researcher can empirically assess several (configurations of) similarity measures while comparing IFSs that characterize experience-based evaluations is proposed and presented. By means of the proposed package, one can (1) build a large number of IFSs according to different learning scenarios, (2) compare those IFSs using existing or novel similarity measures, and (3) generate a comprehensive report about how each similarity measure reflects a perceived similarity. Reports generated by the package show that only a few of the existing similarity measures reflect properly a perceived similarity when IFSs resulting from opposite learning scenarios are compared to each other.","1558-4739","978-1-5090-6034-4","10.1109/FUZZ-IEEE.2017.8015689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8015689","","Fuzzy sets;Software packages;Open source software;Software measurement;Decision making;Pattern recognition;Current measurement","","3","","27","IEEE","24 Aug 2017","","","IEEE","IEEE Conferences"
"Applying Binary Code Similarity Detection on Acceleration Processor","G. Yin; Y. Tang; W. Xie; Z. Luo; Y. Wang","College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China",2023 4th International Conference on Computer Engineering and Intelligent Control (ICCEIC),"13 Feb 2024","2023","","","454","459","Binary code similarity detection, as an integral part of network security, has remained a hot spot in the research fields of intellectual property protection, vulnerability detection, patch analysis, and malicious software detection. It carries significant usability value. With the rapid development of deep learning and neural network technologies, new algorithms and thoughts have been introduced into the research of binary code similarity detection, achieving breakthrough progress. MT-3000, a heterogeneous multi-zone acceleration processor, which is entirely designed and implemented by National University of Defense Technology, possesses powerful computing performance. In this paper, based on the latest deep learning theory and using the domestically produced and controllable high-performance MT-3000 acceleration processor for relevant tests and researches on the binary code similarity detection, proposes relevant conclusions and suggestions.","","979-8-3503-0887-7","10.1109/ICCEIC60201.2023.10426711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10426711","code similarity detection;deep learning;MT-3000;Euclidean distance","Deep learning;Ecosystems;Software algorithms;Process control;Binary codes;Life estimation;Usability","","","","10","IEEE","13 Feb 2024","","","IEEE","IEEE Conferences"
"Evaluating similarity measures for software decompositions","Zhihua Wen; V. Tzerpos","York University, Toronto, ONT, Canada; York University, Toronto, ONT, Canada","20th IEEE International Conference on Software Maintenance, 2004. Proceedings.","22 Nov 2004","2004","","","368","377","One of the central questions that a similarity measure for software decompositions has to address is whether to consider discrepancies in terms of the nodes of a particular decomposition, or assess similarity based on differences in clustering the edges of the system's dependency graph. We argue that considering nodes or edges in isolation is too one-sided. We outline shortcomings of previous approaches, and introduce the first dissimilarity measure that takes both nodes and edges into account. We also present experiments on real and synthetic data sets that illustrate the differences between various measures.","1063-6773","0-7695-2213-0","10.1109/ICSM.2004.1357822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1357822","","Software measurement;Software systems;Software maintenance;Clustering algorithms;Software algorithms;Particle measurements;System testing;Benchmark testing;Information retrieval","","12","","16","IEEE","22 Nov 2004","","","IEEE","IEEE Conferences"
"High Performance Data Mining Algorithms and Similarity Models Research","S. Xue; H. Wang; T. Ran","Computer and Software Institute, Nanjing University of Information Science and Technology, Nanjing, Jiangsu, China; School of Computer Science and Technology, Wuhan University of Technology, Wuhan, Hubei, China; School of Computer Science and Technology, Wuhan University of Technology, Wuhan, Hubei, China",2008 International Conference on Computer Science and Software Engineering,"22 Dec 2008","2008","4","","411","414","For the complex data of multilevel and large volume distributed in different regions, how to seek and find both be interested and useful information is what scientists are devoted to. Existing efficient method of research is an association rule mining of distributed database system. This paper introduced the distributed association rule mining algorithm. By analyzing the Aproiri algorithm, we have proposed Fast Distributed Mining of Association Rule algorithm and Similarity model. The test results show it can effectively improve the mining accuracy rate.","","978-0-7695-3336-0","10.1109/CSSE.2008.1359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4722646","data mining;association rule;algorithm;data resource heterogeneous;similarit","Data mining;Association rules;Itemsets;Computer science;Database systems;Transaction databases;Distributed databases;Distributed decision making;Software engineering;Software algorithms","","","","5","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"A design diversity metric and reliability analysis for redundant systems","S. Mitra; N. R. Saxena; E. J. McCluskey","Center for Reliable Computing, Departments of Electrical Engineering and Computer Science, University of Stanford, Stanford, CA, USA; Center for Reliable Computing, Departments of Electrical Engineering and Computer Science, University of Stanford, Stanford, CA, USA; Center for Reliable Computing, Departments of Electrical Engineering and Computer Science, University of Stanford, Stanford, CA, USA",International Test Conference 1999. Proceedings (IEEE Cat. No.99CH37034),"6 Aug 2002","1999","","","662","671","Design diversity has long been used to protect redundant systems against common-mode failures. The conventional notion of diversity relies on ""independent"" generation of ""different"" implementations. This concept is qualitative and does not provide a basis to compare the reliabilities of two diverse systems. In this paper, for the first time, we present a metric to quantify diversity among several designs. Based on this metric, we derive analytical reliability models that show a simple relationship between design diversity, system failure rate, and mission time. In addition, we present simulation results to demonstrate the effectiveness of design diversity in Duplex and Triple Modular Redundant (TMR) systems. For independent multiple-module failures, we show that, mere use of different implementations does not always guarantee higher reliability compared to redundant systems with identical implementations-it is important to analyze the reliability of redundant systems using our metric. For common-mode failures and design faults, there is a significant gain in using different implementations-however, as our analysis shows, the gain diminishes as the mission time increases. Our simulation results also demonstrate the usefulness of diversity for enhancing the self-testing properties of redundant systems.","1089-3539","0-7803-5753-1","10.1109/TEST.1999.805794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=805794","","Failure analysis;Circuit faults;Hardware;Field programmable gate arrays;Protection;Redundancy;Very large scale integration;Software systems;Analytical models;Electromagnetic interference","","33","1","28","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Preparing Text Reports from Web Pages Employing Similarity Tests","J. G. Ramos; J. C. Solorio; L. Campoy; S. Ruiz; N. Jasso","Instituto Tecnológico de La Piedad, Av. Tecnológico, México, CP; Instituto Tecnológico de La Piedad, Av. Tecnológico, México, CP; Instituto Tecnológico de La Piedad, Av. Tecnológico, México, CP; Instituto Tecnológico de La Piedad, Av. Tecnológico, México, CP; Instituto Tecnológico de La Piedad, Av. Tecnológico, México, CP",2013 Mexican International Conference on Computer Science,"12 Dec 2013","2013","","","13","19","The World Wide Web is the main source of information for many organizations and common users. However, the analysis and selection of the web content is still an arduous manual task in many cases. When a web query is sent towards a web search engine, a list of URLs is received, frequently ordered by popularity (such as Google's PageRank algorithm). Then, the user must read and analyze each URL in order to find out the convenient information. In this work a method that automatically constructs a text report induced by a web query from a set of URLs is presented. The method extracts text slices (excerpts) from web pages considering the most similar text w.r.t. a web query as slicing criterion. A slice is composed by document object model (DOM) nodes, whereas similarity is calculated using standard techniques employed in natural language processing.","2332-5712","978-0-7695-5087-9","10.1109/ENC.2013.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6679814","information retrieval;slicing;similarity;summarization","Web pages;Vectors;Software tools;Standards;Natural language processing;Google","","1","","18","IEEE","12 Dec 2013","","","IEEE","IEEE Conferences"
"An Industrial Investigation of Similarity Measures for Model-Based Test Case Selection","H. Hemmati; L. Briand","Simula Research Laboratory and Department of Informatics, University of Oslo, Norway; Simula Research Laboratory and Department of Informatics, University of Oslo, Norway",2010 IEEE 21st International Symposium on Software Reliability Engineering,"11 Nov 2010","2010","","","141","150","Applying model-based testing (MBT) in practice requires practical solutions for scaling up to large industrial systems. One challenge that we have faced while applying MBT was the generation of test suites that were too large to be practical, even for simple coverage criteria. The goal of test case selection techniques is to select a subset of the generated test suite that satisfies resource constraints while yielding a maximum fault detection rate. One interesting heuristic is to choose the most diverse test cases based on a pre-defined similarity measure. In this paper, we investigate and compare possible similarity functions to support similarity-based test selection in the context of state machine testing, which is the most common form of MBT. We apply the proposed similarity measures and a selection strategy based on genetic algorithms to an industrial software system. We compare their fault detection rate based on actual faults. The results show that applying Jaccard Index on test cases represented as a set of trigger-guards is the most cost-effective similarity measure. We also discuss the overall benefits of our test selection approach in terms of test execution savings.","2332-6549","978-1-4244-9056-1","10.1109/ISSRE.2010.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635133","Test case selection;model-based testing;UML state machine;similarity measure;genetic algorithms","Unified modeling language;Encoding;Testing;Gallium;Context;Fault detection;Hamming distance","","43","1","21","IEEE","11 Nov 2010","","","IEEE","IEEE Conferences"
"Multi-objective Grammar-guided Genetic Programming with Code Similarity Measurement for Program Synthesis","N. Tao; A. Ventresque; T. Saber","School of Computer Science, University College, Dublin, Ireland; School of Computer Science, University College, Dublin, Ireland; Lerothe Irish Software Research Centre",2022 IEEE Congress on Evolutionary Computation (CEC),"6 Sep 2022","2022","","","1","8","Grammar-Guided Genetic Programming (G3P) is widely recognised as one of the most successful approaches for program synthesis, i.e., the task of automatically discovering an executable piece of code given user intent. G3P has been shown capable of successfully evolving programs in arbitrary languages that solve several program synthesis problems based only on a set of input/output examples. Despite its success, the restriction on the evolutionary system to only leverage input/output error rate during its assessment of the programs it derives limits its scalabil-ity to larger and more complex program synthesis problems. With the growing number and size of open software repositories and generative artificial intelligence approaches, there is a sizeable and growing number of approaches for retrieving/generating source code (potentially several partial snippets) based on textual problem descriptions. Therefore, it is now, more than ever, time to introduce G3P to other means of user intent (particularly textual problem descriptions). In this paper, we would like to assess the potential for G3P to evolve programs based on their similarity to particular target codes of interest (obtained using some code retrieval/generative approach). Through our experimental evaluation on a well-known program synthesis benchmark, we have shown that G3P successfully manages to evolve some of the desired programs with all four considered similarity measures. However, in its default configuration, G3P is not as successful with similarity measures as it is with the classical input/output error rate when solving program synthesis problems. Therefore, we propose a novel multi-objective G3P approach that combines the similarity to the target program and the traditional input/output error rate. Our experiments show that compared to the error-based G3P, the multi-objective G3P approach could improve the success rate of specific problems and has great potential to improve on the traditional G3P system.","","978-1-6654-6708-7","10.1109/CEC55065.2022.9870312","Science Foundation Ireland(grant numbers:13/RC/2094_P2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870312","Program Synthesis;Grammar-Guided Genetic Programming;Code Similarity;Multi-Objective Optimization","Codes;Error analysis;Measurement uncertainty;Genetic programming;Evolutionary computation;Benchmark testing;Software","","5","","33","IEEE","6 Sep 2022","","","IEEE","IEEE Conferences"
"A Parallel Self-Similar Network Traffic Simulation Method on a Large Time Scale","J. Tian; J. Xu; H. C. Zhang","Nankai University, Institute of Machine Intelligence, Tianjin, China; Nankai University, Institute of Machine Intelligence, Tianjin, China; Nankai University, Institute of Machine Intelligence, Tianjin, China",2008 International Symposium on Information Science and Engineering,"30 Dec 2008","2008","2","","149","153","Measurements of network traffic have shown that self-similarity is a ubiquitous phenomenon spanning across diverse network environments. Previously, the researchers designed network traffic simulation system with sequential methods to generate a small number of network traffics in a short time scale. But there is one difficulty in simulating network traffics using parallel methods with high accuracy in a large time scale. In this paper, we present a parallel method of generating self-similar network traffic based on parallel algorithm and implement it via TCP/IP. We also carry out some experiments to show that this parallel method can generate highly accurate network simulation traffics with specified Hurst parameters.","2160-1291","978-0-7695-3494-7","10.1109/ISISE.2008.194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732363","Self-Similar Model;Network Traffic Simulation;Parallel Simulation Algorithm","Telecommunication traffic;Traffic control;System testing;Software testing;Computer networks;Software systems;Software tools;Automatic testing;Network synthesis;Computational modeling","","","","6","IEEE","30 Dec 2008","","","IEEE","IEEE Conferences"
"Estimation of software diversity by fault simulation and failure searching","Luping Chen; J. May; G. Hughes","Safety Systems Research Centre, Department of Compute Science, University of Bristol, UK; Safety Systems Research Centre, Department of Compute Science, University of Bristol, UK; Safety Systems Research Centre, Department of Compute Science, University of Bristol, UK",Proceedings 12th International Symposium on Software Reliability Engineering,"7 Aug 2002","2001","","","122","131","An important problem for computer-based systems is providing fault tolerance for unknown (at the time of commencement of service) systematic design errors. Such design errors can have a long latency in normal operation and only become apparent under specific conditions associated with particular combinations of input and internal system states. The use of 'diverse' software versions remains a possible approach to prevent coincidental failure, but its potential value has never been quantified. This paper presents the application of data-flow and constant perturbation to simulate the introduction of faults or errors into programs and explores methods to establish the magnitudes and locations of the associated input space failure regions. Used together, these two techniques enable failure behaviour to be described in a quantitative way and provide a method to estimate the diversity of multi-version software. A simple case and a industrial software are studied to illustrate the applications of the approach.","1071-9458","0-7695-1306-9","10.1109/ISSRE.2001.989465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=989465","","Software testing;Computer errors;Software safety;Computational modeling;Computer simulation;Fault tolerant systems;Application software;Software quality;Software engineering;Fault tolerance","","1","","28","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Bug Mining Model Based on Event-Component Similarity to Discover Similar and Duplicate GUI Bugs","N. K. Nagwani; P. Singh","Department of Computer Science & Engineering, National Institute of Technology, Raipur, India; Department of Computer Science & Engineering, National Institute of Technology, Raipur, India",2009 IEEE International Advance Computing Conference,"31 Mar 2009","2009","","","1388","1392","All most all of the bugs related to graphical user interface (GUI) module of applications and are described in terms of events associated with GUI components. In this paper, a bug mining model for discovering duplicate and similar GUI bugs is presented and approach for detecting the similar and duplicate GUI bugs is described. Resolution of similar and duplicate bugs are almost identical, so if similar and duplicates are identified it will optimize the time for fixing reported GUI bugs and it can also help in achieving the faster development. A GUI bug can be transformed into a sequence of events, components and expected implementation requirements for each GUI event. This transformation is used in this paper to discover the similar and duplicate GUI bugs. First all the GUI bugs are transformed into events, components and requirements sequence, then these sequences are pair wise matched and common subsequence is generated which will indicate the similarity for the GUI bugs.","","978-1-4244-2927-1","10.1109/IADCC.2009.4809219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809219","similar bugs;duplicate bugs;event component similarity","Graphical user interfaces;Computer bugs;Application software;Databases;Testing;Information retrieval;Image retrieval;Documentation;Software performance;Terminology","","3","1","11","IEEE","31 Mar 2009","","","IEEE","IEEE Conferences"
"On the Diversity of Machine Learning Models for System Reliability","F. Machida","Department of Computer Science, University of Tsukuba, Tsukuba, Japan",2019 IEEE 24th Pacific Rim International Symposium on Dependable Computing (PRDC),"9 Jan 2020","2019","","","276","27609","The diversity of system components is one of the important contributing factors of reliable and secure software systems. In a software fault-tolerant system using diverse versions of software components, a component failure caused by defects or malicious attacks can be covered by other versions. Machine learning systems can also benefit from such a multi-version approach to improve the system reliability. Nevertheless, there are few studies addressing this issue. In this paper, we experimentally analyze how outputs of machine learning modules can be diversified by using different versions of machine learning algorithms, neural network architectures and perturbated input data. The experiments are conducted on image classification tasks of MNIST data set and Belgian Traffic Sign data set. Different neural network architectures, support vector machines and random forests are used for constructing diverse machine learning models. The diversity is characterized by the coverage of errors over the test samples. We observe that the different machine learning models have quite different error coverages that can be leveraged for system reliability design. Based on the experimental results, we construct the reliability model for three-version machine learning architecture with a diversity measure defined as the intersection of error spaces in the sample space. From the presented reliability model, we derive a necessary condition under which three-version architecture achieves a higher system reliability than a single machine learning module.","2473-3105","978-1-7281-4961-5","10.1109/PRDC47002.2019.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952144","Diversity, image classification, machine learning, reliability, software fault-tolerance","","","8","","32","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Using similarity measures for test scenario selection","P. G. Sapna; H. Mohanty","Department of Computer and Information Sciences, University of Hyderabad, Hyderabad, India; Department of Computer and Information Sciences, University of Hyderabad, Hyderabad, India",2009 International Conference on Industrial and Information Systems (ICIIS),"11 Mar 2010","2009","","","386","391","Specification based testing involves using specification as the basis for generating test cases. The Unified Modeling Language (UML) consists of diagrams to capture the static and dynamic behaviour of a system. Generating test scenarios using UML activity diagrams produces all possible scenarios which is impossible to test exhaustively. Test scenario selection involves selecting an effective subset of scenarios for testing. This paper presents a new metric based on common subscenario between scenarios, their lengths, and weights based on the position of the common subscenario in the scenario. The aim of this strategy is to select scenarios that are least similar and at the same time provide high coverage. The method is compared with results of random selection to study effectiveness of our technique.","2164-7011","978-1-4244-4836-4","10.1109/ICIINFS.2009.5429829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5429829","","Software testing;Unified modeling language;System testing;Costs;Programming;Software quality;Fault detection;Object oriented modeling;Computer industry;Information systems","","1","","12","IEEE","11 Mar 2010","","","IEEE","IEEE Conferences"
"ForkSim: Generating software forks for evaluating cross-project similarity analysis tools","J. Svajlenko; C. K. Roy; S. Duszynski","University of Saskatchewan, Canada; University of Saskatchewan, Canada; Fraunhofer IESE, Kaiserslautern, Germany",2013 IEEE 13th International Working Conference on Source Code Analysis and Manipulation (SCAM),"28 Oct 2013","2013","","","37","42","Software project forking, that is copying an existing project and developing a new independent project from the copy, occurs frequently in software development. Analysing the code similarities between such software projects is useful as developers can use similarity information to merge the forked systems or migrate them towards a reuse approach. Several techniques for detecting cross-project similarities have been proposed. However, no good benchmark to measure their performance is available. We developed ForkSim, a tool for generating datasets of synthetic software forks with known similarities and differences. This allows the performance of cross-project similarity tools to be measured in terms of recall and precision by comparing their output to the known properties of the generated dataset. These datasets can also be used in controlled experiments to evaluate further aspects of the tools, such as usability or visualization concepts. As a demonstration of our tool, we evaluated the performance of the clone detector NiCad for similarity detection across software forks, which showed the high potential of ForkSim.","","978-1-4673-5739-5","10.1109/SCAM.2013.6648182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648182","","Cloning;Software;Taxonomy;Conferences;Detectors;Java;Benchmark testing","","6","","18","IEEE","28 Oct 2013","","","IEEE","IEEE Conferences"
"Multilevel Traceability Links Establishments Between SOFL Formal Specifications and Java Codes Using Multi-dimensional Similarity Measures","J. Li; S. Liu; A. Liu; R. Huang","Graduate School of Advanced Science and Engineering, Hiroshima University, Hiroshima, Japan; Graduate School of Advanced Science and Engineering, Hiroshima University, Hiroshima, Japan; Graduate School of Advanced Science and Engineering, Hiroshima University, Hiroshima, Japan; Faculty of Computer and Information Sciences, Hosei University, Tokyo, Japan","2021 IEEE 21st International Conference on Software Quality, Reliability and Security (QRS)","10 Mar 2022","2021","","","852","863","Linking the components in a formal specification to those in the corresponding program is a prerequisite for formal specification-based program fault detection. Existing traceability link techniques for reducing manpower and time cost suffer from the limitation in effectiveness due to over dependency of textual similarity. Unlike the existing work, this paper presents an automatic method for constructing traceability links between SOFL formal specifications and Java codes, taking semantical, structural, functional, and relational similarities measures into account. It operates at multiple levels of a formal specification, such as data flows, processes, and modules, to establish finegrained link relationships between artifacts. Further, a comparative evaluation of the proposed method, using two selected modules of the SOFL formal specification of a critical ATM system and its Java implementation with 951 code of lines, demonstrates an improvement in precision and more generality than existing latent semantic indexing that is an information retrieval-based method.","2693-9177","978-1-6654-5813-9","10.1109/QRS54544.2021.00094","China Scholarship Council(grant numbers:(CSC No. 202108050145)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9724917","software traceability links;formal specification;SOFL;program review","Java;Codes;Fault detection;Semantics;Software quality;Inspection;Software reliability","","2","","18","IEEE","10 Mar 2022","","","IEEE","IEEE Conferences"
"Data diversity: an approach to software fault tolerance","P. E. Ammann; J. C. Knight","Software Productivity consortium, Reston, VA, USA; Software Productivity consortium, Reston, VA, USA",IEEE Transactions on Computers,"6 Aug 2002","1988","37","4","418","425","Data diversity is described, and the results of a pilot study are presented. The regions of the input space that cause failure for certain experimental programs are discussed, and data reexpression, the way in which alternate input data sets can be obtained, is examined. A description is given of the retry block which is the data-diverse equivalent of the recovery block, and a model of the retry block, together with some empirical results is presented. N-copy programming which is the data-diverse equivalent of N-version programming is considered, and a simple model and some empirical results are also given.<>","1557-9956","","10.1109/12.2185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=2185","","Fault tolerance;System testing;Application software;Buildings;Computer applications;Software testing;Redundancy;Software algorithms;NASA;Computer science","","237","6","12","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Architecture Design of a Network Traffic Simulation System Based on Self-Similar Model","T. Jie; X. Jing; Z. Huachuan","Institute of Machine Intelligence, Nankai University, Tianjin, China; Institute of Machine Intelligence, Nankai University, Tianjin, China; Institute of Machine Intelligence, Nankai University, Tianjin, China",2008 International Conference on Computational Intelligence and Security,"22 Dec 2008","2008","2","","192","196","In order to generate self-similar network traffics, researchers designed network traffic simulation system using sequential methods to generate network traffics with self-similar property on a short time scale. But there is one difficulty in how the simulation system can generate network traffics with high accuracy on a much larger time scale. So, in this paper, we present an architecture design for the distributed testing system of generating self-similar network traffic based on parallel methods and implement it via TCP/IP. We also carry out some experiments to show that this distributed system can generate highly accurate network traffics in specified Hurst parameters.","","978-0-7695-3508-1","10.1109/CIS.2008.189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4724763","Self-Similar Model;Network Traffic Simulation;Distributed System","Telecommunication traffic;Traffic control;System testing;Software testing;Computational modeling;Computer networks;Computer architecture;Software systems;Network synthesis;Software tools","","1","","6","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"Cloud Model based classifier","Liu Yu; Chen Gui-Sheng","State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; China Institute of Electronics Engineering, Beijing, China",2009 International Conference on Test and Measurement,"17 Feb 2010","2009","1","","427","430","Cloud Model is a well-known model of the uncertainty transition between a linguistic term of a qualitative concept and its numerical representation. Samples to be classified generally contain many features. Different features have different importance, which are often classified by weights. For the same category, feature vectors were mapped into clouds. With different numerical characters of the clouds, we could get the cloud similarities and feature weights. The testing samples' contribution to a certain class was measured by the certainty degree of Cloud Model. We proposed a new classification algorithm based on Could Model. Experiments show that such an approach could achieve a better or at least a comparable classification accuracy with other algorithms.","2157-5606","978-1-4244-4699-5","10.1109/ICTM.2009.5412899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5412899","classification;feature weight learning;similarity;Cloud Model","Clouds;Electronic equipment testing;Classification algorithms;Entropy;Learning;Weight measurement;Classification tree analysis;Decision trees;Software testing;Software measurement","","","","10","IEEE","17 Feb 2010","","","IEEE","IEEE Conferences"
"SoftMon: A Tool to Compare Similar Open-source Software from a Performance Perspective","S. S. Singh; S. R. Sarangi","Computer Science and Engineering, IIT Delhi; Computer Science, IIT Delhi",2020 IEEE/ACM 17th International Conference on Mining Software Repositories (MSR),"20 Jun 2023","2020","","","397","408","Over the past two decades, a rich ecosystem of open-source software has evolved. For every type of application, there are a wide variety of alternatives. We observed that even if different applications that perform similar tasks and compiled with the same versions of the compiler and the libraries, they perform very differently while running on the same system. Sadly prior work in this area that compares two code bases for similarities does not help us in finding the reasons for the differences in performance. In this paper, we develop a tool, SoftMon, that can compare the codebases of two separate applications and pinpoint the exact set of functions that are disproportionately responsible for differences in performance. Our tool uses machine learning and NLP techniques to analyze why a given open-source application has a lower performance as compared to its peers, design bespoke applications that can incorporate specific innovations (identified by SoftMon) in competing applications, and diagnose performance bugs. In this paper, we compare a wide variety of large open-source programs such as image editors, audio players, text editors, PDF readers, mail clients and even full-fledged operating systems (OSs). In all cases, our tool was able to pinpoint a set of at the most 10–15 functions that are responsible for the differences within 200 seconds. A subsequent manual analysis assisted by our graph visualization engine helps us find the reasons. We were able to validate most of the reasons by correlating them with subsequent observations made by developers or from existing technical literature. The manual phase of our analysis is limited to 30 minutes (tested with human subjects).","2574-3864","978-1-4503-7517-7","10.1145/3379597.3387444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10148752","Software comparison;Performance debugging;NLP based matching","Visualization;Technological innovation;Codes;Operating systems;Manuals;Machine learning;Libraries","","1","","83","","20 Jun 2023","","","IEEE","IEEE Conferences"
"Repulsive Particle Swarm Optimization based on new diversity","Guochao Niu; Baodi Chen; J. Zeng","Software Engineering Institute, Xidian University, Xi'an, China; Complex System and Computational Intelligence Laboratory, Taiyuan University of Science and Technology, Taiyuan, China; Complex System and Computational Intelligence Laboratory, Taiyuan University of Science and Technology, Taiyuan, China",2010 Chinese Control and Decision Conference,"1 Jul 2010","2010","","","815","819","To avoid the problem of premature convergence, a new diversity-guided Particle Swarm Optimizer (PSO), namely MARPSO is proposed, which is a modification of attractive and repulsive PSO (ARPSO), suggested by Riget and Vesterstorm[1]. A novel measure of population diversity function is presented and a new concept of the particle's best flight direction is introduced. The simulation test results of four classic functions show that: compared with Standard PSO (BPSO) and ARPSO, MARPSO can effectively increase the diversity of swarm, while maintain a higher convergence speed.","1948-9447","978-1-4244-5181-4","10.1109/CCDC.2010.5498113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5498113","Particle Swarm Optimization;Population Diversity;Global Search;Particle's Best Flight Direction","Particle swarm optimization;Convergence;Stochastic processes;Computational intelligence;Laboratories;Testing;Software engineering;Particle measurements;Genetic algorithms;Simulated annealing","","","","11","IEEE","1 Jul 2010","","","IEEE","IEEE Conferences"
"How are Deep Learning Models Similar? An Empirical Study on Clone Analysis of Deep Learning Software","X. Wu; L. Qin; B. Yu; X. Xie; L. Ma; Y. Xue; Y. Liu; J. Zhao",University of Science and Technology of China; University of Science and Technology of China; Kyushu University; Nanyang Technological University; Kyushu University; University of Science and Technology of China; Nanyang Technological University; Kyushu University,2020 IEEE/ACM 28th International Conference on Program Comprehension (ICPC),"25 Jul 2023","2020","","","172","183","Deep learning (DL) has been successfully applied to many cuttingedge applications, e.g., image processing, speech recognition, and natural language processing. As more and more DL software is made open-sourced, publicly available, and organized in model repositories and stores (MODEL Zoo, Modeldepot), there comes a need to understand the relationships of these DL models regarding their maintenance and evolution tasks. Although clone analysis has been extensively studied for traditional software, up to the present, clone analysis has not been investigated for DL software. Since DL software adopts the data-driven development paradigm, it is still not clear whether and to what extent the clone analysis techniques of traditional software could be adapted to DL software. In this paper, we initiate the first step on the clone analysis of DL software at three different levels, i.e., source code level, model structural level, and input/output (I/O)-semantic level, which would be a key in DL software management, maintenance and evolution. We intend to investigate the similarity between these DL models from clone analysis perspective. Several tools and metrics are selected to conduct clone analysis of DL software at three different levels. Our study on two popular datasets (i.e., MNIST and CIFAR-10) and eight DL models of five architectural families (i.e., LeNet, ResNet, DenseNet, AlexNet, and VGG) shows that: 1). the three levels of similarity analysis are generally adequate to find clones between DL models ranging from structural to semantic; 2). different measures for clone analysis used at each level yield similar results; 3) clone analysis of one single level may not render a complete picture of the similarity of DL models. Our findings open up several research opportunities worth further exploration towards better understanding and more effective clone analysis of DL software.","2643-7171","978-1-4503-7958-8","10.1145/3387904.3389254","National Natural Science Foundation of China (General Program)(grant numbers:61972373); CAS Pioneer Hundred Talents Program(grant numbers:20H04168,19K24348,19H04086,18H04097); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10186854","Code clone detection;deep learning;model similarity","Deep learning;Analytical models;Source coding;Semantics;Cloning;Speech recognition;Maintenance engineering","","","","67","","25 Jul 2023","","","IEEE","IEEE Conferences"
"Text Data Processing on Non-Functional Requirement for the Similarity Between Requirement Elicitation with Deployment Diagram and Recommendation for SRS Improvement","Z. Zahra; Y. Priyadi","Department of Informatics, Telkom University, Bandung, Indonesia; Department of Software Engineering, Telkom University, Bandung, Indonesia",2023 IEEE World AI IoT Congress (AIIoT),"13 Jul 2023","2023","","","0830","0836","The discrepancy between the developer’s understanding of the client’s wishes in the Software Requirement Specification document is one of the backgrounds in this research. This research uses SRS Baker’s Corner, which is an Android-based cake and pastry product ordering platform. The primary purpose of this research is to process text data on Non-Functional Requirements, where the extraction results can be used as a reference for comparing the suitability between Requirement Elicitation and Deployment Diagram with the text pre-processing method. This research has produced two similarity values, namely between Requirement Elicitation with Non-Functional Requirement and Non-Functional Requirement with Deployment Diagram based on the results of text data extraction in d1-d15. The naming of d1 to d15 is an identity for a text document. The value ""d"" stands for ""document."" In the search process for Requirement Elicitation with Non-Functional Requirement, the cosine similarity value closest to 1 is 0.751304, obtained from d2 and d6. Based on the cosine similarity value, the kappa index value is 0.54488 or has a moderate proportion of agreement, and Gwet’s AC1 value is 0.88041, which has an almost perfect proportion of agreement. In the search process for Non-Functional Requirement with Deployment Diagram, the cosine similarity value, which is relatively high, is 0.604605, which is obtained from d6 and d11. Based on the cosine similarity value, the kappa index value is 0.30845 or has a fair proportion of agreement, and Gwet’s AC1 value is 0.95837, which has an almost perfect proportion of agreement. In addition to producing similarity values, there are improvement recommendations for documents with relatively low kappa index values.","","979-8-3503-3761-7","10.1109/AIIoT58121.2023.10174437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174437","Extraction;Similarity;Requirement Elicitation;Non-Functional Requirement;Deployment Diagram","Operating systems;Data processing;Software;Indexes;Data mining;Artificial intelligence","","1","","23","IEEE","13 Jul 2023","","","IEEE","IEEE Conferences"
"Mobile multimedia antenna systems for station wagons and the achievable diversity effectiveness obtained by analysis of virtual test drives","J. F. Hopf; H. K. Lindenmeier; L. M. Reiter","Faculty for Electrical and Information Engineering, Institute for High Frequency Technology, University of the Bundeswehr, Munich, Germany; Faculty for Electrical and Information Engineering, Institute for High Frequency Technology, University of the Bundeswehr, Munich, Germany; Faculty for Electrical and Information Engineering, Institute for High Frequency Technology, University of the Bundeswehr, Munich, Germany",Radio Science,"9 Dec 2016","2003","38","2","18-1","18-6","For modern cars, antennas are required for AM reception, FM and TV diversity reception, weatherband reception (USA), terrestrial digital radio, remote control functions, keyless entry, mobile phone for all worldwide used systems, GPS, and in the future, satellite broadcast radio services. Those services cover the frequency range from 150 kHz up to 2.4 GHz. Such kind of a multiantenna system developed for station wagons is presented in this paper. The obtainable FM and TV diversity effectiveness is discussed for several types of antenna arrangements in detail. This value is the number of fictitious completely decorrelated antenna signals and is obtained by virtual test drives. The characteristic of the respective antennas under test is introduced in the software as antenna pattern, measured or calculated with respect to amplitude and phase. During the computer analysis the car with the antennas is driven virtually through a Rayleigh field scenario with desired and undesired signals.","1944-799X","","10.1029/2001RS002561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7770212","diversity systems;multiantenna systems;virtual test drives;diversity effectiveness;antennas;station wagons","Automobiles;Mobile antennas;Frequency modulation;Antenna measurements;Mobile communication;Color","","","","","","9 Dec 2016","","","AGU","AGU Journals"
"Growth- and Entropy-Based SOA Measurement: Vision and Approach in a Large Scale Environment","A. Fiegler; R. R. Dumke","Software Engineering Group, Institute for Distributed Systems, Faculty of Computer Science, Otto-von-Guericke University of Magdeburg, Magdeburg, Germany; Software Engineering Group, Institute for Distributed Systems, Faculty of Computer Science, Otto-von-Guericke University of Magdeburg, Magdeburg, Germany",2011 Joint Conference of the 21st International Workshop on Software Measurement and the 6th International Conference on Software Process and Product Measurement,"29 Dec 2011","2011","","","318","322","Service-oriented architectures (SOA) can be considered as an enabling methodology for Cloud Computing and the IT's industrialization, standardization and commodity approach. The efforts to effectively introduce SOA were driven by the evermore increasing complexity and volume of information to be consumed. This paper discusses in this context some major quality characteristics of SOA systems and new measurement approaches, considering complex IT systems and digital ecosystems. This approach is based on growth models related to SOA's reference architecture as well as diversity and entropy. On a field test certain metrics are applied to a real large scale SOA system. As a result some major and important characteristics of the SOA system can be proven and weak structures in services orchestrations exposed.","","978-1-4577-1930-1","10.1109/IWSM-MENSURA.2011.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113080","SOA;Quality;Measurement;Growth Model;Complexity;Diversity;Entropy","Service oriented architecture;Semiconductor optical amplifiers;Entropy;Business;Complexity theory;Biological system modeling","","1","","11","IEEE","29 Dec 2011","","","IEEE","IEEE Conferences"
"GuiDiv: Mitigating Code-reuse Attack in an IoT Cluster Using Guided Control Flow Diversification","Y. Li; Q. Zhou; B. Li; Y. Zhuang","School of Cyber Science and Engineering, Zhengzhou University, Zhengzhou, China; School of Computer and Artificial Intelligence, Zhengzhou University, Zhengzhou, China; School of Computer and Artificial Intelligence, Zhengzhou University, Zhengzhou, China; School of Cyber Science and Engineering, Zhengzhou University, Zhengzhou, China","2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","29 May 2024","2023","","","422","433","Code randomization, aka software diversification, is an effective way to mitigate code-reuse attacks. This mechanism diversifies the target software into heterogeneous variants, making a specific attack chain unfeasible for the transformed variants. Enhancing the heterogeneity of these variants is important for this method to reach its expected security level. Additionally, limiting their execution overhead is necessary to ensure the availability of this protection. However, finding the optimal subset among a large number of diversified variants is computationally difficult. This creates a dilemma in software diversification schema where enhancing heterogeneity and reducing execution overhead are both desired.To ensure a determined code quality control in generating software variants, we propose a guided software diversification mechanism (called GuiDiv). GuiDiv formalizes the iterate-used transformations into a branching process of a tree (called DivTree) and introduces an optimization process (called nodemerging) to guide the diversification. The optimizer evaluates the intermediate compilation results using multi-target evaluation functions in each iteration. This process aims to optimize the contribution of structural heterogeneity from redundant instructions, allowing variants with higher structural dissimilarity and lower overhead to have a higher chance of participating in the next iteration. We developed a proof-of-concept compilation module and used OpenSSL as the performance benchmark. In the evaluations, compared to related schemes, GuiDiv can bring higher control flow dissimilarity in most test cases. Regarding the variant heterogeneity, variants generated by GuiDiv exhibit significantly lower execution overhead.","2324-9013","979-8-3503-8199-3","10.1109/TrustCom60117.2023.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10538815","internet of things;code-reuse attack;code randomization;guided software diversification","Codes;Limiting;Merging;Software algorithms;Quality control;Software;Security","","","","46","IEEE","29 May 2024","","","IEEE","IEEE Conferences"
"RoBin: Facilitating the Reproduction of Configuration-Related Vulnerability","L. Chen; J. Guo; Z. He; D. Mu; B. Mao","National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China","2021 IEEE 20th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","9 Mar 2022","2021","","","91","98","Vulnerability reproduction paves a way in debugging software failures, which need intensive manual efforts. However, some key factors (e.g., software configuration, trigger method) are often missing, so we can not directly reproduce the failure without extra attempts. Even worse, highly customized configuration options of programs create a barrier for reproducing the vulnerabilities that only appear under some specific combinations of configurations. In this paper, we address the problem mentioned above - reproducing the configuration-related vulnerability. We try to solve it by proposing a binary similarity-based method to infer the specific building configurations via the binary from crash report. The main challenges are as follows: precise compilation option inference, program configuration inference, and source-code-to-binary matching. To achieve the goal, we implement RoBin, a binary similarity-based building configuration inference tool. To demonstrate the effectiveness, we test RoBin on 21 vulnerable cases upon 4 well-known open-source programs. It shows a strong ability in pinpointing the building configurations causing the vulnerability. The result can help developers reproduce and diagnose the vulnerability, and finally, patch the programs.","2324-9013","978-1-6654-1658-0","10.1109/TrustCom53373.2021.00030","Chinese National Natural Science Foundation(grant numbers:NSFC 61272078,NSFC 62032010); Fundamental Research Funds for the Central Universities(grant numbers:2020kfyXJJS129); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9724369","Binary Code Similarity;Building Configurations;Reproduction;Vulnerability","Privacy;Conferences;Buildings;Manuals;Debugging;Binary codes;Computer crashes","","3","","23","IEEE","9 Mar 2022","","","IEEE","IEEE Conferences"
"An Optimization Strategy for Evolutionary Testing Based on Cataclysm","M. Wang; B. Li; Z. Wang; X. Xie","School of Computer Science and Engineering, South University, Nanjing, China; School of Computer Science and Engineering, South University, Nanjing, China; Department of Computer Science and Technology, Chuzhou University, Chuzhou, China; School of Computer Science and Engineering, South University, Nanjing, China",2010 IEEE 34th Annual Computer Software and Applications Conference Workshops,"1 Nov 2010","2010","","","359","364","Evolutionary Testing (ET) is an effective test case generation technique which uses some meta-heuristic search algorithm, especially genetic algorithm, to generate test cases automatically. However, the prematurity of the population may decrease the performance of ET. To solve this problem, this paper presents a novel optimization strategy based on cataclysm. It monitors the diversity of population during the evolution process of ET. Once the prematurity is detected, it will use the operator, cataclysm, to recover the diversity of the population. The experimental results show that the proposed strategy can improve the performance of ET evidently.","","978-0-7695-4105-1","10.1109/COMPSACW.2010.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5614562","Evolutionary Testing;premature;cataclysm;diversity measure","Testing;Thigh;Optimization;Gallium;Monitoring;Genetic algorithms;Genetics","","2","","12","IEEE","1 Nov 2010","","","IEEE","IEEE Conferences"
"Harnessing Web-Based Application Similarities to Aid in Regression Testing","K. Dobolyi; W. Weimer","Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA",2009 20th International Symposium on Software Reliability Engineering,"28 Dec 2009","2009","","","71","80","Web-based applications are growing in complexity and criticality, increasing the need for their precise validation. Regression testing is an established approach for providing information about the quality of an application in the face of recurring updates that dominate the web. We present techniques to address a key challenge of the automated regression testing of web-based applications. Innocuous program evolutions often appear to fail tests and must be manually inspected. We rely on inherent similarities between independent web-based applications to provide fully automated solutions for reducing the number of false positives associated with regression testing such applications, simultaneously focusing on returning all true positives. Our approach predicts which test cases merit human inspection by applying a model derived from regression testing other programs. We are 2.5 to 50 times as accurate as current industrial practice, but require no user annotations.","2332-6549","978-1-4244-5375-7","10.1109/ISSRE.2009.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362085","regression;testing;web application","Automatic testing;Application software;HTML;Humans;Predictive models;Costs;Automation;XML;Training data;Software reliability","","9","1","39","IEEE","28 Dec 2009","","","IEEE","IEEE Conferences"
"Test Migration Between Mobile Apps with Similar Functionality","F. Behrang; A. Orso","Georgia Institute of Technology, Atlanta, USA; Georgia Institute of Technology, Atlanta, USA",2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE),"9 Jan 2020","2019","","","54","65","The use of mobile apps is increasingly widespread, and much effort is put into testing these apps to make sure they behave as intended. To reduce this effort, and thus the overall cost of mobile app testing, we propose APPTESTMIGRATOR, a technique for migrating test cases between apps in the same category (e.g., banking apps). The intuition behind APPTESTMIGRATOR is that many apps share similarities in their functionality, and these similarities often result in conceptually similar user interfaces (through which that functionality is accessed). APPTESTMIGRATOR leverages these commonalities between user interfaces to migrate existing tests written for an app to another similar app. Specifically, given (1) a test case for an app (source app) and (2) a second app (target app), APPTESTMIGRATOR attempts to automatically transform the sequence of events and oracles in the test for the source app to events and oracles for the target app. We implemented APPTESTMIGRATOR for Android mobile apps and evaluated it on a set of randomly selected apps from the Google Play Store in four different categories. Our initial results are promising, support our intuition that test migration is possible, and motivate further research in this direction.","2643-1572","978-1-7281-2508-4","10.1109/ASE.2019.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952387","Test migration, GUI testing, mobile apps","Graphical user interfaces;Mobile applications;Testing;Instruments;Banking;Google","","40","","34","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"CSSM: A Context-Based Semantic Similarity Measure","A. Yousfi; M. H. El Yazidi; A. Zellou","Software Project Management Research Team, École Nationale Supérieure d’Informatique et d’Analyse des Systèmes (ENSIAS), Mohammed V University, Rabat, Morocco; Software Project Management Research Team, École Nationale Supérieure d’Informatique et d’Analyse des Systèmes (ENSIAS), Mohammed V University, Rabat, Morocco; Software Project Management Research Team, École Nationale Supérieure d’Informatique et d’Analyse des Systèmes (ENSIAS), Mohammed V University, Rabat, Morocco","2020 IEEE 2nd International Conference on Electronics, Control, Optimization and Computer Science (ICECOCS)","14 Jan 2021","2020","","","1","6","Semantic similarity is very critical in applications that manipulate data across heterogeneous, autonomous and distributed data sources. It helps connect these data sources. Nevertheless, current semantic similarity approaches were proven to achieve a very moderate accuracy. Furthermore, they are merely applicable when we wish to determine the semantic similarity between words. In this paper, we present CSSM, a Context-based Semantic Similarity Measure. Experimental results on Miller & Charles benchmark dataset show that CSSM performs semantic similarity comparisons properly, and obtains high accuracy.","","978-1-7281-6921-7","10.1109/ICECOCS50124.2020.9314376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9314376","Semantic similarity;Similarity measures;Dis-similarity distances","Semantics;Integrated circuits;Distributed databases;Current measurement;Benchmark testing;Web sites;Warehousing","","2","","22","IEEE","14 Jan 2021","","","IEEE","IEEE Conferences"
"A Lightweight Cross-Version Binary Code Similarity Detection Based on Similarity and Correlation Coefficient Features","H. Guo; S. Huang; C. Huang; M. Zhang; Z. Pan; F. Shi; H. Huang; D. Hu; X. Wang","College of Electronics Engineering, National University of Defense Technology, Hefei, China; College of Electronics Engineering, National University of Defense Technology, Hefei, China; College of Cybersecurity, Sichuan University, Chengdu, China; College of Electronics Engineering, National University of Defense Technology, Hefei, China; College of Electronics Engineering, National University of Defense Technology, Hefei, China; College of Electronics Engineering, National University of Defense Technology, Hefei, China; College of Electronics Engineering, National University of Defense Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; College of Electronics Engineering, National University of Defense Technology, Hefei, China",IEEE Access,"8 Jul 2020","2020","8","","120501","120512","The technique of binary code similarity detection (BCSD) has been applied in many fields, such as malware detection, plagiarism detection and vulnerability search, etc. Existing solutions for the BCSD problem usually compare specific features between binaries based on the control flow graphs of functions from binaries or compute the embedding vector of binary functions and solve the problem based on deep learning algorithms. In this paper, from another research perspective, we propose a new and lightweight method to solve cross-version BCSD problem based on multiple features. It transforms binary functions into vectors and signals and computes the similarity coefficient value and correlation coefficient value for solving cross-version BCSD problem. Without relying on the CFG of functions, deep learning algorithms and other related attributes, our method works directly on the raw bytes of each binary and it can be used as an alternative method to coping with various complex situations that exist in the real-world environment. We implement the method and evaluate it on a custom dataset with about 423,282 samples. The result shows that the method could perform well in cross-version BCSD field, and the recall of our method could reach 96.63%, which is almost the same as the state-of-the-art static solution.","2169-3536","","10.1109/ACCESS.2020.3004813","Laboratory of Network Security, College of Electronics Engineering, National University of Defense Technology; Provincial Natural Science Foundation of Anhui(grant numbers:1908085QF291); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9125913","Binary code similarity detection;cross-version binary;malware detection;similarity coefficient;correlation coefficient","Feature extraction;Binary codes;Deep learning;Malware;Correlation;Semantics;Correlation coefficient","","8","","29","CCBY","25 Jun 2020","","","IEEE","IEEE Journals"
"Detect Similar Mobile Applications with Transfer Learning","N. Bu; L. Yu; W. Ma; C. Du; S. Niu; G. Long","Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences",2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity),"5 May 2016","2015","","","856","859","Recent years have witnessed the fast growth of the use of the mobile applications (a.k.a. ""apps""). Detecting similar apps is a basic problem in the app ecosystem. It is not only beneficial to app search and recommender systems, but also helpful for people to discover new apps. State-of-the-art studies defined several app similarity functions by the metainformation of apps, such as descriptions and reviews, and succeeded to apply it to apps from Google Play. There do exist some app stores that provide similar app lists when people search. Obviously such similarity relation information will help improve similar app recommendation in app stores where app recommendation is of poor quality or even does not exist. However few methods take the existing similarity relations between apps from different app stores into consideration. Our approach attempts to use such relation information to learn a new app similarity function from these stores, and combine this new function with existing functions defined from meta-information of apps. With transfer learning, our proposed similarity function can be used in app stores where no similar apps are presented. Empirical results on Chinese app data sets show that our method outperforms the state-of-the-art method significantly.","","978-1-5090-1893-2","10.1109/SmartCity.2015.175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463830","Mobile Application;Similarity Function;Recommendation","Kernel;Training;Mobile applications;Training data;Recommender systems;Google","","1","","5","IEEE","5 May 2016","","","IEEE","IEEE Conferences"
"Using Diversity to Harden Multithreaded Programs Against Exploitation","D. M. Tagatac; M. Polychronakis; S. J. Stolfo","Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Stony Brook University, Stony Brook, NY, USA","2016 IEEE 2nd International Conference on Big Data Security on Cloud (BigDataSecurity), IEEE International Conference on High Performance and Smart Computing (HPSC), and IEEE International Conference on Intelligent Data and Security (IDS)","4 Jul 2016","2016","","","208","213","Multithreaded programming is here to stay, and concurrency bugs are the focus of a growing number of cyberattacks. While most defensive efforts against such attacks seek to identify bugs during debugging, an alternative method seeks to make exploitation harder without the need to first identify the bugs -- or even the fact that there are any. Time randomization introduces more diversity among instances of the same software. In much the same way that ASLR-induced diversity in memory locations thwarts attacks crafted for specific addresses, time randomization-induced diversity in thread timing aims to thwart concurrency attacks crafted for specific vulnerability windows. We study three implementations of time randomization, all using the injection of NOPs to alter program timing. Their application to two real-world concurrency bugs results in a marked increase in the cost to exploit those bugs. After demonstrating the effectiveness of the method, especially when NOPs are injected before library function calls following synchronization points, methods for improving the efficiency of this defense against concurrency attacks in future research are proposed.","","978-1-5090-2403-2","10.1109/BigDataSecurity-HPSC-IDS.2016.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502291","time randomization;concurrency bugs;software diversity","Concurrent computing;Libraries;Software;Delays;Computer bugs;Synchronization","","","","27","IEEE","4 Jul 2016","","","IEEE","IEEE Conferences"
"Revisiting Binary Code Similarity Analysis Using Interpretable Feature Engineering and Lessons Learned","D. Kim; E. Kim; S. K. Cha; S. Son; Y. Kim","KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea",IEEE Transactions on Software Engineering,"18 Apr 2023","2023","49","4","1661","1682","Binary code similarity analysis (BCSA) is widely used for diverse security applications, including plagiarism detection, software license violation detection, and vulnerability discovery. Despite the surging research interest in BCSA, it is significantly challenging to perform new research in this field for several reasons. First, most existing approaches focus only on the end results, namely, increasing the success rate of BCSA, by adopting uninterpretable machine learning. Moreover, they utilize their own benchmark, sharing neither the source code nor the entire dataset. Finally, researchers often use different terminologies or even use the same technique without citing the previous literature properly, which makes it difficult to reproduce or extend previous work. To address these problems, we take a step back from the mainstream and contemplate fundamental research questions for BCSA. Why does a certain technique or a certain feature show better results than the others? Specifically, we conduct the first systematic study on the basic features used in BCSA by leveraging interpretable feature engineering on a large-scale benchmark. Our study reveals various useful insights on BCSA. For example, we show that a simple interpretable model with a few basic features can achieve a comparable result to that of recent deep learning-based approaches. Furthermore, we show that the way we compile binaries or the correctness of underlying binary analysis tools can significantly affect the performance of BCSA. Lastly, we make all our source code and benchmark public and suggest future directions in this field to help further research.","1939-3520","","10.1109/TSE.2022.3187689","Institute of Information & Communications Technology Planning & Evaluation(grant numbers:2021-0-01332); Developing Next-Generation Binary Decompiler; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9813408","Binary code similarity analysis;similarity measures;feature evaluation and selection;benchmark","Benchmark testing;Computer architecture;Binary codes;Syntactics;Semantics;Licenses;Market research","","20","","166","CCBY","1 Jul 2022","","","IEEE","IEEE Journals"
"Quickly Generating Diverse Valid Test Inputs with Reinforcement Learning","S. Reddy; C. Lemieux; R. Padhye; K. Sen","University of California, Berkeley, USA; University of California, Berkeley, USA; University of California, Berkeley, USA; University of California, Berkeley, USA",2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE),"21 Dec 2020","2020","","","1410","1421","Property-based testing is a popular approach for validating the logic of a program. An effective property-based test quickly generates many diverse valid test inputs and runs them through a parameterized test driver. However, when the test driver requires strict validity constraints on the inputs, completely random input generation fails to generate enough valid inputs. Existing approaches to solving this problem rely on whitebox or greybox information collected by instrumenting the input generator and/or test driver. However, collecting such information reduces the speed at which tests can be executed. In this paper, we propose and study a black-box approach for generating valid test inputs. We first formalize the problem of guiding random input generators towards producing a diverse set of valid inputs. This formalization highlights the role of a guide which governs the space of choices within a random input generator. We then propose a solution based on reinforcement learning (RL), using a tabular, on-policy RL approach to guide the generator. We evaluate this approach, RLCheck, against pure random input generation as well as a state-of-the-art greybox evolutionary algorithm, on four real-world benchmarks. We find that in the same time budget, RLCheck generates an order of magnitude more diverse valid inputs than the baselines.","1558-1225","978-1-4503-7121-6","","Samsung; Facebook; Fujitsu; NSF(grant numbers:CCF-1900968,CCF-1908870,CNS-1817122); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284117","","Monte Carlo methods;Instruments;Reinforcement learning;Evolutionary computation;Benchmark testing;Generators;Software engineering","","2","","50","","21 Dec 2020","","","IEEE","IEEE Conferences"
"An adaptive diversity strategy for particle swarm optimization","Fang Wang; Naiqin Feng; Yuhui Qiu","Intelligent Software and Software Engineering Laboratory, Southwest University, Chongqing, China; Intelligent Software and Software Engineering Laboratory, Southwest University, Chongqing, China; Intelligent Software and Software Engineering Laboratory, Southwest University, Chongqing, China",2005 International Conference on Natural Language Processing and Knowledge Engineering,"27 Feb 2006","2005","","","760","764","In this paper, we present a diversity strategy for particle swarm optimizer. The modified algorithm re-initializes part of particles with poorer fitness during the searching process. It is empirically tested and compared with other published methods on many famous benchmark functions. The experimental results illustrate that the proposed algorithm has the potential to achieve higher success ratio and better solution quality. It is very competitive for hard multimodal function optimization.","","0-7803-9361-9","10.1109/NLPKE.2005.1598838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1598838","","Particle swarm optimization;Software engineering;Laboratories;Benchmark testing;Birds;Optimization methods;Genetic engineering;Genetic algorithms;Convergence;Stochastic processes","","3","","14","IEEE","27 Feb 2006","","","IEEE","IEEE Conferences"
"Preparing for the Unexpected: Diversity Improves Planning Resilience in Evolutionary Algorithms","T. Gabor; L. Belzner; T. Phan; K. Schmid",LMU Munich; Maiborn Wolff; LMU Munich; LMU Munich,2018 IEEE International Conference on Autonomic Computing (ICAC),"21 Oct 2018","2018","","","131","140","As automatic optimization techniques find their way into industrial applications, the behavior of many complex systems is determined by some form of planner picking the right actions to optimize a given objective function. In many cases, the mapping of plans to objective reward may change due to unforeseen events or circumstances in the real world. In those cases, the planner usually needs some additional effort to adjust to the changed situation and reach its previous level of performance. Whenever we still need to continue polling the planner even during re-planning, it oftentimes exhibits severely lacking performance. In order to improve the planner's resilience to unforeseen change, we argue that maintaining a certain level of diversity amongst the considered plans at all times should be added to the planner's objective. Effectively, we encourage the planner to keep alternative plans to its currently best solution. As an example case, we implement a diversity-aware genetic algorithm using two different metrics for diversity (differing in their generality) and show that the blow in performance due to unexpected change can be severely lessened in the average case. We also analyze the parameter settings necessary for these techniques in order to gain an intuition how they can be incorporated into larger frameworks or process models for software and systems engineering.","2474-0756","978-1-5386-5139-1","10.1109/ICAC.2018.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8498134","planning;resilience;robustness;self-protection;self-healing;diversity;optimization;evolutionary algorithms;unexpected events;dynamic fitness","Resilience;Planning;Optimization;Robustness;Production facilities;Evolutionary computation;Software","","6","","48","IEEE","21 Oct 2018","","","IEEE","IEEE Conferences"
"Downsized testers use diverse new technologies","J. Eidnes","Military Avionics Division, Honeywell, Inc., MN, USA",AUTOTESTCON 93,"6 Aug 2002","1993","","","585","590","Several diverse new technologies were brought together during the development of two downsized testers for the F-16 Central Air Data Computer. The small size, clean design, and ease of operation produced as a result of this project illustrated the effectiveness of integrating these new technologies into a single system. This paper discusses changes in the test station development process that were brought about by these new technologies.<>","","0-7803-0646-5","10.1109/AUTEST.1993.396304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=396304","","Hardware;Instruments;Military computing;Central air conditioning;Software testing;Microcomputers;Aerospace electronics;Software systems;Buildings;System testing","","","","1","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"CoMSS: Context based measure for semantic similarity between conceptual models","E. A. Kaundal; A. Kaur","Department of Computer Science Engineering, Chandigarh University, Gharuan, Punjab, India; Department of Computer Science Engineering, Chandigarh University, Gharuan, Punjab, India",2017 International Conference on Intelligent Computing and Control Systems (ICICCS),"11 Jan 2018","2017","","","1080","1088","Artifacts are defined as the tools which act as building block for developing a software or project. Artifacts are of several kinds like UML and BPMN. The overall connotation of the document in SDLC is combination of sensible or significant words represented in the form of different artifacts. In this approach main focus is on the precision of the documents or artifacts developed by requirement analysts. This phase is purely personal opinion oriented, later on which may cause rejection of the software during acceptance testing. Our aim is to preserve the overall meaning of the document that's why we compare the class diagram (conceptual model) with BPMN so that the meaning of the requirements provided by the stakeholders should be preserved in both forms of artifacts. The word specificity and word semantics plays vital role in assessing the semantic similarity between the two artifacts. In this paper the frequency (word specificity) is calculated between the vectors with the help of TF-IDF and the semantic similarity between the vectors is calculated with the help of WordNet algorithms. The proposed similarity measures are evaluated in divergent context, the benchmark dataset i.e SemEval (Semantic Evaluation) 2012 Semantic Textual Similarity test set, competition organized in 2012. Three standard case studies are used to evaluate the semantic similarity between the artifacts named as Rambaugh's ATM Model (Rambaugh et al. 1991), EFP (Kurt, 1995), Course Registration (IBM Corp, 2004).","","978-1-5386-2745-7","10.1109/ICCONS.2017.8250633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8250633","Natural language processing;Vector space model;WordNet;Sentence similarity;CoMSS;TF-IDF;Semantic similarity;Knowledge Based systems;Information Retrieval","Semantics;Computational modeling;Software;Analytical models;Unified modeling language;Online banking;Control systems","","","","18","IEEE","11 Jan 2018","","","IEEE","IEEE Conferences"
"A Quantitative Analysis Framework for Recurrent Neural Network","X. Du; X. Xie; Y. Li; L. Ma; Y. Liu; J. Zhao","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Kyushu University, Japan; Nanyang Technological University, Singapore; Kyushu University, Japan",2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE),"9 Jan 2020","2019","","","1062","1065","Recurrent neural network (RNN) has achieved great success in processing sequential inputs for applications such as automatic speech recognition, natural language processing and machine translation. However, quality and reliability issues of RNNs make them vulnerable to adversarial attacks and hinder their deployment in real-world applications. In this paper, we propose a quantitative analysis framework - DeepStellar - to pave the way for effective quality and security analysis of software systems powered by RNNs. DeepStellar is generic to handle various RNN architectures, including LSTM and GRU, scalable to work on industrial-grade RNN models, and extensible to develop customized analyzers and tools. We demonstrated that, with DeepStellar, users are able to design efficient test generation tools, and develop effective adversarial sample detectors. We tested the developed applications on three real RNN models, including speech recognition and image classification. DeepStellar outperforms existing approaches three hundred times in generating defect-triggering tests and achieves 97% accuracy in detecting adversarial attacks. A video demonstration which shows the main features of DeepStellar is available at: https://sites.google.com/view/deepstellar/tool-demo.","2643-1572","978-1-7281-2508-4","10.1109/ASE.2019.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952565","recurrent neural netwrod;model abstraction;quantitative analysis;similarity metrics;coverage criteria","Testing;Tools;Training data;Statistical analysis;Recurrent neural networks;Security;Computer architecture","","5","","18","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"An empirical study on reliability modeling for diverse software systems","Xia Cai; M. R. Lyu","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, China",15th International Symposium on Software Reliability Engineering,"24 Jan 2005","2004","","","125","136","Reliability and fault correlation are two main concerns for design diversity, yet empirical data are limited in investigating these two. In previous work, we conducted a software project with real-world application for investigation on software testing and fault tolerance for design diversity. Mutants were generated by injecting one single real fault recorded in the software development phase to the final versions. In this paper, we perform more analysis and experiments on these mutants to evaluate and investigate the reliability features in diverse software systems. We apply our project data on two different reliability models and estimate the reliability bounds for evaluation purpose. We also parameterize fault correlations to predict the reliability of various combinations of versions, and compare three different fault-tolerant software architectures.","1071-9458","0-7695-2215-7","10.1109/ISSRE.2004.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383112","","Software systems;Fault tolerance;Application software;Reliability engineering;Software testing;Aerospace electronics;Computer science;Data engineering;Design engineering;Programming","","3","","21","IEEE","24 Jan 2005","","","IEEE","IEEE Conferences"
"Learning from Open-Source Projects: An Empirical Study on Defect Prediction","Z. He; F. Peters; T. Menzies; Y. Yang","University of Chinese Academy of Sciences, Beijing, China; Lane Department of CS & EE, West Virginia University, Morgantown, USA; Lane Department of CS & EE, West Virginia University, Morgantown, USA; Lab for Internet Software Technology, Institute of Software Chinese Academy of Sciences, Beijing, China",2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement,"12 Dec 2013","2013","","","45","54","The fundamental issue in cross project defect prediction is selecting the most appropriate training data for creating quality defect predictors. Another concern is whether historical data of open-source projects can be used to create quality predictors for proprietary projects from a practical point-of-view. Current studies have proposed statistical approaches to finding these training data, however, thus far no apparent effort has been made to study their success on proprietary data. Also these methods apply brute force techniques which are computationally expensive. In this work we introduce a novel data selection procedure which takes into account the similarities between the distribution of the test and potential training data. Additionally we use feature subset selection to increase the similarity between the test and training sets. Our procedure provides a comparable and scalable means of solving the cross project defect prediction problem for creating quality defect predictors. To evaluate our procedure we conducted empirical studies with comparisons to the within company defect prediction and a relevancy filtering method. We found that our proposed method performs relatively better than the filtering method in terms of both computation cost and prediction performance.","1949-3789","978-0-7695-5056-5","10.1109/ESEM.2013.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681337","software defect prediction;cross-project;instance selection;feature subset selection;data similarity","Open source software;Training data;Predictive models;Data models;Training;Filtering","","89","","33","IEEE","12 Dec 2013","","","IEEE","IEEE Conferences"
"ASSD: Arabic Semantic Similarity Dataset","B. Dahy; M. Farouk; K. Fathy","Department of Computer Science, Faculty of Computers and Information (of Assiut University), Assiut, Egypt; Department of Computer Science, Faculty of Computers and Information (of Assiut University), Assiut, Egypt; Department of Computer Science, Faculty of Computers and Information (of Assiut University), Assiut, Egypt","2021 9th International Japan-Africa Conference on Electronics, Communications, and Computations (JAC-ECC)","3 Feb 2022","2021","","","130","134","Finding semantic similarity between sentences is very useful in many NLP applications, such as information retrieval, plagiarism detection, information extraction, and machine translation. Limitations in Arabic language resources have led to a poor level of research in Arabic sentence similarity. This challenge makes identifying semantically similar sentences in Arabic even more difficult. This paper presents a new Arabic dataset for the sentence similarity task. This dataset can be used to help develop sentence similarity approaches. In addition, the main purpose of the created dataset is to evaluate the sentence similarity approach. The dataset has been collected from Wikipedia, an intermediate lexicon, and other WWW resources. This paper gives more details about the processes of collecting data, filtering, preprocessing the pairs of sentences and some statistics about the dataset, for building a benchmark for semantic textual similarity. The dataset is available for future research in this field. The experiment shows that the created dataset is an efficient tool for evaluating semantic similarity approaches for the Arabic language.","","978-1-6654-8292-9","10.1109/JAC-ECC54461.2021.9691424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9691424","Arabic Dataset;Arabic Semantic Similarity;Arabic Sentences Similarity;Arabic Word Similarity","Filtering;Plagiarism;Semantics;Buildings;Encyclopedias;Benchmark testing;Internet","","1","","44","IEEE","3 Feb 2022","","","IEEE","IEEE Conferences"
"Classification of Non-Functional Requirements Using Fuzzy Similarity KNN Based on ISO / IEC 25010","I. M. S. Raharja; D. O. Siahaan","Informatics Department, Institut Teknologi Sepuluh Nopember, Indonesia; Informatics Department, Institut Teknologi Sepuluh Nopember, Indonesia",2019 12th International Conference on Information & Communication Technology and System (ICTS),"30 Sep 2019","2019","","","264","269","In developing software, one of the important role is non-functional requirements. They are often forgotten by the developer, so that it causes adverse effects. For this reason, a non-functional requirement classification method is needed to make it easier for software developers to classify non-functional requirements from requirement document. Most of studies in this area are focusing on single label classification. However, a non-functional requirement sentence can be classified to more than one class. Therefore, a classification technique that support multi-labels was needed. This research proposes a model for classifying non-functional requirements into quality aspects based on ISO/IEe 25010. It uses Fuzzy Similarity KNN (FSKNN) for building the sentence-based classification model. Six difference dataset which is contain 1432 sentence is used in the test. Best accuracy, precision and recall value from classification using FSKNN respectively is 42.8%, 68.1%, and 55.9%.","","978-1-7281-2133-8","10.1109/ICTS.2019.8850944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8850944","Non-Functional Requirements;Classification;FSKNN;ISO /IEC 25010","ISO Standards;Software quality;IEC Standards;Training data;Mathematical model","","9","","17","IEEE","30 Sep 2019","","","IEEE","IEEE Conferences"
"A lightweight software control system for cyber awareness and security","M. Co; C. L. Coleman; J. W. Davidson; S. Ghosh; J. D. Hiser; J. C. Knight; A. Nguyen-Tuong","Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA",2009 2nd International Symposium on Resilient Control Systems,"18 Sep 2009","2009","","","19","24","Designing and building software that is free of defects that can be exploited by malicious adversaries is a difficult task. Despite extensive efforts via the application of formal methods, use of automated software engineering tools, and performing extensive pre-deployment testing, exploitable errors still appear in software. The problem of cyber resilience is further compounded by the growing sophistication of adversaries who can marshal substantial resources to compromise systems. This paper describes a novel, promising approach to improving the resilience of software. The approach is to impose a process-level software control system that continuously monitors an application for signs of attack or failure and responds accordingly. The system uses software dynamic translation to seamlessly insert arbitrary sensors and actuators into an executing binary. The control system employs the sensors to detect attacks and the actuators to effect an appropriate response. Using this approach, several novel monitoring and response systems have been developed. The paper describes our light-weight process-level software control system, our experience using it to increase the resilience of systems, and discusses future research directions for extending and enhancing this powerful approach to achieving cyber awareness and resilience.","","978-1-4244-4853-1","10.1109/ISRCS.2009.5251353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5251353","Virtual Execution;Software Dynamic Translation;Cyber Security;Cyber Awareness;Diversity;Randomization","Software systems;Lighting control;Control systems;Computer security;Resilience;Application software;Process control;Sensor systems;Actuators;Automatic control","","1","","15","IEEE","18 Sep 2009","","","IEEE","IEEE Conferences"
"A semantic similarity retrieval model based on Lucene","Y. Zhou; X. Wu; R. Wang","School of Computer Science and Engineering, Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Engineering, Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Engineering, Guilin University of Electronic Technology, Guilin, China",2014 IEEE 5th International Conference on Software Engineering and Service Science,"23 Oct 2014","2014","","","854","858","In recent years, more and more users hope the search results can meet human's demand when they use a search engine. On the basis of analysis and study on the open source Lucene system architecture, a semantic search system is designed based on the special XML data sources in this paper. What's more, we use the word item location and word semantic to improve the Lucene's search results and conduct experiments to test and verify the retrieval performance, the accuracy of similarity search, the space efficiency of index and the time-efficiency of supporting inquiry: And finally by deploying the Tomcat server to implement our implement system. The experiment results prove that compared with the original Lucene indexing system, our system can improve the indexing efficiency, query efficiency and accuracy.","2327-0594","978-1-4799-3279-5","10.1109/ICSESS.2014.6933700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933700","Lucene;similarity;lexical item location;semantic;XML","Semantics;XML;Search engines;Algorithm design and analysis;Accuracy;Indexing","","2","","9","IEEE","23 Oct 2014","","","IEEE","IEEE Conferences"
"An experimental evaluation of the assumption of independence in multiversion programming","J. C. Knight; N. G. Leveson","Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of California, Irvine, CA, USA",IEEE Transactions on Software Engineering,"26 Sep 2012","1986","SE-12","1","96","109","N-version programming has been proposed as a method of incorporating fault tolerance into software. Multiple versions of a program (i.e. `N') are prepared and executed in parallel. Their outputs are collected and examined by a voter, and, if they are not identical, it is assumed that the majority is correct. This method depends for its reliability improvement on the assumption that programs that have been developed independently will fail independently. An experiment is described in which the fundamental axiom is tested. In all, 27 versions of a program were prepared independently from the same specification at two universities and then subjected to one million tests. The results of the tests revealed that the programs were individually extremely reliable but that the number of tests in which more than one program failed was substantially more than expected. The results of these tests are presented along with an analysis of some of the faults that were found in the programs. Background information on the programmers used is also summarized.","1939-3520","","10.1109/TSE.1986.6312924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6312924","Design diversity;fault-tolerant software;multiversion programming;N-version programming;software reliability","Programming;Software;Educational institutions;Software reliability;NASA","","495","1","","IEEE","26 Sep 2012","","","IEEE","IEEE Journals"
"An experiment in software redundancy with diverse methodologies","J. M. Adams; A. Taha","Department of Computer Science, New Mexico State University, USA; Department of Computer Science, New Mexico State University, USA",Proceedings of the Twenty-Fifth Hawaii International Conference on System Sciences,"6 Aug 2002","1992","ii","","83","90 vol.2","The goal of this experiment was to study the possibility of achieving highly reliable software using an approach to software redundancy with diverse methodologies. The experiment was similar to an experiment done by Knight and Leveson (1986) except that two different programming methodologies were used. Data from the experiment were analyzed using the simple statistical model for multiversion programming developed by Knight and Leveson and the more sophisticated statistical model of Eckhardt and Lee (1985), to see if results were consistent with the previous results for a single methodology. A still more sophisticated statistical model due to Littlewood and Miller (1989) was used to assess the effectiveness of using diverse methodologies.<>","","0-8186-2420-5","10.1109/HICSS.1992.183280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=183280","","Redundancy;Software safety;Computer languages;Software algorithms;Logic programming;Programming profession;Testing;Reflection;Computer science;Algorithm design and analysis","","4","","7","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Bug Detection Using Particle Swarm Optimization with Search Space Reduction","A. Reungsinkonkarn; P. Apirukvorapinit","Department of Computer Information System, Assumption University; Faculty of Information Technology, Thai-Nichi Institute of Technology","2015 6th International Conference on Intelligent Systems, Modelling and Simulation","29 Oct 2015","2015","","","53","57","A bug detection tool is an important tool in software engineering development. Many research papers have proposed techniques for detecting software bug, but there are certain semantic bugs that are not easy to detect. In our views, a bug can occur from incorrect logics that when a program is executed with a particular input, the program will behave in unexpected ways. In this paper, we propose a method and tool for software bugs detection by finding such input that causes an unexpected output guided by the fitness function. The method uses a Hierarchical Similarity Measurement Model (HSM) to help create the fitness function to examine a program behavior. Its tool uses Particle Swarm Optimization (PSO) with Search Space Reduction (SSR) to manipulate input by contracting and eliminating unfavorable areas of input search space. The programs under experiment were selected from four different domains such as financial, decision support system, algorithms and machine learning. The experimental result shows a significant percentage of success rate up to 93% in bug detection, compared to an estimated success rate of 28% without SSR.","2166-0670","978-1-4799-8258-5","10.1109/ISMS.2015.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7311209","Bug Detection;Fitness Function;Hierarchical Similarity Measurement Model (HSM);Particle Swarm Optimization (PSO);Optimization","Computer bugs;Software;Complexity theory;Particle swarm optimization;Computational modeling;Atmospheric measurements;Particle measurements","","6","","15","IEEE","29 Oct 2015","","","IEEE","IEEE Conferences"
"Polarization angle diversity and new digital software radio architecture","M. Aono; K. Takei","Department of Energy management system, Hitachi Research Laboratory, Hitachi-shi, Ibaraki-ken, Japan; Department of Energy management system, Hitachi Research Laboratory, Hitachi-shi, Ibaraki-ken, Japan","2015 International Conference on Circuits, Power and Computing Technologies [ICCPCT-2015]","16 Jul 2015","2015","","","1","3","We are developing new radio architecture for applying a wireless communication system to controlling and monitoring systems in industrial infrastructure systems. Using polarization angle diversity, we can achieve reliable communication in a non line-of-sight situation. To realize polarization angle diversity, we use a rotating polarized radio wave. When we use polarization angle diversity, we need to control radio frequencies more easily. New software radio architecture create radio frequency in a digital circuit directly. It has a possibility to control a rotating polarization radio wave. And by experiment, I show a result of basic communication test and confirm its functions.","","978-1-4799-7075-9","10.1109/ICCPCT.2015.7159299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7159299","M2M radio;block coding;polarization diversity","Computer architecture;Wireless communication;Digital circuits;Software radio;Hardware;Field programmable gate arrays;Mixers","","2","","3","IEEE","16 Jul 2015","","","IEEE","IEEE Conferences"
"A Source Code Similarity System for Plagiarism Detection","Z. Đurić; D. Gašević",NA; NA,The Computer Journal,"18 Jan 2018","2013","56","1","70","86","Source code plagiarism is an easy to do task, but very difficult to detect without proper tool support. Various source code similarity detection systems have been developed to help detect source code plagiarism. Those systems need to recognize a number of lexical and structural source code modifications. For example, by some structural modifications (e.g. modification of control structures, modification of data structures or structural redesign of source code) the source code can be changed in such a way that it almost looks genuine. Most of the existing source code similarity detection systems can be confused when these structural modifications have been applied to the original source code. To be considered effective, a source code similarity detection system must address these issues. To address them, we designed and developed the source code similarity system for plagiarism detection. To demonstrate that the proposed system has the desired effectiveness, we performed a well-known conformism test. The proposed system showed promising results as compared with the JPlag system in detecting source code similarity when various lexical or structural modifications are applied to plagiarized code. As a confirmation of these results, an independent samples t-test revealed that there was a statistically significant difference between average values of F-measures for the test sets that we used and for the experiments that we have done in the practically usable range of cut-off threshold values of 35–70%.","1460-2067","","10.1093/comjnl/bxs018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8226597","algorithms;plagiarism;similarity detection;software;source code","","","21","","","","18 Jan 2018","","","OUP","OUP Journals"
"Automated software diversity for hardware fault detection","G. Gaiswinkler; A. Gerstinger","Elektrobit Austria GmbH, Vienna, Austria; Institute of Computer Technology, University of Technology, Vienna, Vienna, Austria",2009 IEEE Conference on Emerging Technologies & Factory Automation,"4 Dec 2009","2009","","","1","7","Software in dependable systems must be able to tolerate or detect faults in the underlying infrastructure, such as the hardware. This paper presents a cost efficient automated method how register faults in the microprocessor can be detected during execution. This is done with the help of using compiler options to generate diverse binaries. The efficacy of this approach has been analyzed with the help of a CPU emulator, which was modified exactly for this purpose. The promising results show, that by using this approach, it is possible to automatically detect the vast majority of the injected register faults. In our simulations, two diverse versions have-despite of experiencing the same fault during execution - never delivered the same incorrect result, so we could detect all injected faults.","1946-0759","978-1-4244-2727-7","10.1109/ETFA.2009.5347167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5347167","","Hardware;Fault detection;Testing;Program processors;Application software;Microprocessors;Registers;Optimizing compilers;Optimization methods;Software systems","","10","","10","IEEE","4 Dec 2009","","","IEEE","IEEE Conferences"
"Alternatives to achieve software diversity in common channel signaling networks","N. L. Hung; A. R. Jacob; S. E. Makris","Bellcores Raritan River Software, USA; Bellcores Navesink Research and Engineering Center, Red Bank, NJ, USA; Bellcores Navesink Research and Engineering Center, Red Bank, NJ, USA",IEEE Journal on Selected Areas in Communications,"6 Aug 2002","1994","12","3","533","538","With the increasing amount of software deployed in the common channel signaling networks (CCSNs) and its increasing complexity, software and its failure effects on the CCSNs have become a major concern. The software error contributing to the 1991 CCSN outages, which affected a large number of customer lines, has underscored the vulnerability of the CCSNs to software failures. The current mated pair signaling transfer point (STP) implementations in the CCSNs, with both STPs from the same supplier having the same software, make this architecture susceptible to common-cause software failure modes that might result in failures of both STPs simultaneously. To address these concerns, ways have been considered to achieve software diversity in the CCSNs by ensuring software failure mode independence among network nodes. Four potential alternatives are identified here: (i) multiple software developments in STPs; (ii) different software generics for backup; (iii) mixed-supplier STP pairs; and (iv) E-link sets to different supplier STPs. The advantages and disadvantages of these alternatives to ensure software diversity are examined in this paper and should be weighed by individual telecommunications network providers. concerns expressed in this paper are not exhaustive listings, but rather catalysts for further studies and discussions.<>","1558-0008","","10.1109/49.285295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285295","","Intelligent networks;Software testing;Fault tolerance;Software reliability;Jacobian matrices;Computer architecture;Programming;Telecommunication services;Software engineering;Guidelines","","4","1","8","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"$\Delta$ΔBreakpad: Diversified Binary Crash Reporting","B. Abrath; B. Coppens; M. Mishra; J. Van den Broeck; B. De Sutter","Computer Systems Lab, Ghent University, Ghent, Belgium; Computer Systems Lab, Ghent University, Ghent, Belgium; Computer Systems Lab, Ghent University, Ghent, Belgium; Computer Systems Lab, Ghent University, Ghent, Belgium; Electronics and Information Systems, Ghent University, Gent, Belgium",IEEE Transactions on Dependable and Secure Computing,"1 Jul 2020","2020","17","4","841","856","This paper introduces ΔBreakpad. It extends the Breakpad crash reporting system to handle software diversity effectively and efficiently by replicating and patching the debug information of diversified software versions. Simple adaptations to existing open source compiler tools are presented that on the one hand introduce significant amounts of diversification in the code and stack layout of ARMv7 binaries to mitigate the widespread deployment of code injection and code reuse attacks, while on the other hand still supporting accurate crash reporting. An evaluation on SPEC2006 benchmarks demonstrates that the corresponding computational, storage, and communication overheads are small.","1941-0018","","10.1109/TDSC.2018.2823751","Innovation by Science and Technology in Flanders(grant numbers:3G013013); European Union Seventh Framework Programme(grant numbers:609734); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8332984","Software security;software diversity;crash reporting","Computer crashes;Software;Servers;Tools;Benchmark testing;Google;Registers","","1","","23","IEEE","6 Apr 2018","","","IEEE","IEEE Journals"
"A scalable method to measure similarity between two EDA-generated timing graphs","J. L. M. Lee","Software Engineering, Altera Corporation Malaysia, Penang, Malaysia 11900","2015 International Conference on Computer, Communications, and Control Technology (I4CT)","27 Aug 2015","2015","","","44","48","This is a case study of the use of graph similarity to correlate the timing models obtained from two electronic design automation (EDA) static timing analysis tools (Altera's Quartus II software versus Synopsys PrimeTime). Timing models are data modelled from the post-layout netlist and parasitics extraction. The field programmable gate array's (FPGA) timing model is used by customers to optimize their designs. As mask designs are constantly revisioned, new timing models are generated and thus the Quartus II software must constantly be updated with the new models. A verification needs to be carried out at every new iteration of timing models to ensure the regression testing of timing models is stable and reliable. This case study discusses one such verification methodology. A timing graph consists of nodes and edges. Edges have weights attached to them that can denote some characteristic, such as timing arc delays in this case. Out of the many graph similarity algorithms in the field, the most cited are edit distance similarity, neighbourhood matching, spectral matching and belief propagation. Neighbourhood matching, which was used in this study, is a point-to-point matching of a node's similarity score based on its neighbourhood's similarity score. The timing graph from the Quartus II software was generated with an in-house Tcl scripting language applications programming interface. The timing graph from PrimeTime was generated from its timing reports. An algorithm was postulated to calculate graph similarity based on edge weights of the graphs. The algorithm compared both graphs and produced a matrix of graph similarity scores for all paired nodes. The algorithm was tested on five data paths taken from the two EDA tools under evaluation. Our results showed good correlation between intuitive similarity measure and our algorithmic calculation.","","978-1-4799-7952-3","10.1109/I4CT.2015.7219534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219534","timing graph;point-to-point matching;graph similarity;FPGA timing model","Delays;Field programmable gate arrays;Software;Data models;Symmetric matrices;Software algorithms","","","","10","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Network Intrusion Detection Using Diversity-Based Centroid Mechanism","M. S. Gondal; A. J. Malik; F. A. Khan","Department of Computer Science, National University of Computer and Emerging Sciences, Islamabad, Pakistan; Department of Software Engineering, Foundation University, Rawalpindi, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Islamabad, Pakistan",2015 12th International Conference on Information Technology - New Generations,"1 Jun 2015","2015","","","224","228","Threats to computer networks are numerous and potentially devastating. Intrusion detection techniques provide protection to our data and track unauthorized access. Many algorithms and techniques have been proposed to improve the accuracy and minimize the false positive rate of the intrusion detection system (IDS). Statistical techniques, evolutionary techniques, and data mining techniques have also been used for this purpose. In this paper, we use a centroid-based technique for network intrusion detection in which the centroid is constructed on the basis of diversity. Diversity of a point is the sum of the distances from a point to all other points in a cluster. The point having minimum diversity is chosen as a centroid. The performance of diversity-based centroid shows significant improvement in the classification of intrusions. Experimental results on the KDDCup99 dataset demonstrate that the proposed method shows excellent performance in terms of accuracy, detection rate, and false positive rate.","","978-1-4799-8828-0","10.1109/ITNG.2015.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113477","Intrusion Detection System (IDS);Centroid;Diversity;Classification","Intrusion detection;Accuracy;Probes;Testing;Training;Classification algorithms","","8","","17","IEEE","1 Jun 2015","","","IEEE","IEEE Conferences"
"Generic Side-channel Distinguisher Based on Kolmogorov-Smirnov Test: Explicit Construction and Practical Evaluation","L. Jiye; Z. Yongbin; Y. Shuguo; F. Dengguo","State Key Laboratory of Information Security, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Software, Chinese Academy of Sciences, Beijing, China",Chinese Journal of Electronics,"31 Jul 2023","2012","21","3","547","553","Construction and evaluation of efficient distinguishers with broad generality is one fundamental problem in the area of side-channel cryptanalysis. Due to their capabilities to deal with general correlations, MIA-like distinguishers have received wide attention from academia. In this paper, we conduct a comprehensive comparison investigation of existing MIA-like distinguishers, and then propose a new generic side-channel distinguisher based on partial Kolmogorov-Smirnov test, namely PKS distinguisher. Theoretical analysis and experimental attacks unanimously justify that PKS distinguisher works remarkably well with both linear and non-linear leakage models. Specifically, PKS distinguisher has obvious advantages over existing MIA-like distinguishers in terms of both success rate and guessing entropy. Additionally, lower computational complexity of PKS distinguisher further shows its better applicability than MIA-like distinguishers.","2075-5597","","","National Natural Science Foundation of China(grant numbers:61073178); Natural Science Foundation of Beijing(grant numbers:4112064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197402","Side-channel cryptanalysis;Power analysis attack;Distinguisher;Distribution similarity;Kolmogorov-Smirnov test","Analytical models;Costs;Correlation;Computational modeling;Entropy;Computational complexity;Sorting","","","","16","","31 Jul 2023","","","CIE","CIE Journals"
"Diversity-by-Design for Dependable and Secure Cyber-Physical Systems: A Survey","Q. Zhang; A. Z. Mohammed; Z. Wan; J. -H. Cho; T. J. Moore","Department of Computer Science, Virginia Tech, Falls Church, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA, USA; Department of Computer Science, Virginia Tech, Falls Church, VA, USA; Department of Computer Science, Virginia Tech, Falls Church, VA, USA; Network Science Division, U.S. Army Research Laboratory, Adelphi, MD, USA",IEEE Transactions on Network and Service Management,"10 Mar 2022","2022","19","1","706","728","Diversity-based security approaches have been studied for several decades since the 1970s. The concept of diversity-by-design emerged in the 1980s. Since then, diversity-based system design research has been explored to provide more secure and dependable services in cyber-physical systems (CPSs). In this work, we are particularly interested in providing an in-depth, comprehensive survey of existing diversity-based approaches, their insights, and associated future work directions for building secure and dependable CPSs. This will allow us to provide promising ways of providing quality network and services based on key diversity-by-design principles for those who want to conduct research on developing secure and dependable CPSs using diversity as a system design feature. This survey paper mainly provides: (i) The common concept of diversity based on its multidisciplinary nature along with the historical evolution of the concept of diversity-by-design for providing secure and dependable services; (ii) the key diversity-by-design principles; (iii) the key benefits and caveats of using the diversity-by-design; (iv) the main concerns of CPS environments utilizing the diversity-by-design; (v) an extensive survey and discussions of existing diversity-based approaches based on five different classifications; (vi) the types of attacks considered by diversity-based approaches; (vii) the overall trends of evaluation methodologies used for diversity-based approaches, in terms of metrics, datasets, and testbeds; and (viii) the insights, lessons, and gaps identified from this extensive survey and future work directions.","1932-4537","","10.1109/TNSM.2021.3091391","Army Research Office(grant numbers:W91NF-20-2-0140); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462505","Diversity-by-design;software diversity;heterogeneity;security;dependability;cyber-physical systems","Security;Software;Measurement;Viruses (medical);Software as a service;Programming;Hardware","","","","182","IEEE","22 Jun 2021","","","IEEE","IEEE Journals"
"Sentence similarity detection in Malayalam language using cosine similarity","P. P. Gokul; B. K. Akhil; K. K. M. Shiva","Maryland Power Electronics Laboratory, Electrical and Computer Engineering Department, Institute for Systems Research, University of Maryland, College Park, MD, USA; Maryland Power Electronics Laboratory, Electrical and Computer Engineering Department, Institute for Systems Research, University of Maryland, College Park, MD, USA; NA","2017 2nd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","15 Jan 2018","2017","","","221","225","Identifying paraphrase in Malayalam language is difficult task because it is a highly agglutinative language and the linguistic structure in Malayalam language is complex compared to other languages. Here we use individual words synonyms to find the similarity between two sentences. In this paper, cosine similarity method is used to find the paraphrases in Malayalam language. In this paper we present the observations on sentence similarity between two Malayalam sentences using cosine similarity method, we used test data of 900 and 1400 sentence pairs of FIRE 2016 Malayalam corpus that used in two iterations to present and obtained an accuracy of 0.8 and 0.59.","","978-1-5090-3704-9","10.1109/RTEICT.2017.8256590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8256590","Natural Language processing;Paraphrase detection;Semantic similarity;Cosine Similarity;jaccard Similarity","Tagging;Semantics;Conferences;Market research;Communications technology;Training","","15","","12","IEEE","15 Jan 2018","","","IEEE","IEEE Conferences"
"Challenges of the Dynamic Detection of Functionally Similar Code Fragments","F. Deissenboeck; L. Heinemann; B. Hummel; S. Wagner","Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; University of Stuttgart, Germany",2012 16th European Conference on Software Maintenance and Reengineering,"5 Apr 2012","2012","","","299","308","Classic clone detection approaches are hardly capable of finding redundant code that has been developed independently, i.e., is not the result of copy&paste. To automatically detect such functionally similar code of independent origin, we experimented with a dynamic detection approach that applies random testing to selected chunks of code similar to Jiang&Su's approach. We found that such an approach faces several limitations in its application to diverse Java systems. This paper details on our insights regarding these challenges of dynamic detection of functionally similar code fragments. Our findings support a substantiated discussion on detection approaches and serve as a starting point for future research.","1534-5351","978-0-7695-4666-7","10.1109/CSMR.2012.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178896","dynamic analysis;functional similarity","Cloning;Java;Pipelines;Software systems;Measurement;Testing;Detectors","","20","","10","IEEE","5 Apr 2012","","","IEEE","IEEE Conferences"
"Towards Developer-Centered Secure Coding Training","V. Pikulin; D. Kubo; K. Nissanka; S. Bandara; M. A. Shamsiemon; A. Yasmin; A. Jayatilaka; A. Madugalla; T. Kanij","Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Depatment of Engineering, Monash University, Kuala Lumpur, Malaysia; Centre for Research on Engineering Software Technologies (CREST), The University of Adelaide, Adelaide, Australia; Department of Software Systems and Cybersecurity, Monash University, Melbourne, Australia; Department of Software Systems and Cybersecurity, Monash University, Melbourne, Australia",2023 38th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW),"2 Nov 2023","2023","","","24","31","Software security continues to be a matter of concern for both end-users and developers, with the cost of potential lapses expected to become larger as software plays a larger role in society. Despite investments in secure coding training programmes, organisations are not achieving the expected success rate. An often overlooked reason for this among many others is that current training programmes are not tailored to consider the diversity among software developers as it relates to human aspects. In this research, data was gathered from software developers of various backgrounds on their perceptions of secure coding training, their expectations from and challenges with such a training program. The findings suggest that developers with personality traits of agreeableness tend to ignore secure coding standards. Additionally, developers with higher work experience tend to demand storage management, responsible use of privileges, security and privacy laws and testing topics to be included in the secure coding training. Furthermore, in terms of training structure, developers with higher openness tend to demand hands-on training to be included. The study's findings seek to inform future researchers and organisations on factors to consider when designing adaptive secure coding programs that would address the needs of developers from different backgrounds.","2151-0849","979-8-3503-3032-8","10.1109/ASEW60602.2023.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298735","Secure Coding;Programming;Cybersecurity;Training;Developers;Diversity;Human Aspects","Training;Privacy;Storage management;Encoding;Software;Security;Standards","","1","","21","IEEE","2 Nov 2023","","","IEEE","IEEE Conferences"
"Using Program Data-State Diversity in Test Data Search","M. Alshraideh; L. Bottaci","Department of Computer Science, University of Hull, Hull, UK; Department of Computer Science, University of Hull, Hull, UK",Testing: Academic & Industrial Conference - Practice And Research Techniques (TAIC PART'06),"16 Oct 2006","2006","","","107","114","Search-based automatic software test data generation for structural testing depends on the instrumentation of the test goal to construct a many-valued function which is then optimised. The method encounters difficulty when the search is in a region in which the function is not able to discriminate between different candidate test cases because it returns a constant value. A typical example of this problem arises in the instrumentation of branch predicates that depend on the value of a boolean-valued (flag) variable. Existing transformation techniques can solve many cases of the problem but there are situations for which transformation techniques are inadequate. This paper presents a technique for directing the search when the function that instruments the test goal is not able to discriminate candidate test inputs. The new technique depends on introducing program data-state diversity as an additional search goal. The search is guided by a new evaluation (cost) function made up of two parts, one depends on the conventional instrumentation of the test goal, the other depends on the diversity of the data-states produced during execution of the program under test. The method is demonstrated for a number of example programs for which existing methods are inadequate.","","0-7695-2672-1","10.1109/TAIC-PART.2006.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1691676","","Automatic testing;Instruments;Cost function;Software testing;Computer science;Search methods;Genetic algorithms","","1","","18","IEEE","16 Oct 2006","","","IEEE","IEEE Conferences"
"Cloned Buggy Code Detection in Practice Using Normalized Compression Distance","T. Ishio; N. Maeda; K. Shibuya; K. Inoue","Nara Institute of Science and Technology, Nara, Japan; NEC Corporation, Tokyo, Japan; NEC Corporation, Tokyo, Japan; Osaka University, Osaka, Japan",2018 IEEE International Conference on Software Maintenance and Evolution (ICSME),"11 Nov 2018","2018","","","591","594","Software developers often write similar source code fragments in a software product. Since such code fragments may include the same mistake, developers have to inspect code clones if they found a bug in their code. In this study, we developed a tool to detect clones of a faulty code fragment for a software company, since existing code clone detection tools do not fit the requirements of the company. The tool employs Normalized Compression Distance for source code comparison, because its definition is understandable for developers, and also it is easy to support multiple programming languages. We conducted two experiments using an existing research dataset and actual examples. Based on the evidence, the tool has been deployed in several projects in the company.","2576-3148","978-1-5386-7870-1","10.1109/ICSME.2018.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530071","Code clone detection;Source code similarity;Source code search;Bug fix;Development tool","Tools;Cloning;Companies;Computer bugs;Benchmark testing;Microsoft Windows","","7","","18","IEEE","11 Nov 2018","","","IEEE","IEEE Conferences"
"Best Parameter Selection Of Rabin-Karp Algorithm In Detecting Document Similarity","A. D. Hartanto; A. Syaputra; Y. Pristyanto","Faculty of Computer Science, Universitas Amikom Yogyakarta, Yogyakarta, Indonesia; Faculty of Computer Science, Universitas Amikom Yogyakarta, Yogyakarta, Indonesia; Faculty of Computer Science, Universitas Amikom Yogyakarta, Yogyakarta, Indonesia",2019 International Conference on Information and Communications Technology (ICOIACT),"23 Dec 2019","2019","","","457","461","Text mining is usually used to detect document similarities and plagiarism. The field of education is one area that is prone to plagiarism. Plagiarism can kill someone's creativity because this action does not require energy and does not have to think hard. Therefore, the act of plagiarism must be prevented from causing harm to various parties. By using matching strings on documents, it can be used to detect plagiarism. One method that can be used is Rabin-Karp Algorithm, but in several studies that have been done the researchers did not test the k-gram value and database value, in theory, this would affect the performance of the Rabin-Karp Algorithm. Therefore in this study, the selection of k-gram values and prime bases was conducted to determine the effect on the performance of the Rabin-Karp Algorithm. The results showed that the selection of gram values and prime bases affected the processing time in testing the data and the similarity values of the documents being tested. In this study the value of k = 5 on k-gram has the fastest time for the testing process, both testing with multiple data 25 and testing the data for all amounts of data the number is 300.","","978-1-7281-1655-6","10.1109/ICOIACT46704.2019.8938458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938458","Text Mining;Rabin-Karp;Parameter Selection;Document Similarity","Plagiarism;Testing;Computer science;Text mining;Information and communication technology;Flowcharts;Filtering","","6","","15","IEEE","23 Dec 2019","","","IEEE","IEEE Conferences"
"Collaborative Filtering Method with the use of Production Rules","A. S. Mohammed; Y. Meleshko; S. Balaji B; S. Serhii","Dept of Computer Engineering, Lebanese French University, Salahaddin University, Erbil, KR-Iraq; Dept of Cyber Security & Software, Central Ukrainian National Technical University, Kropyvnytskyi, Ukraine; Dept of Information Technology, Lebanese French University, Erbil, KR-Iraq; Dept of Computer Science and Programming, National Technical University (Kharkiv Polytechnic Institute), Ukraine",2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE),"20 Feb 2020","2019","","","387","391","this paper proposes a new collaborative filtering method with the calculation of unknown similarity coefficients between users via the application of production rules, which aims to improve the work quality of recommendation systems, to develop of production rules for the developed system. The methods used are: graph theory, the theory of algorithms, mathematical statistics, object-oriented programming, and fuzzy logic. The developed systems are new collaborative filtering method with the definition of unknown similarity coefficients between users through the application of production rules was developed, software for the implementation and testing of this method was developed, experiments on the developed software was conducted. The production rules to determine unknown similarity coefficients in recommendation systems was proposed. The new method of collaborative filtering with the application of production rules has been developed to find unknown similarity coefficients between users that may be possibly used to improve the work quality of the recommendation system. The conducted experiments showed that the developed method enhances the quality indicators of the recommendation system, such as item space coverage and the total number of predicted preferences of users.","","978-1-7281-3778-0","10.1109/ICCIKE47802.2019.9004257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004257","recommendation systems;production rules;collaborative filtering;similarity coefficients","Collaboration;Production;Information filters;Computational intelligence;Software","","1","","13","IEEE","20 Feb 2020","","","IEEE","IEEE Conferences"
"Building software engineering teams that work: The impact of dominance on group conflict and Performance outcomes","T. L. Lewis; W. J. Smith",Radford University; Virginia Technology,2008 38th Annual Frontiers in Education Conference,"22 Dec 2008","2008","","","S3H-1","S3H-6","This project is designed to build on theories of team composition and proposes an innovative way of assigning students to teams. Currently, professors are using a variety of team assignment techniques to form software engineering teams. This research believes that a contributing factor to the undesired outcomes (i.e., low performing teams and high levels of conflict) of software engineering teams is that the teams were not formed using ldquorelevant and salientrdquo criteria. To address the relevance issue, we test the impact of problem solving preferences (a sub-set of the MBTI scale) on group conflict and performance. We then test the extent to which the numerical dominance (i.e., salience) of problem solving styles influences conflict and performance. It was found that dominance of problem solving styles is related to negative team outcomes. We conclude by discussing ways in which instructors and team members may minimize negative team outcomes when there is no choice other than forming a team with one dominant problem solving preference.","2377-634X","978-1-4244-1969-2","10.1109/FIE.2008.4720498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4720498","MBTI;Numerical Dominance;Problem Solving Style;Team Diversity;Team Dynamics","Software engineering;Problem-solving;Testing;Demography;Buildings;Teamwork;Programming;Software design;Information technology;Technological innovation","","7","","25","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"DistSim - Scalable Distributed in-Memory Semantic Similarity Estimation for RDF Knowledge Graphs","C. F. Draschner; J. Lehmann; H. Jabeen","University of Bonn, Bonn, Germany; University of Bonn, Bonn, Germany; University of Cologne, Cologne, Germany",2021 IEEE 15th International Conference on Semantic Computing (ICSC),"3 Mar 2021","2021","","","333","336","In this paper, we present DistSim, a Scalable Distributed in-Memory Semantic Similarity Estimation framework for Knowledge Graphs. DistSim provides a multitude of state-of-the-art similarity estimators. We have developed the Similarity Estimation Pipeline by combining generic software modules. For large scale RDF data, DistSim proposes MinHash with locality sensitivity hashing to achieve better scalability over all-pair similarity estimations. The modules of DistSim can be set up using a multitude of (hyper)-parameters allowing to adjust the tradeoff between information taken into account, and processing time. Furthermore, the output of the Similarity Estimation Pipeline is native RDF. DistSim is integrated into the SANSA stack, documented in scala-docs, and covered by unit tests. Additionally, the variables and provided methods follow the Apache Spark MLlib name-space conventions. The performance of DistSim was tested over a distributed cluster, for the dimensions of data set size and processing power versus processing time, which shows the scalability of DistSim w.r.t. increasing data set sizes and processing power. DistSim is already in use for solving several RDF data analytics related use cases. Additionally, DistSim is available and integrated into the open-source GitHub project SANSA.","2325-6516","978-1-7281-8899-7","10.1109/ICSC50631.2021.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364473","Distributed RDF Analytics;Scalable Semantic Similarity Estimation;Knowledge Graph Data Analytics Pipeline;SANSA","Scalability;Semantics;Pipelines;Estimation;Distributed databases;Resource description framework;Software development management","","3","","21","IEEE","3 Mar 2021","","","IEEE","IEEE Conferences"
"Impact Analysis of Syntactic and Semantic Similarities on Patch Prioritization in Automated Program Repair","M. Asad; K. K. Ganguly; K. Sakib","Institute of Information Technology University of Dhaka, Dhaka, Bangladesh; Institute of Information Technology University of Dhaka, Dhaka, Bangladesh; Institute of Information Technology University of Dhaka, Dhaka, Bangladesh",2019 IEEE International Conference on Software Maintenance and Evolution (ICSME),"5 Dec 2019","2019","","","328","332","Patch prioritization means sorting candidate patches based on probability of correctness. It helps to minimize the bug fixing time and maximize the precision of an automated program repairing technique. Approaches in the literature use either syntactic or semantic similarity between faulty code and fixing element to prioritize patches. Unlike others, this paper aims at analyzing the impact of combining syntactic and semantic similarities on patch prioritization. As a pilot study, it uses genealogical and variable similarity to measure semantic similarity, and normalized longest common subsequence to capture syntactic similarity. For evaluating the approach, 22 replacement mutation bugs from IntroClassJava benchmark were used. The approach repairs all the 22 bugs and achieves a precision of 100%.","2576-3148","978-1-7281-3094-1","10.1109/ICSME.2019.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918958","patch prioritization;semantic similarity;syntactic similarity;automated program repair","Computer bugs;Syntactics;Semantics;Maintenance engineering;Measurement;Benchmark testing;Information technology","","8","","17","IEEE","5 Dec 2019","","","IEEE","IEEE Conferences"
