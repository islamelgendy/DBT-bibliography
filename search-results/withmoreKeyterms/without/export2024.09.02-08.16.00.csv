"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"One-Dimensional Soft-Demapping Algorithms for Rotated QAM and Software Implementation on DSP","K. Kim; N. Basutkar; K. Bae; P. Xue; H. Yang","Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea; Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea; Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea; Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea; Samsung Electronics, Samsung Advanced Institute of Technology, Yongin, Gyeonggi, South Korea",IEEE Transactions on Signal Processing,"10 Jul 2013","2013","61","15","3918","3930","To improve detection performance of quadrature amplitude modulation (QAM), signal space diversity (SSD) has been exploited and adopted for the second generation of digital video broadcasting (DVB-T2) system. Maximum-likelihood detection (MLD) to get full SSD is avoided because of enormous computational complexity. Its max-log approximated detection (full search algorithm) and subregion based soft-demappers are also too complex to be implemented due to their two-dimensional (2D) Euclidean distance calculation. In particular, the complexity becomes the main burden for the software implementation, which is attractive for multistandard broadcasting receivers. To tackle the main bottleneck, we propose one-dimensional (1D) soft-demappers. By reformulating a rotated QAM signal as two layered pulse amplitude modulation (PAM) signals, the full search algorithm is simplified to an MMSE decorrelation followed by 1D soft-demapping, where Gaussian approximation is used for the interferences. Additional interference cancellation is considered to further suppress its residual interference. For 256-QAM with 4/5 code rate in memoryless Rayleigh channels with/without erasures, the performance gap to the full search is within 0.15 dB at 10-3 bit error rate (BER), while the complexity is less than 8%. Due to the significant complexity reduction of the proposed algorithms, the software implementation of a DVB-T2 receiver on DSP is feasible with 73% less computations than the one with the full-search-based soft-demapper.","1941-0476","","10.1109/TSP.2013.2262681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6515394","Coarse-grained reconfigurable array (CGRA) architecture;digital signal processor (DSP);interference cancellation (IC);log likelihood ratio (LLR);minimum mean square error (MMSE);rotated QAM;signal space diversity (SSD);soft-demapping;software defined radio (SDR)","Quadrature amplitude modulation;Complexity theory;Software algorithms;Signal processing algorithms;Approximation algorithms;Decorrelation;Software","","12","1","29","IEEE","13 May 2013","","","IEEE","IEEE Journals"
"Compressive Sensing based Software Defined GPR for Subsurface Imaging","Y. Zhang; D. Orfeo; D. Huston; T. Xia","School of Engineering, University of Vermont, Burlington, VT, USA; School of Engineering, University of Vermont, Burlington, VT, USA; School of Engineering, University of Vermont, Burlington, VT, USA; School of Engineering, University of Vermont, Burlington, VT, USA",2021 IEEE Radar Conference (RadarConf21),"18 Jun 2021","2021","","","1","6","This paper presents the design of a new ground penetrating radar (GPR) integrating software defined radio (SDR) and compressive sensing (CS) technologies. In recent literature, SDR has been explored for designing GPR in the way of stepped-frequency continuous wave (SFCW) radar. In the operation, the software defined GPR (SD GPR) radiates a series of sinusoidal signals of evenly spaced frequencies at each scan position. The reflection signals of all frequency tones are received and their amplitude and phase responses are measured and characterized. As each individual frequency tone needs to be generated, transmitted and received in sequence, it results in a slow scan speed. In this study, compressive sensing is explored to expedite SD GPR operation speed. For SD GPR subsurface survey, when the target area is spatially sparse, i.e. the buried objects are sparsely distributed, In addition, we develop a CS based signal processing algorithm specifically for improving image quality and reducing the clutter. To reconstruct the image correctly, an automatic parameter selection algorithm based on the structural similarity index measure (SSIM) is proposed. For validation, a laboratory test was conducted. The experimental results demonstrate that the CS imaging algorithm produces less clutter comparing with the traditional GPR image algorithms, such as the time domain back projection (BPA) method.","2375-5318","978-1-7281-7609-3","10.1109/RadarConf2147009.2021.9455291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455291","Software Defined GPR;Subsurface Imaging;Compressive Sensing;Structural Similarity Index Measure (SSIM)","Ground penetrating radar;Software algorithms;Signal processing algorithms;Radar imaging;Software;Frequency measurement;Indexes","","4","","21","IEEE","18 Jun 2021","","","IEEE","IEEE Conferences"
"Tibetan Few-Shot Learning Model Based on Matching Networks","Z. Zhang; G. Xiong; Y. Yu; X. Wang; X. Feng; N. Tashi","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information Science and Technology, Tibet University, Lhasa, China",2023 International Conference on Neuromorphic Computing (ICNC),"19 Mar 2024","2023","","","446","451","This paper highlights the low-resource Tibetan few-shot learning model and establishes accuracy benchmarks utilizing Matching Networks (MN). Addressing the issues of low quality and limited usability in the existing Tibetan-Chinese parallel corpus, this paper constructs a small-scale and high-quality Tibetan-Chinese parallel corpus containing 110,000 sentence pairs using data filtering, deduplication, deletion of blank lines, and special symbol processing. Based on full context embeddings, Softmax-based attention mechanisms, and similarity metrics, the Tibetan few-shot learning model based on MN is proposed to help the model learn logical Tibetan knowledge rapidly from few-shot data. Different distance metrics on Cosine, Euclidean, Poincare, and Minkowski distances are used to test the accuracy of the Tibetan k-shot learning model, which provides a unified and reliable benchmark for the Tibetan few-shot learning tasks. This research provides substantial assistance in solving the issues of machine learning performing poorly in low-resource settings. The experiment results demonstrate that the accuracy of all metrics is improved with the number of shots increased, and Euclidean distance performs well in 5-way 1-shot learning, cosine performs well in 5-way 2-shot learning, and Minkowski distance $(\mathrm{p}=3)$ shows excellent accuracy in 5-way 3-shot learning. Notably, we used our own Tibetan data set and succeeded in enhancing accuracy by a noteworthy 1.6% in a 5-way 3-shot setup.","","979-8-3503-1688-9","10.1109/ICNC59488.2023.10462784","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10462784","Tibetan;few-shot learning;matching networks;machine learning;similarity metrics","Measurement;Training;Symbols;Benchmark testing;Solids;Data models;Usability","","","","20","IEEE","19 Mar 2024","","","IEEE","IEEE Conferences"
"Adaptive Multi-Hash Similarity Fusion for Remote Sensing Image Retrieval","J. Yu; H. Li; Y. Ge; H. Shao; J. Xiong","Software School, Nanchang Hongkong University, Nanchang, Jiangxi, China; School of Arts, Media and Computers, Jiangxi Tourism and Commerce Vocational College, Nanchang, Jiangxi, China; Software School, Nanchang Hongkong University, Nanchang, Jiangxi, China; Software School, Nanchang Hongkong University, Nanchang, Jiangxi, China; Software School, Nanchang Hongkong University, Nanchang, Jiangxi, China","2024 5th International Conference on Geology, Mapping and Remote Sensing (ICGMRS)","9 Jul 2024","2024","","","117","121","With the exponential growth of remote sensing (RS) images, content-based remote sensing image retrieval (CBRSIR) has become an effective method to retrieve target images from RS data. However, existing CBRSIR methods often rely on a single feature, which fails to fully capture the rich and complex visual content. To address this limitation, we propose an adaptive multi-hash similarity fusion method for RSIR. Firstly, deep features and manual features are extracted to provide varying perspectives on the image. Secondly, in order to enhance retrieval efficiency, these features are transformed into low-dimensional hash codes through the probability ordinal-preserving semantic hashing method. Finally, various hash similarities are fused to capitalize on the complementarity of different views and narrow the semantic gap. Given that different hash similarities contribute disparately to the final retrieval result during fusion, determining the weight distribution is critical for enhancing the fusion effect. Therefore, the mean average precision results are utilized to adaptively determine fusion weights. Experiments on two benchmark datasets demonstrate that the proposed method outperforms other RSIR methods. Comparative experiments with exhaustive weighting reveal the simplicity and effectiveness of our adaptive weight allocation method.","","979-8-3503-6571-9","10.1109/ICGMRS62107.2024.10581361","China National Science Foundation(grant numbers:42261070,41801288); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10581361","Remote sensing image retrieval;Hashing similarity fusion;Adaptive weight assignment;Deep features;Manual features","Visualization;Codes;Geology;Semantics;Image retrieval;Manuals;Benchmark testing","","","","17","IEEE","9 Jul 2024","","","IEEE","IEEE Conferences"
"Assessment of Data Diversity Methods for Software Fault Tolerance Based on Mutation Analysis","G. Gallardo; J. May; J. C. Gallardo","University of Bristol, UK; Safety Systems Research Centre (SSRC), University of Bristol, UK; SSRC, UK",Second Workshop on Mutation Analysis (Mutation 2006 - ISSRE Workshops 2006),"2 Apr 2007","2006","","","6","6","One of the main concerns in safety-critical software is to ensure sufficient reliability because proof of the absence of systematic failures has proved to be an unrealistic goal. fault-tolerance (FT) is one method for improving reliability claims. It is reasonable to assume that some software FT techniques offer more protection than others, but the relative effectiveness of different software FT schemes remains unclear. We present the principles of a method to assess the effectiveness of FT using mutation analysis. The aim of this approach is to observe the power of FT directly and use this empirical process to evolve more powerful forms of FT. We also investigate an approach to FT that integrates data diversity (DD) assertions and TA. This work is part of a longer term goal to use FT in quantitative safety arguments for safety critical systems.","","0-7695-2897-X","10.1109/MUTATION.2006.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4144725","","Diversity methods;Fault tolerance;Genetic mutations;Software safety;Redundancy;Software testing;Fault tolerant systems;Software systems;Failure analysis;System testing","","","","17","IEEE","2 Apr 2007","","","IEEE","IEEE Conferences"
"BEDIVFUZZ: Integrating Behavioral Diversity into Generator-based Fuzzing","H. L. Nguyen; L. Grunske","Humboldt-Universität zu Berlin, Germany; Humboldt-Universität zu Berlin, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","249","261","A popular metric to evaluate the performance of fuzzers is branch coverage. However, we argue that focusing solely on covering many different branches (i.e., the richness) is not sufficient since the majority of the covered branches may have been exercised only once, which does not inspire a high confidence in the reliability of the covered code. Instead, the distribution of the executed branches (i.e., the evenness) should also be considered. That is, behavioral diversity is only given if the generated inputs not only trigger many different branches, but also trigger them evenly often with diverse inputs. We introduce BEDIVFUZZ, a feedback-driven fuzzing technique for generator-based fuzzers. BEDIVFUZZ distinguishes between structure-preserving and structure-changing mutations in the space of syntactically valid inputs, and biases its mutation strategy towards validity and behavioral diversity based on the received program feedback. We have evaluated BEDIVFUZZ on Ant, Maven, Rhino, Closure, Nashorn, and Tomcat. The results show that BE-DIVFUZZ achieves better behavioral diversity than the state of the art, measured by established biodiversity metrics, namely the Hill numbers, from the field of ecology.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793964","Structure-aware fuzzing;behavioral diversity;random testing","Measurement;Codes;Focusing;Fuzzing;Ecology;Behavioral sciences;Reliability","","7","","54","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Empirical study of post-envelope detection receive diversity combining for passive UHF RFID tags","L. B. B. Paet; J. J. S. Marciano","Electrical and Electronics Engineering Institute, University of Philippines, Quezon, Philippines; Electrical and Electronics Engineering Institute, University of Philippines, Quezon, Philippines",TENCON 2011 - 2011 IEEE Region 10 Conference,"12 Jan 2012","2011","","","773","777","The concept of incorporating receive diversity combining schemes into UHF RFID tags is presented in this work. The inclusion of the said schemes into RFID tags is employed as a possible solution to the effects of multipath propagation on the reader-to-tag (R→T) wireless link which reduce the read range and degrade the read reliability of current passive RFID systems. To explore this concept, the authors constructed reader and tag emulation platforms using National Instruments PXI hardware modules and LabVIEW software programs for modeling the R→T communications link. The reader emulation platform was used to model the transmit section of an RFID reader and is capable of transmitting user-predetermined sequences of RFID commands. The tag emulation platform was used to model the receive section of a single-or multi-antenna RFID tag. These two platforms were utilized as a testbed for developing and testing the following 2-channel diversity combining schemes for UHF RFID tags: (1) selection diversity combining (SDC), (2) post-detection direct additive combining (DACP), and (3) post-detection ratio squared combining (RSCP). Experiments were conducted to determine the read range and read reliability performance. Results of these experiments show that a maximum of 26.67% improvement in the read range and a maximum of 16.64% improvement in the read reliability of UHF RFID systems can be obtained by integrating receive diversity schemes into RFID tags. Improvements were recorded even for tag antenna spacings as low as 0.05?.","2159-3450","978-1-4577-0255-6","10.1109/TENCON.2011.6129215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129215","spatial diversity;multi-antenna signal processing;passive UHF RFID;EPC Gen 2 RFID","Diversity reception;Antennas;Reliability;Emulation;Passive RFID tags;Hardware","","1","","13","IEEE","12 Jan 2012","","","IEEE","IEEE Conferences"
"Generation of High-Quality Relevant Judgments through Document Similarity and Document Pooling for the Evaluation of Information Retrieval Systems","M. H. Joseph; S. D. Ravana","Department of Information Systems, Faculty of Computer Science & Information Technology, University of Malaya, Malaysia; Department of Information Systems, Faculty of Computer Science & Information Technology, University of Malaya, Malaysia","2022 14th International Conference on Software, Knowledge, Information Management and Applications (SKIMA)","6 Feb 2023","2022","","","261","265","The Information Retrieval System Evaluation have carried out through Cranfield-paradigm in which the test collections provide the foundation of the evaluation process. The test collections consist of document corpus, topics, and a set of relevance judgements. The relevant judgements are the documents which retrieved from the test collections based on the topics. The precision of the evaluation process is based on the number of relevant documents in the relevant judgement list called qrels. This paper presents a study on how methodologies like pooling and document similarity helps to generate more relevant documents into the relevance judgments set in order to increase the accuracy of the evaluation process. The initial results have shown that combination of pooling with document similarity performs better compared to base clustering or classification.","2573-3214","978-1-6654-9334-5","10.1109/SKIMA57145.2022.10029459","Ministry of Higher Education(grant numbers:FRGS/1/2020/1CT06/UM/02/1); Universiti Malaya(grant numbers:RMFI521-2021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10029459","Information retrieval;Evaluation;Pooling;Document similarity;Information Systems","Information retrieval;Software;Information management","","","","15","IEEE","6 Feb 2023","","","IEEE","IEEE Conferences"
"Software Side Channel Vulnerability Detection Based on Similarity Calculation and Deep Learning","W. Sun; Z. Yan; X. Xu; W. Ding; L. Gao","School of Cyber Engineering Xidian University, Xi’an, China; School of Cyber Engineering Xidian University, Xi’an, China; School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; School of Cyber Engineering Xidian University, Xi’an, China; School of Cyber Engineering Xidian University, Xi’an, China","2022 IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","20 Mar 2023","2022","","","800","809","Software Side Channel Vulnerabilities (SSCVs) cause serious security threats, which introduces a big challenge to software development. With the sustaining growth of software complexity and scale, SSCV detection has become a tedious work. Existing methods suffer from efficiency, accuracy and generality problems, and ignore the detection of vulnerability variants. Applying machine learning is promising due to high efficiency and automation, but training an effective model is still an open issue due to the lack of side-channel vulnerability data. In this paper, we propose a novel two-stage SSCV detection method based on similarity calculation and deep learning. We target three types of vulnerability variants that have different degrees of similarity to original ones. The first detection stage applies Deterministic Finite Automata (DFA) and Trie tree to regularize software codes for detecting vulnerability Variants 1 and 2 through similarity calculation. The second stage uses Long Short-Term Memory and Neural Network Classifier (LSTM-NNClassifier) to discover vulnerability Variant 3. In addition, we offer a code augmentation method to construct a sufficient dataset to train the LSTM-NNClassifier for overcoming the problem of lacking training data. Extensive experiments based on real world data show the efficiency and accuracy of our detection method.","2324-9013","978-1-6654-9425-0","10.1109/TrustCom56396.2022.00112","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10063617","Side Channel Attack;Vulnerability Detection;Deep Learning;Similarity Calculation","Deep learning;Training;Privacy;Codes;Learning automata;Neural networks;Training data","","","","34","IEEE","20 Mar 2023","","","IEEE","IEEE Conferences"
"Indoor antenna diversity testbed","K. Bialkowski; S. Zagriatski; A. Postula; M. E. Bialkowski","School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD, Australia; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD, Australia; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD, Australia; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD, Australia",2005 IEEE Antennas and Propagation Society International Symposium,"12 Dec 2005","2005","2B","","759","762 vol. 2B","This paper presents a high precision testbed for evaluating antenna diversity techniques in an indoor environment. Details concerning mechanical, electrical and electronics hardware and associated measurement software are described. Initial measurement results for two Bluetooth modules operating with co-polar and cross-polar monopole antennas in the ISM 2.4 GHz band are given.","1947-1491","0-7803-8883-6","10.1109/APS.2005.1552127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1552127","","Testing;Polarization;Antenna measurements;Transmitting antennas;MIMO;Gears;Coaxial cables;Software measurement;Receiving antennas;Transmitters","","4","","3","IEEE","12 Dec 2005","","","IEEE","IEEE Conferences"
"A Semantics-Based Hybrid Approach on Binary Code Similarity Comparison","Y. Hu; H. Wang; Y. Zhang; B. Li; D. Gu","Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Technology, SEIEE, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Software Engineering,"11 Jun 2021","2021","47","6","1241","1258","Binary code similarity comparison is a methodology for identifying similar or identical code fragments in binary programs. It is indispensable in fields of software engineering and security, which has many important applications (e.g., plagiarism detection, bug detection). With the widespread of smart and Internet of Things (IoT) devices, an increasing number of programs are ported to multiple architectures (e.g., ARM, MIPS). It becomes necessary to detect similar binary code across architectures as well. The main challenge of this topic lies in the semantics-equivalent code transformation resulting from different compilation settings, code obfuscation, and varied instruction set architectures. Another challenge is the trade-off between comparison accuracy and coverage. Unfortunately, existing methods still heavily rely on semantics-less code features which are susceptible to the code transformation. Additionally, they perform the comparison merely either in a static or in a dynamic manner, which cannot achieve high accuracy and coverage simultaneously. In this paper, we propose a semantics-based hybrid method to compare binary function similarity. We execute the reference function with test cases, then emulate the execution of every target function with the runtime information migrated from the reference function. Semantic signatures are extracted during the execution as well as the emulation. Lastly, similarity scores are calculated from the signatures to measure the likeness of functions. We have implemented the method in a prototype system designated as BinMatch which performs binary code similarity comparison across architectures of x86, ARM and MIPS on the Linux platform. We evaluate BinMatch with nine real-word projects compiled with different compilation settings, on variant architectures, and with commonly-used obfuscation methods, totally performing over 100 million pairs of function comparison. The experimental results show that BinMatch is resilient to the semantics-equivalent code transformation. Besides, it not only covers all target functions for similarity comparison, but also improves the accuracy comparing to the state-of-the-art solutions.","1939-3520","","10.1109/TSE.2019.2918326","National Natural Science Foundation of China(grant numbers:U1636217); National Key Research and Development Program of China(grant numbers:2016YFB0801201,2016QY071401); Ministry of Industry and Information Technology of the People's Republic of China(grant numbers:[2018] 282); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721093","Binary code similarity comparison;reverse engineering;program analysis;code clone","Binary codes;Semantics;Computer architecture;Runtime;Computer science;Feature extraction;Internet of Things","","8","","65","IEEE","23 May 2019","","","IEEE","IEEE Journals"
"Development of Class Diagrams Based on Use Case, and Sequence Diagrams Using a Text Mining Approach in SRS Penguin","N. F. Setiyawan; Y. Priyadi; W. Astuti","Department of Informatics, Telkom University, Bandung, Indonesia; Department of Software Engineering, Telkom University, Bandung, Indonesia; Department of Informatics, Telkom University, Bandung, Indonesia",2023 IEEE World AI IoT Congress (AIIoT),"13 Jul 2023","2023","","","0070","0076","Software requirement specification is a document that can be used as a guide for developers to develop applications. This study uses SRS from the Penguin application to help determine the development of class diagrams based on use case and sequence diagrams using the text mining method. The results of this process will be calculated for similarity, after which validation and testing will be carried out using Gwet’s AC1 and Cohen Kappa. Based on the results and discussion, three artifacts were formed, namely actors from use case diagrams (AUC), objects from sequence diagrams (OSD), and class names from class diagrams (NCD). The three artifacts produce two comparisons in the formation of class diagrams. The first comparison is between AUC and NCD, with the highest cosine similarity score of 0.666. From this score, the resulting construction of class diagram component names is seller and customer. The first comparison also resulted in a score of 0.088 for Cohen Kappa and 0.756 for Gwet’s AC1. Furthermore, for the second comparison, between OSD and NCD, two results were obtained with the same score, namely 0.9. This score resulted in the formation of class component names such as seller, transaction page, revenue page, expenditure page, and penguin app system. And the second comparison has a Cohen kappa score of 0.112 and 0.926 for Gwet’s AC1 score. The results of the Cohen Kappa score, and Gwet’s AC1 can be used as recommendations for improving class names that match the actors names in use case diagram, and object names in the sequence diagram.","","979-8-3503-3761-7","10.1109/AIIoT58121.2023.10174287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174287","software requirement specification;class diagram;use case diagram;text mining;similarities;validation","Text mining;Software;Artificial intelligence;Testing","","1","","27","IEEE","13 Jul 2023","","","IEEE","IEEE Conferences"
"Human activity recognition from basic actions using graph similarity measurement","N. Noorit; N. Suvonvorn","Department of Computer Engineering, Prince of Songkla University, Songkhla, Thailand; Department of Computer Engineering, Prince of Songkla University, Songkhla, Thailand",2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE),"27 Aug 2015","2015","","","7","11","Human activity recognition has an important role for the automatic anomaly event detection and recognition application such as surveillance system and patient monitoring system. In this paper, we propose a human activity recognition method based on graph similarity measurement technique (GSM). The basic actions with their movements for each person in the interested area are extracted and calculated. The action sequence with movement features of labelled dataset are used as basis data to establish the statistical activity graph model that used to calculate similarity between graphs. The system performs good results, (sensitivity and specificity are about 80% for first testing activity and about 90% for second testing activity).","","978-1-4799-1966-6","10.1109/JCSSE.2015.7219761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219761","human activity recognition;directed graph;graph similarity measurement","Joints;Conferences;Computer science;Software engineering","","1","","13","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Optimizing Spaced $k$-mer Neighbors for Efficient Filtration in Protein Similarity Search","W. Li; B. Ma; K. Zhang","Department of Computer Science, University of Western Ontario, London, ON, Canada; School of Computer Science, University of Waterloo, Waterloo, Canada; Department of Computer Science, University of Western Ontario, London, ON, Canada",IEEE/ACM Transactions on Computational Biology and Bioinformatics,"21 May 2014","2014","11","2","398","406","Large-scale comparison or similarity search of genomic DNA and protein sequence is of fundamental importance in modern molecular biology. To perform DNA and protein sequence similarity search efficiently, seeding (or filtration) method has been widely used where only sequences sharing a common pattern or “seed” are subject to detailed comparison. Therefore these methods trade search sensitivity with search speed. In this paper, we introduce a new seeding method, called spaced $k$-mer neighbors, which provides a better tradeoff between the sensitivity and speed in protein sequence similarity search. With the method of spaced $k$-mer neighbors, for each spaced $k$-mer, a set of spaced $k$-mers is selected as its neighbors. These pre-selected spaced $k$-mer neighbors are then used to detect hits between query sequence and database sequences. We propose an efficient heuristic algorithm for the spaced neighbor selection. Our computational experimental results demonstrate that the method of spaced $k$-mer neighbors can improve the overall tradeoff efficiency over existing seeding methods.","1557-9964","","10.1109/TCBB.2014.2306831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6744614","Spaced seeds;homology search;similarity search","Sensitivity;Proteins;Amino acids;Databases;DNA;Bioinformatics;Frequency modulation","Algorithms;Animals;Computational Biology;Drosophila;Humans;Mice;Proteins;Sequence Analysis, Protein;Sequence Homology, Amino Acid;Software","4","","23","IEEE","19 Feb 2014","","","IEEE","IEEE Journals"
"Measuring semantic similarity by contextualword connections in Chinese news story segmentation","X. Nie; W. Feng; L. Wan; L. Xie","School of Computer Science and Technology, School of Computer Software, School of Computer Software, Tianjin University, Tianjin, China; Tianjin University, Tianjin, Tianjin, CN; Tianjin University, Tianjin, Tianjin, CN; School of Computer Science, Northwestern Polytechnical University, Xian, China","2013 IEEE International Conference on Acoustics, Speech and Signal Processing","21 Oct 2013","2013","","","8312","8316","A lot of recent work in story segmentation focuses on developing better partitioning criteria to segment news transcripts into sequences of topically coherent stories, while simply relying on the repetition based hard word-level similarities and ignoring the semantic correlations between different words. In this paper, we propose a purely data-driven approach to measuring soft semantic word- and sentence-level similarity from a given corpus, without the guidance of linguistic knowledge, ground-truth topic labeling or story boundaries. We show that contextual word connections can help to produce semantically meaningful similarity measurement between any pair of Chinese words. Based on this, we further use a parallel all-pair SimRank algorithm to propagate such contextual similarities throughout the whole vocabulary. The resultant word semantic similarity matrix is then used to refine the classical cosine similarity measurement of sentences. Experiments on benchmark Chinese news corpora show that, story segmentation using the proposed soft semantic similarity measurement can always produce better segmentation accuracy than using the hard similarity. Specifically, we can achieve 3%-10% average F1-measure improvement to state-of-the-art NCuts based story segmentation.","2379-190X","978-1-4799-0356-6","10.1109/ICASSP.2013.6639286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6639286","Semantic similarity;contextual word connections;similarity propagation;story segmentation","Semantics;Educational institutions;Vocabulary;Measurement;Benchmark testing;Accuracy;Correlation","","5","","12","IEEE","21 Oct 2013","","","IEEE","IEEE Conferences"
"Finding Causally Different Tests for an Industrial Control System","C. M. Poskitt; Y. Chen; J. Sun; Y. Jiang","Singapore Management University, Singapore; ShanghaiTech University, China; Singapore Management University, Singapore; Tsinghua University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2578","2590","Industrial control systems (ICSs) are types of cyber-physical systems in which programs, written in languages such as ladder logic or structured text, control industrial processes through sensing and actuating. Given the use of ICSs in critical infrastructure, it is important to test their resilience against manipulations of sensor/actuator inputs. Unfortunately, existing methods fail to test them comprehensively, as they typically focus on finding the simplest-to-craft manipulations for a testing goal, and are also unable to determine when a test is simply a minor permutation of another, i.e. based on the same causal events. In this work, we propose a guided fuzzing approach for finding 'meaningfully different’ tests for an ICS via a general formalisation of sensor/actuator-manipulation strategies. Our algorithm identifies the causal events in a test, generalises them to an equivalence class, and then updates the fuzzing strategy so as to find new tests that are causally different from those already identified. An evaluation of our approach on a real-world water treatment system shows that it is able to find 106% more causally different tests than the most comparable fuzzer. While we focus on diversifying the test suite of an ICS, our formalisation may be useful for other fuzzers that intercept communication channels.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172721","Cyber-physical systems;fuzzing;test diversity;equivalence classes;causality","Integrated circuits;Process control;Communication channels;Fuzzing;Model checking;Mathematical models;Sensors","","1","","47","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Data Fusion Algorithm Based on Fuzzy Similarity Weighted Least Square for Positioning with the Global Positioning System","A. E. Abdalla; B. Shetar; M. S. Abdelwahab","Electrical Engineering Department, Miltary Technical College, Cairo, Egypt; Electrical Engineering Department, Miltary Technical College, Cairo, Egypt; Electrical Engineering Department, Miltary Technical College, Cairo, Egypt",2020 12th International Conference on Electrical Engineering (ICEENG),"27 Aug 2020","2020","","","467","470","The Global Positioning System, GPS customs solutions to determine the coordinates of the GPS receiver location and the receiver clock offset from data extracted from at least four pseudoranges. The constancy and accuracy are essential requirements in positioning calculation. The Least Squares, LS estimate has been widely used for solving GPS positioning problems. Aside its valuable properties, the LS estimate can be affected by outliers which reflect to its performance in terms of accuracy. In this paper, a new approach is applied to LS estimate to increase its accuracy and reliability. Assuming six or more satellites are observed. First, several sets of measurements are formed by making all possible combinations of observed satellites at least five satellites in each set. Second, the LS estimate approach is applied for each set of measurement to estimate the receiver position. A cluster of each set of measurements is obtained and its statistical properties mean and standard deviation are computed. Grubbs’s outlier algorithm is applied to all clusters to find the outlier measurements. The fusion of position data set is based on the fuzzy similarity between the sets of cluster position where the importance weight of each set of data is extracted. According to the proposed algorithm, software is developed using MATLAB. The proposed algorithm is tested, and the position accuracy is improved. Moreover, it reflects the efficiency and feasibility to real-time data processing and monitoring","","978-1-7281-3052-1","10.1109/ICEENG45378.2020.9171714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171714","Fusion data;Weighted least square method;GPS;Data fusion;Fuzzy Similarity;Grubbs’s Statistic;Outlier;Mean and Standard Deviation","Weight measurement;Satellites;Software algorithms;Measurement uncertainty;Clustering algorithms;Data integration;Receivers","","3","","10","IEEE","27 Aug 2020","","","IEEE","IEEE Conferences"
"VulMiningBGS: Detection of overflow vulnerabilities based on graph similarity","Z. Yu; J. Xue; X. Sun; W. Wang; Y. Song; L. Chen; Z. Qin","School of Cyber Science and Engineering Southeast University, Nanjing, China; School of Cyber Science and Engineering Southeast University, Nanjing, China; Internet Technology Center, State Grid Zhejiang Electric Power Co., Ltd. Research Institute, Hangzhou, China; Internet Department, State Grid Zhejiang Electric Power Co., Ltd., Hangzhou, China; School of Cyber Science and Engineering Southeast University, Nanjing, China; School of Cyber Science and Engineering Southeast University, Nanjing, China; School of Cyber Science and Engineering Southeast University, Nanjing, China",2022 18th International Conference on Computational Intelligence and Security (CIS),"7 Apr 2023","2022","","","386","390","The increasing number of software vulnerabilities pose serious security attacks and lead to system compromise, information leakage or denial of service. It is a challenge to further improve the vulnerability detection technique. Nowadays most applications are implemented using C/C++. In this paper we focus on the detection of overflow vulnerabilities in C/C++ source code. A novel scheme named VulMiningBGS (Vulnerability Mining Based on Graph Similarity) is proposed. We convert the source code into Top N-Weighted Range Sum Feature Graph (TN-WRSFG), and graph similarity comparisons based on source code level can be effectively carried on to detect possible vulnerabilities. Three categories of vulnerabilities in the Juliet test suite are used, i.e., CWE121, CWE122 and CWE190, with four indicators for performance evaluation (precision, recall, accuracy and F1_score). Experimental results show that our scheme outperforms the traditional methods, and is effective in the overflow vulnerability detection for C/C++ source code.","","979-8-3503-4627-5","10.1109/CIS58238.2022.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10091381","vulnerability detection;graph similarity comparison;weighted range sum feature graph","Performance evaluation;Deep learning;Source coding;Feature extraction;Software;Security;Computational intelligence","","1","","15","IEEE","7 Apr 2023","","","IEEE","IEEE Conferences"
"Study of Concept Similarity Algorithm between Steel Ontologies","Y. Hu; W. Li; S. Liu","School of Computer Science and Technology Tianjin University, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China",2012 Third World Congress on Software Engineering,"10 Jan 2013","2012","","","19","22","Concepts similarity calculation is the basis for ontology mapping. Vocabulary, meaning of the word, property and instance of concepts are the important facts when calculating concepts similarity. All the facts above are combined and a composite method is proposed to calculate concepts similarity in this paper. In order to keep the effectiveness and comprehensiveness of the method, we combine concepts vocabularies matching algorithm, synonyms basing on Word Net matching algorithm, concepts properties and instances similarities. By calculating test data, the experiment result shows that the method can calculate concepts similarity effectively between two steel ontologies.","","978-1-4673-4546-0","10.1109/WCSE.2012.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6394917","ontology;semantic distance;concept similarity","Ontologies;Vocabulary;Semantics;Educational institutions;Steel;Semantic Web","","","","7","IEEE","10 Jan 2013","","","IEEE","IEEE Conferences"
"Document clustering and topic discovery based on semantic similarity in scientific literature","J. Jayabharathy; S. Kanmani; A. A. Parveen","Department of Computer Science & Engineering, Pondicherry Engineering College, Pondicherry, India; Department of Information Technology, Pondicherry Engineering College, Pondicherry, India; Department of Computer Science & Engineering, Pondicherry Engineering College, Pondicherry, India",2011 IEEE 3rd International Conference on Communication Software and Networks,"8 Sep 2011","2011","","","425","429","Unlabeled document collections are becoming increasingly common and mining such databases becomes a major challenge. It is a major issue to retrieve relevant documents from the larger document collection. By clustering the text documents, the documents sharing similar topics are grouped together. Incorporating semantic features will improve the accuracy of document clustering methods. In order to determine at a sight whether the content of a cluster are of user interest or not, topic discovery methods are required to tag each clusters identifying distinct and representative topic of each cluster. Most of the existing topic discovery methods often assign labels to clusters based on the terms that the clustered documents contain. In this paper a modified semantic-based model is proposed where related terms are extracted as concepts for concept-based document clustering by bisecting k-means algorithm and topic detection method for discovering meaningful labels for the document clusters based on semantic similarity by Testor theory. The proposed method is compared to the Topic Detection by Clustering Keywords method using F-measure and purity as evaluation metrics. Experimental results prove that the proposed semantic-based model outperforms the existing work.","","978-1-61284-486-2","10.1109/ICCSN.2011.6014600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6014600","Document clustering;Topic discovery;Semantic similarity;Concept;Testor theory","Internet;Data mining;Information retrieval;Information services;Electronic publishing","","11","2","13","IEEE","8 Sep 2011","","","IEEE","IEEE Conferences"
"Coexistence of SCTP and TCP variants under self-similar network","L. Charoenwatana; S. Rattanabung","Department of Mathematics, Statistics, and Computer, Ubon Ratchathani University, Ubon Ratchathani, Thailand; Ubon Rajathanee University, Ubon Ratchathani, TH",2011 Eighth International Joint Conference on Computer Science and Software Engineering (JCSSE),"23 Jun 2011","2011","","","17","22","SCTP will co-exist with TCP on the Internet in a near future as its maturity progresses. Self-similarity is long known as an inherent characteristic of the IP network in which performance of SCTP under such environment is yet to be investigated. This paper reports behaviors and throughput of SCTP and TCP streams when co-existed together in the same channel under self-similar traffic environment. Simulation tests on several TCP variants including New-Reno, Reno, Tahoe, Vegas, and SACK using ns2 simulator are conducted. Results reveal that SCTP acquires averagely only 50% throughput when competing with TCP. Although found that self-similarity does not extensively distort SCTP-TCP performance, it, nevertheless, offers indirect advantage to SCTP in gaining throughput proportion against TCP.","","978-1-4577-0687-5","10.1109/JCSSE.2011.5930082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5930082","Network Protocol;TCP;SCTP;Self-Similarity","","","2","","17","IEEE","23 Jun 2011","","","IEEE","IEEE Conferences"
"A concept similarity computation based on multi-property ontology","Y. Xiquan; C. Xin; J. Na","Department of Computer Science and Technology, College of Humanities & Sciences, Northeast Normal University, Changchun, Jilin, China; School of Computer Science and Information Technology, Northeast Normal University, Changchun, Jilin, China; School of Computer Science and Information Technology, Northeast Normal University, Changchun, Jilin, China",The 2nd International Conference on Software Engineering and Data Mining,"9 Aug 2010","2010","","","538","543","In this paper, we propose a method of concept similarity calculation based on multi-property ontology, in which the relationship among properties is established under the evolutionary and taxonomy theory. In order to test the accuracy of our concept similarity calculation, we build a model of the multi-property tea ontology at first. Then, to study the tea ontology properties evolution method, we provide property weight priority algorithms. Finally by comparing our calculating result with that in the other three methods, we safely conclude that our calculating accuracy is extremely high, and the result agree with opinions of tea experts.","","978-89-88678-22-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5542864","concept similarity measure;multi-property feature;tea ontology","Ontologies;Computer science;Taxonomy;Information technology;Educational institutions;Testing;Accuracy;Computer architecture;Grid computing;Semantic Web","","","2","14","","9 Aug 2010","","","IEEE","IEEE Conferences"
"Integrating Personality and Learning Profiles of Students in Formative Course Evaluation System for Gaining Insights on Diversity and Improving Learner Experience Analytics Dashboard","J. Wu; M. S. Khalid","Department of Computer Science, Technical University of Denmark, Copenhagen, Denmark; Department of Computer Science, Technical University of Denmark, Copenhagen, Denmark","2024 International Conference on Advances in Computing, Communication, Electrical, and Smart Systems (iCACCESS)","22 Apr 2024","2024","","","1","8","The study address the scarcity of empirical design research on personalized feedback analytics in higher education. It focuses on the redesign and testing of a prototype, aiming to tackle the design dilemmas associated with personality profiles and personalized analytics for both teachers and stu-dents. Building upon the existing Wyblo App, the click-through prototype integrates VARK and MBTI models for learning preferences and personality analysis. Employing a design thinking methodology and a mixed-methods approach, the research defined requirements through interviews, surveys, and existing literature. The prototype's interfaces provided teachers with personality and learning preferences-based feedback analysis, aiding in pedagogical decisions. For students, the analytics offered personalized insights and recommendations compared to peers. The positive feedback from initial testing served as anecdotal evidence, emphasizing the need for broader, authentic testing for reliable generalization. The study envisions inspiring learning technology designers to incorporate personalized insights into course evaluation analytics, fostering reflective practices for both students and teachers based on individualized learning preferences and teaching approaches.","","979-8-3503-5028-9","10.1109/iCACCESS61735.2024.10499505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10499505","Formative evaluation;Personalized feedback;Learning preference;Personality test;Analytics dashboard","Surveys;Analytical models;Education;Buildings;Prototypes;Reliability;Interviews","","","","43","IEEE","22 Apr 2024","","","IEEE","IEEE Conferences"
"The Application of Levenshtein Algorithm in the Examination of the Question Bank Similarity","M. -M. Shao; D. -M. Qian","TianShi Coll., Tianjin, China; TianShi Coll., Tianjin, China",2016 International Conference on Robots & Intelligent System (ICRIS),"5 Dec 2016","2016","","","422","424","The question database similarity detection is a test that can quickly in the huge, find the similarity is very high, which questions repeated also need screening. General use Excel API JAVA program with the distance editing algorithm, to achieve a direct access to the excel question bank. In designing a question bank repeated questions detection algorithm, we have found that based on the Levenshtein algorithm often appear memory overrun and unable to output, to improve exam similarity detection efficiency brings great negative effect. Through the actual operation of the study, using the string segmentation and increase the control statement can be very good to improve the problem, to improve the test efficiency is very favorable.","","978-1-5090-4155-8","10.1109/ICRIS.2016.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7757159","Levenshtein Algorithm;Item Bank;Similarity Measure","Robots;Intelligent systems","","5","","6","IEEE","5 Dec 2016","","","IEEE","IEEE Conferences"
"Automatically Identifying Shared Root Causes of Test Breakages in SAP HANA","G. An; J. Yoon; J. Sohn; J. Hong; D. Hwang; S. Yoo","School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; SnT, University of Luxembourg, Luxembourg; SAP Labs Korea, Seoul, Republic of Korea; SAP Labs Korea, Seoul, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),"17 Jun 2022","2022","","","65","74","Continuous Integration (CI) of a largescale software system such as SAP HANA can produce a non-trivial number of test breakages. Each breakage that newly occurs from daily runs needs to be manually inspected, triaged, and eventually assigned to developers for debugging. However, not all new breakages are unique, as some test breakages would share the same root cause; in addition, human errors can produce duplicate bug tickets for the same root cause. An automated identification of breakages with shared root causes will be able to significantly reduce the cost of the (typically manual) post-breakage steps. This paper investigates multiple similarity functions between test breakages to assist and automate the identification of test breakages that are caused by the same root cause. We consider multiple information sources, such as static (i.e., the code itself), historical (i.e., whether the test results have changed in a similar way in the past), as well as dynamic (i.e., whether the coverage of test cases are similar to each other), for the purpose of such automation. We evaluate a total of 27 individual similarity functions, using realworld CI data of SAP HANA from a six-month period. Further, using these individual similarity functions as in-put features, we construct a classification model that can predict whether two test breakages share the same root cause or not. When trained using ground truth labels extracted from the issue tracker of SAP HANA, our model achieves an F1 score of 0.743 when evaluated using a set of unseen test breakages collected over three months. Our results show that a classification model based on test similarity functions can successfully support the bug triage stage of a CI pipeline.","","978-1-6654-9590-5","10.1145/3510457.3513051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793878","Continuous Integration;Test Similarity;Root Cause Analysis","Root cause analysis;Pipelines;Computer bugs;Debugging;Manuals;Predictive models;Feature extraction","","1","","44","","17 Jun 2022","","","IEEE","IEEE Conferences"
"NiCad+: Speeding the Detecting Process of NiCad","C. Feng; T. Wang; J. Liu; Y. Zhang; K. Xu; Y. Wang","National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China; National Laboratary for Parallel and Distributed Processing, College of Computer, National University of Defense Technology, Changsha, China",2020 IEEE International Conference on Service Oriented Systems Engineering (SOSE),"1 Sep 2020","2020","","","103","110","With the development of the Internet and the construction of open source software communities, there has been a surge in open source software. Code Reuse—copy-past and modify open source code, which becomes a convenient choice for developers to save time and reduce labor costs. So there are more and more similar code fragments, code clones, in code project as a popular phenomenon. The code clone may import uncertainties into the program, which is a hot spot for urgent exploration. This paper summarized code clone detection tools and techniques in four categories at present and introduced one detection tool, NiCad, with high recall and precision. However, NiCad is not perfect for large-scale code clone detection scenarios, because NiCad is slow when dealing with large-scale of codes. Therefore, we speeded the detection process of NiCad, and and named the improved tool NiCad+. We greatly improved the efficiency of NiCad without effecting its recall and precision. The time-cost of detecting code clone was remarkable shortened by reducing the matching times. When testing with BigCloneEval, it only takes 28.43% time-cost as original NiCad. When testing with varying input sizes, the speeded detection process performs better than the original one from 10 KLoC (lines of code) to 5 MLoC.","2642-6587","978-1-7281-6972-9","10.1109/SOSE49046.2020.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183401","code clone detection, NiCad, large scale, similarity, open source software","Cloning;Tools;Open source software;Semantics;Syntactics;Heuristic algorithms","","3","","30","IEEE","1 Sep 2020","","","IEEE","IEEE Conferences"
"Evaluation of Diversity in Movie Recommendation Systems","R. Chintya; D. S. Kusumo; A. Gandhi","School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia; School of Computing, Telkom University, Bandung, Indonesia",2024 2nd International Conference on Software Engineering and Information Technology (ICoSEIT),"16 Apr 2024","2024","","","64","69","There are many movie streaming applications today, such as Netflix, Disney Hotstar, Viu, WeTV, iQiYi, and others. The application offers a variety of movies that users can watch, thus confusing users. Each user has a different interest in the content provided. Thus, it is important to use a recommendation system on platforms that provide services to users to provide satisfaction through recommendations so that users feel satisfied. Several studies have focused more on measuring the accuracy aspect of the recommendation system. In comparison, there is an aspect of the recommendation system besides accuracy, namely diversity. Diversity is an aspect that plays a role in providing various recommendations based on users and content on the platform. Evaluation of the diversity aspect of the recommendation system is carried out by implementing the K-means clustering and cosine similarity algorithms using a film dataset. Then, measure it using the Intra-list diversity metric and get a result of 0.65. Tests on users were also carried out regarding user satisfaction with the list of films using a questionnaire so that the median value was 4, and the mode value was between 4 and 5. From the results of the evaluation, it was found that the recommendations provided were diverse and satisfactory for users.","","979-8-3503-1750-3","10.1109/ICoSEIT60086.2024.10497505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10497505","recommendation system;diversity;user satisfaction","Measurement;Clustering algorithms;Motion pictures;Real-time systems;Information technology;Recommender systems;Testing","","","","20","IEEE","16 Apr 2024","","","IEEE","IEEE Conferences"
"Research on the parallel algorithm for self-similar network traffic simulation","H. Zhang; J. Xu; J. Tian","Institute of Machine Intelligence, Nankai University, Tianjin, China; Institute of Machine Intelligence, Nankai University, Tianjin, China; Institute of Machine Intelligence, Nankai University, Tianjin, China",2009 2nd IEEE International Conference on Computer Science and Information Technology,"11 Sep 2009","2009","","","355","359","As the Web application is world wide used, system' s performance, especially reliability, becomes more significant. Traditional performance testing tools such as QA Load and LoadRunner will generate the stress data with the fixed scale. But in the real time, network traffic is model-based. We focus on generating test data to simulate network traffic accurately for Web application reliability testing. The statistical results of network traffic show that the property of the self-similarity is ubiquitous in Web environment. So generating self-similar network traffic is demanded. But nowadays, there is a bottleneck in generating network traffic by single computer. We need a parallel method to solve this problem. In this paper we propose a distributed system based on a parallel algorithm to generate self-similar traffic using the Fraction Gaussian Noise (FGN) model. The experiment results show that the network traffic generated by the distributed system has self-similar property.","","978-1-4244-4519-6","10.1109/ICCSIT.2009.5234666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234666","Parallel Algorithm;Distributed System;Generating Network Traffic;Self-similar Model","Parallel algorithms;Telecommunication traffic;Traffic control;Testing;Stress;Computational modeling;Application software;Computer network reliability;Computer networks;Pervasive computing","","1","","6","IEEE","11 Sep 2009","","","IEEE","IEEE Conferences"
"Exploiting Wireless Links Diversity in Software-Defined IEEE 802.11 Enterprise Wlan","M. F. Monir; F. Granelli","Dept. of Computer Science and Engineering, Independent University, Bangladesh Dhaka, Bangladesh; Dept. of Information Engineering and Computer Science, University of Trento (UniTrento), Trento, Italy",GLOBECOM 2020 - 2020 IEEE Global Communications Conference,"25 Jan 2021","2020","","","1","6","Adoption of wireless technologies is rising dramatically. As traffic load is continuously rising with the rapid growth of user scale and mobile services, today's Wireless Local Area Network (WLAN) enterprise is facing a series of crucial challenges such as packet loss, interference, poor bandwidth etc. This is because of the inherent design of the IEEE 802.11 architecture. Enabling Software Defined Networking (SDN) in Wi-Fi enterprise would solve the puzzle of current WLAN technology limitations and ensure high scalability and performance. While standardization is focusing on performance enhancement by evolving the Wi-Fi MAC/PHY protocols, in this work we focus on bandwidth optimization in IEEE S02.11 by using Software Defined Networking (SDN). We analyze various programming abstractions for WLANs and exploit the wireless link diversity in Software Defined Enterprise-WLAN with the support of the 5GEMPOWERSDN platform. A multiple uplink mechanism between user devices and Access Points (APs) is proposed that allows a remarkable performance improvement in the network in terms of throughput and packet delivery ratio.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9322469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9322469","Software Defined Networking (SDN);Software Defined Wireless Networks (SDWN);WLANs;network performance;programming abstractions","Uplink;Wireless fidelity;Wireless communication;Wireless networks;Programming;IEEE 802.11 Standard;Throughput","","2","","14","IEEE","25 Jan 2021","","","IEEE","IEEE Conferences"
"A methodology for using edges to measure structural and semantic similarity of XML documents","Hong-Jun Qiu; Wen-Jing Yu","School of Engineering, Shantou University, Shantou, China; South China Institute of Software Engineering, GZU, Guangzhou, China",2009 International Conference on Machine Learning and Cybernetics,"25 Aug 2009","2009","3","","1653","1658","XML is a standard data representation format that comes with its own structure and semantics. The similarity measurement of XML should include data, structure and semantics, but the semantic measurement has not yet received strong attention. Aiming at the product structure domain, a methodology for using edges to measure structural and semantic similarity of XML is presented in this paper. Based on the semantics of product structure described in XML, the edge constraint is used to improve the structural similarity efficiency. An effective weight mechanism interrelated with XML model hiberarchy is adopted to address the semantics problem, to enhance the similarity precision. The implement pseudocode is presented. The experimental tests demonstrate that the proposed method can efficiently measure the structural and semantic similarity of product structures described in XML.","2160-1348","978-1-4244-3702-3","10.1109/ICMLC.2009.5212295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5212295","XML;Product structure;Structural and semantic similarity;Measurement","XML;Machine learning algorithms;Machine learning;Cybernetics;Data engineering;Computational complexity;Assembly;Software measurement;Measurement standards;Software standards","","","","8","IEEE","25 Aug 2009","","","IEEE","IEEE Conferences"
"Diversity TMR: Proof of concept in a mixed-signal case","G. de M. Borges; L. F. Gonçalves; T. R. Balen; M. Lubaszewski","Departamento de Engenharia Elétrica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil; Departamento de Engenharia Elétrica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil; Departamento de Engenharia Elétrica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil; Departamento de Engenharia Elétrica, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande do Sul, Brazil",2010 11th Latin American Test Workshop,"19 Aug 2010","2010","","","1","6","In this paper a design diversity fault tolerance technique is applied to a mixed-signal (MS) system. Three different implementations of a second order low-pass filter (which perform the same transfer function) associated to a majority voter are used to build the TMR scheme. The whole system is prototyped by using a programmable mixed-signal device. Some functional faults are injected into the circuit blocks and practical measurements are made on the prototyped system. Results show that the design diversity TMR is a feasible technique that can increase reliability of some classes of state-of-art MS circuits.","2373-0862","978-1-4244-7785-2","10.1109/LATW.2010.5550343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5550343","fault tolerance;mixed-signal;redundancy;design diversity","Low pass filters;Tunneling magnetoresistance;Software;Circuit faults;Hardware;Finite impulse response filter","","4","","17","IEEE","19 Aug 2010","","","IEEE","IEEE Conferences"
"Dual downlink signals level balancing methodology for LTE user equipment test conformance","G. S. Lau; R. B. Ahmad","School of Computer & Communication Engineering, University Malaysia Perlis, Arau, Perlis, Malaysia; School of Computer & Communication Engineering, University Malaysia Perlis, Arau, Perlis, Malaysia","2016 International Conference on Robotics, Automation and Sciences (ICORAS)","9 Mar 2017","2016","","","1","5","Receiver diversity related conformance tests of 2G/3G cellular devices either with multipath propagation or not typically would utilize RF channel emulator (or RF fader) to balance the dual downlink signal levels before reception by dual receiver antennas of device. The RF fader has capability to close loop output power level, so it allows user to set the desired output level. With this capability, dual downlink signal inputs into the fader can be level adjusted in order to get the balance and similar output level of both signals from fader. For receiver diversity tests with only static propagation which is default to LTE device, since it is in static propagation, fader would be underutilized for only diversity purpose. To be cost save, such balancing approach could be alternatively replaced with discrete components and software algorithm. A new setup is designed with this approach to balance the dual downlink levels in order to comply the receiver test conformance. This paper will describe about the methodology.","","978-1-5090-6205-8","10.1109/ICORAS.2016.7872613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872613","LTE;Dual Downlink;Balancing;User equipment;Receiver diversity","Attenuators;Receivers;Downlink;Attenuation;Radio frequency;Switches;Software","","","","5","IEEE","9 Mar 2017","","","IEEE","IEEE Conferences"
"Data diverse fault tolerant architecture for component based systems","A. Sil; O. Bandyopadhyay; N. Chaki","National Institute of Technical Teacher''s Training and Research, Kolkata, India; National Institute of Technical Teacher''s Training and Research, Kolkata, India; University of Calcutta, Kolkata, India",2009 World Congress on Nature & Biologically Inspired Computing (NaBIC),"22 Jan 2010","2009","","","942","946","Of late, component based software design has become a major focus in software engineering research and computing practice. These software components are used in a wide range of applications some of which may have mission critical requirements. In order to achieve required level of reliability, these component-based designs have to incorporate special measures to cope up with software faults. This paper presents a fault tolerant component based data driven architecture that is based on C2 architectural framework and implements data diverse fault tolerance strategies. The proposed design makes a trade-off between platform flexibility, reliability and efficiency at run time and exhibits its ability to tolerate faults in a cost effective manner. Application of proposed design is exhibited with a case study.","","978-1-4244-5053-4","10.1109/NABIC.2009.5393876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5393876","","Fault tolerant systems;Connectors;Fault tolerance;Mission critical systems;Computer architecture;Software design;Costs;Testing;Software engineering;Application software","","1","","15","IEEE","22 Jan 2010","","","IEEE","IEEE Conferences"
"The Impact of Diversity on Online Ensemble Learning in the Presence of Concept Drift","L. L. Minku; A. P. White; X. Yao","Centre of Excellence of Research in Computational Intelligence and Applications (CERCIA), School of Computer Science, University of Binningham, Birmingham, UK; School of Mathematics and Statistics, University of Binningham, Birmingham, UK; Centre of Excellence of Research in Computational Intelligence and Applications (CERCIA), School of Computer Science, University of Binningham, Birmingham, UK",IEEE Transactions on Knowledge and Data Engineering,"18 Mar 2010","2010","22","5","730","742","Online learning algorithms often have to operate in the presence of concept drift (i.e., the concepts to be learned can change with time). This paper presents a new categorization for concept drift, separating drifts according to different criteria into mutually exclusive and nonheterogeneous categories. Moreover, although ensembles of learning machines have been used to learn in the presence of concept drift, there has been no deep study of why they can be helpful for that and which of their features can contribute or not for that. As diversity is one of these features, we present a diversity analysis in the presence of different types of drifts. We show that, before the drift, ensembles with less diversity obtain lower test errors. On the other hand, it is a good strategy to maintain highly diverse ensembles to obtain lower test errors shortly after the drift independent on the type of drift, even though high diversity is more important for more severe drifts. Longer after the drift, high diversity becomes less important. Diversity by itself can help to reduce the initial increase in error caused by a drift, but does not provide the faster recovery from drifts in long-term.","1558-2191","","10.1109/TKDE.2009.156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5156502","Concept drift;online learning;neural network ensembles;diversity.","Machine learning;Testing;Application software;Training data;Information filtering;Industrial training;Neural networks;Time factors;Computer industry;Industrial control","","325","","51","IEEE","6 Jul 2009","","","IEEE","IEEE Journals"
"Feedback-directed exploration of web applications to derive test models","A. M. Fard; A. Mesbah","University of British Columbia Vancouver, BC, Canada; University of British Columbia Vancouver, BC, Canada",2013 IEEE 24th International Symposium on Software Reliability Engineering (ISSRE),"2 Jan 2014","2013","","","278","287","Dynamic exploration techniques play a significant role in automated web application testing and analysis. However, a general web application crawler that exhaustively explores the states can become mired in limited specific regions of the web application, yielding poor functionality coverage. In this paper, we propose a feedback-directed web application exploration technique to derive test models. While exploring, our approach dynamically measures and applies a combination of code coverage impact, navigational diversity, and structural diversity, to decide a-priori (1) which state should be expanded, and (2) which event should be exercised next to maximize the overall coverage, while minimizing the size of the test model. Our approach is implemented in a tool called FEEDEx. We have empirically evaluated the efficacy of FEEDEx using six web applications. The results show that our technique is successful in yielding higher coverage while reducing the size of the test model, compared to classical exhaustive techniques such as depth-first, breadth-first, and random exploration.","2332-6549","978-1-4799-2366-3","10.1109/ISSRE.2013.6698880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698880","model generation;web app;coverage;testing;diversity","Portable document format;IEEE Xplore","","22","1","","IEEE","2 Jan 2014","","","IEEE","IEEE Conferences"
"Analysis of Automated Evaluation for Multi-document Summarization Using Content-Based Similarity","L. -Q. Qiu; B. Pang","State Key Laboratory of Software Development Environment, Beihang University, China; State Key Laboratory of Software Development Environment, Beihang University, China",Second International Conference on the Digital Society,"25 Feb 2008","2008","","","60","63","We introduce an automated evaluation method based on content similarity, and construct a vector space of words, on which we compute cosine similarity of automated summaries and human summaries. The method is tested on DUC 2005 data, and produces acceptable results, which may avoid some shortcomings of n-gram. We also test the effects of stopwords and stemming.","","978-0-7695-3087-1","10.1109/ICDS.2008.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4456020","automated evaluation;multi-document summarization;content -based similarity","Humans;Testing;NIST;Functional analysis;Programming;Vocabulary;Natural languages;Performance evaluation;Costs;Large-scale systems","","","","5","IEEE","25 Feb 2008","","","IEEE","IEEE Conferences"
"Harfu Jar Detection System In Al-Quran Using Pierce Similarity Algorithm as a Basic Learning Media of Arabic Language","M. Jannah; A. A. Nababan","Software Engineering, STMIK Pelita Nusantara Medan, Indonesia; Software Engineering, STMIK Pelita Nusantara Medan, Indonesia","2020 3rd International Conference on Mechanical, Electronics, Computer, and Industrial Technology (MECnIT)","14 Aug 2020","2020","","","349","354","Arabic language has a very broad language structure, we need to know the most dominant Arabic language found in the Al-Quran, so to know the interpretation (Tafsir) of the Al-Quran, we must learn Arabic language. One of the basic parts of Arabic language is nahwu science, nahwu is the study of laying row in Arabic such as the kasra, dhamma and fatta. Jar letters is one of basic part in nahwu science. In this research, a detection system about Jar patterns will be developed with image processing approach. This system was built using Delphi XE with 7 sample of Jar letters where it will be used in the training process. The process of detecting Jar patterns is using a method that will find the distance value from training and testing process on the Al-Quran image. Training process stage begins with the bitmap extension file of the original image,then change the size to gray scale level and convolution edge detection so that it will produce a vector value for each Jar pattern. Testing process will be use the Pierce Similarity Algorithm to measure the distance value of the Jar pattern to be recognized. The percentage of system detection results obtained, the pierce similarity method is able to recognize a Jar pattern of 60-80%.","","978-1-7281-7403-7","10.1109/MECnIT48290.2020.9166632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166632","Image Processing;Pattern Recognition;Pierce Similarity;Jar Letter","","","","","16","IEEE","14 Aug 2020","","","IEEE","IEEE Conferences"
"LASSO Based Similarity Learning of Near-Infrared Spectra for Quality Control","J. Huo; C. Li; H. Wang; H. Li","School of Electrical Engineering, Zhengzhou University, Zhengzhou, China; China Tobacco Henan Industrial Co., Ltd, Zhengzhou, China; China Tobacco Henan Industrial Co., Ltd, Zhengzhou, China; China Tobacco Henan Industrial Co., Ltd, Zhengzhou, China",2020 IEEE 11th International Conference on Software Engineering and Service Science (ICSESS),"4 Nov 2020","2020","","","424","427","This paper presents a novel method for quality control with similarity learning of near-infrared spectra (NIRS). The product quality is rated by measuring the similarity between the tested products and the standard. To automatic this process, we use mahalanobis distance(MahalD) as the metric to estimate the difference of the segmented NIR spectra that are measured from tobacco product samples and standard references. The features used to score the quality rate are then generated by least absolute shrinkage and selection operator(LASSO), which selects the most related wavelengths from MahalD map. The dimension-reduced MahalD map is then loaded into a more advanced regression learning, like SparseNet, Support Vector Machine(SVM) or Random Forrest(RF) to build a model for quality rate prediction. Results from these regression methods are tested and compared, which show this method is effective and LASSO feature selection can improve the prediction accuracy.","2327-0594","978-1-7281-6579-0","10.1109/ICSESS49938.2020.9237682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237682","LASSO;Mahalanobis Distance;SVM;Sparse Regression;Random Forest Regression;Quality Control","Support vector machines;Wavelength measurement;Quality control;Prediction algorithms;Feature extraction;Standards;Software engineering","","1","","24","IEEE","4 Nov 2020","","","IEEE","IEEE Conferences"
"Automated Repair of Java Programs with Random Search via Code Similarity","H. Cao; F. Liu; J. Shi; Y. Chu; M. Deng","College of Information Science and Engineering, Henan University of Technology, zhengzhou; College of Information Science and Engineering, Henan University of Technology, zhengzhou; College of Information Science and Engineering, Henan University of Technology, zhengzhou; College of Information Science and Engineering, Henan University of Technology, zhengzhou; College of Information Science and Engineering, Henan University of Technology, zhengzhou","2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)","1 Apr 2022","2021","","","470","477","Automatic program repair is a cutting-edge research direction in software engineering in recent years. The existing program repair techniques based on genetic programming suffer from requiring verification of a large number of candidate patches, which consume a lot of computational resources. We instead propose Random search via Code Similarity based automate program Repair (RCSRepair). First, we use test filtering and test case prioritization techniques in fault localization to reduce and restructure test cases. Second, a combination of random search and code similarity is used to generate patches. Finally, overfitting detection is performed on the patches that pass the test cases to improve the quality of the patch. The experimental results show that our approach can successfully fix 54 bugs of 224 real-world bugs in Defects4J and has outperform the compared approaches.","2693-9371","978-1-6654-7836-6","10.1109/QRS-C55045.2021.00075","National Natural Science Foundation of China(grant numbers:61602154,61340037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9742203","program repair;random search;test case prioritization;patch overfitted","Java;Software maintenance;Codes;Filtering;Computer bugs;Software quality;Maintenance engineering","","1","","19","IEEE","1 Apr 2022","","","IEEE","IEEE Conferences"
"Researches of Sentence Similarity Computation Method Based on the Enhanced Petri Net","F. Chen; W. Chen","Computer Teaching and Experiment Center, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Computer Teaching and Experiment Center, Xi'an Jiaotong University, Xi'an, Shaanxi, China",2009 International Conference on Computational Intelligence and Software Engineering,"28 Dec 2009","2009","","","1","5","In the field of natural language processing (NPL), sentence similarity computation has a wide application. The key of sentence similarity computation is to grasp the characteristics and the meaning of the sentence quickly and accurately. In this paper, we present a new and advanced sentence similarity computation model based on the enhanced Petri net, which is mainly for the Chinese sentence. The basic idea of this model is utilizing semantic properties to expand the Petri net and reconstruct Petri net to an opening structure. The deduction method of this model is equation of state, which make the judgment of sentence similarity closer to the process of human thought. Moreover, we have tested the sentence similarity computation methods and algorithms. It proves that this method covers most aspects of sentence similarity computation and has a superior performance during experiments.","","978-1-4244-4507-3","10.1109/CISE.2009.5363839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363839","","Humans;Education;Equations;Uncertainty;Abstracts;Natural language processing;Application software;Computational modeling;Testing;Statistics","","","","8","IEEE","28 Dec 2009","","","IEEE","IEEE Conferences"
"An Application of Multicriteria Weighted Graph Similarity Method to Social Networks Analyzing","Z. Tarapata; R. Kasprzyk","Faculty of Cybernetics, Military University of Technology, Warsaw, Poland; Faculty of Cybernetics, Military University of Technology, Warsaw, Poland",2009 International Conference on Advances in Social Network Analysis and Mining,"4 Sep 2009","2009","","","366","368","In the paper a concept of multicriteria weighted graphs similarity (MWGSP) method and its application to examine some properties of social networks is considered. The approach extends known approaches based on the graph similarity with two features: (1) the similarity is calculated as structural and non-structural (quantitative) in weighted graph, (2) choice of the most similar graph (subgraph) to graph (subgraph) representing examined objects is based on multicriteria decision. We test our similarity measures on email network for which the expected results are known, and on the terrorist net that prepared and executed September 11, 2001 attacks.","","978-0-7695-3689-7","10.1109/ASONAM.2009.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231827","social networks;weighted graph similarity;multicriteria optimization;early warning system","Social network services;Terrorism;Chemical analysis;Paper technology;Cybernetics;Electronic mail;Testing;Computer errors;Histograms;Application software","","8","","7","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"An Approach of Semantic Similarity Measure between Ontology Concepts Based on Multi Expression Programming","S. Xia; Z. Hu; Q. Niu","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China",2009 Sixth Web Information Systems and Applications Conference,"31 Dec 2009","2009","","","184","188","To improve accuracy of semantic similarity measure between ontology concepts, four main factors that impact on semantic similarity measure is taken into account. They are semantic distance, semantic depth, semantic coincidence and semantic density. Firstly, they were preprocessed to obtain four basic methods for calculating semantic similarity. And then Multi Expression Programming algorithm was adopted to combine and optimize the four basic methods. Thus, an approach of semantic similarity measure between ontology concepts based on Multi Expression Programming is proposed. At last, the approach is tested using dataset extracted from WordNet. The experiment result shows that the approach can be able to exclude the influence of non-key factor and enhance accuracy of semantic similarity measure.","","978-0-7695-3874-7","10.1109/WISA.2009.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368079","Ontology;hierarchical structure;semantic similarity;Multi Expression Programming (MEP)","Ontologies;Evolutionary computation;Information retrieval;Information systems;Application software;Computer science;Optimization methods;Testing;Genetic programming;Information technology","","4","1","10","IEEE","31 Dec 2009","","","IEEE","IEEE Conferences"
"Two Level Question Classification Based on SVM and Question Semantic Similarity","J. Fu; Y. Qu; Z. Wang","School of Computer Science & Technology, Beijing Institute of Technology, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Mathematics and Computer Science, Harbin University, Harbin, China",2009 International Conference on Electronic Computer Technology,"27 Feb 2009","2009","","","366","370","Question classification is very important in question answering system. This paper presents our research about question classification in a real-world on-line interactive question answering system in computer service & support domain. In the domain, questions are divided into 15 cursory categories and 220 sub-categories. The difference of this system is that standard question sentences represent the subcategories rather than only classification criterion. For the special situation, the two level question classification method is present in the paper. Support vector machine method is adopted to train a classifier on coarse categories; question semantic similarity model is used to classify the question into sub-categories. The lexical feature and domain ontology concept hierarchy is constructed and exploited to enhance the expression capacity of the feature characteristic for both feature selection for SVM and question semantic similarity computing. When trained and tested on the 11000 question instances in the domain, our approach reaches an accuracy up to 91.5%, which outperforms the result of the baseline.","","978-0-7695-3559-3","10.1109/ICECT.2009.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4795985","question classification;SVM;question semantic similarity","Support vector machines;Support vector machine classification;Computer science;Ontologies;Information technology;Mathematics;Testing;Application software;Intelligent robots;Machine learning","","2","","6","IEEE","27 Feb 2009","","","IEEE","IEEE Conferences"
"When Does ""Diversity""' in Development Reduce Common Failures? Insights from Probabilistic Modeling","K. Salako; L. Strigini","Centre for Software Reliability, City University, London, United Kingdom; Centre for Software Reliability, City University, London, United Kingdom",IEEE Transactions on Dependable and Secure Computing,"9 Apr 2014","2014","11","2","193","206","Fault tolerance via diverse redundancy, with multiple ""versions""' of a system in a redundant configuration, is an attractive defence against design faults. To reduce the probability of common failures, development and procurement practices pursue ""diversity""' between the ways the different versions are developed. But difficult questions remain open about which practices are more effective to this aim. About these questions, probabilistic models have helped by exposing fallacies in ""common sense"" judgements. However, most make very restrictive assumptions. They model well scenarios in which diverse versions are developed in rigorous isolation from each other: A condition that many think desirable, but is unlikely in practice. We extend these models to cover nonindependent development processes for diverse versions. This gives us a rigorous way of framing claims and open questions about how best to pursue diversity, and about the effects--negative and positive--of commonalities between developments, from specification corrections to the choice of test cases. We obtain three theorems that, under specific scenarios, identify preferences between alternative ways of seeking diversity. We also discuss nonintuitive issues, including how expected system reliability may be improved by creating intentional ""negative""' dependences between the developments of different versions.","1941-0018","","10.1109/TDSC.2013.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6579596","Common-mode failure;software diversity;fault tolerance;multiversion software;probability of failure on demand;reliability","Phase frequency detector;Software;Reliability;Random variables;Computational modeling;Correlation;Probabilistic logic","","9","","24","IEEE","15 Aug 2013","","","IEEE","IEEE Journals"
"Detecting functionally similar code within the same project","R. Tajima; M. Nagura; S. Takada","Keio Gijuku Daigaku, Minato-ku, Tokyo, JP; Nihon Daigaku, Chiyoda-ku, Tokyo, JP; Keio Gijuku Daigaku, Minato-ku, Tokyo, JP",2018 IEEE 12th International Workshop on Software Clones (IWSC),"29 Mar 2018","2018","","","51","57","Multiple developers often take part in a software development project. Although these developers are collaborating towards the development within the same project, each developer creates code on their own. This may lead to duplicate or similar code appearing in different parts of the software. Such code should be removed to improve maintainability. This paper proposes an approach to automatically detect such code, which we shall call functionally similar code. The unit of detection is at the method level, and we focus on input/output and the method structure using program dependence graph. We show the results of applying our approach on open source software.","2572-6587","978-1-5386-6430-8","10.1109/IWSC.2018.8327319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327319","Functionally similar code detection;Random testing;Program dependence graph","Cloning;Testing;Databases;Software;Semantics;Data mining;Java","","5","","","IEEE","29 Mar 2018","","","IEEE","IEEE Conferences"
"A Weighted Raw Reputation Generating Approach Based on Similarity","J. Zhang; X. Zhang; J. Zhu; J. Xu","Dept. of Comput. Sci., Nankai Univ., Tianjin, China; Dept. of Comput. Sci., Nankai Univ., Tianjin, China; Dept. of Comput. Sci., Nankai Univ., Tianjin, China; Dept. of Comput. Sci., Nankai Univ., Tianjin, China",2010 Second International Conference on Communication Software and Networks,"25 Mar 2010","2010","","","136","140","In the anti-spam field, raw reputation is the current mailing behavior of one email server. Meanwhile, it is the foundation of the distributed spam processing technology based on reputation mechanism. In this paper, the advantages and disadvantages of the existing several raw reputation generating approaches are analyzed, and a new method: MSGuard is proposed. MSGuard is a weighted raw reputation generating approach based on similarity. Simulation results demonstrate that: in the scenario which the malicious nodes provide inauthentic evaluations, the average differences between the expectations and the raw reputations calculated by TrustGuard and MSRep are 0.4 and 0.5 respectively. And the difference of either EigenTrust or MSGuard is only approximate 0.05. In the scenario which the collusive and disguised malicious nodes exist, the difference between the expectation and the raw reputation calculated by EigenTrust is 0.25, and it is less than 0.1 by MSGuard. MSGuard can reflect nodes' actual mailing situations more accurately.","","978-1-4244-5727-4","10.1109/ICCSN.2010.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5437617","spam;raw reputation;similarity;inauthentic evaluation;weighting factor","Internet;Computer science;Network servers;Testing;Algorithm design and analysis;Arithmetic;Search engines;Protection;Feedback","","","","12","IEEE","25 Mar 2010","","","IEEE","IEEE Conferences"
"Enhancing a Keyword Search Using Segmentation and Similarity Measure Algorithms: A Case Study of Phuket Attractions","K. Chochiang; W. Khuanwilai","College of Computing, Prince of Songkla University, Phuket, Thailand; College of Computing, Prince of Songkla University, Phuket, Thailand",2019 16th International Joint Conference on Computer Science and Software Engineering (JCSSE),"14 Oct 2019","2019","","","26","31","A system to support an incorrectly typed input keyword search in Thai language is proposed in this work. Segmentation and similarity measure algorithms are employed to enhance the traditional keyword search engine. The average of six similarity measure algorithms including Levenshtein, Overlap (bi-gram), Overlap (tri-gram), Jaccard, Dice (bi-gram), and Dice (tri-gram). The prototype is tested by 93 subjects including both native and non-native Phuket subjects. Top twenty-five Phuket attraction names are used as the data set. The experimental results show that the proposed system can improve the efficiency of the original search from 54.4% to 91.6% while the execution time of the extra steps can be negligible. Moreover, Bi-gram algorithms seem to outperform their Tri-gram counterpaths in this experiment and Jaccard seems to be outperformed by other similarity measure algorithms.","2642-6579","978-1-7281-0719-6","10.1109/JCSSE.2019.8864176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864176","Search engine;Incorrect keyword;Dice;Overlap;Levenshtein;Jaccard","Keyword search;Sea measurements;Engines;Current measurement;Testing;Prototypes;Search engines","","","","12","IEEE","14 Oct 2019","","","IEEE","IEEE Conferences"
"A Divide and Conquer Approach to All Solutions Satisfiability Problem","X. Ren; W. Guo; Z. Mo; W. Tian","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China",2018 IEEE 4th International Conference on Computer and Communications (ICCC),"1 Aug 2019","2018","","","2590","2595","SAT, is one of the fundamental topics in computer science, which has a long history in AI. As a variant of SAT, the all solutions satisfiability problem(AllSAT) is widely used in the field of electronic design automation. It is to generate all or part solutions of a given SAT instance. The computational complexity of AllSAT is higher than general SAT, which leads to less research related and poor performance of existing AllSAT solvers. In this paper, we propose to solve AllSAT by a divide-and-conquer-based approach called DIV2, which solve more instances within the time limit. Besides, we present a segmentation strategy for DIV2, called Jaccard similarity segmentation, which improves the efficiency of DIV2. The experimental result shows that the method proposed in this paper, has a better performance than the state-of-the-art algorithms, with regarding to the number of instances solved and the total number of solutions found for SAT 2014 competition benchmark.","","978-1-5386-8339-2","10.1109/CompComm.2018.8780746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780746","Satisfiability problem;AllSAT solvers;Divide and Conquer;Similarity Segmentation;Jaccard similarity coefficient","Computational complexity;IEEE Sections;Software engineering;Computer science;Design automation;Benchmark testing","","3","","22","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"COSMOS — An innovative nodal architecture for controlling large numbers of small satellites and other diverse assets","T. Sorensen; E. Pilger; M. Nunes","Interstel Technologies, Inc., Honolulu, HI, USA; Interstel Technologies, Inc., Honolulu, HI, USA; Interstel Technologies, Inc., Honolulu, HI, USA",2015 7th International Conference on Recent Advances in Space Technologies (RAST),"20 Aug 2015","2015","","","385","389","The Hawaii Space Flight Laboratory (HSFL) at the University of Hawaii at Manoa developed the Comprehensive Open-architecture Solution for Mission Operations Systems (COSMOS) under a three-year NASA grant. This innovative suite of software and hardware was initially designed for supporting the operations of multiple small satellites, but during its development, it evolved into a comprehensive system of systems that is capable of providing nearly all operations functions to support an integrated system of objects to be monitored and controlled, called nodes. These nodes are not limited to spacecraft, but can be almost any type of vehicle or electronic entity that has communication connectivity with the distributed COSMOS system. Even the vehicles themselves can operate COSMOS as their onboard controlling software. HSFL built a 55-kg satellite called Hiakasat that is due to launch on the ORS-4 mission in 2015. This satellite uses COSMOS for its onboard flight software, which integrates seamlessly with the COSMOS system that is being used to operate the mission on the ground. COSMOS is currently being used to monitor research ship gathering data, and even controlling rovers on simulated lunar missions. This innovative nodal architecture will allow a fully integrated system that can combine satellites with UAVs, submersible, ships, and other robotic craft.","","978-1-4799-7697-3","10.1109/RAST.2015.7208374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7208374","mission operations;spacecraft software;system of systems;nodal architecture","Satellites;Software;Monitoring;Space vehicles;Computer architecture;Space missions","","","","8","IEEE","20 Aug 2015","","","IEEE","IEEE Conferences"
"The Behavioral Diversity of Java JSON Libraries","N. Harrand; T. Durieux; D. Broman; B. Baudry","EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden; EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden; EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden; EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden",2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE),"11 Feb 2022","2021","","","412","422","JSON is an essential file and data format in domains that span scientific computing, web APIs or configuration management. Its popularity has motivated significant software development effort to build multiple libraries to process JSON data. Previous studies focus on performance comparison among these libraries and lack a software engineering perspective. We present the first systematic analysis and comparison of the input / output behavior of 20 JSON libraries, in a single software ecosystem: Java/Maven. We assess behavior diversity by running each library against a curated set of 473 JSON files, including both well-formed and ill-formed files. The main design differences, which influence the behavior of the libraries, relate to the choice of data structure to represent JSON objects and to the encoding of numbers. We observe a remarkable behavioral diversity with ill-formed files, or corner cases such as large numbers or duplicate data. Our unique behavioral assessment of JSON libraries paves the way for a robust processing of ill-formed files, through a multi-version architecture.","2332-6549","978-1-6654-2587-2","10.1109/ISSRE52982.2021.00050","Swedish Foundation for Strategic Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700248","JSON;Java;Behavioral Diversity","Java;Systematics;Scientific computing;Data structures;Libraries;Software;Software reliability","","2","","44","IEEE","11 Feb 2022","","","IEEE","IEEE Conferences"
"Assessing Air-Interface Dataset Similarity and Diversity for AI-Enabled Wireless Communications","H. Tang; L. Yang; R. Zhou; J. Liang; H. Wei; X. Wang; Q. Shi; Z. -Q. Luo","Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China; Wireless Research Department, Huawei Company, Shanghai, China; Wireless Research Department, Huawei Company, Shanghai, China; Wireless Research Department, Huawei Company, Shanghai, China; School of Software Engineering, Tongji University, Shanghai, China; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China",2024 IEEE International Conference on Communications Workshops (ICC Workshops),"12 Aug 2024","2024","","","1623","1628","Ahstract- The integration of artificial intelligence (AI) into wireless communication systems is set to profoundly transform the design and optimization of emerging sixth-generation (6G) networks. The success of AI-driven wireless systems hinges on the quality of the air-interface data, which is fundamental to the performance of AI algorithms. Within data quality assessment (DQA), the measurement of similarity and diversity stands as crucial. Similarity assesses the consistency of datasets in mirroring their intrinsic statistical properties, which is essential for AI model accuracy. In contrast, diversity relates to the models' ability to generalize across various contexts. This paper concentrates on these aspects of DQA and proposes a comprehensive framework for analyzing similarity and diversity in wireless air-interface data. Catering to various data types, such as channel state information (CSI), signal-to-interference-plus-noise ratio (SINR), and reference signal received power (RSRP), the framework is validated using CSI data. Through this validation, we demonstrate the framework's efficacy in improving CSI compression and recovery in Massive Multiple-Input Multiple-Output (MIMO) systems, highlighting its significance and versatility in complex wireless network environments.","2694-2941","979-8-3503-0405-3","10.1109/ICCWorkshops59551.2024.10615485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10615485","Data quality assessment;AI-enabled wireless communication;similarity;diversity","Wireless communication;Data integrity;Conferences;Atmospheric modeling;Wireless networks;Transforms;Artificial intelligence","","","","30","IEEE","12 Aug 2024","","","IEEE","IEEE Conferences"
"Formal Analysis of Timing Diversity for Autonomous Systems","A. Christmann; R. Hapka; R. Ernst","Institute of Computer and Network Engineering, Technische Universität Braunschweig, Germany; Institute of Computer and Network Engineering, Technische Universität Braunschweig, Germany; Institute of Computer and Network Engineering, Technische Universität Braunschweig, Germany","2023 Design, Automation & Test in Europe Conference & Exhibition (DATE)","2 Jun 2023","2023","","","1","6","The design of autonomous systems, such as for automated driving and avionics, is challenging due to high performance requirements combined with high criticality. Complex applications demand the full performance of commercial high performance multi-core systems of-the-shelf (COTS), with or without accelerators. While these systems are optimized for performance, hard real-time requirements and deterministic timing behavior are major constraints for safety-critical systems. Unfortunately, infrequent timing outliers caused by interleaved hardware-software effects of COTS systems complicate traditional worst-case design. This conflict often prohibits deploying COTS hardware and consequently prevents sophisticated applications, too. Recently, an approach called Timing Diversity was introduced, which proposes to exploit existing dual modular redundant hardware platforms to mask deadline violations. This paper puts Timing Diversity on a theoretical foundation and provides specification for different implementations. It demonstrates that Timing Diversity needs fast recovery to be effective, proposes a recovery strategy and provides a mathematical model for the reliability of the resulting system. Using experimental data in a Linux based system, it shows that fast recovery is useful, making Timing Diversity a realistic option for compute demanding hard real-time applications.","1558-1101","979-8-3503-9624-9","10.23919/DATE56975.2023.10137030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10137030","","Autonomous systems;Reliability theory;Software;Hardware;Real-time systems;Mathematical models;Timing","","1","","16","","2 Jun 2023","","","IEEE","IEEE Conferences"
"A Hybrid Approach to Paraphrase Detection Based on Text Similarities and Machine Learning Classifiers","M. Hany; W. H. Gomaa","Faculty of Computer Science, MSA University, Giza, Egypt; Faculty of Computer and Artificial Intelligence, Faculty of Computer Science, Beni-Suef University, MSA University, Egypt","2022 2nd International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC)","1 Jun 2022","2022","","","343","348","In the realm of natural language processing (NLP), paraphrase detection is a highly common and significant activity. Because it is involved in a lot of complicated and complex NLP applications like information retrieval, text mining, and plagiarism detection. The proposed model finds the best combination of the three types of similarity techniques that are string similarity, semantic similarity and embedding similarity. Then, inputs these similarity scores that range from 0 to 1, to the machine learning classifiers. This proposed model will be benchmarked on “the Microsoft research paraphrase corpus” dataset (MSRP) and from this approach for paraphrase detection problem, the accuracy acquired is 75.78% and F1-Score of 83.01 %.","","978-1-6654-6677-6","10.1109/MIUCC55081.2022.9781678","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781678","Paraphrase Detection;Text Similarity;Machine Learning;Natural Language Processing","Text mining;Plagiarism;Semantics;Machine learning;Benchmark testing;Ubiquitous computing;Information retrieval","","4","","19","IEEE","1 Jun 2022","","","IEEE","IEEE Conferences"
"Semantic Word Error Rate for Sentence Similarity","C. Spiccia; A. Augello; G. Pilato; G. Vassallo","Italian National Research Council (CNR), Istituto di calcolo e reti ad alte prestazioni (ICAR), Palermo, Italy; Italian National Research Council (CNR), Istituto di calcolo e reti ad alte prestazioni (ICAR), Palermo, Italy; Italian National Research Council (CNR), Istituto di calcolo e reti ad alte prestazioni (ICAR), Palermo, Italy; Dipart. di Ingegneria Chimica, Universitá degli Studi di Palermo, Palermo, Italy",2016 IEEE Tenth International Conference on Semantic Computing (ICSC),"24 Mar 2016","2016","","","266","269","Sentence similarity measures have applications in several tasks, including: Machine Translation, Paraphrase Identification, Speech Recognition, Question-answering and Text Summarization. However, measures designed for these tasks are aimed at assessing equivalence rather than resemblance, partly departing from human cognition of similarity. While this is reasonable for these activities, it hinders the applicability of sentence similarity measures to other tasks. We therefore propose a new sentence similarity measure specifically designed for resemblance evaluation, in order to cover these fields better. Experimental results are discussed.","","978-1-5090-0662-5","10.1109/ICSC.2016.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439346","Semantic Word Error Rate;SWER;sentence similarity measure;sentence resemblance;word relatedness;Latent Semantic Analysis;LSA;Word Error Rate;WER","Extraterrestrial measurements;Semantics;Current measurement;Measurement uncertainty;Error analysis;Atmospheric measurements;Particle measurements","","4","","22","IEEE","24 Mar 2016","","","IEEE","IEEE Conferences"
"FLeCCS: A Technique for Suggesting Fragment-Level Similar Co-change Candidates","M. Mondal; C. K. Roy; B. Roy; K. A. Schneider","Computer Science and Engineering Discipline, Khulna University, Bangladesh; Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science, University of Saskatchewan, Canada",2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC),"28 Jun 2021","2021","","","160","171","When a programmer changes a particular code fragment, the other similar code fragments in the code-base may also need to be changed together (i.e., co-changed) consistently to ensure that the software system remains consistent. Existing studies and tools apply clone detectors to identify these similar co-change candidates for a target code fragment. However, clone detectors suffer from a confounding configuration choice problem and it affects their accuracy in retrieving co-change candidates.In our research, we propose and empirically evaluate a lightweight co-change suggestion technique that can automatically suggest fragment level similar co-change candidates for a target code fragment using WA-DiSC (Weighted Average Dice-Sørensen Co-efficient) through a context-sensitive mining of the entire code-base. We apply our technique, FLeCCS (Fragment Level Co-change Candidate Suggester), on six subject systems written in three different programming languages (Java, C, and C#) and compare its performance with the existing state-of-the-art techniques. According to our experiment, our technique outperforms not only the existing code clone based techniques but also the association rule mining based techniques in detecting co-change candidates with a significantly higher accuracy (precision and recall). We also find that File Proximity Ranking performs significantly better than Similarity Extent Ranking when ranking the co-change candidates suggested by our proposed technique.","2643-7171","978-1-6654-1403-6","10.1109/ICPC52881.2021.00024","Natural Sciences and Engineering Research Council of Canada; Canada First Research Excellence Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463009","Code Clones;Clone-Types;Micro-Clones;Co-change Candidates","Couplings;Java;Databases;Cloning;Detectors;Tools;Software systems","","3","","69","IEEE","28 Jun 2021","","","IEEE","IEEE Conferences"
"Siamese Similarity Between Two Sentences Using Manhattan's Recurrent Neural Networks","A. A. Aziz; E. C. Djamal; R. Ilyas","Department of Informatics, Universitas Jenderal Achmad Yani, Cimahi, Indonesia; Department of Informatics, Universitas Jenderal Achmad Yani, Cimahi, Indonesia; Department of Informatics, Universitas Jenderal Achmad Yani, Cimahi, Indonesia","2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)","13 Apr 2020","2019","","","1","6","Paraphrasing detection needs to understand the sentence as a whole, not just every word. Therefore, if a learning machine does it, it is necessary to process it as a whole word, the relationship between words in a sentence. Recurrent Neural Networks (RNN) are methods commonly used to describe the connection between inputs. This study proposed the detection of paraphrases between two sentences using Manhattan Recurrent Neural Networks. One sentence contains several words arranged in sequence using the Word2vec function. The connection of each word in the RNN network used Long Short-Term Memory. (LSTM). Obtained 800,000 pairs of training data provide accuracy of 82.54% of new data. The experimental results showed that the amount of training data variation is dominant to the number of training data. These results are better than the accuracy of the new data, with half of the training data only yielding 64%. Besides, the result gave the number of epochs during the training collected increased data correctness result.","","978-1-7281-3452-9","10.1109/ICAICTA.2019.8904412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8904412","Siamese Similarity;RNN;paraphrase;word2vec;LSTM","Training data;Recurrent neural networks;Natural language processing;Semantics;Labeling;Plagiarism;Training","","3","","21","IEEE","13 Apr 2020","","","IEEE","IEEE Conferences"
"Movie Recommendation based on User Similarity of Consumption Pattern Change","M. Kim; S. Jeon; H. Shin; W. Choi; H. Chung; Y. Nah","Dept. of Data Science, Dankook University, Yongin-si, Korea; Dept. of Computer Science, Dankook University, Yongin-si, Korea; Dept. of Data Science, Dankook University, Yongin-si, Korea; Software-Centric University, Project Office Dankook University, Yongin-si, Korea; Dept. of Applied Computer Eng., Dankook University, Seoul, Korea; Dept. of Applied Computer Eng., Dankook University, Seoul, Korea",2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),"8 Aug 2019","2019","","","317","319","The recurrent neural network(RNN) deep learning algorithm, which mainly learns and predicts sequence data and time series data, is mainly used in language modeling, stock price prediction, and chat bot. In this paper, we propose a method of predicting and recommending a movie by considering movie consumption patterns of users. We measure the similarity between users based on movie rating data, classify users with similar movie preferences, and learn the consumption pattern of each similar user group to improve the prediction accuracy by considering the change of preference over time. In order to show the effectiveness of the proposed method, we apply the collaborative filtering algorithm, the simple RNN and our modified RNN and compare their prediction accuracies.","","978-1-7281-1488-0","10.1109/AIKE.2019.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8791705","movie-recommendation;user-similarity;consumption-pattern;sequence-data;Recurrent-Neural-Network","Motion pictures;Collaboration;Filtering;Recurrent neural networks;Filtering algorithms;Data models;Predictive models","","11","","8","IEEE","8 Aug 2019","","","IEEE","IEEE Conferences"
"The Improved Artificial Neural Network Based on Cosine Similarity in Facial Emotion Recognition","K. C. Kirana; S. Wibawanto; N. Hidayah; G. P. Cahyono","Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Electrical Engineering, Universitas Negeri Malang, Malang, Indonesia; Department of Guidance and Counseling, Universitas Negeri Malang, Malang, Indonesia; Software Engineering, Visionet Data International, Malang, Indonesia","2019 6th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)","3 Feb 2020","2019","","","45","48","In this study, we present the improved artificial neural network based on cosine similarity in facial emotion recognition. We apply a shifting window that employs a neural network for two concurrent processes consisting of face detection and emotional recognition. To prevent the slow and futile computations, non-face areas need to be filtered from neurons on each network layer, thus we propose the improved artificial neural network based on cosine similarity. Cosine similarity is employed to bypass the process of non-face areas in the neural network. The accuracy of the proposed method reaches 0.84, while the accuracy of the original neural network method reaches 0.74. It can be concluded that our methods work accurately. It can be concluded that our method works accurately. The proposed method is superior to the state-of-the-art algorithms","","978-602-0737-30-0","10.23919/EECSI48112.2019.8977006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977006","emotion recognition;neural network;cosine similarity","","","4","","15","","3 Feb 2020","","","IEEE","IEEE Conferences"
"Cutting Force Similarity Calculation in Milling Process Using Siamese LSTM Structure","J. Kwak; W. Jo; S. Lee; H. Kim; J. Koo; D. Kim","Division of Artificial Intelligence and Software, Ewha Womans University, Seoul, South Korea; Computer Science and Engineering, Chungnam National University, Daejeon, South Korea; Computer Science and Engineering, Chungnam National University, Daejeon, South Korea; Manufacturing System R&BD Group, Korea Institute of Industrial Technology, Cheonan, South Korea; Manufacturing System R&BD Group, Korea Institute of Industrial Technology, Cheonan, South Korea; Department of Data Science, Ewha Womans University, Seoul, South Korea",2023 2nd International Conference on Mechatronics and Electrical Engineering (MEEE),"24 May 2023","2023","","","54","58","Cutting force is a key factor in machining processes. Cutting force similarity is required for several important issues, namely: stability evaluation, process control, and process parameter setting. This study employed a long short-term memory (LSTM) with Siamese architecture to measure the similarity of the cutting forces in a milling process. The Siamese LSTM was trained with time series data of the vertical cutting force collected from a cutting tool during the milling process to calculate the similarity. For evaluation, dynamic time warping (DTW), a common approach used to calculate the similarity of time series data, was employed for comparison with the Siamese LSTM. Experimental results showed that the proposed Siamese LSTM outperformed the conventional DTW-based similarity calculation.","","978-1-6654-7445-0","10.1109/MEEE57080.2023.10126810","Korea Institute of Industrial Technology(grant numbers:Kitech EO-19-0043); National Research Foundation(grant numbers:2020R1F1A1075781); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10126810","similarity;cutting force;Siamese neural network;dynamic time warping;Manhattan distance;long short-term memory","Training;Electrical engineering;Mechatronics;Force measurement;Force;Time series analysis;Process control","","","","11","IEEE","24 May 2023","","","IEEE","IEEE Conferences"
"Field Tests of Digital Terrestrial Multimedia Broadcasting System RAVIS","A. V. Dvorkovich; V. P. Dvorkovich; V. A. Irtyuga; K. S. Mityagin","MIPT -School of Radio Engineering and Computer Technology, Moscow Institute of Physics and Technology, Moscow, Russian Federation; Multimedia Technology and Telecommunication Dep., Moscow Institute of Physics and Technology, Moscow, Russian Federation; Multimedia Systems and Technology Lab., Moscow Institute of Physics and Technology, Moscow, Russian Federation; Multimedia Systems and Technology Lab., Moscow Institute of Physics and Technology, Moscow, Russian Federation",2018 Engineering and Telecommunication (EnT-MIPT),"11 Jul 2019","2018","","","3","7","Field tests of digital terrestrial multimedia broadcasting system RAVIS have been held in 2017-2018 in two test zones in Russian Federation - Kazan city (Tatarstan Republic) and Izhevsk city (Udmurtia Republic). Fixed and mobile reception were tested. New services of digital broadcasting were demonstrated.","","978-1-7281-0432-4","10.1109/EnT-MIPT.2018.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8757474","digital broadcasting;fixed reception;mobile reception;diverse reception;public warning;emergency","Multimedia communication;Receivers;Radio transmitters;Modulation;Urban areas;Digital multimedia broadcasting","","3","","7","IEEE","11 Jul 2019","","","IEEE","IEEE Conferences"
"Maximizing diversity in CPUs: Using GPUs as coprocessors to achieve safety integrity","F. Reichenbach; J. Endresen; S. -E. Ellevseth","ABB Corporate Research Bergerveien 12, Billingstad; ABB Corporate Research Bergerveien 12, Billingstad; ABB Corporate Research Bergerveien 12, Billingstad",2014 12th IEEE International Conference on Industrial Informatics (INDIN),"6 Nov 2014","2014","","","182","187","Modern System-on-Chip (SOC) architectures offer much for a relatively small price, but often industrial machine builders only use a fraction of the functionality. Their main interest is the performance boost by using multiple cores. For safety devices, the on-chip redundancy is beneficially to achieve higher reliability, but since most platforms are homogenous, there is a need to get systematic and common cause failures under control. Graphics Processing Units (GPU`s) are more and more available in modern SOCs, but their utilization in industrial products is still marginal. This paper proposes a concept how GPUs can improve the overall safety integrity with additional diversity in hardware and software.","2378-363X","978-1-4799-4905-2","10.1109/INDIN.2014.6945505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945505","Safety reliability;diversity;CPU;GPU;OpenCL","Graphics processing units;Safety;Kernel;Multicore processing;Hardware","","2","","12","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Success within App Distribution Platforms: The Contribution of App Diversity and App Cohesivity","V. Dibia; C. Wagner",City University of Hong Kong; City University of Hong Kong,2015 48th Hawaii International Conference on System Sciences,"30 Mar 2015","2015","","","4304","4313","As the plethora of mobile apps continues to grow, app publishers are increasingly challenged on the appropriate strategies to adopt in order to improve app success. In this report, we adopt theoretical lens from transaction cost theory and economic utility in the development and test of a model that examines the impacts of app diversity and app cohesivity on app success. Using data gathered from the Microsoft Windows Phone App distribution platform, our main conclusions are as follows: app diversity (the number of geographic locales an app is built to support) is of particular significance as a potential driver of app success within platforms and app cohesivity (a measure of integration with the platforms services) is positively associated with app success (its download count/rank within the platform). Interestingly, both relationships appear to be moderated by the pricing scheme adopted by publishers for that app. Theoretical and practical implications are discussed as well as avenues for future research work.","1530-1605","978-1-4799-7367-5","10.1109/HICSS.2015.515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070335","platform ecosystems;transaction costs;app diversity;app Cohesivity;transaction costs;utility;multi-lingual support","Software;Ecosystems;Mobile communication;Pricing;Mobile handsets;Economics;Privacy","","5","","31","IEEE","30 Mar 2015","","","IEEE","IEEE Conferences"
"XDIVINSA: eXtended DIVersifying INStruction Agent to Mitigate Power Side-Channel Leakage","T. H. Pham; B. Marshall; A. Fell; S. -K. Lam; D. Page","Department of Computer Science, University of Bristol, United Kingdom; Department of Computer Science, University of Bristol, United Kingdom; Barcelona Supercomputing Center, Spain; Nanyang Technological University, Singapore; Department of Computer Science, University of Bristol, United Kingdom","2021 IEEE 32nd International Conference on Application-specific Systems, Architectures and Processors (ASAP)","23 Aug 2021","2021","","","179","186","Side-channel analysis (SCA) attacks pose a major threat to embedded systems due to their ease of accessibility. Realising SCA resilient cryptographic algorithms on embedded systems under tight intrinsic constraints, such as low area cost, limited computational ability, etc., is extremely challenging and often not possible. We propose a seamless and effective approach to realise a generic countermeasure against SCA attacks. XDIVINSA, an extended diversifying instruction agent, is introduced to realise the countermeasure at the microarchitecture level based on the combining concept of diversified instruction set extension (ISE) and hardware diversification. XDIVINSA is developed as a lightweight co-processor that is tightly coupled with a RISC-V processor. The proposed method can be applied to various algorithms without the need for software developers to undertake substantial design efforts hardening their implementations against SCA. XDIVINSA has been implemented on the SASEBO G-III board which hosts a Kintex-7 XC7K160T FPGA device for SCA mitigation evaluation. Experimental results based on non-specific t-statistic tests show that our solution can achieve leakage mitigation on the power side channel of different cryptographic kernels, i.e., Speck, ChaCha20, AES, and RSA with an acceptable performance overhead compared to existing countermeasures.","2160-052X","978-1-6654-2701-2","10.1109/ASAP52443.2021.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516611","Side channel Attacks;Instruction Set Extension;Hardware Diversification","Performance evaluation;Embedded systems;Microarchitecture;Instruction sets;Software algorithms;Systems architecture;Software","","1","","32","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"A grid execution environment similarity metric","Wei Wang; Bin-Xing Fang","Department of Computer Science, Harbin Institute of Technology, Harbin, Heilongjiang, China; Department of Computer Science, Harbin Institute of Technology, Harbin, Heilongjiang, China",2005 International Conference on Machine Learning and Cybernetics,"7 Nov 2005","2005","5","","3007","3012 Vol. 5","A program's behavior is always tightly related with the computing environment where it runs, especially for parallel programs running in grid. Debugging tries to locate the reason for incorrect program behavior by analyzing the states, which happen during a program's execution. In order to allow cyclic debugging, re-execution mechanisms are used most frequently. The dynamic characteristics of grid will hinder re-execution to work, because the behavior of a program will be various according to the current configuration of execution environment. By modeling grid environments with graphics, this paper proposes the metric to evaluate the similarity between grid applications execution environments. The GA based resource selection algorithm is presented to construct similar execution environments in grids. A serial of experiments shows that the similarity metrics is appropriate.","2160-1348","0-7803-9091-1","10.1109/ICMLC.2005.1527458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1527458","Grid;parallel debugging;computing environment;resource management;similarity metric;genetic algorithm","Debugging;Grid computing;Machine learning algorithms;Concurrent computing;Graphics;Resource management;Software testing;Costs;Runtime;Distributed computing","","","","11","IEEE","7 Nov 2005","","","IEEE","IEEE Conferences"
"Visualizing similarity between program executions","D. Leon; A. Podgurski; W. Dickinson","Corporacion NGS, Ciudad Guayana, Venezuela; EECS Department, Case Western Reserve University, Cleveland, OH, USA; Fused MultiModality Imaging, Solon, OH, USA",16th IEEE International Symposium on Software Reliability Engineering (ISSRE'05),"5 Dec 2005","2005","","","11 pp.","321","Multidimensional scaling (MDS) is a technique for visualizing multidimensional data points as a 2D scatter plot. It can be applied to execution profiles of software to reveal how similar executions are to one another. This is useful for certain software engineering applications, which require accurate representation of small dissimilarities and nearest neighbor relationships. However, the high-dimensionality of profiles can cause MDS techniques to represent small dissimilarities poorly. We evaluate several variants of MDS on large sets of profiles, to see which techniques produce the most accurate displays. These include four previously proposed techniques -classical scaling followed by iterative majorization, energy minimization, ordinal AIDS, and cluster differences scaling - and two techniques of our invention - hierarchical MDS and sparse region scaling. The results suggest that each technique except ordinal MDS can significantly improve the representation of small dissimilarities between program executions and that hierarchical MDS and sparse region scaling perform best overall","2332-6549","0-7695-2482-6","10.1109/ISSRE.2005.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544745","","Multidimensional systems;Displays;Software testing;Euclidean distance;Data visualization;Scattering;Application software;Software tools;Maintenance;Software engineering","","7","","16","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"VulDetector: Detecting Vulnerabilities Using Weighted Feature Graph Comparison","L. Cui; Z. Hao; Y. Jiao; H. Fei; X. Yun","Chinese Academy of Science, Institute of Information Engineering, Beijing, China; Chinese Academy of Science, Institute of Information Engineering, Beijing, China; Chinese Academy of Science, Institute of Information Engineering, Beijing, China; Chinese Academy of Science, Institute of Information Engineering, Beijing, China; Chinese Academy of Science, Institute of Information Engineering, Beijing, China",IEEE Transactions on Information Forensics and Security,"27 Jan 2021","2021","16","","2004","2017","Code similarity is one promising approach to detect vulnerabilities hidden in software programs. However, due to the complexity and diversity of source code, current methods suffer low accuracy, high false negative and poor performance, especially in analyzing a large program. In this paper, we propose to tackle these problems by presenting VulDetector, a static-analysis tool to detect C/C++ vulnerabilities based on graph comparison at the granularity of function. At the key of VulDetector is a weighted feature graph (WFG) model which characterizes function with a small yet semantically rich graph. It first pinpoints vulnerability-sensitive keywords to slice the control flow graph of a function, thereby reducing the graph size without compromising security-related semantics. Then, each sliced subgraph is characterized using WFG, which provides both syntactic and semantic features in varying degrees of security. As for graph comparison, we take full usage of vulnerability graph and patch graph to improve accuracy. In addition, we propose two optimization methods based on analysis of vulnerabilities. We have implemented VulDetector to automatically detect vulnerabilities in software programs with known vulnerabilities. The experimental results prove the effectiveness and efficiency of VulDetector.","1556-6021","","10.1109/TIFS.2020.3047756","National Natural Science Foundation of China(grant numbers:61972392,62072453); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2020164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309254","Vulnerability detection;code similarity;weighted feature graph","Syntactics;Software;Testing;Semantics;Security;Optimization methods;Lenses","","30","","53","IEEE","28 Dec 2020","","","IEEE","IEEE Journals"
"Research on Experimental Process Monitoring Method of Closed Experimental Equipment Based on Image Recognition Technology","W. Tong; Z. Shen; X. Chu; L. Pang; X. Wang","Laboratory for Space Environment and Physical Sciences, Harbin Institute of Technology, Harbin, China; School of Electrical Engineering and Automation, Harbin Institute of Technology, Harbin, China; School of Electrical Engineering and Automation, Harbin Institute of Technology, Harbin, China; Laboratory for Space Environment and Physical Sciences, Harbin Institute of Technology, Harbin, China; Laboratory for Space Environment and Physical Sciences, Harbin Institute of Technology, Harbin, China","2021 International Conference on Communications, Information System and Computer Engineering (CISCE)","9 Jun 2021","2021","","","442","446","Compared with open experimental equipment, closed experimental equipment that uses computer experimental software with a private protocol to complete the experimental process has higher security and is widely used in the fields such as space environment experiment simulation. This paper takes the private protocol computer experiment software of the closed experimental equipment as the research object, while proposes a cooperative monitoring strategy for the experiment process. By combining the image structure similarity comparison algorithm with dynamic event monitoring, this method realizes the monitoring of the experimental process of a closed experimental equipment with a proprietary protocol computer experimental software. The test results of this method show that the experimental process monitoring method proposed in this paper has better performance and higher accuracy and reliability.","","978-1-6654-0352-8","10.1109/CISCE52179.2021.9445875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9445875","Image recognition technology;Closed experimental equipment;Structural similarity;Collaborative monitoring strategy","Process monitoring;Protocols;Image recognition;Heuristic algorithms;Software algorithms;Reliability engineering;Software","","","","11","IEEE","9 Jun 2021","","","IEEE","IEEE Conferences"
"Big Data Critical Computing Based on the Similarity-Difference Metric","A. V. Hacimahmud; L. Shapa; V. Hahanov; A. Mishchenko; O. Shevchenko; S. Chumachenko; E. Litvinova","Computer Engineering Department, Azerbaijan State Oil and Industry University, Baku, Azerbaijan; Design Automation Department, Kharkov National University of Radio Electronics, Kharkov, Ukraine; Design Automation Department, Kharkov National University of Radio Electronics, Kharkov, Ukraine; Design Automation Department, Kharkov National University of Radioelectronics, Kharkov, Ukraine, USA; Design Automation Department, Kharkov National University of Radio Electronics, Kharkov, Ukraine; Design Automation Department, Kharkov National University of Radio Electronics, Kharkov, Ukraine; Design Automation Department, Kharkov National University of Radio Electronics, Kharkov, Ukraine",2020 IEEE East-West Design & Test Symposium (EWDTS),"15 Oct 2020","2020","","","1","6","Models, methods and algorithms for cyber-social computing are proposed that use the similarity-difference metric of unitary coded information for processing big data in order to generate adequate actuator signals for controlling cyber-social critical systems. A set-theoretic method for data retrieval has being developed based on the similarity-difference of the frequency parameters of primitive elements, which makes it possible to determine the similarity of objects, the strategy of transforming one object into another, as well as to identify the level of common interests, conflict. The definitions of the fundamental concepts in the field of computing are given on the basis of metric relations between interacting processes and phenomena. A software application is proposed for calculating the similarity-differences of objects based on the formation of frequency vectors of two sets of primitive data. A high level of correlation between the results of the application and the well-known system for determining plagiarism is shown.","2472-761X","978-1-7281-9899-6","10.1109/EWDTS50664.2020.9225110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225110","computing;cyber social computing;decision-making;unitary data codes;similarity-difference;big data analysis;plagiarism","Measurement;Monitoring;Process control;Design automation;Cloud computing;Big Data;Transforms","","","","9","IEEE","15 Oct 2020","","","IEEE","IEEE Conferences"
"Duplicate short text detection based on Word2vec","J. Gao; Y. He; X. Zhang; Y. Xia","School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China",2017 8th IEEE International Conference on Software Engineering and Service Science (ICSESS),"23 Apr 2018","2017","","","33","37","In modern life, people own new social relationship, watch news, create e-commerce transactions and have entertainment online. Light blogs and short comments become more and more popular. The traditional duplicate long text detection algorithms are hard to be applied in the current situations, so more effective duplicate detection algorithm for short text is needed. Based on the bag-of-words model Word2vec, this paper proposes a kind of duplicate detection algorithm with semantic embedded for short text. Words are embedded into vectors which are as input elements in Simhash algorithm to acquire 64 bits sequence, then compare two sequences with Hamming distances and return result filtered by preset threshold value. Subsequently, a more superior improvement is proposed where we add weighted idea into. The results are compared with the unweighted Word2vec method and the traditional TF-IDF method. Experiments are carried out on the SICK corpus, and its result shows that the weighted Word2vec method achieves higher accuracy and recall rate.","2327-0594","978-1-5386-0497-7","10.1109/ICSESS.2017.8342858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8342858","short text;duplicate detection;TF-IDF;Word2vec;semantic similarity;Simhash","Detection algorithms;Semantics;Entertainment industry;Blogs","","12","","23","IEEE","23 Apr 2018","","","IEEE","IEEE Conferences"
"Self-Similarity Based Classification of 3D Surface Textures","L. Qi; L. Zhang; J. Dong; Z. Yu; A. Yang","Computer Science Department, Ocean University of China, Qingdao, China; Computer Science Department, Ocean University of China, Qingdao, China; Computer Science Department, Ocean University of China, Qingdao, China; Administrative Office of Qingdao Software Technology Park, Qingdao, China; School of Information Science and Engineering, Ocean University of China",2008 Congress on Image and Signal Processing,"16 Jul 2008","2008","2","","402","406","This paper presents a novel 3D surface texture classification method based on self-similarity maps which are calculated directly from raw captured texture images. 3D surface textures have special properties for they are sensitive to illumination and view conditions. Some previous classification methods which are illumination invariant or rotation invariant have shown to be effective to this particularity, but most of them are model-based. We introduce a new approach to classify 3D surface texture image sets by automatically extracted self-similarity maps. Feature vectors are then generated from responses to a filter bank of the self-similarity maps. Classification is achieved by comparing the L2 distance between training and testing feature vectors. The experiment results show our approach achieves an accuracy of 95%.","","978-0-7695-3119-9","10.1109/CISP.2008.294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4566335","self-similarity;3D surface texture;classification","Surface texture;Sea surface;Lighting;Rough surfaces;Surface roughness;Reflectivity;Oceans;Filter bank;Testing;Humans","","3","","10","IEEE","16 Jul 2008","","","IEEE","IEEE Conferences"
"Semantic Similarity-based Visual Reasoning without Language Information","C. Choi; H. Lim; H. Jang; J. Park; E. Kim; K. Lim","Department of Computer Engineering, Hanbat National University, Daejeon, South Korea; Department of Computer Engineering, Hanbat National University, Daejeon, South Korea; Surromind Co., Ltd., Seoul, South Korea; Euclidsoft Co., Ltd., Daejeon, South Korea; Department of AI Software, Hanbat National University, Daejeon, South Korea; Department of Computer Engineering, Hanbat National University, Daejeon, South Korea",2023 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),"23 Mar 2023","2023","","","107","111","In this research, we propose new training data for the visual reasoning task based on semantic similarity and proposed a deep learning model that utilizes the data. The first contribution of this study is the construction of training data. Based on a total of 40 object attributes, we created a visual inference problem using only image data. As a result, a total of 6,000 datasets were built to create training and test data. We also propose a visual inference model as the second contribution of this work. The inference model shown in this study was evaluated for two tasks using ResNet50 and Vision Transformer, respectively. Based on the experimental evaluation results, we investigated the suitable pre-trained model for both single-choice binary reasoning and multiple-selection reasoning, respectively.","2831-6983","978-1-6654-5645-6","10.1109/ICAIIC57133.2023.10067104","National Information Society Agency (NIA); Ministry of Education(grant numbers:2021RIS-004,2021RIFIAI063474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10067104","Visual Reasoning;Inference;Image similarity;Deep Learning","Training;Deep learning;Visualization;Semantics;Training data;Transformers;Cognition","","","","13","IEEE","23 Mar 2023","","","IEEE","IEEE Conferences"
"Fuzzing Methods Recommendation Based on Feature Vectors","C. Zhang; J. Chen","School of Computer Science & Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science & Communication Engineering, Jiangsu University, Zhenjiang, China",2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE),"20 Jan 2022","2021","","","1079","1081","Fuzzing is a technique that aims to detect vulnerabilities or exceptions through unexpected input and has found tremendous recent interest in both academia and industry. Although these fuzzing methods have great advantages in the field of vulnerability detection, they also have their own disadvantages in the face of different target programs. It is obviously impractical for a fuzzing test method to adapt to all the target programs. Therefore, we study how to select the appropriate fuzzing methods for different target programs. Specifically, we first analyze the program, and then extract the feature vectors of the target program to get the information of the program, such as syntax, context and so on. Next, we build a matching model to match the similarity of target program and the fuzzing algorithm to select the fuzzing algorithm with higher matching degree. Through our matching model, we get a more suitable fuzzing algorithm to improve the detection efficiency, precision, recall, F-measure, and other statistical measures.","2643-1572","978-1-6654-0337-5","10.1109/ASE51524.2021.9678630","National Natural Science Foundation of China; China Postdoctoral Science Foundation; Postdoctoral Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678630","Fuzzing;Vulnerability detection;Feature vector;Similarity","Industries;Software algorithms;Fuzzing;Syntactics;Feature extraction;Data mining;Faces","","","","15","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"Enhancing Population Diversity for Genetic Algorithms","F. Huang; N. Xiao; Q. Chen","Faculty of Software, Fujian Normal University, Fuzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China",2009 Fifth International Conference on Natural Computation,"28 Dec 2009","2009","4","","222","226","The premature convergence may lead the genetic algorithms (GAs) to a local optimum but not a global one. Maintaining the population diversity in GAs, or minimize its loss, may alleviate this problem to a certain extent. A novel selector based on eugenics (EBSelector) has been proposed to faciliate effective selection of individuals to perform crossover, inspired by the eugenic theory about how to make familial disease less happen and to produce high-quality offspring. Demonstrated through a suite of benchmark test functions, the proposed algorithm is shown competitive performance with improved convergence speed.","2157-9563","978-0-7695-3736-8","10.1109/ICNC.2009.560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365430","genetic algorithms;population diversity;eugenics theory","Genetic algorithms;Diseases;Time measurement;Demography;Evolution (biology);Benchmark testing;Convergence;Biology computing;Evolutionary computation;Frequency diversity","","","","13","IEEE","28 Dec 2009","","","IEEE","IEEE Conferences"
"Stopping Memory Disclosures via Diversification and Replicated Execution","K. Lu; M. Xu; C. Song; T. Kim; W. Lee","University of Minnesota, Minneapolis, MN, USA; Georgia Institute of Technology, Atlanta, GA, USA; University of California, Riverside, CA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA",IEEE Transactions on Dependable and Secure Computing,"7 Jan 2021","2021","18","1","160","173","With the wide deployment of security mechanisms such as Address Space Layout Randomization (ASLR), memory disclosures have become a prerequisite for critical memory-corruption attacks (e.g., code-reuse attack)-adversaries are forced to exploit memory disclosures to circumvent ASLR as the first step. As a result, the security threats of memory disclosures are now significantly aggravated-they break not only data confidentiality but also the effectiveness of security mechanisms. In this paper, we propose a general detection methodology and develop a system to stop memory disclosures. We observe that memory disclosures are not root causes but rather consequences of a variety of hard-to-detect program errors such as memory corruption and uninitialized read. We thus propose a replicated execution-based methodology to generally detect memory disclosures, regardless of their causes. We realize this methodology with Buddy: By seamlessly maintaining two identical running instances of a target program and diversifying only its target data, Buddy can accurately detects memory disclosures of the data, as doing so will result in the two instances outputting different values. Extensive evaluation results show that Buddy is reliable and efficient while stopping real memory disclosures such as the Heartbleed leak.","1941-0018","","10.1109/TDSC.2018.2878234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8510822","Memory disclosure;diversification;replicated execution;N-version system;code-reuse attack","Synchronization;Security;Kernel;Benchmark testing;Web servers;Memory management;Layout","","15","","56","IEEE","26 Oct 2018","","","IEEE","IEEE Journals"
"Balancing Convergence and Diversity in Multiobjective Immune Algorithm","L. Li; W. Lin; Q. Lin; Z. Ming","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China",2020 12th International Conference on Advanced Computational Intelligence (ICACI),"26 Aug 2020","2020","","","102","109","Recently, multiobjective immune algorithms (MOIAs) become popular, which are designed for multiobjective optimization problems (MOPs). However, most existing MOIAs put more attention on maintaining diversity as the used clonal selection strategy will allocate more cloning for the sparse areas, which may hamper the convergence to speed to the optimal Pareto front, especially for some complicated MOPs. To alleviate the phenomenon mentioned above, we propose a dynamic mechanism into traditional MOIAs in this paper, aiming to balance convergence and diversity, called BCD-MOIA. First, MOP will be decomposed into several single subproblems by decomposition method, and then these subproblems will be optimized simultaneously. Second, we propose a novel measure metric instead of the crowding distance to assign the clone number for each solution, which includes two main parts. The first part focuses on the diversity performance, i.e., the perpendicular distance between solution and its associated weight vectors. The second part uses the aggregated function values quantified by the decomposition method, which is more efficient for accelerating the convergence speed and maintaining diversity as well. Moreover, a dynamic mechanism is performed during the whole evolutionary process, focusing on diversity and convergence at different stages. By this way, our proposed algorithm can tradeoff the performance on convergence and diversity dynamically. The effectiveness of our proposed algorithm BCD-MOIA is validated by comparing with three competitive MOIAs and three multi-objective evolutionary algorithms for tackling two sets of complicated problems.","2573-3311","978-1-7281-4248-7","10.1109/ICACI49185.2020.9177787","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177787","immune algorithnb multiobjective optimization problems;convergence and diversity","Cloning;Convergence;Sociology;Statistics;Optimization;Heuristic algorithms;Software algorithms","","2","","26","IEEE","26 Aug 2020","","","IEEE","IEEE Conferences"
"Query term expansion and reweighting using term co-occurrence similarity and fuzzy inference","Byeong Man Kim; Ju Youn Kim; Jongwan Kim","School of Computer & Software Engineering, Kum-Oh National University of Technology, Kumi, Gyeongbuk, South Korea; School of Computer & Software Engineering, Kum-Oh National University of Technology, Kumi, Gyeongbuk, South Korea; School of Computer & Information Engineering, Taegu University, Gyeongsan, Gyeongbuk, South Korea",Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569),"7 Aug 2002","2001","2","","715","720 vol.2","To improve the effectiveness of the classic relevance techniques for the vector model, a novel technique for term expansion and term reweighting is suggested. The advantages of the classic techniques are simplicity and good results. However, due to the simplicity, the term occurrence pattern is not considered explicitly. To supplement the classic relevance techniques, we introduce the term cooccurrence similarity as a measure of how similar the distributions within the feedbacked documents of a given term and the initial query are. With this similarity and additional information, the weight in the new query of the term is calculated by fuzzy inference. Although the experiments are performed on the small collection, the results show that the technique proposed in the paper yields substantial improvements in retrieval effectiveness.","","0-7803-7078-3","10.1109/NAFIPS.2001.944690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=944690","","Feedback;Software;World Wide Web;Web search;Search engines;Information retrieval;Frequency measurement;Testing","","4","","14","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Cooperative Control of Water Volumes of Parallel Ponds Attached to An Open Channel Based on Information Consensus with Minimum Diversion Water Loss","C. Tricaud; Y. Chen","Center for Self-Organizing and Intelligent Systems (CSOIS), Department of Electrical and Computer Engineering, Utah State University, Logan, UT, USA; Center for Self-Organizing and Intelligent Systems (CSOIS), Department of Electrical and Computer Engineering, Utah State University, Logan, UT, USA",2007 International Conference on Mechatronics and Automation,"24 Sep 2007","2007","","","3283","3288","Decision making through information sharing for a canal irrigation system is discussed in this paper. A consensus-based decision algorithm is used to manage water distribution into a parallel ponds network and achieve good quality of service and minimum water-loss. The algorithm is tested in a simulation software reproducing the major dynamics of the system for different scenarios. While not taking into account some of the non-linearities and focusing on feasibility, the algorithm shows interesting results under ideal flow control conditions especially regarding convergence. Robustness is estimated by Monte Carlo evaluation of the effects of delay uncertainty, and the strategy maintains convergence.","2152-744X","978-1-4244-0827-6","10.1109/ICMA.2007.4304088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4304088","Consensus;Irrigation Control;Open Water Channel","Irrigation;Convergence;Delay estimation;Decision making;Quality management;Quality of service;Software algorithms;Software testing;System testing;Nonlinear dynamical systems","","4","","14","IEEE","24 Sep 2007","","","IEEE","IEEE Conferences"
"A New Local Search-Based Multiobjective Optimization Algorithm","B. Chen; W. Zeng; Y. Lin; D. Zhang","Software School, Xiamen University, Xiamen, Fujian, China; Software School, Xiamen University, Xiamen, Fujian, China; School of Information Science and Engineering, Xiamen University, Xiamen, Fujian, China; School of Information Science and Engineering, Xiamen University, Xiamen, Fujian, China",IEEE Transactions on Evolutionary Computation,"27 Jan 2015","2015","19","1","50","73","In this paper, a new multiobjective optimization framework based on nondominated sorting and local search (NSLS) is introduced. The NSLS is based on iterations. At each iteration, given a population P, a simple local search method is used to get a better population P', and then the nondominated sorting is adopted on P ∪ P' to obtain a new population for the next iteration. Furthermore, the farthest-candidate approach is combined with the nondominated sorting to choose the new population for improving the diversity. Additionally, another version of NSLS (NSLS-C) is used for comparison, which replaces the farthest-candidate method with the crowded comparison mechanism presented in the nondominated sorting genetic algorithm II (NSGA-II). The proposed method (NSLS) is compared with NSLS-C and the other three classic algorithms: NSGA-II, MOEA/D-DE, and MODEA on a set of seventeen bi-objective and three tri-objective test problems. The experimental results indicate that the proposed NSLS is able to find a better spread of solutions and a better convergence to the true Pareto-optimal front compared to the other four algorithms. Furthermore, the sensitivity of NSLS is also experimentally investigated in this paper.","1941-0026","","10.1109/TEVC.2014.2301794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718037","Multiobjective optimization;nondominated sorting;local search;diversity;test problems;Diversity;local search;multiobjective optimization;nondominated sorting;test problems","Sociology;Statistics;Optimization;Sorting;Search methods;Convergence;Algorithm design and analysis","","127","","85","IEEE","21 Jan 2014","","","IEEE","IEEE Journals"
"Estimation Improvement of Objective Scores of Answer Statements with Consideration of Semantic Similarity","Y. Yokoyama; T. Hochin; H. Nomiya","Graduate School of Life and Environmental Sciences, Kyoto Prefectural University, Kyoto, Japan; Faculty of Information and Human Sciences, Kyoto Institute of Technology, Kyoto, Japan; Faculty of Information and Human Sciences, Kyoto Institute of Technology, Kyoto, Japan","2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","23 Aug 2018","2018","","","188","193","To eliminate mismatches between the intentions of questioners and respondents of Question and Answer (Q&A) sites, we have clarified that the impression of the statements could be captured by nine factors, and the factor scores could be estimated from the feature values of the statements. Objective scores of the statements could be estimated fairly good, and that those of subjective statements could be estimated well by taking the natural logarithm of the factor scores with the consideration of cross-validation. This paper tries to perform multiple regression analysis with the consideration of semantic similarity between Q&A. A statement is represented with an average word vector of the words appearing in the statement. The semantic similarity of two statements is calculated through the cosine of the two average word vectors of the two statements. As a result, there could be a possibility that semantic similarity would be effective in estimating objective scores.","","978-1-5386-5889-5","10.1109/SNPD.2018.8441035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8441035","Q & A site;factor score;multiple regression analysis;objective score;word vector;semantic similarity","Estimation;Semantics;Regression analysis;Barium;Data models;Internet;Software","","1","","21","IEEE","23 Aug 2018","","","IEEE","IEEE Conferences"
"Machine Learning for Real-Time Data-Driven Security Practices","S. Coleman; P. Doody; A. Shields","Department of Computing, Institute of Technology Tralee, Tralee, Ireland; Department of Computing, Institute of Technology Tralee, Tralee, Ireland; Department of Computing, Institute of Technology Tralee, Tralee, Ireland",2018 29th Irish Signals and Systems Conference (ISSC),"23 Dec 2018","2018","","","1","6","The risk of cyber-attacks exploiting vulnerable organisations has increased significantly over the past several years. These attacks may combine to exploit a vulnerability breach within a system's protection strategy, which has the potential for loss, damage or destruction of assets. Consequently, every vulnerability has an accompanying risk, which is defined as the ""intersection of assets, threats, and vulnerabilities"" [1]. This research project aims to experimentally compare the similarity-based ranking of cyber security information utilising a recommendation environment. The Memory-Based Collaborative Filtering technique was employed, specifically the User-Based and Item-Based approaches. These systems utilised information from the National Vulnerability Database, specifically for the identification and similarity-based ranking of cyber-security vulnerability information, relating to hardware and software applications. Experiments were performed using the Item-Based technique, to identify the optimum system parameters, evaluated through the AUC evaluation metric. Once identified, the Item-Based technique was compared with the User-Based technique which utilised the parameters identified from the previous experiments. During these experiments, the Pearson's Correlation Coefficient and the Cosine similarity measure was used. From these experiments, it was identified that utilised the Item-Based technique which employed the Cosine similarity measure, an AUC evaluation metric of 0.80225 was achieved.","","978-1-5386-6046-1","10.1109/ISSC.2018.8585360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585360","recommender systems;collaborative filtering;memory-based;user-based;item-based;similarity-based ranking;national vulnerability database;cyber security","Collaboration;Measurement;Recommender systems;Software","","1","","22","IEEE","23 Dec 2018","","","IEEE","IEEE Conferences"
"Automatic Assessment of 3D Modeling Exams","A. Sanna; F. Lamberti; G. Paravati; C. Demartini","Dipartimento di Automatica e Informatica, Politecnico di Torino, Torino, Italy; Dipartimento di Automatica e Informatica, Politecnico di Torino, Torino, Italy; Dipartimento di Automatica e Informatica, Politecnico di Torino, Torino, Italy; Dipartimento di Automatica e Informatica, Politecnico di Torino, Torino, Italy",IEEE Transactions on Learning Technologies,"9 Mar 2012","2012","5","1","2","10","Computer-based assessment of exams provides teachers and students with two main benefits: fairness and effectiveness in the evaluation process. This paper proposes a fully automatic evaluation tool for the Graphic and Virtual Design (GVD) curriculum at the First School of Architecture of the Politecnico di Torino, Italy. In particular, the tool is designed for the 3D modeling course, taught during the second year, where students have to prove their ability to model static scenes using the open source modeler Blender. During the final exam, students are required to create a 3D model as similar as possible to a reference object proposed by the teacher and shown through a set of 2D views; the similarity of the images is judged according to both model shape and materials. The traditional assessment process is particularly slow and strongly based on teachers subjective evaluation; the proposed solution efficiently implements an objective assessment mechanism that exploits computer vision and image analysis algorithms to automatically extract similarity indices. These indices are related to partial evaluation grades, which are then combined to obtain the final mark. A comparison with the traditional assessment process shows robustness and trustworthiness of the designed approach.","1939-1382","","10.1109/TLT.2011.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728788","solid modelling;computer aided instruction;computer science education;computer vision;educational courses;educational institutions;further education;public domain software;shape similarity criteria;3D modeling exam assessment;computer-based exam assessment;evaluation process effectiveness;evaluation process fairness;automatic evaluation tool;graphic and virtual design curriculum;First School of Architecture;Politecnico di Torino;Italy;3D modeling course;static scene model;Blender open source modeler;objective assessment mechanism;computer vision;image analysis algorithm;similarity index extraction;partial evaluation grade;material similarity criteria;Solid modeling;Three dimensional displays;Materials;Education;Computer graphics;Computational modeling;Shape;3D modeling.;Evaluation methodologies;teaching and learning strategies;higher education;computer graphics","Solid modeling;Three dimensional displays;Materials;Education;Computer graphics;Computational modeling;Shape","","15","","44","IEEE","10 Mar 2011","","","IEEE","IEEE Journals"
"Wavelet based despeckling of multiframe optical coherence tomography data using similarity measure and anisotropic diffusion filtering","W. Habib; A. M. Siddiqui; I. Touqir","Dept. of Computer Software Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Dept. of Electrical Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Dept. of Electrical Engineering, National University of Sciences and Technology, Islamabad, Pakistan",2013 IEEE International Conference on Bioinformatics and Biomedicine,"6 Feb 2014","2013","","","330","333","We propose a new algorithm for despeckling multiframe Optical Coherence Tomography (OCT) data based on wavelet shrinkage using anisotropic diffusion and similarity comparison between frames. In this algorithm detail coefficients are weighted for noise reduction, where these weights are calculated based on similarity comparison between approximation coefficients. This comparison is based on the assumption that frames have similar structural content while noise is temporally uncorrelated. Approximation coefficients are denoised using Perona Malik anisotropic diffusion. Finally these processed coefficients are averaged to get a denoised image. Experimental results show that the proposed method performs better than the previously formulated denoising algorithms both in terms of noise reduction and structural content preservation.","","978-1-4799-1309-1","10.1109/BIBM.2013.6732512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6732512","anisotropic diffusion;denoise;despeckle;multi frame;optical coherence tomography;similarity measure;speckle noise;wavelet","Noise;Speckle;Noise reduction;Anisotropic magnetoresistance;Noise measurement;Approximation methods;Approximation algorithms","","3","","26","IEEE","6 Feb 2014","","","IEEE","IEEE Conferences"
"SCSNet: Sharpened Cosine Similarity-Based Neural Network for Hyperspectral Image Classification","M. Ahmad; M. Mazzara","Department of Computer Science, National University of Computer and Emerging Sciences, Chiniot, Pakistan; Institute of Software Development and Engineering, Innopolis University, Innopolis, Russia",IEEE Geoscience and Remote Sensing Letters,"22 Feb 2024","2024","21","","1","4","Hyperspectral image classification (HSIC) faces challenges in preserving high-frequency features during downsampling and hierarchical filtering in the CNN architecture. To overcome this, we propose sharpened cosine similarity (SCS) as an alternative to convolutions within a neural network for HSIC. SCSNet emphasizes parameter efficiency by bypassing nonlinear activation layers, normalization steps, and dropout post the SCS layer. Additionally, MaxAbsPool is implemented instead of MaxPool for superior performance. Experimental results on public HSI datasets demonstrate SCS’s comparable accuracy, achieving 99% for both Indian Pines and Salinas datasets.","1558-0571","","10.1109/LGRS.2024.3365611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433668","Cosine similarity;hyperspectral image classification (HSIC);neural network (NN)","Training;Kernel;Three-dimensional displays;Feature extraction;Measurement;Image classification;Solid modeling","","1","","29","IEEE","13 Feb 2024","","","IEEE","IEEE Journals"
"A Novel Enhanced Particle Swarm Optimization Method with Diversity and Neighborhood Search","D. C. Tran; Z. Wu; H. Wang","Vietnam Academy of Science and Technology, Hanoi, Vietnam; State Key Lab of Software Engineering, Wuhan University, Wuhan, PR, China; School of Information Engineering, Nanchang Institute of Technology, Nanchang, PR, China","2013 IEEE International Conference on Systems, Man, and Cybernetics","27 Jan 2014","2013","","","180","187","By learning from different particle in local neighborhood and global neighborhood Particle Swarm Optimization (PSO) algorithm achieved a trade-off between exploration and exploitation abilities. In this paper, we propose a new approach by combining diversity mechanism and neighborhood search strategies, called a novel enhanced PSO method with Diversity and Neighborhood Search (EPSODNS). In this paper we propose a new local neighborhood search strategy that promotes the exploitation ability of algorithm. Our experiments are conducted on test benchmarks include 13 well-known numerical benchmarks. The results show that EPSODNS obtains a better majority of the test problems.","1062-922X","978-1-4799-0652-9","10.1109/SMC.2013.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6721791","particle swarm optimization;neighborhood search;diversity;global optimization","Search problems;Benchmark testing;Convergence;Sociology;Statistics;Diversity reception;Topology","","2","","28","IEEE","27 Jan 2014","","","IEEE","IEEE Conferences"
"Distinguishing Similar Design Pattern Instances through Temporal Behavior Analysis","R. Xiong; D. Lo; B. Li","School of Computer Science and Engineering, Southeast University, Nanjing, China; School of Information Systems, Singapore Management University, Singapore, Singapore; School of Computer Science and Engineering, Southeast University, Nanjing, China","2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)","2 Apr 2020","2020","","","296","307","Design patterns (DPs) encapsulate valuable design knowledge of object-oriented systems. Detecting DP instances helps to reveal the underlying rationale, thus facilitates the maintenance of legacy code. Resulting from the internal similarity of DPs, implementation variants, and missing roles, approaches based on static analysis are unable to well identify structurally similar instances. Existing approaches further employ dynamic techniques to test the runtime behaviors of candidate instances. Automatically verifying the runtime behaviors of DP instances is a challenging task in multiple aspects. This paper presents an approach to improve the verification process of existing approaches. To exercise the runtime behaviors of DP instances in cases that test cases of legacy systems are often unavailable, we propose a markup language, TSML (Test Script Markup Language), to direct the generation of test cases by putting a DP instance into use. The execution of test cases is monitored based on a trace method that enables us to specify runtime events of interest using regular expressions. To characterize runtime behaviors, we introduce a modeling and specification method employing Allen's interval-based temporal relations, which supports variant behaviors in a flexible way without hard-coded algorithms. A prototype tool has been implemented and evaluated on six open source systems to verify 466 instances reported by five existing approaches with respect to five DPs. The results show that the dynamic analysis increases the F1-score by 53.6% in distinguishing similar DP instances.","1534-5351","978-1-7281-5143-4","10.1109/SANER48275.2020.9054804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054804","Design Pattern Detection;Temporal Analysis;Reverse Engineering;Software Comprehension;Knowledge Representation","Runtime;Markup languages;Object oriented modeling;Heuristic algorithms;Prototypes;Static analysis;Maintenance engineering","","2","","69","IEEE","2 Apr 2020","","","IEEE","IEEE Conferences"
"VHF voice and data communications via Equatorial Electrojet scattering: Channel characterization and application of a frequency diversity technique using Software Defined Radio technology","N. P. Yoza; M. A. Milla; J. L. Chau; R. F. Alonso","Radio Observatorio de Jicamarca, Instituto Geofísico del Perú, Lima, Peru; Radio Observatorio de Jicamarca, Instituto Geofísico del Perú, Lima, Peru; Radio Observatorio de Jicamarca, Instituto Geofísico del Perú, Lima, Peru; Radio Observatorio de Jicamarca, Instituto Geofísico del Perú, Lima, Peru",2011 XXXth URSI General Assembly and Scientific Symposium,"20 Oct 2011","2011","","","1","1","The Equatorial Electrojet (EEJ) is a horizontal electron current flowing along the magnetic Ecuador, confined to a thin layer located at 100 km altitude in the ionosphere. The EEJ can be used as a scattering media to establish radio communication links in the VHF band. The aim of this work is to study the characteristics of the EEJ as a communication channel and to improve the quality of voice and data communications using the frequency diversity technique. To perform these studies, we have developed a simulator for EEJ radio communications in order to test different modulation techniques. The results obtained from the simulations have been verified experimentally by establishing an EEJ radio link between two radio stations in the Peruvian territory. The simulation and experimental results of this work will be reported. In addition, a new radio communication system based on Software-Defined Radio technology is being developed at the Jicamarca Radio Observatory. This system will be used to provide communications to remote locations in Peru.","","978-1-4244-6051-9","10.1109/URSIGASS.2011.6051050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051050","","Data communication;Frequency diversity;Data models;Signal to noise ratio;Scattering;Frequency modulation","","1","","6","IEEE","20 Oct 2011","","","IEEE","IEEE Conferences"
"Improved Sentence Similarity Algorithm based on VSM and its application in Question Answering System","Xu Liang; Dongjiao Wang; Ming Huang","Software Technology Institute, Dalian Jiaotong University, Dalian, China; Software Technology Institute, Dalian Jiaotong University, Dalian, China; Software Technology Institute, Dalian Jiaotong University, Dalian, China",2010 IEEE International Conference on Intelligent Computing and Intelligent Systems,"6 Dec 2010","2010","1","","368","371","In the FAQ-based Chinese Question Answering System, the most critical issue is how to calculate the similarity between the user questions and the questions in the FAQ. The traditional VSM-based Sentence Similarity Algorithm usually regards word as the basic linguistic unit of sentences and mainly considers the statistical information of words in questions, but doesn't take the word importance in the professional field and the semantic information of words into account. For these reasons, this paper proposes an Improved Sentence Similarity Algorithm Based on VSM, regarding notion as the basic linguistic unit of sentences, through conceptually abstracting and professionally classifying to improve the performance of Sentence Similarity Algorithm. Testing in Chinese FAQ system of specific areas, experimental result shows that the performance of the improved algorithm is superior to the traditional VSM-based sentence similarity algorithm evidently.","","978-1-4244-6585-9","10.1109/ICICISYS.2010.5658525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5658525","VSM model;sentence similarity;FAQ;Chinese question answering system","Semantics;Accuracy","","6","","10","IEEE","6 Dec 2010","","","IEEE","IEEE Conferences"
"2nd PCA on 3D protein structure similarity","Y. Chen; S. Chang; X. H. Tian","College of Software Technology, South China Agricultural University, Guangzhou, China; College of Software Technology, South China Agricultural University, Guangzhou, China; College of Software Technology, South China Agricultural University, Guangzhou, China",2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA),"29 Nov 2010","2010","","","253","257","Regarding the issue that 3D protein structure similarity determination requires a lot of computing time, this paper proposes a 3D protein structure consistency comparison using 2nd PCA (second principal component analysis). Mainly through 3D protein structure distance matrix to compute the corresponding PCA2 value, define their similarity by the PCA2 ratio of the two protein structures to be compared. This method does not require pre-registration for the protein backbone. Through a series of tests to verify that, by guaranteeing certain accuracy, this method greatly improves the speed of the similarity comparison.","","978-1-4244-6440-1","10.1109/BICTA.2010.5645321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645321","3D Protein;Structure Similarity;2nd PCA analysis","Proteins;Face recognition;Bioinformatics;Search problems;Shape","","","","10","IEEE","29 Nov 2010","","","IEEE","IEEE Conferences"
"Duals in Spectral Fault Localization","L. Naish; H. J. Lee","Department of Computing and Information Systems, University of Melbourne, VIC, Australia; Dolby Laboratories, Inc., Sydney, Australia",2013 22nd Australian Software Engineering Conference,"19 Sep 2013","2013","","","51","59","Numerous set similarity metrics have been used for ranking ""suspiciousness"" of code in spectral fault localization, which uses execution profiles of passed and failed test cases to help locate bugs. Research in data mining has identified several forms of possibly desirable symmetry in similarity metrics. Here we define several forms of ""duals"" of metrics, based on these forms of symmetries. Use of these duals, plus some other slight modifications, leads to several new similarity metrics. We show that versions of several previously proposed metrics are optimal, or nearly optimal, for locating single bugs. We also show that a form of duality exists between locating single bugs and locating ""deterministic"" bugs (execution of which always results in test case failure). Duals of the various single bug optimal metrics are optimal for locating such bugs. This more theoretical work leads to a conjecture about how different metrics could be chosen for different stages of software development.","2377-5408","978-0-7695-4995-8","10.1109/ASWEC.2013.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601292","program spectra;fault localization;debugging;set similarity","Measurement;Computer bugs;Software;Data mining;Vectors;Benchmark testing;Australia","","14","","26","IEEE","19 Sep 2013","","","IEEE","IEEE Conferences"
"Code Similarity Detection Technique Based on AST Unsupervised Clustering Method","Y. Xie; W. Zhou; H. Hu; Z. Lu; M. Wu","School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Science and Technology on Communication Information Security Control Laboratory, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; Science and Technology on Communication Information Security Control Laboratory, Beijing, China",2020 IEEE 6th International Conference on Computer and Communications (ICCC),"12 Feb 2021","2020","","","1590","1595","Code similarity detection is one of the important means to maintain the healthy development of the software eco-environment. Early code similarity detection method is mainly based on the code attribute measurement technology, this method can quickly detect more obvious similar parts on small-scale code datasets, but when faced with large-scale datasets or code segments with similar syntax and semantics, the detection performance is not effective. The new code similarity detection technology based on tree-structure representation and machine learning can adapt to different data changes, thus providing new solutions. This paper proposes a new detection method that combines the abstract syntax tree (AST) structure and unsupervised clustering, this new method can improve the detection efficiency of code clustering analysis, because it not only considers the syntax and semantic information of the code, but also reduces the workload of code data preprocessing through unsupervised clustering.","","978-1-7281-8635-1","10.1109/ICCC51575.2020.9344882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344882","code similarity detection;plagiarism detection;cluster analysis;unsupervised learning;code measurement method;abstract syntax tree","Clustering methods;Semantics;Clustering algorithms;Machine learning;Syntactics;Tools;Benchmark testing","","","","10","IEEE","12 Feb 2021","","","IEEE","IEEE Conferences"
"Fault Injection Scheme for Embedded Systems at Machine Code Level and Verification","A. Jin; J. -h. Jiang","Department of Computer Science and Technology, University of Tongji, Shanghai, China; Department of Computer Science and Technology, University of Tongji, Shanghai, China",2009 15th IEEE Pacific Rim International Symposium on Dependable Computing,"31 Dec 2009","2009","","","55","62","In order to evaluate software from the third party whose source codes are not available, after a careful analysis of the statistic data sorted by orthogonal defect classification, and the corresponding relation between patterns of high level language programs and machine codes, we propose a fault injection scheme at machine code level suitable respectively to the IA32 ARM and MIPS architecture, which takes advantage of mutating machine code. To prove the feasibility and validity of this scheme, two sets of programs are chosen as our experimental target: Set I consists of two different versions of triangle testing algorithms, and Set II is a subset of the Mibench which is a collection of performance benchmark programs designed for embedded systems; we inject both high level faults into the source code written in C language and the corresponding machine code level faults directly into the executables, and monitor their running on Linux. The results from experiments show that at least 96% of total similarity degree is obtained. Therefore, we conclude that the effect of injecting corresponding faults on both the source code level and machine code level are mostly the same. Therefore, our scheme is rather useful in analyzing system behavior under faults.","","978-0-7695-3849-5","10.1109/PRDC.2009.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5368226","embedded program;software-implemented fault injection;mutation;fault injection at machine code level;similarity degree","Embedded system;Genetic mutations;Embedded software;Pattern analysis;High level languages;Benchmark testing;Condition monitoring;Hardware;Computer architecture;Embedded computing","","5","","10","IEEE","31 Dec 2009","","","IEEE","IEEE Conferences"
"Wi-Not: Exploiting radio diversity in software-defined 802.11-based WLANs","E. Coronado; D. Harutyunyan; R. Riggio; J. Villalǒn; A. Garrido","High-Performance Networks and Architectures (RAAP), University of Castilla-La Mancha, Albacete, Spain; FBK CREATE-NET, Trento, Italy; FBK CREATE-NET, Trento, Italy; High-Performance Networks and Architectures (RAAP), University of Castilla-La Mancha, Albacete, Spain; High-Performance Networks and Architectures (RAAP), University of Castilla-La Mancha, Albacete, Spain",NOMS 2018 - 2018 IEEE/IFIP Network Operations and Management Symposium,"9 Jul 2018","2018","","","1","4","The increasing demand for live streaming and for remote sensing applications is bringing renewed interest on uplink performances in Wi-Fi networks. Radio diversity can improve the performance of such applications by opportunisti-cally receiving mobile users' traffic at multiple attachment points. However, radio diversity techniques can not be used in standard Wi-Fi networks due to backwards compatibility problems. In this paper we present Wi-Not, a novel SDN-based solution for exploiting radio diversity in software-defined WLANs. Wi-Not allows mobile terminals to be associated to multiple Wi-Fi APs in the uplink direction improving frame delivery probability in uplink-constrained applications. Wi-Not does not require changes to the mobile terminals and can be easily deployed with minimal changes to the network infrastructure. An experimental evaluation carried out over a real-world testbed shows that this approach can deliver an improvement of up to 80% in terms of UDP goodput and up to 60% of TCP throughput. We release the entire implementation including the controller and the data-path under a permissive license for academic use.","2374-9709","978-1-5386-3416-5","10.1109/NOMS.2018.8406197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8406197","Software Defined Networking;IEEE 802.11;WLANs;load-balancing;resiliency","Uplink;Downlink;IEEE 802.11 Standard;Wireless communication;Bandwidth;Switches","","","1","13","IEEE","9 Jul 2018","","","IEEE","IEEE Conferences"
"Towards Generic User Interface for Web Based Systems Serving Similar Functions","R. Ahmad; Zhang Li; F. Azam","School of Software Engineering, Beijing Aeronautics and Astronautics University, Beijing, China; School of Software Engineering, Beijing Aeronautics and Astronautics University, Beijing, China; School of Software Engineering, Beijing Aeronautics and Astronautics University, Beijing, China","Fourth International Conference on Software Engineering Research, Management and Applications (SERA'06)","11 Sep 2006","2006","","","297","306","During the rapid growth of World Wide Web in the recent past, ‘usability’ and ‘navigation’ have emerged as problems of concern to the research community. Large web systems are being made so complex that often the users have to make excessive amount of ‘navigational efforts’ to complete their tasks. We identify certain aspects which aggravate the ‘navigational burden’ of a user. Vital amongst them are, complex navigational structure of web, unfamiliarity of users with the website, and disagreement between the research community and practitioners. This paper is based on the empirical analysis of an experimental data obtained from the prospective students who were invited to interact with the websites of few world class educational institutions from four different countries. The data allows us to determine that despite active research in the area of usability engineering, the users still experience heavy ‘navigational burden’ while performing same task using similar systems. The users do not observe any improvement in their ‘familiarity’ with these web systems even when they interact with more than one such systems which serve similar functions. This leads us to propose a solution with a different approach that is; to resort to ‘Generic User Interface’ as a ‘standard’ for organizations serving similar functions such as universities, hospitals etc. We then present some convincing arguments to support our proposal and answer some of the opponent’s voices, followed by a brief discussion on the future work to be done in this direction.","","0-7695-2656-X","10.1109/SERA.2006.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1691395","","User interfaces;Navigation;Usability;Software engineering;ISO standards;Testing;Web sites;Educational institutions;Data engineering;Hospitals","","2","","33","IEEE","11 Sep 2006","","","IEEE","IEEE Conferences"
"Diversity: A Heuristic to Improve Robustness of Self-Adaptive Cloud Architectures","F. Chauvel; H. Song; F. Fleurey","SINTEF ICT, Oslo, Norway; SINTEF ICT, Oslo, Norway; SINTEF ICT, Oslo, Norway",2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC),"14 Mar 2016","2015","","","132","141","In complex biological systems, the hypothesis that bio-diversity contributes to stability or robustness is an active debate. The FP7 DIVERSIFY project tests whether this hypothesis holds for software systems, and explores the use of diversity as a heuristic to increase robustness in self-adaptive architectures. Inspired by Ecology, we present here a technique to evaluate diversity of software architectures and we report preliminary investigations of its correlation with robustness. Given existing cloud-based architectures, we artificially inject predefined levels of diversity and measure the resulting robustness. In four out of our five industrial case studies, a higher diversity appeared correlated with a higher robustness.","","978-0-7695-5697-0","10.1109/UCC.2015.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7431404","cloud-computing;service architecture;diversity;robustness;correlation;models","Robustness;Cloud computing;Topology;Computer architecture;Sociology;Correlation","","1","","26","","14 Mar 2016","","","IEEE","IEEE Conferences"
"A Fast Heuristic Algorithm for Similarity Search in Large DNA Databases","I. -S. Jeong; K. -W. Park; H. -S. Lim",NA; NA; NA,2007 Frontiers in the Convergence of Bioscience and Information Technologies,"16 May 2008","2007","","","335","340","Knowledge Discovery techniques seek to find new information about a domain. These techniques can either be manually performed by an expert, or automated using software algorithms (Machine Learning). However some domains (such as the field of lung function testing) contain volumes of data too vast for effective manual analysis, and require background knowledge too complex for Machine Learning algorithms. This study examines how the Multiple Classification Ripple-Down Rules (MCRDR) Knowledge Acquisition process can be adapted to develop a new Knowledge Discovery method, Exposed MCRDR. A prototype system was developed and tested in the domain of lung function. Preliminary results suggest that the EMCRDR method can be successfully applied to efficiently discover new knowledge in a complex domain. The study also reveals many potential areas of study and development for the MCRDR method, and Knowledge Acquisition and Knowledge Discovery methods in general.","","978-0-7695-2999-8","10.1109/FBIT.2007.147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4524129","","Heuristic algorithms;DNA;Databases;Machine learning algorithms;Lungs;Knowledge acquisition;Software performance;Software algorithms;Machine learning;Testing","","","","","IEEE","16 May 2008","","","IEEE","IEEE Conferences"
"Benchmarking mid-range CAD tools in a diverse product environment: recommendations and results","R. A. Bauernschub; D. E. King","AAI Corporation, Hunt Valley, MD, USA; TTC, Germantown, MD, USA",ITHERM 2000. The Seventh Intersociety Conference on Thermal and Thermomechanical Phenomena in Electronic Systems (Cat. No.00CH37069),"6 Aug 2002","2000","1","","193","198","Processing power increases of recent years, coupled with decreasing costs of both hardware and software, have combined to dramatically improve product designers' access to CAD tools. Operations that were once only possible on expensive Unix-based workstations can now be performed on less expensive Windows-based personal computers. A new category of CAD tools (commonly described as ""mid-range"" tools) has emerged to exploit these trends. This paper outlines the process used to develop a custom benchmark test used to evaluate three mid-range CAD tools: Solid Edge v.6, Solid Works 98+, and Mechanical Desktop v.3. Specific objectives of the exercise were to compare the mid-range tools against the current Unix-based CAD tool in order to: (i) ascertain if significant ""ease-of-use"" could be realized, and (ii) determine what capabilities would be lost (if these tools replaced the current tool) or gained (if they were used to augment the current tool). Topics addressed include: identifying tool requirements, conducting initial screening, developing evaluation tests, specifying both objective and subjective scoring systems, performing the tests, and presenting the results to users and executive management. The effects of a diverse product line on the benchmarking activity are noted. Development of special requirements due to data transfer to and from other CAD and CAE tools is outlined.","1089-9870","0-7803-5912-7","10.1109/ITHERM.2000.866826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=866826","","Design automation;Benchmark testing;Solids;System testing;Costs;Hardware;Software tools;Product design;Workstations;Microcomputers","","","","12","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"A Novel Diversity Guided Galactic Swarm Optimization With Feedback Mechanism","O. Uymaz; B. Turkoglu; E. Kaya; T. Asuroglu","Department of Software Engineering, Konya Technical University, Konya, Türkiye; Department of Artificial Intelligence and Data Engineering, Ankara University, Ankara, Türkiye; Department of Computer Engineering, Konya Technical University, Konya, Türkiye; Faculty of Medicine and Health Technology, Tampere University, Tampere, Finland",IEEE Access,"9 Aug 2024","2024","12","","108154","108175","Galactic Swarm Optimization (GSO) is an optimization method inspired by the movements of stars and star clusters in the galaxy. This method aims to find the best solution in two phases using other known optimization methods. The first phase explores the search space, while the second phase tries to refine the best solution. In GSO, the population of the best individuals obtained from the first phase is used as the initial population for the second phase. This process is repeated until the stopping criterion is met. Although the knowledge obtained from the first phase is transferred to the second phase in GSO, there is no knowledge transfer from the second phase to the first phase. In this study, we propose a modification where the knowledge obtained in the second phase is transferred back to the first phase. Additionally, the Particle Swarm Optimization (PSO) method, used as the search method in the original study, has a fast convergence problem, which hinders an effective discovery process in the first phase of GSO. To address this, the proposed diversity-guided modification regulates population diversity and enhances exploration. To demonstrate the performance of the proposed method, twenty-six traditional benchmark functions and three engineering design problems were used. The proposed method was compared with the original GSO and six current optimization methods. The results of the experimental study were analyzed using statistical tests. The experimental results and analyses show that the proposed method performs successfully.","2169-3536","","10.1109/ACCESS.2024.3438104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10623140","Galactic swarm optimization;population diversity;metaheuristic optimization","Statistics;Sociology;Particle swarm optimization;Metaheuristics;Classification algorithms;Stars;Search problems","","","","46","CCBY","5 Aug 2024","","","IEEE","IEEE Journals"
"Fuzzy Similarity Index For Discrimination Of EEG Signals","E. D. Ubeyli","Department of Electrical and Electronics Engineering, Faculty of Engineering, TOBB University of Economics and Technology, Ankara, Turkey",2006 International Conference of the IEEE Engineering in Medicine and Biology Society,"15 Dec 2016","2006","","","5346","5349","In this study, a new approach based on the computation of fuzzy similarity index was presented for discrimination of electroencephalogram (EEG) signals. The EEG, a highly complex signal, is one of the most common sources of information used to study brain function and neurological disorders. The analyzed EEG signals were consisted of five sets (set A-healthy volunteer, eyes open; set B-healthy volunteer, eyes closed; set C-seizure-free intervals of five patients from hippocampal formation of opposite hemisphere; set D-seizure-free intervals of five patients from epileptogenic zone; set E-epileptic seizure segments). The EEG signals were considered as chaotic signals and this consideration was tested successfully by the computation of Lyapunov exponents. The computed Lyapunov exponents were used to represent the EEG signals. The aim of the study is discriminating the EEG signals by the combination of Lyapunov exponents and fuzzy similarity index. Toward achieving this aim, fuzzy sets were obtained from the feature sets (Lyapunov exponents) of the signals under study. The results demonstrated that the similarity between the fuzzy sets of the studied signals indicated the variabilities in the EEG signals. Thus, the fuzzy similarity index could discriminate the healthy EEG segments (sets A and B) and the other three types of segments (sets C, D, and E) recorded from epileptic patients","1557-170X","1-4244-0032-5","10.1109/IEMBS.2006.259316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4463011","Fuzzy similarity index;Chaotic signal;Lyapunov exponents;Electroencephalogram (EEG) signals","Electroencephalography;Chaos;Epilepsy;Fuzzy sets;Signal analysis;Eyes;Diseases;Signal generators;Brain modeling;Parameter estimation","Algorithms;Artificial Intelligence;Diagnosis, Computer-Assisted;Diagnosis, Computer-Assisted;Electroencephalography;Electroencephalography;Epilepsy;Epilepsy;Fuzzy Logic;Humans;Models, Statistical;Models, Theoretical;Signal Processing, Computer-Assisted;Software","1","","16","IEEE","15 Dec 2016","","","IEEE","IEEE Conferences"
"An Efficient Inclusive Similarity Based Clustering (ISC) Algorithm for Big Data","J. Sangeetha; V. S. J. Prakash","Cauvery College For Women, Trichy; NA",2017 World Congress on Computing and Communication Technologies (WCCCT),"19 Oct 2017","2017","","","84","88","In recent days, the big data opinion mining is considered as an important research area because, the size of the user reviews increase in petabytes. Opinion classification is the process of identifying the positive, negative and neutral opinion from the text. The traditional data mining software tools find it difficult to manage the reviews because of its size. Hence, to provide an efficient big data opinion mining, an efficient Inclusive Similarity based Clustering (ISC) algorithm is proposed. During pre-processing the data is cleaned with Parts of Speech (PoS) tagger and sliced by using the proposed Threshold based Data Partitioning (TDP) algorithm. After pre-processing the dataset, the inclusive similarity algorithm computes the similarity between the consecutive reviews and constructs an adjacency matrix. The proposed ISC algorithm exploits the adjacency matrix and merges the clusters into a single cluster. The performance of the proposed method is validated with the existing algorithms for the metrics such as time consumption, memory utility and accuracy. The comparison results prove that the proposed ISC algorithm provides optimal results for all the metrics than the existing algorithms.","","978-1-5090-5573-9","10.1109/WCCCT.2016.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074498","Inclusive Similarity based Clustering (ISC);Parts of Speech (PoS);min-max normalization;opinion mining;inclusive similarity algorithm;slicing","Clustering algorithms;Algorithm design and analysis;Partitioning algorithms;Data mining;Classification algorithms;Filtering;Big Data","","4","","21","IEEE","19 Oct 2017","","","IEEE","IEEE Conferences"
"A Threefold Similarity Analysis of Crowdsourcing Feeds","K. Liu; G. Motta; L. You; T. Ma","Dept. of Industrial and Information Engineering, University of Pavia, Pavia, Italy; Dept. of Industrial and Information Engineering, University of Pavia, Pavia, Italy; Dept. of Industrial and Information Engineering, University of Pavia, Pavia, Italy; Dept. of Industrial and Information Engineering, University of Pavia, Pavia, Italy",2015 International Conference on Service Science (ICSS),"8 Feb 2016","2015","","","93","98","Crowdsourcing is a valuable social sensing for the smarter city. We present an approach for classifying crowd sourced feeds from a threefold point of view, namely image, text, and geography. The main idea is to extract feeds within a specific geographic range, and then analyze similarity of image color and text semantic. The approach enables to identify feeds that report the same issue, hence filtering redundant information. Based on proved methods and algorithms, such approach has been implemented in a software application, called CITY FEED, that is used by the Municipality of Pavia.","2165-3836","978-1-4799-9947-7","10.1109/ICSS.2015.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7400779","Crowdsourcing;Smart city;Image similarity analysis;Text similarity analysis","Feeds;Cities and towns;Image color analysis;Histograms;Semantics;Integrated circuit modeling","","3","","29","IEEE","8 Feb 2016","","","IEEE","IEEE Conferences"
