@inbook{10.1145/3387940.3392238,
author = {S\'{a}nchez-Gord\'{o}n, Mary and Rijal, Laxmi and Colomo-Palacios, Ricardo},
title = {Beyond Technical Skills in Software Testing: Automated versus Manual Testing},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392238},
abstract = {Software testing is not a purely technical, but rather socio-technical activity. Although there are a few studies on this topic, to the best of our knowledge there is a lack of research focusing specifically on skills, in particular soft skills needed for automated and manual testing. In both cases, software testing is a challenging task that requires considerable effort by practitioners. The aim of this study is to identify what are the most valued skills with regards to these different types of testing. To do so, a survey was applied among software practitioners and 72 responses were received. The questionnaire covers 35 skills grouped in technical (hard) and non-technical (soft) skills. The results of this exploratory study provide empirical evidence that reveals the importance that software practitioners give to hard and soft skills alike.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {161–164},
numpages = {4}
}

@inproceedings{10.1145/1276958.1277178,
author = {Windisch, Andreas and Wappler, Stefan and Wegener, Joachim},
title = {Applying Particle Swarm Optimization to Software Testing},
year = {2007},
isbn = {9781595936974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1276958.1277178},
doi = {10.1145/1276958.1277178},
abstract = {Evolutionary structural testing is an approach to automatically generating test cases that achieve high structural code coverage. It typically uses genetic algorithms (GAs) to search for relevant test cases. In recent investigations particle swarm optimization (PSO), an alternative search technique, often outperformed GAs when applied to various problems. This raises the question of how PSO competes with GAs in the context of evolutionary structural testing.In order to contribute to an answer to this question, we performed experiments with 25 small artificial test objects and 13 more complex industrial test objects taken from various development projects. The results show that PSO outperforms GAs for most code elements to be covered in terms of effectiveness and efficiency.},
booktitle = {Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation},
pages = {1121–1128},
numpages = {8},
keywords = {evolutionary testing, particle swarm optimization, automatic test case generation, genetic algorithm},
location = {London, England},
series = {GECCO '07}
}

@inproceedings{10.1145/3439961.3439993,
author = {Souza, \'{E}rica Ferreira de and Falbo, Ricardo de Almeida and Specimille, Marcos S. and Coelho, Alexandre G. N. and Vijaykumar, Nandamudi L. and Felizardo, Katia Romero and Meinerz, Giovani Volnei},
title = {Experience Report on Developing an Ontology-Based Approach for Knowledge Management in Software Testing},
year = {2020},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439993},
doi = {10.1145/3439961.3439993},
abstract = { Software testing is a knowledge intensive process. Thus, Knowledge Management (KM) emerges as a means to manage testing knowledge, and, consequently, to improve software quality. However, there are only a few KM solutions supporting software testing. This paper reports experiences from the development of an approach, Ontology-based Testing Knowledge Management (OntoT-KM), to assist in launching KM initiatives in the software testing domain with the support of Knowledge Management Systems (KMSs). OntoT-KM provides a process guiding how to start applying KM in software testing. OntoT-KM is based on the findings of a systematic mapping on KM in software testing and the results of a survey with testing practitioners. Moreover, OntoT-KM considers the conceptualization established by a Reference Ontology on Software Testing (ROoST). As a proof of concept, OntoT-KM was applied to develop a KMS called Testing KM Portal (TKMP), which was evaluated in terms of usefulness, usability and functional correctness. Results show that the developed KMS from OntoT-KM is a potential system for managing knowledge in software testing, so, the approach is able to guide KM initiatives in software testing.},
booktitle = {19th Brazilian Symposium on Software Quality},
articleno = {32},
numpages = {10},
keywords = {Software Testing, Testing Ontology, Knowledge Management System, Knowledge Management},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS'20}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00015,
author = {Kochhar, Pavneet Singh and Xia, Xin and Lo, David},
title = {Practitioners' Views on Good Software Testing Practices},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00015},
doi = {10.1109/ICSE-SEIP.2019.00015},
abstract = {Software testing is an integral part of software development process. Unfortunately, for many projects, bugs are prevalent despite testing effort, and testing continues to cost significant amount of time and resources. This brings forward the issue of test case quality and prompts us to investigate what make good test cases. To answer this important question, we interview 21 and survey 261 practitioners, who come from many small to large companies and open source projects distributed in 27 countries, to create and validate 29 hypotheses that describe characteristics of good test cases and testing practices. These characteristics span multiple dimensions including test case contents, size and complexity, coverage, maintainability, and bug detection. We present highly rated characteristics and rationales why practitioners agree or disagree with them, which in turn highlight best practices and trade-offs that need to be considered in the creation of test cases. Our findings also highlight open problems and opportunities for software engineering researchers to improve practitioner activities and address their pain points.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {61–70},
numpages = {10},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1145/331960.331965,
author = {Sirer, Emin G\"{u}n and Bershad, Brian N.},
title = {Using Production Grammars in Software Testing},
year = {2000},
isbn = {1581132557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/331960.331965},
doi = {10.1145/331960.331965},
abstract = {Extensible typesafe systems, such as Java, rely critically on a large and complex software base for their overall protection and integrity, and are therefore difficult to test and verify. Traditional testing techniques, such as manual test generation and formal verification, are too time consuming, expensive, and imprecise, or work only on abstract models of the implementation and are too simplistic. Consequently, commercial virtual machines deployed so far have exhibited numerous bugs and security holes.In this paper, we discuss our experience with using production grammars in testing large, complex and safety-critical software systems. Specifically, we describe lava, a domain specific language we have developed for specifying production grammars, and relate our experience with using lava to generate effective test suites for the Java virtual machine. We demonstrate the effectiveness of production grammars in generating complex test cases that can, when combined with comparative and variant testing techniques, achieve high code and value coverage. We also describe an extension to production grammars that enables concurrent generation of certificates for test cases. A certificate is a behavioral description that specifies the intended outcome of the generated test case, and therefore acts as an oracle by which the correctness of the tested system can be evaluated in isolation. We report the results of applying these testing techniques to commercial Java implementations. We conclude that the use of production grammars in combination with other automated testing techniques is a powerful and effective method for testing software systems, and is enabled by a special purpose language for specifying extended production grammars.},
booktitle = {Proceedings of the 2nd Conference on Domain-Specific Languages},
pages = {1–13},
numpages = {13},
location = {Austin, Texas, USA},
series = {DSL '99}
}

@article{10.1145/331963.331965,
author = {Sirer, Emin G\"{u}n and Bershad, Brian N.},
title = {Using Production Grammars in Software Testing},
year = {2000},
issue_date = {Jan. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/331963.331965},
doi = {10.1145/331963.331965},
abstract = {Extensible typesafe systems, such as Java, rely critically on a large and complex software base for their overall protection and integrity, and are therefore difficult to test and verify. Traditional testing techniques, such as manual test generation and formal verification, are too time consuming, expensive, and imprecise, or work only on abstract models of the implementation and are too simplistic. Consequently, commercial virtual machines deployed so far have exhibited numerous bugs and security holes.In this paper, we discuss our experience with using production grammars in testing large, complex and safety-critical software systems. Specifically, we describe lava, a domain specific language we have developed for specifying production grammars, and relate our experience with using lava to generate effective test suites for the Java virtual machine. We demonstrate the effectiveness of production grammars in generating complex test cases that can, when combined with comparative and variant testing techniques, achieve high code and value coverage. We also describe an extension to production grammars that enables concurrent generation of certificates for test cases. A certificate is a behavioral description that specifies the intended outcome of the generated test case, and therefore acts as an oracle by which the correctness of the tested system can be evaluated in isolation. We report the results of applying these testing techniques to commercial Java implementations. We conclude that the use of production grammars in combination with other automated testing techniques is a powerful and effective method for testing software systems, and is enabled by a special purpose language for specifying extended production grammars.},
journal = {SIGPLAN Not.},
month = {dec},
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1145/563340.563446,
author = {Goldwasser, Michael H.},
title = {A Gimmick to Integrate Software Testing throughout the Curriculum},
year = {2002},
isbn = {1581134738},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/563340.563446},
doi = {10.1145/563340.563446},
abstract = {We discuss our experiences in which students of a programming course were asked to submit both an implementation as well as a test set. A portion of a student's grade was then devoted both to the validity of a student's program on others' test sets, as well as how that student's test set performed in uncovering flaws in others' programs. The advantages are many, as this introduces implicit principles of software testing together with a bit of fun competition. The major complication is that such an all-pairs execution of tests grows quadratically with the number of participants, necessitating a fully automated scoring system.},
booktitle = {Proceedings of the 33rd SIGCSE Technical Symposium on Computer Science Education},
pages = {271–275},
numpages = {5},
location = {Cincinnati, Kentucky},
series = {SIGCSE '02}
}

@article{10.1145/563517.563446,
author = {Goldwasser, Michael H.},
title = {A Gimmick to Integrate Software Testing throughout the Curriculum},
year = {2002},
issue_date = {March 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {0097-8418},
url = {https://doi.org/10.1145/563517.563446},
doi = {10.1145/563517.563446},
abstract = {We discuss our experiences in which students of a programming course were asked to submit both an implementation as well as a test set. A portion of a student's grade was then devoted both to the validity of a student's program on others' test sets, as well as how that student's test set performed in uncovering flaws in others' programs. The advantages are many, as this introduces implicit principles of software testing together with a bit of fun competition. The major complication is that such an all-pairs execution of tests grows quadratically with the number of participants, necessitating a fully automated scoring system.},
journal = {SIGCSE Bull.},
month = {feb},
pages = {271–275},
numpages = {5}
}

@inproceedings{10.1145/3349341.3349444,
author = {Yu, Jiujiu and Zhang, Jishan and Yu, Chunyan and Pan, Liqiong and Li, Shouyin},
title = {Design of Subject-Based Learning Website for Software Testing Course Based on Smart Campus},
year = {2019},
isbn = {9781450371506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349341.3349444},
doi = {10.1145/3349341.3349444},
abstract = {The integration of information technology and smart education has been realized through smart campus deeply, which has promoted the continuous development of MOOC (Massive Open Online Course) and SPOC (Small Private Online Course). A subject-based learning website for software testing course on the cloud platform of smart education is designed that based on smart campus. Teachers could guide the students to implement learning activities on SPOC in the form of task exploration by releasing related topics on software testing course and get good learning feedback on application. Finally, further research work is expected on construction of the subject-based learning website in local universities.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science},
pages = {423–427},
numpages = {5},
keywords = {Software testing, Cloud platform of smart education, SPOC, Smart campus, Subject-based learning website, Task exploration},
location = {Wuhan, Hubei, China},
series = {AICS 2019}
}

@inproceedings{10.1145/359369.359392,
author = {Jones, Edward L.},
title = {Software Testing in the Computer Science Curriculum -- a Holistic Approach},
year = {2000},
isbn = {1581132719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/359369.359392},
doi = {10.1145/359369.359392},
abstract = {Although testing accounts for 50% of the cost of software, it receives little treatment in most curricula. This paper presents some approaches to giving all students multiple, incremental exposures to software testing throughout the curriculum. A unifying framework is presented which identifies a minimal set of test experiences, skills and concepts students should accumulate. The holistic approach combines common test experiences in core courses, an elective course in software testing, and volunteer participation in a test laboratory.},
booktitle = {Proceedings of the Australasian Conference on Computing Education},
pages = {153–157},
numpages = {5},
location = {Melbourne, Australia},
series = {ACSE '00}
}

@inproceedings{10.5555/2819009.2819250,
author = {Gay, Gregory and Antoniol, Giuliano},
title = {8th International Workshop on Search-Based Software Testing (SBST 2015)},
year = {2015},
publisher = {IEEE Press},
abstract = {This paper is a report on the 8th International Workshop on Search-Based Software Testing at the 37th International Conference on Sofrware Engineering (ICSE). Search-Based Software Testing (SBST) is a form of Search-Based Software Engineering (SBSE) that optimizes testing through the use of computational search. SBST is used to generate test data, prioritize test cases, minimize test suites, reduce human oracle cost, verify software models, test service-orientated architectures, construct test suites for interaction testing, and validate real-time properties. The objectives of this workshop are to bring together researchers and industrial practitioners from SBST and the wider software engineering community to share experience and provide directions for future research, and to encourage the use of search techniques to combine aspects of testing with other aspects of the software engineering lifecycle.Three full research papers, three short papers, and three position papers will be presented in the two-day workshop. Additionally, six development groups have pitted their test generation tools against a common set of programs and benchmarks, and will present their techniques and results. This report will give the background of the workshop and detail the provisional program.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {1001–1002},
numpages = {2},
location = {Florence, Italy},
series = {ICSE '15}
}

@article{10.1145/2464526.2464539,
author = {Rao, K. Koteswara and Raju, GSVP and Nagaraj, Srinivasan},
title = {Optimizing the Software Testing Efficiency by Using a Genetic Algorithm: A Design Methodology},
year = {2013},
issue_date = {May 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/2464526.2464539},
doi = {10.1145/2464526.2464539},
abstract = {This paper presents a design method for optimizing software-testing efficiency by identifying the most critical path clusters in a program. This is done by the application of soft computing techniques, specifically genetic algorithms. We develop a genetic algorithm that selects the software path clusters to test, which are weighted in accordance with the criticality of the path. Exhaustive software testing is rarely possible because it becomes intractable for even medium-sized software applications. Typically only parts of a program can be tested, but these parts are not necessarily the most error prone ones. Therefore, we are designing a more selective approach for testing the paths that are more critical, which results in improving the testing efficiency.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {may},
pages = {1–5},
numpages = {5},
keywords = {genetic algorithm, testing efficiency, soft computing, control flow graph, bugs, optimization}
}

@article{10.1145/3442694,
author = {Bluemke, Ilona and Malanowska, Agnieszka},
title = {Software Testing Effort Estimation and Related Problems: A Systematic Literature Review},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442694},
doi = {10.1145/3442694},
abstract = {Although testing effort estimation is a very important task in software project management, it is rarely described in the literature. There are many difficulties in finding any useful methods or tools for this purpose. Solutions to many other problems related to testing effort calculation are published much more often. There is also no research focusing on both testing effort estimation and all related areas of software engineering. To fill this gap, we performed a systematic literature review on both questions. Although our primary objective was to find some tools or implementable metods for test effort estimation, we have quickly discovered many other interesting topics related to the main one. The main contribution of this work is the presentation of the testing effort estimation task in a very wide context, indicating the relations with other research fields. This systematic literature review presents a detailed overview of testing effort estimation task, including challenges and approaches to automating it and the solutions proposed in the literature. It also exhaustively investigates related research topics, classifying publications that can be found in connection to the testing effort according to seven criteria formulated on the basis of our research questions. We present here both synthesis of our finding and the deep analysis of the stated research problems.},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {53},
numpages = {38},
keywords = {Testing effort, testing effort estimation-related problems, systematic literature review, testing effort estimation}
}

@inproceedings{10.1145/3084226.3084265,
author = {Karhap\"{a}\"{a}, Pertti and Haghighatkhah, Alireza and Oivo, Markku},
title = {What Do We Know about Alignment of Requirements Engineering and Software Testing?},
year = {2017},
isbn = {9781450348041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3084226.3084265},
doi = {10.1145/3084226.3084265},
abstract = {Context: The alignment of different software engineering activities for coordinated functioning and optimized product development is of great importance, particularly in industrial-scale development. The link between intermediate activities has been researched extensively, but the link between requirements engineering (RE) and software testing (ST) is a relatively less explored area.Objective: The objective of this study is to aggregate, structure, and classify all existing research regarding alignment of RE and ST published by the end of 2015.Method: We conducted a systematic mapping study (SMS) and aggregated all studies relevant to our scope. The primary studies are analyzed in terms of publication trend, focus area, i.e., how alignment is supported, the application domain and benefits and challenges, methodological data, and scientific rigor and industrial relevance.Results: There is a growing interest towards the topic. Several different techniques have been identified to improve RE and ST alignment. Test generation from requirements specification has received most attention. Alignment of RE and ST is particularly important for large safety-critical domains. While many challenges have been reported, the supporting evidence for benefits is scarce. Frameworks/methods/techniques is the most frequent contribution type. Solution proposal and evaluation research were the most frequently applied research type. Case study research was the most frequently applied research method, however, almost half of the studies did not clearly report any research method.Conclusion: Despite the numerous approaches that are proposed, it is not clear what approach is suitable in what context and why. To support industry in RE and ST alignment, guidelines and tool support are needed. The supporting evidence for claimed benefits is very limited. Overall, the research area is in its early stages and an increase in both the number and rigor of empirical studies are required.},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
pages = {354–363},
numpages = {10},
keywords = {Software engineering, validation, alignment, software testing, requirements engineering, verification},
location = {Karlskrona, Sweden},
series = {EASE'17}
}

@inproceedings{10.1109/ASE.2003.1240327,
author = {D\'{\i}az, Eugenia and Tuya, Javier and Blanco, Raquel},
title = {Automated Software Testing Using a Metaheuristic Technique Based on Tabu Search},
year = {2003},
isbn = {0769520359},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2003.1240327},
doi = {10.1109/ASE.2003.1240327},
abstract = {The use of techniques for automating the generation of software test cases is very important as it can reduce the time and cost of this process. The latest methods for automatic generation of tests use metaheuristic search techniques, i.e. Genetic Algorithms and Simulated Annealing. There is a great deal of research into the use of Genetic Algorithms to obtain a specific coverage in software testing but there is none using the metaheuristic Tabu Search technique. In this paper, we explain how we have created an efficient testing technique that combines Tabu Search with Korel's chaining approach. Our technique automatically generates test data in order to obtain branch coverage in software testing.},
booktitle = {Proceedings of the 18th IEEE International Conference on Automated Software Engineering},
pages = {310–313},
numpages = {4},
location = {Montreal, Quebec, Canada},
series = {ASE'03}
}

@inproceedings{10.1145/3321707.3321880,
author = {Oliveira, Carlos and Aleti, Aldeida and Li, Yuan-Fang and Abdelrazek, Mohamed},
title = {Footprints of Fitness Functions in Search-Based Software Testing},
year = {2019},
isbn = {9781450361118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3321707.3321880},
doi = {10.1145/3321707.3321880},
abstract = {Testing is technically and economically crucial for ensuring software quality. One of the most challenging testing tasks is to create test suites that will reveal potential defects in software. However, as the size and complexity of software systems increase, the task becomes more labour-intensive and manual test data generation becomes infeasible. To address this issue, researchers have proposed different approaches to automate the process of generating test data using search techniques; an area that is known as Search-Based Software Testing (SBST).SBST methods require a fitness function to guide the search to promising areas of the solution space. Over the years, a plethora of fitness functions have been proposed. Some methods use control information, others focus on goals. Deciding on what fitness function to use is not easy, as it depends on the software system under test. This work investigates the impact of software features on the effectiveness of different fitness functions. We propose the Mapping the Effectiveness of Test Automation (META) Framework which analyses the footprint of different fitness functions and creates a decision tree that enables the selection of the appropriate function based on software features.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1399–1407},
numpages = {9},
keywords = {search based software engineering, genetic algorithms},
location = {Prague, Czech Republic},
series = {GECCO '19}
}

@inproceedings{10.1145/2993288.2993303,
author = {da Costa Ara\'{u}jo, Iaron and da Silva, Wesley Oliveira and de Sousa Nunes, Jos\'{e} B. and Neto, Francisco Oliveira},
title = {ARRESTT: A Framework to Create Reproducible Experiments to Evaluate Software Testing Techniques},
year = {2016},
isbn = {9781450347662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993288.2993303},
doi = {10.1145/2993288.2993303},
abstract = {Researchers have reported that software testing techniques (STT) in general lack empirical evidence, and yet empirical studies are still maturing in our field. Furthermore, validating existing experiments is often neglected by researchers in software engineering. Both executing and reproducing experiments are important to validate current scientific discoveries reported in literature. However, there is a lack of tools and frameworks to support these tasks. We propose a framework named ARRESTT that aids experimenters in creating and reproducing experiments. We validate ARRESTT through reproduction of a known experiment with test case selection techniques, and we are able to achieve results very similar to the original experiment. Based on an evaluation of reproducibility attributes, we conclude that ARRESTT enhances reproducibility of an experiment and does not demand a lot of effort to configure and execute an experiment.},
booktitle = {Proceedings of the 1st Brazilian Symposium on Systematic and Automated Software Testing},
articleno = {1},
numpages = {10},
keywords = {Software Testing Techniques, Reproducible Research, Empirical Software Engineering},
location = {Maringa, Parana, Brazil},
series = {SAST}
}

@inproceedings{10.1145/2600821.2600832,
author = {Sahaf, Zahra and Garousi, Vahid and Pfahl, Dietmar and Irving, Rob and Amannejad, Yasaman},
title = {When to Automate Software Testing? Decision Support Based on System Dynamics: An Industrial Case Study},
year = {2014},
isbn = {9781450327541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600821.2600832},
doi = {10.1145/2600821.2600832},
abstract = { Software test processes are complex and costly. To reduce testing effort without compromising effectiveness and product quality, automation of test activities has been adopted as a popular approach in software industry. However, since test automation usually requires substantial upfront investments, automation is not always more cost-effective than manual testing. To support decision-makers in finding the optimal degree of test automation in a given project, we propose in this paper a simulation model using the System Dynamics (SD) modeling technique. With the help of the simulation model, we can evaluate the performance of test processes with varying degrees of automation of test activities and help testers choose the most optimal cases. As the case study, we describe how we used our simulation model in the context of an Action Research (AR) study conducted in collaboration with a software company in Calgary, Canada. The goal of the study was to investigate how the simulation model can help decision-makers decide whether and to what degree the company should automate their test processes. As a first step, we compared the performances of the current fully manual testing with several cases of partly automated testing as anticipated for implementation in the partner company. The development of the simulation model as well as the analysis of simulation results helped the partner company to get a deeper understanding of the strengths and weaknesses of their current test process and supported decision-makers in the cost effective planning of improvements of selected test activities. },
booktitle = {Proceedings of the 2014 International Conference on Software and System Process},
pages = {149–158},
numpages = {10},
keywords = {system dynamics, automated testing, process simulation, manual testing, decision support, Software testing},
location = {Nanjing, China},
series = {ICSSP 2014}
}

@inproceedings{10.1145/2635868.2635929,
author = {Just, Ren\'{e} and Jalali, Darioush and Inozemtseva, Laura and Ernst, Michael D. and Holmes, Reid and Fraser, Gordon},
title = {Are Mutants a Valid Substitute for Real Faults in Software Testing?},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635929},
doi = {10.1145/2635868.2635929},
abstract = { A good test suite is one that detects real faults. Because the set of faults in a program is usually unknowable, this definition is not useful to practitioners who are creating test suites, nor to researchers who are creating and evaluating tools that generate test suites. In place of real faults, testing research often uses mutants, which are artificial faults -- each one a simple syntactic variation -- that are systematically seeded throughout the program under test. Mutation analysis is appealing because large numbers of mutants can be automatically-generated and used to compensate for low quantities or the absence of known real faults. Unfortunately, there is little experimental evidence to support the use of mutants as a replacement for real faults. This paper investigates whether mutants are indeed a valid substitute for real faults, i.e., whether a test suite’s ability to detect mutants is correlated with its ability to detect real faults that developers have fixed. Unlike prior studies, these investigations also explicitly consider the conflating effects of code coverage on the mutant detection rate. Our experiments used 357 real faults in 5 open-source applications that comprise a total of 321,000 lines of code. Furthermore, our experiments used both developer-written and automatically-generated test suites. The results show a statistically significant correlation between mutant detection and real fault detection, independently of code coverage. The results also give concrete suggestions on how to improve mutation analysis and reveal some inherent limitations. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {654–665},
numpages = {12},
keywords = {Test effectiveness, real faults, mutation analysis, code coverage},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inbook{10.1145/3387939.3388616,
author = {Haensel, Joachim and Adriano, Christian M. and Dyck, Johannes and Giese, Holger},
title = {Collective Risk Minimization via a Bayesian Model for Statistical Software Testing},
year = {2020},
isbn = {9781450379625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387939.3388616},
abstract = {In the last four years, the number of distinct autonomous vehicles platforms deployed in the streets of California increased 6-fold, while the reported accidents increased 12-fold. This can become a trend with no signs of subsiding as it is fueled by a constant stream of innovations in hardware sensors and machine learning software. Meanwhile, if we expect the public and regulators to trust the autonomous vehicle platforms, we need to find better ways to solve the problem of adding technological complexity without increasing the risk of accidents. We studied this problem from the perspective of reliability engineering in which a given risk of an accident has severity and probability of occurring. Timely information on accidents is important for engineers to anticipate and reuse previous failures to approximate the risk of accidents in a new city. However, this is challenging in the context of autonomous vehicles because of the sparse nature of data on the operational scenarios (driving trajectories in a new city). Our approach was to mitigate data sparsity by reducing the state space through monitoring of multiple-vehicles operations. We then minimized the risk of accidents by determining proper allocation of tests for each equivalence class. Our contributions comprise (1) a set of strategies to monitor the operational data of multiple autonomous vehicles, (2) a Bayesian model that estimates changes in the risk of accidents, and (3) a feedback control-loop that minimizes these risks by real-locating test effort. Our results are promising in the sense that we were able to measure and control risk for a diversity of changes in the operational scenarios. We evaluated our models with data from two real cities with distinct traffic patterns and made the data available for the community.},
booktitle = {Proceedings of the IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {45–56},
numpages = {12}
}

@inproceedings{10.1145/3319008.3319708,
author = {Williams, Ashley and Rainer, Austen},
title = {Do Software Engineering Practitioners Cite Software Testing Research in Their Online Articles? A Larger Scale Replication},
year = {2019},
isbn = {9781450371452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319008.3319708},
doi = {10.1145/3319008.3319708},
abstract = {Background: Software engineering (SE) research continues to study the degree to which practitioners perceive research as relevant to practice. Such studies typically comprise surveys of practitioner opinions. In a preliminary, and relatively small scale, study of online articles we previously found few explicit citations to software testing research. Our previous study provided an in situ complement to the typical survey study, however the findings of the previous study were limited by the size of our sample.Objective: To further investigate whether and how practitioners cite software testing research in the grey literature, by using a larger and more diverse dataset.Method: We analyse four distinct datasets totalling over 400,000 online articles with approx. 2M external citations. Two datasets were generated by crawling predefined domains and two were generated by applying heuristics, developed in prior research, in Google searches. Citations are classified and then analysed.Results: We find a (very) low percentage of citations to research.Conclusion: Our replication corroborates our preliminary study and findings from others. In relative terms, topic--specific searches appear to return results that contain articles with more citations. Our results and method provide a basis for benchmarking.},
booktitle = {Proceedings of the Evaluation and Assessment on Software Engineering},
pages = {292–297},
numpages = {6},
keywords = {grey literature, research impact, research relevance, Evidence},
location = {Copenhagen, Denmark},
series = {EASE '19}
}

@inproceedings{10.5555/2819261.2819286,
author = {Ma, Lei and Zhang, Cheng and Yu, Bing and Sato, Hiroyuki},
title = {An Empirical Study on Effects of Code Visibility on Code Coverage of Software Testing},
year = {2015},
publisher = {IEEE Press},
abstract = {Software testability is the degree of difficulty to test a program. Code visibility is important to support design principles, such as information hiding. It is widely believed that code visibility has effects on testability. However, little empirical evidence has been shown to clarify whether and how software testability is influenced by code visibility. We have performed an empirical study to shed light on this problem.Our study focuses on test code coverage, in particular that of automatic testing tools. Code coverage is commonly used for various purposes, such as evaluating test adequacy, assessing test quality, and analyzing testability. Our study uses code coverage as the concrete measurement of testability. By analyzing code coverage of two state-of-the-art tools, in comparison with that of developer-written tests, we have discovered that code visibility does not necessarily have effects on its code coverage, but significantly affects automatic testing tools. Low code visibility often leads to low code coverage for automatic tools. In addition, different treatments on code visibility can result in significant differences in overall code coverage for automatic tools. Using a tool enhancement specific to code visibility, we demonstrate the great potential to improve existing tools.},
booktitle = {Proceedings of the 10th International Workshop on Automation of Software Test},
pages = {80–84},
numpages = {5},
keywords = {software testability, code coverage, automatic testing, code visibility, code accessibility},
location = {Florence, Italy},
series = {AST '15}
}

