@inproceedings{10.1109/SBST.2019.00014,
author = {Kifetew, Fitsum and Devroey, Xavier and Rueda, Urko},
title = {Java Unit Testing Tool Competition: Seventh Round},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SBST.2019.00014},
doi = {10.1109/SBST.2019.00014},
abstract = {We report on the results of the seventh edition of the JUnit tool competition. This year, four tools were executed on a benchmark with (i) new classes, selected from real-world software projects, and (ii) challenging classes from the previous edition. We use Randoop and manual test suites from the projects as baselines. Given the interesting findings of last year, we analyzed the effectiveness of the combined test suites generated by all competing tools and compared; results are confronted with the manual test suites of the projects, as well as those generated by the competing tools. This paper describes our methodology and the results, highlight challenges faced during the contest.},
booktitle = {Proceedings of the 12th International Workshop on Search-Based Software Testing},
pages = {15–20},
numpages = {6},
keywords = {automation, mutation testing, tool competition, Java, combined performance, statistical analysis, benchmark, unit testing},
location = {Montreal, Quebec, Canada},
series = {SBST '19}
}

@inproceedings{10.1145/3468264.3468546,
author = {Zhang, Wuqi and Wei, Lili and Li, Shuqing and Liu, Yepang and Cheung, Shing-Chi},
title = {\DH{}Archer: Detecting on-Chain-off-Chain Synchronization Bugs in Decentralized Applications},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468546},
doi = {10.1145/3468264.3468546},
abstract = {Since the emergence of Ethereum, blockchain-based decentralized applications (DApps) have become increasingly popular and important. To balance the security, performance, and costs, a DApp typically consists of two layers: an on-chain layer to execute transactions and store crucial data on the blockchain and an off-chain layer to interact with users. A DApp needs to synchronize its off-chain layer with the on-chain layer proactively. Otherwise, the inconsistent data in the off-chain layer could mislead users and cause undesirable consequences, e.g., loss of transaction fees. However, transactions sent to the blockchain are not guaranteed to be executed and could even be reversed after execution due to chain reorganization. Such non-determinism in the transaction execution is unique to blockchain. DApp developers may fail to perform the on-chain-off-chain synchronization accurately due to their lack of familiarity with the complex transaction lifecycle. In this work, we investigate the challenges of synchronizing on-chain and off-chain data in Ethereum-based DApps. We present two types of bugs that could result in inconsistencies between the on-chain and off-chain layers. To help detect such on-chain-off-chain synchronization bugs, we introduce a state transition model to guide the testing of DApps and propose two effective oracles to facilitate the automatic identification of bugs. We build the first testing framework, \DH{}Archer, to detect on-chain-off-chain synchronization bugs in DApps. We have evaluated \DH{}Archer on 11 popular real-world DApps. \DH{}Archer achieves high precision (99.3%), recall (87.6%), and accuracy (89.4%) in bug detection and significantly outperforms the baseline methods. It has found 15 real bugs in the 11 DApps. So far, six of the 15 bugs have been confirmed by the developers, and three have been fixed. These promising results demonstrate the usefulness of \DH{}Archer.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {553–565},
numpages = {13},
keywords = {DApps, Decentralized applications, Software testing, Blockchain},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{10.1145/3532182,
author = {Arrieta, Aitor and Valle, Pablo and Agirre, Joseba A. and Sagardui, Goiuria},
title = {Some Seeds Are Strong: Seeding Strategies for Search-Based Test Case Selection},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3532182},
doi = {10.1145/3532182},
abstract = {The time it takes software systems to be tested is usually long. Search-based test selection has been a widely investigated technique to optimize the testing process. In this paper, we propose a set of seeding strategies for the test case selection problem that generate the initial population of pareto-based multi-objective algorithms, with the goals of (1) helping to find an overall better set of solutions and (2) enhancing the convergence of the algorithms. The seeding strategies were integrated with four state-of-the-art multi-objective search algorithms and applied into two contexts where regression-testing is paramount: (1) Simulation-based testing of Cyber-Physical Systems and (2) Continuous Integration. For the first context, we evaluated our approach by using six fitness function combinations and six independent case studies, whereas in the second context we derived a total of six fitness function combinations and employed four case studies. Our evaluation suggests that some of the proposed seeding strategies are indeed helpful for solving the multi-objective test case selection problem. Specifically, the proposed seeding strategies provided a higher convergence of the algorithms towards optimal solutions in 96% of the studied scenarios and an overall cost-effectiveness with a standard search budget in 85% of the studied scenarios.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
keywords = {Regression Testing, Search-based Software Testing, Test Case Selection}
}

@inproceedings{10.1145/3184407.3184422,
author = {Jimenez, Ivo and Watkins, Noah and Sevilla, Michael and Lofstead, Jay and Maltzahn, Carlos},
title = {<i>Quiho</i>: Automated Performance Regression Testing Using Inferred Resource Utilization Profiles},
year = {2018},
isbn = {9781450350952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3184407.3184422},
doi = {10.1145/3184407.3184422},
abstract = {We introduce quiho, a framework for profiling application performance that can be used in automated performance regression tests. quiho profiles an application by applying sensitivity analysis, in particular statistical regression analysis (SRA), using application-independent performance feature vectors that characterize the performance of machines. The result of the SRA, feature importance specifically, is used as a proxy to identify hardware and low-level system software behavior. The relative importance of these features serve as a performance profile of an application (termed inferred resource utilization profile or IRUP), which is used to automatically validate performance behavior across multiple revisions of an application»s code base without having to instrument code or obtain performance counters. We demonstrate that quiho can successfully discover performance regressions by showing its effectiveness in profiling application performance for synthetically introduced regressions as well as those found in real-world applications.},
booktitle = {Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {273–284},
numpages = {12},
keywords = {performance engineering, performance modeling, software testing},
location = {Berlin, Germany},
series = {ICPE '18}
}

@inproceedings{10.1145/3350768.3353816,
author = {Gama, Kiev and da Costa, Andrew Diniz and Coelho, Hendi Lemos and Venieris, Ricardo Almeida and de Lucena, Carlos Jos\'{e} Pereira},
title = {Experimenting with the Peanut Butter and Jelly Sandwich Challenge to Introduce Algorithmic Thinking and Test Case Writing},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3353816},
doi = {10.1145/3350768.3353816},
abstract = {New approaches that offer good learning experiences driven to computer science education have been applied in different places. One of the ways adopted is the application of dynamics in classrooms that challenge students to work in groups and make relations to situations of their lives. Besides, to improve content retention and students engagement, humor is one good element that should be applied in these dynamics. The "Peanut butter and jelly sandwich challenge" is an example that allows including the idea of challenging students using humor as a support to instructional content. This paper explains how that dynamic was applied to two students' groups. The first experience was offered in a mobile programming course that follows a boot camp style and involved a multidisciplinary group with students from three universities. The dynamic applied was used to present the relevance of algorithmic thinking. The second experience used the first case as motivation, adapting it to cover contents focused on test case writing applied to students of computer science. In both cases we present results gathered, such as learning impact for the students.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {27–36},
numpages = {10},
keywords = {Algorithmic Thinking, Software Testing, Humor in Classroom, Test cases},
location = {Salvador, Brazil},
series = {SBES 2019}
}

@inproceedings{10.1145/3395363.3397369,
author = {Lutellier, Thibaud and Pham, Hung Viet and Pang, Lawrence and Li, Yitong and Wei, Moshi and Tan, Lin},
title = {CoCoNuT: Combining Context-Aware Neural Translation Models Using Ensemble for Program Repair},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3397369},
doi = {10.1145/3395363.3397369},
abstract = {Automated generate-and-validate (GV) program repair techniques (APR) typically rely on hard-coded rules, thus only fixing bugs following specific fix patterns. These rules require a significant amount of manual effort to discover and it is hard to adapt these rules to different programming languages. To address these challenges, we propose a new G&amp;V technique—CoCoNuT, which uses ensemble learning on the combination of convolutional neural networks (CNNs) and a new context-aware neural machine translation (NMT) architecture to automatically fix bugs in multiple programming languages. To better represent the context of a bug, we introduce a new context-aware NMT architecture that represents the buggy source code and its surrounding context separately. CoCoNuT uses CNNs instead of recurrent neural networks (RNNs), since CNN layers can be stacked to extract hierarchical features and better model source code at different granularity levels (e.g., statements and functions). In addition, CoCoNuT takes advantage of the randomness in hyperparameter tuning to build multiple models that fix different bugs and combines these models using ensemble learning to fix more bugs. Our evaluation on six popular benchmarks for four programming languages (Java, C, Python, and JavaScript) shows that CoCoNuT correctly fixes (i.e., the first generated patch is semantically equivalent to the developer’s patch) 509 bugs, including 309 bugs that are fixed by none of the 27 techniques with which we compare.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {101–114},
numpages = {14},
keywords = {Automated program repair, AI and Software Engineering, Deep Learning, Neural Machine Translation},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inproceedings{10.1145/3012709.3012718,
author = {Holl, Konstantin and Elberzhager, Frank},
title = {Quality Assurance of Mobile Applications: A Systematic Mapping Study},
year = {2016},
isbn = {9781450348607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3012709.3012718},
doi = {10.1145/3012709.3012718},
abstract = {Mobile applications have become highly pervasive in recent years. The quality of mobile applications for business use, in particular, is relevant for all stakeholders since application failures can lead to serious consequences, such as damage of corporate reputation or financial loss. For other applications, a reasonable level of quality is also required to convince users to use them. The goal of this work is to identify approaches that address the issue of quality assurance for mobile applications. We present an overview of the identified approaches based on certain viewpoints, such as the focused test level and the addressed quality, and show current research challenges. In order to drive the systematic mapping study, we derived seven research questions based on the stated goal. Then two researchers identified 3,192 records from four digital libraries based on a search string related to terms regarding quality assurance for mobile applications and predefined selection criteria. Ultimately, 230 articles were selected. We created clustered views to answer our seven research questions. In addition, we used surveys found to complement our overview of current challenges. The results show an overall upward trend of publications since 2003. Important topics include automation of GUI tests and assurance of non-functional qualities. Aspects of future research could be the establishment of test environments and the focus on defects addressing stronger the specific characteristics of mobile applications.},
booktitle = {Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia},
pages = {101–113},
numpages = {13},
keywords = {mapping study, quality assurance, mobile applications, state of the art, software testing},
location = {Rovaniemi, Finland},
series = {MUM '16}
}

@inproceedings{10.1145/3395363.3397387,
author = {Hildebrandt, Carl and Elbaum, Sebastian and Bezzo, Nicola and Dwyer, Matthew B.},
title = {Feasible and Stressful Trajectory Generation for Mobile Robots},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3397387},
doi = {10.1145/3395363.3397387},
abstract = {While executing nominal tests on mobile robots is required for their validation, such tests may overlook faults that arise under trajectories that accentuate certain aspects of the robot's behavior. Uncovering such stressful trajectories is challenging as the input space for these systems, as they move, is extremely large, and the relation between a planned trajectory and its potential to induce stress can be subtle. To address this challenge we propose a framework that 1) integrates kinematic and dynamic physical models of the robot into the automated trajectory generation in order to generate valid trajectories, and 2) incorporates a parameterizable scoring model to efficiently generate physically valid yet stressful trajectories for a broad range of mobile robots. We evaluate our approach on four variants of a state-of-the-art quadrotor in a racing simulator. We find that, for non-trivial length trajectories, the incorporation of the kinematic and dynamic model is crucial to generate any valid trajectory, and that the approach with the best hand-crafted scoring model and with a trained scoring model can cause on average a 55.9% and 41.3% more stress than a random selection among valid trajectories. A follow-up study shows that the approach was able to induce similar stress on a deployed commercial quadrotor, with trajectories that deviated up to 6m from the intended ones.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {349–362},
numpages = {14},
keywords = {Robotics, Test Generation, Stress Testing, Kinematic and Dynamic Models},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inproceedings{10.1145/3338906.3338972,
author = {Dutta, Saikat and Zhang, Wenxian and Huang, Zixin and Misailovic, Sasa},
title = {Storm: Program Reduction for Testing and Debugging Probabilistic Programming Systems},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338972},
doi = {10.1145/3338906.3338972},
abstract = {Probabilistic programming languages offer an intuitive way to model uncertainty by representing complex probability models as simple probabilistic programs. Probabilistic programming systems (PP systems) hide the complexity of inference algorithms away from the program developer. Unfortunately, if a failure occurs during the run of a PP system, a developer typically has very little support in finding the part of the probabilistic program that causes the failure in the system.  This paper presents Storm, a novel general framework for reducing probabilistic programs. Given a probabilistic program (with associated data and inference arguments) that causes a failure in a PP system, Storm finds a smaller version of the program, data, and arguments that cause the same failure. Storm leverages both generic code and data transformations from compiler testing and domain-specific, probabilistic transformations. The paper presents new transformations that reduce the complexity of statements and expressions, reduce data size, and simplify inference arguments (e.g., the number of iterations of the inference algorithm).  We evaluated Storm on 47 programs that caused failures in two popular probabilistic programming systems, Stan and Pyro. Our experimental results show Storm’s effectiveness. For Stan, our minimized programs have 49% less code, 67% less data, and 96% fewer iterations. For Pyro, our minimized programs have 58% less code, 96% less data, and 99% fewer iterations. We also show the benefits of Storm when debugging probabilistic programs.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {729–739},
numpages = {11},
keywords = {Probabilistic Programming Languages, Software Testing},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/3379597.3387453,
author = {Spadini, Davide and Schvarcbacher, Martin and Oprescu, Ana-Maria and Bruntink, Magiel and Bacchelli, Alberto},
title = {Investigating Severity Thresholds for Test Smells},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387453},
doi = {10.1145/3379597.3387453},
abstract = {Test smells are poor design decisions implemented in test code, which can have an impact on the effectiveness and maintainability of unit tests. Even though test smell detection tools exist, how to rank the severity of the detected smells is an open research topic. In this work, we aim at investigating the severity rating for four test smells and investigate their perceived impact on test suite maintainability by the developers. To accomplish this, we first analyzed some 1,500 open-source projects to elicit severity thresholds for commonly found test smells. Then, we conducted a study with developers to evaluate our thresholds. We found that (1) current detection rules for certain test smells are considered as too strict by the developers and (2) our newly defined severity thresholds are in line with the participants' perception of how test smells have an impact on the maintainability of a test suite. Preprint [https://doi.org/10.5281/zenodo.3744281], data and material [https://doi.org/10.5281/zenodo.3611111].},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {311–321},
numpages = {11},
keywords = {Test Smells, Software Testing, Empirical Software Engineering},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/2771783.2771787,
author = {Dahse, Johannes and Holz, Thorsten},
title = {Experience Report: An Empirical Study of PHP Security Mechanism Usage},
year = {2015},
isbn = {9781450336208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2771783.2771787},
doi = {10.1145/2771783.2771787},
abstract = { The World Wide Web mainly consists of web applications written in weakly typed scripting languages, with PHP being the most popular language in practice. Empirical evidence based on the analysis of vulnerabilities suggests that security is often added as an ad-hoc solution, rather than planning a web application with security in mind during the design phase. Although some best-practice guidelines emerged, no comprehensive security standards are available for developers. Thus, developers often apply their own favorite security mechanisms for data sanitization or validation to prohibit malicious input to a web application. In the context of our development of a new static code analysis tool for vulnerability detection, we studied commonly used input sanitization or validation mechanisms in 25 popular PHP applications. Our analysis of 2.5 million lines of code and over 26 thousand secured data flows provides a comprehensive overview of how developers utilize security mechanisms in practice regarding different markup contexts. In this paper, we discuss these security mechanisms in detail and reveal common pitfalls. For example, we found certain markup contexts and security mechanisms more frequently vulnerable than others. Our empirical study helps researchers, web developers, and tool developers to focus on error-prone markup contexts and security mechanisms in order to detect and mitigate vulnerabilities. },
booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
pages = {60–70},
numpages = {11},
keywords = {input validation, Static analysis, PHP, input sanitization},
location = {Baltimore, MD, USA},
series = {ISSTA 2015}
}

@inproceedings{10.1145/3395363.3397356,
author = {Pradel, Michael and Murali, Vijayaraghavan and Qian, Rebecca and Machalica, Mateusz and Meijer, Erik and Chandra, Satish},
title = {Scaffle: Bug Localization on Millions of Files},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3397356},
doi = {10.1145/3395363.3397356},
abstract = {Despite all efforts to avoid bugs, software sometimes crashes in the field, leaving crash traces as the only information to localize the problem. Prior approaches on localizing where to fix the root cause of a crash do not scale well to ultra-large scale, heterogeneous code bases that contain millions of code files written in multiple programming languages. This paper presents Scaffle, the first scalable bug localization technique, which is based on the key insight to divide the problem into two easier sub-problems. First, a trained machine learning model predicts which lines of a raw crash trace are most informative for localizing the bug. Then, these lines are fed to an information retrieval-based search engine to retrieve file paths in the code base, predicting which file to change to address the crash. The approach does not make any assumptions about the format of a crash trace or the language that produces it. We evaluate Scaffle with tens of thousands of crash traces produced by a large-scale industrial code base at Facebook that contains millions of possible bug locations and that powers tools used by billions of people. The results show that the approach correctly predicts the file to fix for 40% to 60% (50% to 70%) of all crash traces within the top-1 (top-5) predictions. Moreover, Scaffle improves over several baseline approaches, including an existing classification-based approach, a scalable variant of existing information retrieval-based approaches, and a set of hand-tuned, industrially deployed heuristics.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {225–236},
numpages = {12},
keywords = {machine learning, Bug localization, software crashes},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inbook{10.1145/3460319.3464813,
author = {Luo, Sicheng and Xu, Hui and Bi, Yanxiang and Wang, Xin and Zhou, Yangfan},
title = {Boosting Symbolic Execution via Constraint Solving Time Prediction (Experience Paper)},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464813},
abstract = {Symbolic execution is an essential approach for automated test case generation. However, the approach is generally not scalable to large programs. One critical reason is that the constraint solving problems in symbolic execution are generally hard. Consequently, the symbolic execution process may get stuck in solving such hard problems. To mitigate this issue, symbolic execution tools generally rely on a timeout threshold to terminate the solving. Such a timeout is generally set to a fixed, predefined value, e.g., five minutes in angr. Nevertheless, how to set a proper timeout is critical to the tool’s efficiency. This paper proposes an approach to tackle the problem by predicting the time required for solving a constraint model so that the symbolic execution engine could base on the information to determine whether to continue the current solving process. Due to the cost of the prediction itself, our approach triggers the predictor only when the solving time has exceeded a relatively small value. We have shown that such a predictor can achieve promising performance with several different machine learning models and datasets. By further employing an adaptive design, the predictor can achieve an F1-score ranging from 0.743 to 0.800 on these datasets. We then apply the predictor to eight programs and conduct simulation experiments. Results show that the efficiency of constraint solving for symbolic execution can be improved by 1.25x to 3x, depending on the distribution of the hardness of their constraint models.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {336–347},
numpages = {12}
}

@inproceedings{10.1145/1375581.1375607,
author = {Godefroid, Patrice and Kiezun, Adam and Levin, Michael Y.},
title = {Grammar-Based Whitebox Fuzzing},
year = {2008},
isbn = {9781595938602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1375581.1375607},
doi = {10.1145/1375581.1375607},
abstract = {Whitebox fuzzing is a form of automatic dynamic test generation, based on symbolic execution and constraint solving, designed for security testing of large applications. Unfortunately, the current effectiveness of whitebox fuzzing is limited when testing applications with highly-structured inputs, such as compilers and interpreters. These applications process their inputs in stages, such as lexing, parsing and evaluation. Due to the enormous number of control paths in early processing stages, whitebox fuzzing rarely reaches parts of the application beyond those first stages.In this paper, we study how to enhance whitebox fuzzing of complex structured-input applications with a grammar-based specification of their valid inputs. We present a novel dynamic test generation algorithm where symbolic execution directly generates grammar-based constraints whose satisfiability is checked using a custom grammar-based constraint solver. We have implemented this algorithm and evaluated it on a large security-critical application, the JavaScript interpreter of Internet Explorer 7 (IE7). Results of our experiments show that grammar-based whitebox fuzzing explores deeper program paths and avoids dead-ends due to non-parsable inputs. Compared to regular whitebox fuzzing, grammar-based whitebox fuzzing increased coverage of the code generation module of the IE7 JavaScript interpreter from 53% to 81% while using three times fewer tests.},
booktitle = {Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {206–215},
numpages = {10},
keywords = {program verification, grammars, software testing, automatic test generation},
location = {Tucson, AZ, USA},
series = {PLDI '08}
}

@article{10.1145/1379022.1375607,
author = {Godefroid, Patrice and Kiezun, Adam and Levin, Michael Y.},
title = {Grammar-Based Whitebox Fuzzing},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/1379022.1375607},
doi = {10.1145/1379022.1375607},
abstract = {Whitebox fuzzing is a form of automatic dynamic test generation, based on symbolic execution and constraint solving, designed for security testing of large applications. Unfortunately, the current effectiveness of whitebox fuzzing is limited when testing applications with highly-structured inputs, such as compilers and interpreters. These applications process their inputs in stages, such as lexing, parsing and evaluation. Due to the enormous number of control paths in early processing stages, whitebox fuzzing rarely reaches parts of the application beyond those first stages.In this paper, we study how to enhance whitebox fuzzing of complex structured-input applications with a grammar-based specification of their valid inputs. We present a novel dynamic test generation algorithm where symbolic execution directly generates grammar-based constraints whose satisfiability is checked using a custom grammar-based constraint solver. We have implemented this algorithm and evaluated it on a large security-critical application, the JavaScript interpreter of Internet Explorer 7 (IE7). Results of our experiments show that grammar-based whitebox fuzzing explores deeper program paths and avoids dead-ends due to non-parsable inputs. Compared to regular whitebox fuzzing, grammar-based whitebox fuzzing increased coverage of the code generation module of the IE7 JavaScript interpreter from 53% to 81% while using three times fewer tests.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {206–215},
numpages = {10},
keywords = {program verification, software testing, automatic test generation, grammars}
}

@inbook{10.1145/3238147.3238192,
author = {Abdessalem, Raja Ben and Panichella, Annibale and Nejati, Shiva and Briand, Lionel C. and Stifter, Thomas},
title = {Testing Autonomous Cars for Feature Interaction Failures Using Many-Objective Search},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238192},
abstract = {Complex systems such as autonomous cars are typically built as a composition of features that are independent units of functionality. Features tend to interact and impact one another's behavior in unknown ways. A challenge is to detect and manage feature interactions, in particular, those that violate system requirements, hence leading to failures. In this paper, we propose a technique to detect feature interaction failures by casting this problem into a search-based test generation problem. We define a set of hybrid test objectives (distance functions) that combine traditional coverage-based heuristics with new heuristics specifically aimed at revealing feature interaction failures. We develop a new search-based test generation algorithm, called FITEST, that is guided by our hybrid test objectives. FITEST extends recently proposed many-objective evolutionary algorithms to reduce the time required to compute fitness values. We evaluate our approach using two versions of an industrial self-driving system. Our results show that our hybrid test objectives are able to identify more than twice as many feature interaction failures as two baseline test objectives used in the software testing literature (i.e., coverage-based and failure-based test objectives). Further, the feedback from domain experts indicates that the detected feature interaction failures represent real faults in their systems that were not previously identified based on analysis of the system features and their requirements.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {143–154},
numpages = {12}
}

@inbook{10.1145/3368089.3409677,
author = {Jabbarvand, Reyhaneh and Mehralian, Forough and Malek, Sam},
title = {Automated Construction of Energy Test Oracles for Android},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409677},
abstract = {Energy efficiency is an increasingly important quality attribute for software, particularly for mobile apps. Just like any other software attribute, energy behavior of mobile apps should be properly tested prior to their release. However, mobile apps are riddled with energy defects, as currently there is a lack of proper energy testing tools. Indeed, energy testing is a fledgling area of research and recent advances have mainly focused on test input generation. This paper presents ACETON, the first approach aimed at solving the oracle problem for testing the energy behavior of mobile apps. ACETON employs Deep Learning to automatically construct an oracle that not only determines whether a test execution reveals an energy defect, but also the type of energy defect. By carefully selecting features that can be monitored on any app and mobile device, we are assured the oracle constructed using ACETON is highly reusable. Our experiments show that the oracle produced by ACETON is both highly accurate, achieving an overall precision and recall of 99%, and efficient, detecting the existence of energy defects in only 37 milliseconds on average.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {927–938},
numpages = {12}
}

@inproceedings{10.1145/3460319.3464821,
author = {Shariffdeen, Ridwan and Gao, Xiang and Duck, Gregory J. and Tan, Shin Hwei and Lawall, Julia and Roychoudhury, Abhik},
title = {Automated Patch Backporting in Linux (Experience Paper)},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464821},
doi = {10.1145/3460319.3464821},
abstract = {Whenever a bug or vulnerability is detected in the Linux kernel, the kernel developers will endeavour to fix it by introducing a patch into the mainline version of the Linux kernel source tree. However, many users run older “stable” versions of Linux, meaning that the patch should also be “backported” to one or more of these older kernel versions. This process is error-prone and there is usually along delay in publishing the backported patch. Based on an empirical study, we show that around 8% of all commits submitted to Linux mainline are backported to older versions,but often more than one month elapses before the backport is available. Hence, we propose a patch backporting technique that can automatically transfer patches from the mainline version of Linux into older stable versions. Our approach first synthesizes a partial transformation rule based on a Linux mainline patch. This rule can then be generalized by analysing the alignment between the mainline and target versions. The generalized rule is then applied to the target version to produce a backported patch. We have implemented our transformation technique in a tool called FixMorph and evaluated it on 350 Linux mainline patches. FixMorph correctly backports 75.1% of them. Compared to existing techniques, FixMorph improves both the precision and recall in backporting patches. Apart from automation of software maintenance tasks, patch backporting helps in reducing the exposure to known security vulnerabilities in stable versions of the Linux kernel.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {633–645},
numpages = {13},
keywords = {Program Transformation, Patch Backporting, Linux Kernel},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1145/2445196.2445400,
author = {Xu, Dianxiang},
title = {Software Security Testing of an Online Banking System: A Unique Research Experience for Undergraduates and Computer Teachers},
year = {2013},
isbn = {9781450318686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2445196.2445400},
doi = {10.1145/2445196.2445400},
abstract = {This paper presents a unique summer project for a group of undergraduate students and high school computer teachers to gain research experiences in the area of cybersecurity. The students and teachers were selected from the participants in the NSF REU and RET programs at the host institution. Through the research on security testing of a real-world online banking system, the students and teachers have not only learned about the cutting-edge security testing techniques, but also made publishable contributions to the research base. The two collaborating graduate assistants served as an immediate role model for the undergraduates and an indirect role model for high school students through the teachers. With the help from the graduate assistants, the students and teachers were able to work effectively toward achieving their research objectives. The internal competition helped the participants get a better sense of achievement and satisfaction. The research experiences also prepared the teachers with the necessary knowledge for introducing cybersecurity topics (e.g., secure programming) into future classroom activity. As such, the project described in this paper provides a model summer program for undergraduate and/or K-12 teachers to gain research experiences.},
booktitle = {Proceeding of the 44th ACM Technical Symposium on Computer Science Education},
pages = {705–710},
numpages = {6},
keywords = {security testing, access control, software testing, cybersecurity, mutation analysis, security attacks},
location = {Denver, Colorado, USA},
series = {SIGCSE '13}
}

@inbook{10.1145/3460319.3464807,
author = {Chen, Zhe and Wang, Chong and Yan, Junqi and Sui, Yulei and Xue, Jingling},
title = {Runtime Detection of Memory Errors with Smart Status},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464807},
abstract = {C is a dominant language for implementing system software. Unfortunately, its support for low-level control of memory often leads to memory errors. Dynamic analysis tools, which have been widely used for detecting memory errors at runtime, are not yet satisfactory as they cannot deterministically and completely detect some types of memory errors, e.g., segment confusion errors, sub-object overflows, use-after-frees, and memory leaks. We propose Smatus, short for smart status, a new dynamic analysis approach that supports comprehensive runtime detection of memory errors. The key innovation is to create and maintain a small status node for each memory object. Our approach tracks not only the bounds of each pointer’s referent but also the status and reference count of the referent in its status node, where the status represents the liveness and segment type of the referent. A status node is smart as it is automatically destroyed when it becomes useless. To the best of our knowledge, Smatus represents the most comprehensive approach of its kind. In terms of effectiveness (for detecting more kinds of errors), Smatus outperforms state-of-the-art tools, Google’s AddressSanitizer, SoftBoundCETS and Valgrind. In terms of performance, Smatus outperforms SoftBoundCETS and Valgrind in terms of both time and memory overheads incurred, and is on par with AddressSanitizer in terms of the time and memory overheads tradeoff (with much lower memory overhead incurred).},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {296–308},
numpages = {13}
}

@inproceedings{10.1145/3368089.3409730,
author = {Riccio, Vincenzo and Tonella, Paolo},
title = {Model-Based Exploration of the Frontier of Behaviours for Deep Learning System Testing},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409730},
doi = {10.1145/3368089.3409730},
abstract = {With the increasing adoption of Deep Learning (DL) for critical tasks, such as autonomous driving, the evaluation of the quality of systems that rely on DL has become crucial. Once trained, DL systems produce an output for any arbitrary numeric vector provided as input, regardless of whether it is within or outside the validity domain of the system under test. Hence, the quality of such systems is determined by the intersection between their validity domain and the regions where their outputs exhibit a misbehaviour.  In this paper, we introduce the notion of frontier of behaviours, i.e., the inputs at which the DL system starts to misbehave. If the frontier of misbehaviours is outside the validity domain of the system, the quality check is passed. Otherwise, the inputs at the intersection represent quality deficiencies of the system. We developed DeepJanus, a search-based tool that generates frontier inputs for DL systems. The experimental results obtained for the lane keeping component of a self-driving car show that the frontier of a well trained system contains almost exclusively unrealistic roads that violate the best practices of civil engineering, while the frontier of a poorly trained one includes many valid inputs that point to serious deficiencies of the system.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {876–888},
numpages = {13},
keywords = {model based testing, software testing, deep learning, search based software engineering},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

