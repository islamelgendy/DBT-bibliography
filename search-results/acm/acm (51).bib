@inproceedings{10.1145/2814270.2814319,
author = {Le, Vu and Sun, Chengnian and Su, Zhendong},
title = {Finding Deep Compiler Bugs via Guided Stochastic Program Mutation},
year = {2015},
isbn = {9781450336895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814270.2814319},
doi = {10.1145/2814270.2814319},
abstract = { Compiler testing is important and challenging. Equivalence Modulo Inputs (EMI) is a recent promising approach for compiler validation. It is based on mutating the unexecuted statements of an existing program under some inputs to produce new equivalent test programs w.r.t. these inputs. Orion is a simple realization of EMI by only randomly deleting unexecuted statements. Despite its success in finding many bugs in production compilers, Orion’s effectiveness is still limited by its simple, blind mutation strategy. To more effectively realize EMI, this paper introduces a guided, advanced mutation strategy based on Bayesian optimization. Our goal is to generate diverse programs to more thoroughly exercise compilers. We achieve this with two techniques: (1) the support of both code deletions and insertions in the unexecuted regions, leading to a much larger test program space; and (2) the use of an objective function that promotes control-flow-diverse programs for guiding Markov Chain Monte Carlo (MCMC) optimization to explore the search space. Our technique helps discover deep bugs that require elaborate mutations. Our realization, Athena, targets C compilers. In 19 months, Athena has found 72 new bugs — many of which are deep and important bugs — in GCC and LLVM. Developers have confirmed all 72 bugs and fixed 68 of them. },
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {386–399},
numpages = {14},
keywords = {automated testing, Compiler testing, equivalent program variants, Markov Chain Monte Carlo},
location = {Pittsburgh, PA, USA},
series = {OOPSLA 2015}
}

@article{10.1145/2858965.2814319,
author = {Le, Vu and Sun, Chengnian and Su, Zhendong},
title = {Finding Deep Compiler Bugs via Guided Stochastic Program Mutation},
year = {2015},
issue_date = {October 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2858965.2814319},
doi = {10.1145/2858965.2814319},
abstract = { Compiler testing is important and challenging. Equivalence Modulo Inputs (EMI) is a recent promising approach for compiler validation. It is based on mutating the unexecuted statements of an existing program under some inputs to produce new equivalent test programs w.r.t. these inputs. Orion is a simple realization of EMI by only randomly deleting unexecuted statements. Despite its success in finding many bugs in production compilers, Orion’s effectiveness is still limited by its simple, blind mutation strategy. To more effectively realize EMI, this paper introduces a guided, advanced mutation strategy based on Bayesian optimization. Our goal is to generate diverse programs to more thoroughly exercise compilers. We achieve this with two techniques: (1) the support of both code deletions and insertions in the unexecuted regions, leading to a much larger test program space; and (2) the use of an objective function that promotes control-flow-diverse programs for guiding Markov Chain Monte Carlo (MCMC) optimization to explore the search space. Our technique helps discover deep bugs that require elaborate mutations. Our realization, Athena, targets C compilers. In 19 months, Athena has found 72 new bugs — many of which are deep and important bugs — in GCC and LLVM. Developers have confirmed all 72 bugs and fixed 68 of them. },
journal = {SIGPLAN Not.},
month = {oct},
pages = {386–399},
numpages = {14},
keywords = {Markov Chain Monte Carlo, Compiler testing, automated testing, equivalent program variants}
}

@inproceedings{10.1145/1168149.1168166,
author = {Whiting, Mark A. and Cowley, Wendy and Haack, Jereme and Love, Doug and Tratz, Stephen and Varley, Caroline and Wiessner, Kim},
title = {Threat Stream Data Generator: Creating the Known Unknowns for Test and Evaluation of Visual Analytics Tools},
year = {2006},
isbn = {1595935622},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1168149.1168166},
doi = {10.1145/1168149.1168166},
abstract = {We present the Threat Stream Data Generator, an approach and tool for creating synthetic data sets for the test and evaluation of visual analytics tools and environments. We have focused on working with information analysts to understand the characteristics of threat data, to develop scenarios that will allow us to define data sets with known ground truth, to define a process of mapping threat elements in a scenario to expressions in data, and creating a software system to generate the data. We are also developing approaches to evaluating our data sets considering characteristics such as threat subtlety and appropriateness of data for the software to be examined.},
booktitle = {Proceedings of the 2006 AVI Workshop on BEyond Time and Errors: Novel Evaluation Methods for Information Visualization},
pages = {1–3},
numpages = {3},
keywords = {threat stream, data generator, threat},
location = {Venice, Italy},
series = {BELIV '06}
}

@inproceedings{10.1145/2884781.2884821,
author = {Devroey, Xavier and Perrouin, Gilles and Papadakis, Mike and Legay, Axel and Schobbens, Pierre-Yves and Heymans, Patrick},
title = {Featured Model-Based Mutation Analysis},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884821},
doi = {10.1145/2884781.2884821},
abstract = {Model-based mutation analysis is a powerful but expensive testing technique. We tackle its high computation cost by proposing an optimization technique that drastically speeds up the mutant execution process. Central to this approach is the Featured Mutant Model, a modelling framework for mutation analysis inspired by the software product line paradigm. It uses behavioural variability models, viz., Featured Transition Systems, which enable the optimized generation, configuration and execution of mutants. We provide results, based on models with thousands of transitions, suggesting that our technique is fast and scalable. We found that it outperforms previous approaches by several orders of magnitude and that it makes higher-order mutation practically applicable.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {655–666},
numpages = {12},
keywords = {variability, featured transition systems, mutation analysis},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1145/3355048,
author = {Tian, Cong and Chen, Chu and Duan, Zhenhua and Zhao, Liang},
title = {Differential Testing of Certificate Validation in SSL/TLS Implementations: An RFC-Guided Approach},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3355048},
doi = {10.1145/3355048},
abstract = {Certificate validation in Secure Sockets Layer or Transport Layer Security protocol (SSL/TLS) is critical to Internet security. Thus, it is significant to check whether certificate validation in SSL/TLS implementations is correctly implemented. With this motivation, we propose a novel differential testing approach that is based on the standard Request for Comments (RFC). First, rules of certificates are extracted automatically from RFCs. Second, low-level test cases are generated through dynamic symbolic execution. Third, high-level test cases, i.e., certificates, are assembled automatically. Finally, with the assembled certificates being test cases, certificate validations in SSL/TLS implementations are tested to reveal latent vulnerabilities or bugs. Our approach named RFCcert has the following advantages: (1) certificates of RFCcert are discrepancy-targeted, since they are assembled according to standards instead of genetics; (2) with the obtained certificates, RFCcert not only reveals the invalidity of traditional differential testing but also is able to conduct testing that traditional differential testing cannot do; and (3) the supporting tool of RFCcert has been implemented and extensive experiments show that the approach is effective in finding bugs of SSL/TLS implementations. In addition, by providing seed certificates for mutation approaches with RFCcert, the ability of mutation approaches in finding distinct discrepancies is significantly enhanced.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {oct},
articleno = {24},
numpages = {37},
keywords = {SSL/TLS, request for comments, dynamic symbolic execution, Differential testing, certificate validation}
}

@inproceedings{10.1145/18927.18911,
author = {Skibbe, R. E.},
title = {A Practical Approach to the Evaluation of Microcode Systems},
year = {1985},
isbn = {0897911725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/18927.18911},
doi = {10.1145/18927.18911},
abstract = {This paper describes a microcode-evaluation methodology. The supporting test tools were developed by the IBM General Products Division in Tucson, Arizona, to allow effective and comprehensive evaluations of microcode systems. The methodology has been used successfully by the Tucson Test Laboratory (TTL) during the past several years.The evaluation methodology is characterized by an integrated application of static and dynamic analysis techniques. These two modes of analysis are complementary and they allow a level of automation that can significantly enhance the productivity of a testing organization through the systematic application of automated testing techniques. The methodology also establishes a discipline for the microcode-testing process that promotes a formal program of defect removal. Of course, improving the process of removing defects produces a corresponding enhancement in product quality.},
booktitle = {Proceedings of the 18th Annual Workshop on Microprogramming},
pages = {47–56},
numpages = {10},
location = {Pacific Grove, California, USA},
series = {MICRO 18}
}

@article{10.1145/18906.18911,
author = {Skibbe, R. E.},
title = {A Practical Approach to the Evaluation of Microcode Systems},
year = {1985},
issue_date = {Dec. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1050-916X},
url = {https://doi.org/10.1145/18906.18911},
doi = {10.1145/18906.18911},
abstract = {This paper describes a microcode-evaluation methodology. The supporting test tools were developed by the IBM General Products Division in Tucson, Arizona, to allow effective and comprehensive evaluations of microcode systems. The methodology has been used successfully by the Tucson Test Laboratory (TTL) during the past several years.The evaluation methodology is characterized by an integrated application of static and dynamic analysis techniques. These two modes of analysis are complementary and they allow a level of automation that can significantly enhance the productivity of a testing organization through the systematic application of automated testing techniques. The methodology also establishes a discipline for the microcode-testing process that promotes a formal program of defect removal. Of course, improving the process of removing defects produces a corresponding enhancement in product quality.},
journal = {SIGMICRO Newsl.},
month = {dec},
pages = {47–56},
numpages = {10}
}

@article{10.1145/355626.355632,
author = {Jenkins, M. A. and Traub, J. F.},
title = {Principles for Testing Polynomial Zerofinding Programs},
year = {1975},
issue_date = {March 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
issn = {0098-3500},
url = {https://doi.org/10.1145/355626.355632},
doi = {10.1145/355626.355632},
journal = {ACM Trans. Math. Softw.},
month = {mar},
pages = {26–34},
numpages = {9}
}

@article{10.1145/1841909.1841910,
author = {Kiciman, Emre and Livshits, Benjamin},
title = {AjaxScope: A Platform for Remotely Monitoring the Client-Side Behavior of Web 2.0 Applications},
year = {2010},
issue_date = {September 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {1559-1131},
url = {https://doi.org/10.1145/1841909.1841910},
doi = {10.1145/1841909.1841910},
abstract = {The rise of the software-as-a-service paradigm has led to the development of a new breed of sophisticated, interactive applications often called Web 2.0. While Web applications have become larger and more complex, Web application developers today have little visibility into the end-to-end behavior of their systems. This article presents AjaxScope, a dynamic instrumentation platform that enables cross-user monitoring and just-in-time control of Web application behavior on end-user desktops. AjaxScope is a proxy that performs on-the-fly parsing and instrumentation of JavaScript code as it is sent to users’ browsers. AjaxScope provides facilities for distributed and adaptive instrumentation in order to reduce the client-side overhead, while giving fine-grained visibility into the code-level behavior of Web applications. We present a variety of policies demonstrating the power of AjaxScope, ranging from simple error reporting and performance profiling to more complex memory leak detection and optimization analyses. We also apply our prototype to analyze the behavior of over 90 Web 2.0 applications and sites that use significant amounts of JavaScript.},
journal = {ACM Trans. Web},
month = {sep},
articleno = {13},
numpages = {52},
keywords = {software monitoring, Applications, software instrumentation}
}

@inproceedings{10.5555/3103196.3103200,
author = {Yun, Wonkyung and Shin, Donghwan and Bae, Doo-Hwan},
title = {Mutation Analysis for System of Systems Policy Testing},
year = {2017},
isbn = {9781538627990},
publisher = {IEEE Press},
abstract = {A System of Systems (SoS) is a set of the constituent systems (CS) which has managerial and operational independence. To address an SoS-level goal that cannot be satisfied by each CS, an SoS policy guides or forces the CSs to collaborate with each other. If there is a fault in the SoS policy, SoS may fail to reach its goal, even if there is no fault in the CSs. Such a call for SoS policy testing leads to an essential question---how can testers evaluate the effectiveness of test cases?In this paper, we suggest a mutation analysis approach for SoS policy testing. Mutation analysis is a systematic way of evaluating test cases using artificial faults called mutants. As a general mutation framework for SoS policy testing, we present an overview of mutation analysis in SoS policy testing as well as the key aspects that must be defined in practice. To demonstrate the applicability of the proposed approach, we provide a case study using a traffic management SoS with the Simulation of Urban Mobility (SUMO) simulator. The results show that the mutation analysis is effective at evaluating fault detection effectiveness of test cases for SoS policies at a reasonable cost.},
booktitle = {Proceedings of the Joint 5th International Workshop on Software Engineering for Systems-of-Systems and 11th Workshop on Distributed Software Development, Software Ecosystems and Systems-of-Systems},
pages = {16–22},
numpages = {7},
keywords = {system of systems testing, simulation of urban mobility (SUMO), system of systems, system of systems policy, mutation analysis},
location = {Buenos Aires, Argentina},
series = {JSOS '17}
}

@inproceedings{10.1109/ICSE-NIER.2017.8,
author = {Durieux, Thomas and Hamadi, Youssef and Monperrus, Martin},
title = {Production-Driven Patch Generation},
year = {2017},
isbn = {9781538626757},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2017.8},
doi = {10.1109/ICSE-NIER.2017.8},
abstract = {We present an original concept for patch generation: we propose to do it directly in production. Our idea is to generate patches on-the-fly based on automated analysis of the failure context. By doing this in production, the repair process has complete access to the system state at the point of failure. We propose to perform live regression testing of the generated patches directly on the production traffic, by feeding a sandboxed version of the application with a copy of the production traffic, the "shadow traffic". Our concept widens the applicability of program repair, because it removes the requirements of having a failing test case.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Results Track},
pages = {23–26},
numpages = {4},
location = {Buenos Aires, Argentina},
series = {ICSE-NIER '17}
}

@inproceedings{10.1145/3106237.3117763,
author = {Vasic, Marko and Parvez, Zuhair and Milicevic, Aleksandar and Gligoric, Milos},
title = {File-Level vs. Module-Level Regression Test Selection for .NET},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3117763},
doi = {10.1145/3106237.3117763},
abstract = { Regression testing is used to check the correctness of evolving software. With the adoption of Agile development methodology, the number of tests and software revisions has dramatically increased, and hence has the cost of regression testing. Researchers proposed regression test selection (RTS) techniques that optimize regression testing by skipping tests that are not impacted by recent program changes. Ekstazi is one such state-of-the art technique; Ekstazi is implemented for the Java programming language and has been adopted by several companies and open-source projects.  We report on our experience implementing and evaluating Ekstazi#, an Ekstazi-like tool for .NET. We describe the key challenges of bringing the Ekstazi idea to the .NET platform. We evaluate Ekstazi# on 11 open-source projects, as well as an internal Microsoft project substantially larger than each of the open-source projects. Finally, we compare Ekstazi# to an incremental build system (also developed at Microsoft), which, out of the box, provides module-level dependency tracking and skipping tasks (including test execution) whenever dependencies of a task do not change between the current and the last successful build. Ekstazi# on average reduced regression testing time by 43.70% for the open-source projects and by 65.26% for the Microsoft project (the latter is in addition to the savings provided by incremental builds). },
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {848–853},
numpages = {6},
keywords = {file-level dependencies, .NET, Regression test selection},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/2644866.2644885,
author = {Bosch, Mart\'{\i} and Genev\`{e}s, Pierre and Laya\"{\i}ida, Nabil},
title = {Automated Refactoring for Size Reduction of CSS Style Sheets},
year = {2014},
isbn = {9781450329491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2644866.2644885},
doi = {10.1145/2644866.2644885},
abstract = {Cascading Style Sheets (CSS) is a standard language for stylizing and formatting web documents. Its role in web user experience becomes increasingly important. However, CSS files tend to be designed from a result-driven point of view, without much attention devoted to the CSS file structure as long as it produces the desired results. Furthermore, the rendering intended in the browser is often checked and debugged with a document instance. Style sheets normally apply to a set of documents, therefore modifications added while focusing on a particular instance might affect other documents of the set.We present a first prototype of static CSS semantical analyzer and optimizer that is capable of automatically detecting and removing redundant property declarations and rules. We build on earlier work on tree logics to locate redundancies due to the semantics of selectors and properties. Existing purely syntactic CSS optimizers might be used in conjunction with our tool, for performing complementary (and orthogonal) size reduction, toward the common goal of providing smaller and cleaner CSS files.},
booktitle = {Proceedings of the 2014 ACM Symposium on Document Engineering},
pages = {13–16},
numpages = {4},
keywords = {css, web development, style sheets, debugging},
location = {Fort Collins, Colorado, USA},
series = {DocEng '14}
}

@inproceedings{10.1109/ICSE-SEIP.2017.9,
author = {Theisen, Christopher and Murphy, Brendan and Herzig, Kim and Williams, Laurie},
title = {Risk-Based Attack Surface Approximation: How Much Data is Enough?},
year = {2017},
isbn = {9781538627174},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2017.9},
doi = {10.1109/ICSE-SEIP.2017.9},
abstract = {Proactive security reviews and test efforts are a necessary component of the software development lifecycle. Resource limitations often preclude reviewing the entire code base. Making informed decisions on what code to review can improve a team's ability to find and remove vulnerabilities. Risk-based attack surface approximation (RASA) is a technique that uses crash dump stack traces to predict what code may contain exploitable vulnerabilities. The goal of this research is to help software development teams prioritize security efforts by the efficient development of a risk-based attack surface approximation. We explore the use of RASA using Mozilla Firefox and Microsoft Windows stack traces from crash dumps. We create RASA at the file level for Firefox, in which the 15.8% of the files that were part of the approximation contained 73.6% of the vulnerabilities seen for the product. We also explore the effect of random sampling of crashes on the approximation, as it may be impractical for organizations to store and process every crash received. We find that 10-fold random sampling of crashes at a rate of 10% resulted in 3% less vulnerabilities identified than using the entire set of stack traces for Mozilla Firefox. Sampling crashes in Windows 8.1 at a rate of 40% resulted in insignificant differences in vulnerability and file coverage as compared to a rate of 100%.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track},
pages = {273–282},
numpages = {10},
keywords = {attack surface, prediction models, stack traces},
location = {Buenos Aires, Argentina},
series = {ICSE-SEIP '17}
}

@inproceedings{10.1145/1569901.1570253,
author = {Ribeiro, Jos\'{e} Carlos B. and Zenha-Rela, M\'{a}rio Alberto and de Vega, Francisco Fern\'{a}ndez},
title = {An Adaptive Strategy for Improving the Performance of Genetic Programming-Based Approaches to Evolutionary Testing},
year = {2009},
isbn = {9781605583259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1569901.1570253},
doi = {10.1145/1569901.1570253},
abstract = {This paper proposes an adaptive strategy for enhancing Genetic Programming-based approaches to automatic test case generation. The main contribution of this study is that of proposing an adaptive Evolutionary Testing methodology for promoting the introduction of relevant instructions into the generated test cases by means of mutation; the instructions from which the algorithm can choose are ranked, with their rankings being updated every generation in accordance to the feedback obtained from the individuals evaluated in the preceding generation. The experimental studies developed show that the adaptive strategy proposed improves the algorithm's efficiency considerably, while introducing a negligible computational overhead.},
booktitle = {Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation},
pages = {1949–1950},
numpages = {2},
keywords = {search-based test case generation, search-based software engineering, adaptive evolutionary algorithms, genetic programming, evolutionary testing},
location = {Montreal, Qu\'{e}bec, Canada},
series = {GECCO '09}
}

@inproceedings{10.1145/3135932.3135945,
author = {Lehmann, Daniel},
title = {Automatic Testing of Interactive JavaScript Debuggers},
year = {2017},
isbn = {9781450355148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3135932.3135945},
doi = {10.1145/3135932.3135945},
abstract = { When debugging programs, we often assume the debugger itself is correct. However, when it is not, it becomes hard to find bugs or lets developers search for bugs that are not even present. We thus propose a new approach to automatic testing of debuggers, inspired by differential testing of compilers. Our approach generates debugger actions to exercise the debugger and records a trace during the debugging session. By comparing traces of different debuggers against each other, we find deviating behavior and bugs. We evaluate our approach on the JavaScript debuggers of Firefox and Chromium and find 16 previously unreported bugs, four of which are already confirmed and fixed. },
booktitle = {Proceedings Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
pages = {24–26},
numpages = {3},
keywords = {Firefox, automatic testing, Interactive debuggers, differential testing, Chromium},
location = {Vancouver, BC, Canada},
series = {SPLASH Companion 2017}
}

@inproceedings{10.1145/2351676.2351742,
author = {Ledru, Yves and Vega, German and Triki, Taha and Bousquet, Lydie du},
title = {Test Suite Selection Based on Traceability Annotations},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351742},
doi = {10.1145/2351676.2351742},
abstract = { This paper describes the Tobias tool. Tobias is a combinatorial test generator which unfolds a test pattern provided by the test engineer, and performs various combinations and repetitions of test parameters and methods. Tobias is available on-line at tobias.liglab.fr . This website features recent improvements of the tool including a new input language, a traceability mechanism, and the definition of various ``selectors'' which achieve test suite reduction. },
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {342–345},
numpages = {4},
keywords = {Combinatorial testing, Tobias, test suite reduction},
location = {Essen, Germany},
series = {ASE 2012}
}

@article{10.1145/2539036.2539043,
author = {Biswas, Swarnendu and Mall, Rajib and Satpathy, Manoranjan},
title = {A Regression Test Selection Technique for Embedded Software},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1539-9087},
url = {https://doi.org/10.1145/2539036.2539043},
doi = {10.1145/2539036.2539043},
abstract = {The current approaches for regression test selection of embedded programs are usually based on data- and control-dependency analyses, often augmented with human reasoning. Existing techniques do not take into account additional execution dependencies which may exist among code elements in such programs due to features such as tasks, task deadlines, task precedences, and intertask communications. In this context, we propose a model-based regression test selection technique for such programs. Our technique first constructs a graph model of the program; the proposed graph model has been designed to capture several characteristics of embedded programs, such as task precedence order, priority, intertask communication, timers, exceptions and interrupt handlers, which we consider important for regression-test selection. Our regression test selection technique selects test cases based on an analysis of the constructed graph model. We have implemented our technique to realize a prototype tool. The experimental results obtained using this tool show that, on average, our approach selects about 28.33% more regression test cases than those selected by a traditional approach. We observed that, on average, 36.36% of the fault-revealing test cases were overlooked by the existing regression test selection technique.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {dec},
articleno = {47},
numpages = {39},
keywords = {intertask communication, Embedded programs, task execution dependencies, software maintenance, slicing, regression test selection}
}

@inproceedings{10.1145/3152493.3152555,
author = {Colby, Kevin and Maji, Amiya K. and Rahman, Jason and Bottum, Joseph},
title = {Testpilot: A Flexible Framework for User-Centric Testing of HPC Clusters},
year = {2017},
isbn = {9781450351300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152493.3152555},
doi = {10.1145/3152493.3152555},
abstract = {HPC systems are made of many complex hardware and software components, and interaction between these components can often break, leading to job failures and customer dissatisfaction. Testing focused on individual components is often inadequate to identify broken inter-component interactions, therefore, to detect and avoid these, a holistic testing framework is needed which can test the full functionality and performance of a cluster from a user's perspective. Existing tools for HPC cluster testing are either rigid (i.e. works within the context of a single cluster) or are focused on system components (i.e., OS and middleware). In this paper, we present Testpilot---a flexible, holistic, and user-centric testing framework which can be used by system administrators, support staff, or even by users themselves. Testpilot can be used in various testing scenarios such as application testing, application update, OS update, or for continuous monitoring of cluster health. The authors have found Testpilot to be invaluable for regression testing at their HPC site and it has caught many issues that would have otherwise gone into production unnoticed.},
booktitle = {Proceedings of the Fourth International Workshop on HPC User Support Tools},
articleno = {5},
numpages = {10},
keywords = {Job Testing, User-centric Testing, Reliability, Cluster Health, HPC Testing, Regression Testing},
location = {Denver, CO, USA},
series = {HUST'17}
}

@inproceedings{10.5555/227726.227742,
author = {Watanabe, Aki and Sakamura, Ken},
title = {A Specification-Based Adaptive Test Case Generation Strategy for Open Operating System Standards},
year = {1996},
isbn = {0818672463},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {The paper presents a specification based adaptive test case generation (SBATCG) method for integration testing in an open operating system standards environment. In the SBATCG method, templates describing abstract state transitions are derived from a model based specification, and the templates are refined to the internal structure of each implementation. We adopt the Z notation, one of the most widely used formal specification languages. We conducted mutation analysis to study the fault exposure abilities of the SBATCG method and that of a strategy based only on a specification. In our experiment, we used a Z version of the ITRON2 real time multi task operating system specification and two commercially available ITRON2 implementations. The results of this equipment show that the SBATCG method can achieve a higher fault detecting ability than can the strategy using only a specification.},
booktitle = {Proceedings of the 18th International Conference on Software Engineering},
pages = {81–89},
numpages = {9},
keywords = {fault detecting ability, software standards, templates, mutation analysis, internal structure, Z notation, open systems, specification based adaptive test case generation strategy, open operating system standards, fault exposure abilities, ITRON2 real time multi task operating system specification, abstract state transitions, program testing, formal specification languages, model based specification, operating systems (computers), commercially available ITRON2 implementations, formal specification, specification languages, SBATCG method, real-time systems, integration testing, multiprogramming},
location = {Berlin, Germany},
series = {ICSE '96}
}

@inproceedings{10.1145/3387903.3389305,
author = {Alsharif, Abdullah and Kapfhammer, Gregory M. and McMinn, Phil},
title = {Hybrid Methods for Reducing Database Schema Test Suites: Experimental Insights from Computational and Human Studies},
year = {2020},
isbn = {9781450379571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387903.3389305},
doi = {10.1145/3387903.3389305},
abstract = {Given that a relational database is a critical component of many software applications, it is important to thoroughly test the integrity constraints of a database's schema, because they protect the data. Although automated test data generation techniques ameliorate the otherwise manual task of database schema testing, they often create test suites that contain many, sometimes redundant, tests. Since prior work presented a hybridized test suite reduction technique, called STICCER, that beneficially combined Greedy test suite reduction with a test merging method customized for database schemas, this paper experimentally evaluates a different hybridization. Motivated by prior results showing that test suite reduction with the Harrold-Gupta-Soffa (HGS) method can be more effective than Greedy at reducing database schema test suites, this paper evaluates an HGS-driven STICCER variant with both a computational and a human study. Using 34 database schemas and tests created by two test data generators, the results from the computational study reveal that, while STICCER is equally efficient and effective when combined with either Greedy or HGS, it is always better than the isolated use of either Greedy or HGS. Involving 27 participants, the human study shows that, when compared to test suites reduced by HGS, those reduced by a STICCER-HGS hybrid allow humans to inspect test cases faster, but not always more accurately.},
booktitle = {Proceedings of the IEEE/ACM 1st International Conference on Automation of Software Test},
pages = {41–50},
numpages = {10},
location = {Seoul, Republic of Korea},
series = {AST '20}
}

@inbook{10.1145/3493244.3493248,
author = {Copche, Rubens and Souza, Mariana and Villanes, Isabel Karina and Durelli, Vinicius and Eler, Marcelo and Dias-Neto, Arilo Claudio and Endo, Andre Takeshi},
title = {Exploratory Testing of Apps with Opportunity Maps},
year = {2021},
isbn = {9781450395533},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3493244.3493248},
abstract = { Exploratory Testing (ET) is a well-known technique to perform manual tests. Its main goal is to foster creativity and freedom, while the tester learns, designs and executes tests continuously in a time-boxed session. Popular among agile teams, ET is particularly interesting for software systems with highly-mutable features like mobile apps. Previous results have evinced that testers may fail to verify well-known features of mobile apps, while performing unguided manual testing. This paper investigates an intervention to exploratory tests in which opportunity maps are adopted as a mean to improve the manual testing of mobile apps. Included as a supporting artifact during the test sessions, opportunity maps are mind maps with questions targeting features of apps that are known to be error-prone. To assess the usage of opportunity maps in ET, we conducted a study with 22 participants and compared the proposed approach with a traditional session-based approach. Our results indicated that the number of detected bugs was similar in both approaches, different bugs were revealed by each approach, and opportunity maps tend to guide the detection of specific bugs. Among the participants, we found that practitioners uncovered more bugs than students.},
booktitle = {XX Brazilian Symposium on Software Quality},
articleno = {6},
numpages = {10}
}

