@inproceedings{10.1145/2593929.2593937,
author = {Fredericks, Erik M. and DeVries, Byron and Cheng, Betty H. C.},
title = {Towards Run-Time Adaptation of Test Cases for Self-Adaptive Systems in the Face of Uncertainty},
year = {2014},
isbn = {9781450328647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593929.2593937},
doi = {10.1145/2593929.2593937},
abstract = { Self-adaptive systems (SAS) may be subjected to conditions for which they were not explicitly designed. For those high-assurance SAS applications that must deliver critical services, techniques are needed to ensure that only acceptable behavior is provided. While testing an SAS at design time can validate its expected behaviors in known circumstances, testing at run time provides assurance that the SAS will continue to behave as expected in uncertain situations. This paper introduces Veritas, an approach for using utility functions to guide the test adaptation process as part of a run-time testing framework. Specifically, Veritas adapts test cases for an SAS at run time to ensure that the SAS continues to execute in a safe and correct manner when adapting to handle changing environmental conditions. },
booktitle = {Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {17–26},
numpages = {10},
keywords = {software testing, Search-based software engineering, evolutionary algorithms, software assurance},
location = {Hyderabad, India},
series = {SEAMS 2014}
}

@inproceedings{10.1145/1375581.1375607,
author = {Godefroid, Patrice and Kiezun, Adam and Levin, Michael Y.},
title = {Grammar-Based Whitebox Fuzzing},
year = {2008},
isbn = {9781595938602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1375581.1375607},
doi = {10.1145/1375581.1375607},
abstract = {Whitebox fuzzing is a form of automatic dynamic test generation, based on symbolic execution and constraint solving, designed for security testing of large applications. Unfortunately, the current effectiveness of whitebox fuzzing is limited when testing applications with highly-structured inputs, such as compilers and interpreters. These applications process their inputs in stages, such as lexing, parsing and evaluation. Due to the enormous number of control paths in early processing stages, whitebox fuzzing rarely reaches parts of the application beyond those first stages.In this paper, we study how to enhance whitebox fuzzing of complex structured-input applications with a grammar-based specification of their valid inputs. We present a novel dynamic test generation algorithm where symbolic execution directly generates grammar-based constraints whose satisfiability is checked using a custom grammar-based constraint solver. We have implemented this algorithm and evaluated it on a large security-critical application, the JavaScript interpreter of Internet Explorer 7 (IE7). Results of our experiments show that grammar-based whitebox fuzzing explores deeper program paths and avoids dead-ends due to non-parsable inputs. Compared to regular whitebox fuzzing, grammar-based whitebox fuzzing increased coverage of the code generation module of the IE7 JavaScript interpreter from 53% to 81% while using three times fewer tests.},
booktitle = {Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {206–215},
numpages = {10},
keywords = {program verification, grammars, software testing, automatic test generation},
location = {Tucson, AZ, USA},
series = {PLDI '08}
}

@article{10.1145/1379022.1375607,
author = {Godefroid, Patrice and Kiezun, Adam and Levin, Michael Y.},
title = {Grammar-Based Whitebox Fuzzing},
year = {2008},
issue_date = {June 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/1379022.1375607},
doi = {10.1145/1379022.1375607},
abstract = {Whitebox fuzzing is a form of automatic dynamic test generation, based on symbolic execution and constraint solving, designed for security testing of large applications. Unfortunately, the current effectiveness of whitebox fuzzing is limited when testing applications with highly-structured inputs, such as compilers and interpreters. These applications process their inputs in stages, such as lexing, parsing and evaluation. Due to the enormous number of control paths in early processing stages, whitebox fuzzing rarely reaches parts of the application beyond those first stages.In this paper, we study how to enhance whitebox fuzzing of complex structured-input applications with a grammar-based specification of their valid inputs. We present a novel dynamic test generation algorithm where symbolic execution directly generates grammar-based constraints whose satisfiability is checked using a custom grammar-based constraint solver. We have implemented this algorithm and evaluated it on a large security-critical application, the JavaScript interpreter of Internet Explorer 7 (IE7). Results of our experiments show that grammar-based whitebox fuzzing explores deeper program paths and avoids dead-ends due to non-parsable inputs. Compared to regular whitebox fuzzing, grammar-based whitebox fuzzing increased coverage of the code generation module of the IE7 JavaScript interpreter from 53% to 81% while using three times fewer tests.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {206–215},
numpages = {10},
keywords = {program verification, software testing, automatic test generation, grammars}
}

@inproceedings{10.1145/1982595.1982602,
author = {Rusli, Hazlifah Mohd and Puteh, Mazidah and Ibrahim, Suhaimi and Tabatabaei, Sayed Gholam Hassan},
title = {A Comparative Evaluation of State-of-the-Art Web Service Composition Testing Approaches},
year = {2011},
isbn = {9781450305921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1982595.1982602},
doi = {10.1145/1982595.1982602},
abstract = {More and more Web based systems are being developed by composing other single or even composite services. This is due to the fact that not all available services are able to satisfy the needs of a user. The process of composing Web services involves discovering the appropriate services, selecting the best services, combining those services together, and finally executing them. Although much research efforts have been dedicated to the discovery, selection, and composition of services, the process of testing the Web service composition has not been given the same attention. This paper discusses the importance of Web services composition testing, provides a classification of the most prominent approaches in that area, presents several criteria for comparison of those approaches, and conducts a comparative evaluation of the approaches. The results of the paper give an essential perspective to do research work on Web services composition testing.},
booktitle = {Proceedings of the 6th International Workshop on Automation of Software Test},
pages = {29–35},
numpages = {7},
keywords = {web services; software testing; web service composition},
location = {Waikiki, Honolulu, HI, USA},
series = {AST '11}
}

@inproceedings{10.5555/2821339.2821342,
author = {Fredericks, Erik M. and Cheng, Betty H. C.},
title = {An Empirical Analysis of Providing Assurance for Self-Adaptive Systems at Different Levels of Abstraction in the Face of Uncertainty},
year = {2015},
publisher = {IEEE Press},
abstract = {Self-adaptive systems (SAS) must frequently continue to deliver acceptable behavior at run time even in the face of uncertainty. Particularly, SAS applications can self-reconfigure in response to changing or unexpected environmental conditions and must therefore ensure that the system performs as expected. Assurance can be addressed at both design time and run time, where environmental uncertainty poses research challenges for both settings. This paper presents empirical results from a case study in which search-based software engineering techniques have been systematically applied at different levels of abstraction, including requirements analysis, code implementation, and runtime validation, to a remote data mirroring application that must efficiently diffuse data while experiencing adverse operating conditions. Experimental results suggest that our techniques perform better in terms of providing assurance than alternative software engineering techniques at each level of abstraction.},
booktitle = {Proceedings of the Eighth International Workshop on Search-Based Software Testing},
pages = {8–14},
numpages = {7},
location = {Florence, Italy},
series = {SBST '15}
}

@inproceedings{10.1145/3460319.3464819,
author = {Zeng, Zhengran and Zhang, Yuqun and Zhang, Haotian and Zhang, Lingming},
title = {Deep Just-in-Time Defect Prediction: How Far Are We?},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464819},
doi = {10.1145/3460319.3464819},
abstract = {Defect prediction aims to automatically identify potential defective code with minimal human intervention and has been widely studied in the literature. Just-in-Time (JIT) defect prediction focuses on program changes rather than whole programs, and has been widely adopted in continuous testing. CC2Vec, state-of-the-art JIT defect prediction tool, first constructs a hierarchical attention network (HAN) to learn distributed vector representations of both code additions and deletions, and then concatenates them with two other embedding vectors representing commit messages and overall code changes extracted by the existing DeepJIT approach to train a model for predicting whether a given commit is defective. Although CC2Vec has been shown to be the state of the art for JIT defect prediction, it was only evaluated on a limited dataset and not compared with all representative baselines. Therefore, to further investigate the efficacy and limitations of CC2Vec, this paper performs an extensive study of CC2Vec on a large-scale dataset with over 310,370 changes (8.3 X larger than the original CC2Vec dataset). More specifically, we also empirically compare CC2Vec against DeepJIT and representative traditional JIT defect prediction techniques. The experimental results show that CC2Vec cannot consistently outperform DeepJIT, and neither of them can consistently outperform traditional JIT defect prediction. We also investigate the impact of individual traditional defect prediction features and find that the added-line-number feature outperforms other traditional features. Inspired by this finding, we construct a simplistic JIT defect prediction approach which simply adopts the added-line-number feature with the logistic regression classifier. Surprisingly, such a simplistic approach can outperform CC2Vec and DeepJIT in defect prediction, and can be 81k X/120k X faster in training/testing. Furthermore, the paper also provides various practical guidelines for advancing JIT defect prediction in the near future.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {427–438},
numpages = {12},
keywords = {Software Defect Prediction, Just-In-Time Prediction, Deep Learning},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1109/AST.2017.8,
author = {Sun, Chang-ai and Fan, Cuiyang and Wang, Zhen and Liu, Huai},
title = {DμReg: A Path-Aware Mutation Analysis Guided Approach to Regression Testing},
year = {2017},
isbn = {9781538615485},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AST.2017.8},
doi = {10.1109/AST.2017.8},
abstract = {Regression testing re-runs some previously executed test cases, with the purpose of checking whether previously fixed faults have re-emerged and ensuring that the changes do not negatively affect the existing behaviors of the software under development. Today's software is rapidly developed and evolved, and thus it is critical to implement regression testing quickly and effectively. In this paper, we propose a novel technique for regression testing, based on a family of mutant selection strategies. The preliminary results show that the proposed technique can significantly improve the efficiency of different regression testing activities, including test case reduction and prioritization. Our work also makes it possible to develop a unified framework that effectively implements various activities in regression testing.},
booktitle = {Proceedings of the 12th International Workshop on Automation of Software Testing},
pages = {59–64},
numpages = {6},
keywords = {test case prioritization, mutation analysis, regression testing, test case reduction, path depth},
location = {Buenos Aires, Argentina},
series = {AST '17}
}

@inproceedings{10.1145/1900008.1900150,
author = {Brown, Martin K.},
title = {A Framework for Parallel Unit Testings: Work in Progress},
year = {2010},
isbn = {9781450300643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1900008.1900150},
doi = {10.1145/1900008.1900150},
abstract = {The power of parallel computing needs to be exploited on software testing because of challenges that remain today, such improving test effectiveness and automating test input generation. There has been research on applying parallel computing to software testing, but there are still areas where the power of parallel computers can be exploited. Another challenge which has remained due to the lack of tool support is the oracle problem. We want to be relieved of tedious and manual processes in software testing.This paper proposes a framework for parallel unit testing. To alleviate the oracle problem, we will use the Java Modeling Language as the test oracle. We will take advantage of the power of parallel computing and apply it to random unit testing of Java classes to overcome some of today's challenges. We believe that random testing can be used to help us achieve this goal because it is effective and also cost-effective. We will show that we can overcome these challenges by generating and executing more test cases in the same amount of time, and by implementing data diversity. Our framework will be extensible to support additional programming languages and technique diversity.},
booktitle = {Proceedings of the 48th Annual Southeast Regional Conference},
articleno = {110},
numpages = {4},
keywords = {unit testing, random testing, parallelization},
location = {Oxford, Mississippi},
series = {ACM SE '10}
}

@inproceedings{10.5555/319568.319643,
author = {White, Lee J. and Sahay, Prabhat N.},
title = {Experiments Determining Best Paths for Testing Computer Program Predicates},
year = {1985},
isbn = {0818606207},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
abstract = {Zeil has developed a vector space measure which indicates those paths which best detect errors in a selected program predicate. This measure has to be applied to a set of paths post hoc, and so the problem is to heuristically characterize those paths which will provide maximal test information about the selected predicate; the problem of selecting the optimal set of paths is NP-hard. Experiments have been conducted which utilize the vector space criterion to indicate those characteristics of paths which can best be used to test a given predicate. These characteristics will then provide a selection mechanism for an appropriate set of paths. Other questions involve the selection of those paths which sufficiently test all the program predicates, and to experimentally identify those program properties which lead to an irreducible error space for a predicate.},
booktitle = {Proceedings of the 8th International Conference on Software Engineering},
pages = {238–243},
numpages = {6},
keywords = {computer program testing, software testing, path selection, predicate testing},
location = {London, England},
series = {ICSE '85}
}

@inproceedings{10.1145/271771.271802,
author = {Ball, Thomas},
title = {On the Limit of Control Flow Analysis for Regression Test Selection},
year = {1998},
isbn = {0897919718},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/271771.271802},
doi = {10.1145/271771.271802},
abstract = {Automated analyses for regression test selection (RTS) attempt to determine if a modified program, when run on a test t, will have the same behavior as an old version of the program run on t, but without running the new program on t. RTS analyses must confront a price/performance tradeoff: a more precise analysis might be able to eliminate more tests, but could take much longer to run.We focus on the application of control flow analysis and control flow coverage, relatively inexpensive analyses, to the RTS problem, considering how the precision of RTS algorithms can be affected by the type of coverage information collected. We define a strong optimality condition (edge-optimality) for RTS algorithms based on edge coverage that precisely captures when such an algorithm will report that re-testing is needed, when, in actuality, it is not. We reformulate Rothermel and Harrold's RTS algorithm and present three new algorithms that improve on it, culminating in an edge-optimal algorithm. Finally, we consider how path coverage can be used to improve the precision of RTS algorithms.},
booktitle = {Proceedings of the 1998 ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {134–142},
numpages = {9},
keywords = {profiling, control flow analysis, regression testing, coverage},
location = {Clearwater Beach, Florida, USA},
series = {ISSTA '98}
}

@article{10.1145/271775.271802,
author = {Ball, Thomas},
title = {On the Limit of Control Flow Analysis for Regression Test Selection},
year = {1998},
issue_date = {March 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/271775.271802},
doi = {10.1145/271775.271802},
abstract = {Automated analyses for regression test selection (RTS) attempt to determine if a modified program, when run on a test t, will have the same behavior as an old version of the program run on t, but without running the new program on t. RTS analyses must confront a price/performance tradeoff: a more precise analysis might be able to eliminate more tests, but could take much longer to run.We focus on the application of control flow analysis and control flow coverage, relatively inexpensive analyses, to the RTS problem, considering how the precision of RTS algorithms can be affected by the type of coverage information collected. We define a strong optimality condition (edge-optimality) for RTS algorithms based on edge coverage that precisely captures when such an algorithm will report that re-testing is needed, when, in actuality, it is not. We reformulate Rothermel and Harrold's RTS algorithm and present three new algorithms that improve on it, culminating in an edge-optimal algorithm. Finally, we consider how path coverage can be used to improve the precision of RTS algorithms.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {mar},
pages = {134–142},
numpages = {9},
keywords = {coverage, profiling, regression testing, control flow analysis}
}

@article{10.1145/2532780.2532813,
author = {Haller, Klaus},
title = {Mobile Testing},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/2532780.2532813},
doi = {10.1145/2532780.2532813},
abstract = {Mobile apps are everywhere. Some apps entertain and others enable business transactions. Apps increasingly interact with complex IT landscapes. For example, a banking app on a mobile device acts as a front end that invokes services on a back-end server of the bank, which might contact even more servers. Mobile testing becomes crucial and challenging. This paper follows a user-centric testing approach. The app's architecture matters for testing, as does its user base and usage context. Addressing these factors ensures that test cases cover all relevant areas. Most apps need test automation for two reasons: agility and compatibly. Agile projects test frequently, such as every night, to detect bugs early. Compatibility tests ensure that an app runs on all relevant devices and operating system versions on the market. Thus, testers execute test scripts on many devices. This demands for a private device cloud and a mobile test automation framework. Swisscom IT Services followed this path, enabling us to address the major quality issues we identified for mobile apps: pre-usage failures (installation fails, app crashes during startup) and lack of basic regression testing (upgrades buggier than predecessor).},
journal = {SIGSOFT Softw. Eng. Notes},
month = {nov},
pages = {1–8},
numpages = {8},
keywords = {test automation, software testing, test strategy, software quality management, mobile devices, mobile apps}
}

@inproceedings{10.1109/AST.2017.5,
author = {Chiw, Charisee and Kindlmann, Gordon and Reppy, John},
title = {DATm: Diderot's Automated Testing Model},
year = {2017},
isbn = {9781538615485},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AST.2017.5},
doi = {10.1109/AST.2017.5},
abstract = {Diderot is a parallel domain-specific language for the analysis and visualization of multidimensional scientific images, such as those produced by CT and MRI scanners [6], [14], [5]. Diderot is designed to support algorithms that are based on differential tensor calculus and produces a higher-order mathematical model which allows direct manipulation of tensor fields. One of the main challenges of the Diderot implementation is bridging this semantic gap by effectively translating high-level mathematical notation of tensor calculus into efficient low-level code in the target language.A key question for a high-level language, such as Diderot, is how do we know that the implementation is correct. We have previously presented and defended a core set of rewriting rules, but the full translation from source to executable requires much more work. In this paper, we present DATm, Diderot's automated testing model to check the correctness of the core operations in the programming language. DATm can automatically create test programs, and predict what the outcome should be. We measure the accuracy of the computations written in the Diderot language, based on how accurately the output of the program represents the mathematical equivalent of the computations.This paper describes a model for testing a high-level language based on correctness. It introduces the pipeline for DATm, a tool that can automatically create and test tens of thousands of Diderot test programs and that has found numerous bugs. We make a case for the necessity of extensive testing by describing bugs that are deep in the compiler, and only could be found with a unique application of operations. Lastly, we demonstrate that the model can be used to create other types of tests by visual verification.},
booktitle = {Proceedings of the 12th International Workshop on Automation of Software Testing},
pages = {45–51},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {AST '17}
}

@article{10.1145/1022494.1022539,
author = {Andrews, James H.},
title = {Relevant Empirical Testing Research: Challenges and Responses},
year = {2004},
issue_date = {September 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/1022494.1022539},
doi = {10.1145/1022494.1022539},
abstract = {Empirical research on software testing that aims to be relevant to industry faces important challenges. In this position paper, we review the background on software testing research and discuss some of the most important challenges. We then give suggestions on how to respond to these challenges.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {sep},
pages = {1–4},
numpages = {4}
}

@inproceedings{10.1145/3377930.3389810,
author = {Arrieta, Aitor and Agirre, Joseba Andoni and Sagardui, Goiuria},
title = {Seeding Strategies for Multi-Objective Test Case Selection: An Application on Simulation-Based Testing},
year = {2020},
isbn = {9781450371285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377930.3389810},
doi = {10.1145/3377930.3389810},
abstract = {The time it takes software systems to be tested is usually long. This is often caused by the time it takes the entire test suite to be executed. To optimize this, regression test selection approaches have allowed for improvements to the cost-effectiveness of verification and validation activities in the software industry. In this area, multi-objective algorithms have played a key role in selecting the appropriate subset of test cases from the entire test suite. In this paper, we propose a set of seeding strategies for the test case selection problem that generate the initial population of multi-objective algorithms. We integrated these seeding strategies with an NSGA-II algorithm for solving the test case selection problem in the context of simulation-based testing. We evaluated the strategies with six case studies and a total of 21 fitness combinations for each case study (i.e., a total of 126 problems). Our evaluation suggests that these strategies are indeed helpful for solving the multi-objective test case selection problem. In fact, two of the proposed seeding strategies outperformed the NSGA-II algorithm without seeding population with statistical significance for 92.8 and 96% of the problems.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
pages = {1222–1231},
numpages = {10},
keywords = {search-based software testing, regression testing, test case selection},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@article{10.1145/3395042,
author = {Pilgun, Aleksandr and Gadyatskaya, Olga and Zhauniarovich, Yury and Dashevskyi, Stanislav and Kushniarou, Artsiom and Mauw, Sjouke},
title = {Fine-Grained Code Coverage Measurement in Automated Black-Box Android Testing},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3395042},
doi = {10.1145/3395042},
abstract = {Today, there are millions of third-party Android applications. Some of them are buggy or even malicious. To identify such applications, novel frameworks for automated black-box testing and dynamic analysis are being developed by the Android community. Code coverage is one of the most common metrics for evaluating effectiveness of these frameworks. Furthermore, code coverage is used as a fitness function for guiding evolutionary and fuzzy testing techniques. However, there are no reliable tools for measuring fine-grained code coverage in black-box Android app testing.We present the Android Code coVerage Tool, ACVTool for short, that instruments Android apps and measures code coverage in the black-box setting at class, method and instruction granularity. ACVTool has successfully instrumented 96.9% of apps in our experiments. It introduces a negligible instrumentation time overhead, and its runtime overhead is acceptable for automated testing tools. We demonstrate practical value of ACVTool in a large-scale experiment with Sapienz, a state-of-the-art automated testing tool. Using ACVTool on the same cohort of apps, we have compared different coverage granularities applied by Sapienz in terms of the found amount of crashes. Our results show that none of the applied coverage granularities clearly outperforms others in this aspect.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jul},
articleno = {23},
numpages = {35},
keywords = {instrumentation, code coverage, Android, automated software testing}
}

@inproceedings{10.1145/3121245.3121247,
author = {Wetzlmaier, Thomas and Ramler, Rudolf},
title = {Hybrid Monkey Testing: Enhancing Automated GUI Tests with Random Test Generation},
year = {2017},
isbn = {9781450351553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3121245.3121247},
doi = {10.1145/3121245.3121247},
abstract = { Many software projects maintain automated GUI tests that are repeatedly executed for regression testing. Every test run executes exactly the same fixed sequence of steps confirming that the currently tested version shows precisely the same behavior as the last version. The confirmatory approach implemented by these tests limits their ability to find new defects. We therefore propose to combine existing automated regression tests with random test generation. Random test generation creates a rich variety of test steps that interact with the system under test in new, unexpected ways. Enhancing existing test cases with random test steps allows revealing new, hidden defects with little extra effort. In this paper we describe our implementation of a hybrid approach that enhances existing GUI test cases with additional, randomly generated interactions. We conducted an experiment using a mature, widely-used open source application. On average the added random interactions increased the number of visited application windows per test by 23.6% and code coverage by 12.9%. Running the enhanced tests revealed three new defects. },
booktitle = {Proceedings of the 8th ACM SIGSOFT International Workshop on Automated Software Testing},
pages = {5–10},
numpages = {6},
keywords = {random test generation, Software test automation, GUI testing},
location = {Paderborn, Germany},
series = {A-TEST 2017}
}

@article{10.1145/3464940,
author = {Zhang, Man and Arcuri, Andrea},
title = {Adaptive Hypermutation for Search-Based System Test Generation: A Study on REST APIs with EvoMaster},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3464940},
doi = {10.1145/3464940},
abstract = {REST web services are widely popular in industry, and search techniques have been successfully used to automatically generate system-level test cases for those systems. In this article, we propose a novel mutation operator which is designed specifically for test generation at system-level, with a particular focus on REST APIs. In REST API testing, and often in system testing in general, an individual can have a long and complex chromosome. Furthermore, there are two specific issues: (1) fitness evaluation in system testing is highly costly compared with the number of objectives (e.g., testing targets) to optimize for; and (2) a large part of the genotype might have no impact on the phenotype of the individuals (e.g., input data that has no impact on the execution flow in the tested program). Due to these issues, it might be not suitable to apply a typical low mutation rate like 1/n (where n is the number of genes in an individual), which would lead to mutating only one gene on average. Therefore, in this article, we propose an adaptive weight-based hypermutation, which is aware of the different characteristics of the mutated genes. We developed adaptive strategies that enable the selection and mutation of genes adaptively based on their fitness impact and mutation history throughout the search. To assess our novel proposed mutation operator, we implemented it in the EvoMaster tool, integrated in the MIO algorithm, and further conducted an empirical study with three artificial REST APIs and four real-world REST APIs. Results show that our novel mutation operator demonstrates noticeable improvements over the default MIO. It provides a significant improvement in performance for six out of the seven case studies, where the relative improvement is up to +12.09% for target coverage, +12.69% for line coverage, and +32.51% for branch coverage.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {sep},
articleno = {2},
numpages = {52},
keywords = {hypermutation, test generation, search-based software testing, REST API testing}
}

@inproceedings{10.1145/2372233.2372238,
author = {Catal, Cagatay},
title = {On the Application of Genetic Algorithms for Test Case Prioritization: A Systematic Literature Review},
year = {2012},
isbn = {9781450315098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2372233.2372238},
doi = {10.1145/2372233.2372238},
abstract = {We conducted a Systematic Literature Review (SLR) to investigate the effectiveness of genetic algorithms for test case prioritization. The search string retrieved 120 test case prioritization papers, but after we read them in full, we identified that genetic algorithm was used in seven primary studies. One paper does not provide any experimental data. Based on the results of these six papers, we conclude that there is evidence that genetic algorithm-based techniques are effective for test case prioritization and the field is still open for further research.},
booktitle = {Proceedings of the 2nd International Workshop on Evidential Assessment of Software Technologies},
pages = {9–14},
numpages = {6},
keywords = {software engineering, test case prioritization, evolutionary computation, genetic algorithms, systematic literature review, software testing, regression testing},
location = {Lund, Sweden},
series = {EAST '12}
}

@inproceedings{10.1145/3502434.3502455,
author = {Sun, Yuxia and Fu, Ronghua},
title = {IKP-CDIO: Exploration and Practice on Teaching Framework of Embedding Ideological Education into Engineering Curriculum},
year = {2021},
isbn = {9781450385749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3502434.3502455},
doi = {10.1145/3502434.3502455},
abstract = {The concept of “embedding ideological education into curriculum”, briefly called “curriculum ideology”, can be regarded as a new kind of “holistic&nbsp;education” concept. Implementing curriculum ideology in the teaching of engineering courses can simultaneously cultivate the academic and non-academic abilities of engineering college students. At present, such teaching practices are in the exploratory stage, and effective teaching modes and cases are still desired to support embedding ideological education into engineering curriculum. To alleviate the above problem, a new engineering teaching framework called IKP-CDIO is proposed, and a teaching case under the framework and the teaching effects are detailed with a computer major course named "Software Testing".},
booktitle = {2021 5th International Conference on Education and E-Learning},
pages = {185–190},
numpages = {6},
keywords = {software testing course, Engineering curriculum, Ideological education, CDIO teaching framework},
location = {Virtual Event, Japan},
series = {ICEEL 2021}
}

@inproceedings{10.1109/ICSE.2019.00107,
author = {Pham, Hung Viet and Lutellier, Thibaud and Qi, Weizhen and Tan, Lin},
title = {CRADLE: <u class="uu">Cr</u>oss-Backend V<u class="uu">a</u>lidation to <u class="uu">D</u>etect and <u class="uu">L</u>ocalize Bugs in D<u class="uu">e</u>ep Learning Libraries},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00107},
doi = {10.1109/ICSE.2019.00107},
abstract = {Deep learning (DL) systems are widely used in domains including aircraft collision avoidance systems, Alzheimer's disease diagnosis, and autonomous driving cars. Despite the requirement for high reliability, DL systems are difficult to test.Existing DL testing work focuses on testing the DL models, not the implementations (e.g., DL software libraries) of the models. One key challenge of testing DL libraries is the difficulty of knowing the expected output of DL libraries given an input instance. Fortunately, there are multiple implementations of the same DL algorithms in different DL libraries.Thus, we propose CRADLE, a new approach that focuses on finding and localizing bugs in DL software libraries. CRADLE (1) performs cross-implementation inconsistency checking to detect bugs in DL libraries, and (2) leverages anomaly propagation tracking and analysis to localize faulty functions in DL libraries that cause the bugs. We evaluate CRADLE on three libraries (TensorFlow, CNTK, and Theano), 11 datasets (including ImageNet, MNIST, and KGS Go game), and 30 pre-trained models. CRADLE detects 12 bugs and 104 unique inconsistencies, and highlights functions relevant to the causes of inconsistencies for all 104 unique inconsistencies.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {1027–1038},
numpages = {12},
keywords = {bugs detection, deep learning software testing, cross-implementation testing, software testing},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/2576768.2598339,
author = {Poulding, Simon and Feldt, Robert},
title = {Generating Structured Test Data with Specific Properties Using Nested Monte-Carlo Search},
year = {2014},
isbn = {9781450326629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2576768.2598339},
doi = {10.1145/2576768.2598339},
abstract = {Software acting on complex data structures can be challenging to test: it is difficult to generate diverse test data that satisfies structural constraints while simultaneously exhibiting properties, such as a particular size, that the test engineer believes will be effective in detecting faults. In our previous work we introduced G\"{o}delTest, a framework for generating such data structures using non-deterministic programs, and combined it with Differential Evolution to optimize the generation process. Monte-Carlo Tree Search (MCTS) is a search technique that has shown great success in playing games that can be represented as a sequence of decisions. In this paper we apply Nested Monte-Carlo Search, a single-player variant of MCTS, to the sequence of decisions made by the generating programs used by G\"{o}delTest, and show that this combination can efficiently generate random data structures which exhibit the specific properties that the test engineer requires. We compare the results to Boltzmann sampling, an analytical approach to generating random combinatorial data structures.},
booktitle = {Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation},
pages = {1279–1286},
numpages = {8},
keywords = {software testing, nested monte-carlo search, search-based software engineering, data structures},
location = {Vancouver, BC, Canada},
series = {GECCO '14}
}

