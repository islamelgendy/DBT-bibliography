@inproceedings{10.1145/2491627.2491635,
author = {Henard, Christopher and Papadakis, Mike and Perrouin, Gilles and Klein, Jacques and Traon, Yves Le},
title = {Multi-Objective Test Generation for Software Product Lines},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491635},
doi = {10.1145/2491627.2491635},
abstract = {Software Products Lines (SPLs) are families of products sharing common assets representing code or functionalities of a software product. These assets are represented as features, usually organized into Feature Models (FMs) from which the user can configure software products. Generally, few features are sufficient to allow configuring millions of software products. As a result, selecting the products matching given testing objectives is a difficult problem.The testing process usually involves multiple and potentially conflicting testing objectives to fulfill, e.g. maximizing the number of optional features to test while at the same time both minimizing the number of products and minimizing the cost of testing them. However, most approaches for generating products usually target a single objective, like testing the maximum amount of feature interactions. While focusing on one objective may be sufficient in certain cases, this practice does not reflect real-life testing situations.The present paper proposes a genetic algorithm to handle multiple conflicting objectives in test generation for SPLs. Experiments conducted on FMs of different sizes demonstrate the effectiveness, feasibility and practicality of the introduced approach.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {62–71},
numpages = {10},
keywords = {genetic algorithms, feature models, software product lines, test generation, multi-objective optimization},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@inproceedings{10.1145/1188895.1188899,
author = {Santelices, Raul and Sinha, Saurabh and Harrold, Mary Jean},
title = {Subsumption of Program Entities for Efficient Coverage and Monitoring},
year = {2006},
isbn = {1595935843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1188895.1188899},
doi = {10.1145/1188895.1188899},
abstract = {Program entities such as branches, def-use pairs, and call sequences are used in diverse software-development tasks. Reducing a set of entities to a small representative subset through subsumption saves monitoring overhead, focuses the developer's attention, and provides insights into the complexity of a program. Previous work has solved this problem for entities of the same type, and only for some types. In this paper we introduce a novel and general approach for subsumption of entities of any type based on predicate conditions. We discuss applications of this technique, and address future steps.},
booktitle = {Proceedings of the 3rd International Workshop on Software Quality Assurance},
pages = {2–5},
numpages = {4},
keywords = {predicate conditions, entity hierarchies, subsumption, coverage criteria},
location = {Portland, Oregon},
series = {SOQUA '06}
}

@inproceedings{10.1145/3133264.3133300,
author = {Vila, Elior and Novakova, Galia and Todorova, Diana},
title = {Automation Testing Framework for Web Applications with Selenium WebDriver: Opportunities and Threats},
year = {2017},
isbn = {9781450352956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133264.3133300},
doi = {10.1145/3133264.3133300},
abstract = {The present paper discusses the need of automation testing in the process of software development, in order to provide high quality, robust and reliable software product. It answers the question why automation testing plays such a significant role in software development lifecycle as well as why not to use already existing automation testing tools when testing web applications and why it is better to create automation testing framework. Some reliable approaches how to build a testing framework are investigated. Selenium WebDriver tool is pointed out as appropriate solution when creating such framework and its wide use is outlined. Moreover, the paper provides analysis and detailed list of opportunities and threats of using Selenium WebDriver tool. The paper concludes by providing arguments for the value of the creation of automation framework for Web applications with Selenium WebDriver.},
booktitle = {Proceedings of the International Conference on Advances in Image Processing},
pages = {144–150},
numpages = {7},
keywords = {Automation testing tool, software product, automation testing script, web application, Selenium WebDriver, testing framework},
location = {Bangkok, Thailand},
series = {ICAIP 2017}
}

@inproceedings{10.1145/2635868.2635921,
author = {Shi, August and Gyori, Alex and Gligoric, Milos and Zaytsev, Andrey and Marinov, Darko},
title = {Balancing Trade-Offs in Test-Suite Reduction},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635921},
doi = {10.1145/2635868.2635921},
abstract = { Regression testing is an important activity but can get expensive for large test suites. Test-suite reduction speeds up regression testing by identifying and removing redundant tests based on a given set of requirements. Traditional research on test-suite reduction is rather diverse but most commonly shares three properties: (1) requirements are defined by a coverage criterion such as statement coverage; (2) the reduced test suite has to satisfy all the requirements as the original test suite; and (3) the quality of the reduced test suites is measured on the software version on which the reduction is performed. These properties make it hard for test engineers to decide how to use reduced test suites. We address all three properties of traditional test-suite reduction: (1) we evaluate test-suite reduction with requirements defined by killed mutants; (2) we evaluate inadequate reduction that does not require reduced test suites to satisfy all the requirements; and (3) we propose evolution-aware metrics that evaluate the quality of the reduced test suites across multiple software versions. Our evaluations allow a more thorough exploration of trade-offs in test-suite reduction, and our evolution-aware metrics show how the quality of reduced test suites can change after the version where the reduction is performed. We compare the trade-offs among various reductions on 18 projects with a total of 261,235 tests over 3,590 commits and a cumulative history spanning 35 years of development. Our results help test engineers make a more informed decision about balancing size, coverage, and fault-detection loss of reduced test suites. },
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {246–256},
numpages = {11},
keywords = {Test-suite reduction, software evolution},
location = {Hong Kong, China},
series = {FSE 2014}
}

@inproceedings{10.1145/2843859.2843867,
author = {Dolan-Gavitt, Brendan and Hodosh, Josh and Hulin, Patrick and Leek, Tim and Whelan, Ryan},
title = {Repeatable Reverse Engineering with PANDA},
year = {2015},
isbn = {9781450336420},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2843859.2843867},
doi = {10.1145/2843859.2843867},
abstract = {We present PANDA, an open-source tool that has been purpose-built to support whole system reverse engineering. It is built upon the QEMU whole system emulator, and so analyses have access to all code executing in the guest and all data. PANDA adds the ability to record and replay executions, enabling iterative, deep, whole system analyses. Further, the replay log files are compact and shareable, allowing for repeatable experiments. A nine billion instruction boot of FreeBSD, e.g., is represented by only a few hundred MB. PANDA leverages QEMU's support of thirteen different CPU architectures to make analyses of those diverse instruction sets possible within the LLVM IR. In this way, PANDA can have a single dynamic taint analysis, for example, that precisely supports many CPUs. PANDA analyses are written in a simple plugin architecture which includes a mechanism to share functionality between plugins, increasing analysis code re-use and simplifying complex analysis development. We demonstrate PANDA's effectiveness via a number of use cases, including enabling an old but legitimately purchased game to run despite a lost CD key, in-depth diagnosis of an Internet Explorer crash, and uncovering the censorship activities and mechanisms of an IM client.},
booktitle = {Proceedings of the 5th Program Protection and Reverse Engineering Workshop},
articleno = {4},
numpages = {11},
keywords = {Introspection, instrumentation, record/replay},
location = {Los Angeles, CA, USA},
series = {PPREW-5}
}

@inproceedings{10.1145/2970276.2970367,
author = {Feng, Yang and Jones, James A. and Chen, Zhenyu and Fang, Chunrong},
title = {Multi-Objective Test Report Prioritization Using Image Understanding},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970367},
doi = {10.1145/2970276.2970367},
abstract = { In crowdsourced software testing, inspecting the large number of test reports is an overwhelming but inevitable software maintenance task. In recent years, to alleviate this task, many text-based test-report classification and prioritization techniques have been proposed. However in the mobile testing domain, test reports often consist of more screenshots and shorter descriptive text, and thus text-based techniques may be ineffective or inapplicable. The shortage and ambiguity of natural-language text information and the well defined screenshots of activity views within mobile applications motivate our novel technique based on using image understanding for multi-objective test-report prioritization. In this paper, by taking the similarity of screenshots into consideration, we present a multi-objective optimization-based prioritization technique to assist inspections of crowdsourced test reports. In our technique, we employ the Spatial Pyramid Matching (SPM) technique to measure the similarity of the screenshots, and apply the natural-language processing technique to measure the distance between the text of test reports. Furthermore, to validate our technique, an experiment with more than 600 test reports and 2500 images is conducted. The experimental results show that image-understanding techniques can provide benefit to test-report prioritization for most applications. },
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {202–213},
numpages = {12},
keywords = {Image Understanding, Multi-Objective Optimization, Crowdsourced Testing, Test Report Prioritization},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@inproceedings{10.5555/1855741.1855756,
author = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson},
title = {KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs},
year = {2008},
publisher = {USENIX Association},
address = {USA},
abstract = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage -- on average over 90% per tool (median: over 94%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100% coverage on 31 of them.We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
booktitle = {Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation},
pages = {209–224},
numpages = {16},
location = {San Diego, California},
series = {OSDI'08}
}

@inproceedings{10.1109/ICSECOMPANION.2007.56,
author = {Namin, Akbar Siami and Andrews, James H.},
title = {On Sufficiency of Mutants},
year = {2007},
isbn = {0769528929},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSECOMPANION.2007.56},
doi = {10.1109/ICSECOMPANION.2007.56},
abstract = {Mutation is the practice of automatically generating possibly faulty variants of a program, for the purpose of assessing the adequacy of a test suite or comparing testing techniques. The cost of mutation often makes its application infeasible. The cost of mutation is usually assessed in terms of the number of mutants, and consequently the number of "mutation operators" that produce them. We address this problem by finding a smaller subset of mutation operators, called "sufficient", that can model the behaviour of the full set. To do this, we provide an experimental procedure and adapt statistical techniques proposed for variable reduction, model selection and nonlinear regression. Our preliminary results reveal interesting information about mutation operators.},
booktitle = {Companion to the Proceedings of the 29th International Conference on Software Engineering},
pages = {73–74},
numpages = {2},
series = {ICSE COMPANION '07}
}

@inproceedings{10.1145/1449764.1449776,
author = {Arnold, Matthew and Vechev, Martin and Yahav, Eran},
title = {QVM: An Efficient Runtime for Detecting Defects in Deployed Systems},
year = {2008},
isbn = {9781605582153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1449764.1449776},
doi = {10.1145/1449764.1449776},
abstract = {Coping with software defects that occur in the post-deployment stage is a challenging problem: bugs may occur only when the system uses a specific configuration and only under certain usage scenarios. Nevertheless, halting production systems until the bug is tracked and fixed is often impossible. Thus, developers have to try to reproduce the bug in laboratory conditions. Often the reproduction of the bug consists of the lion share of the debugging effort.In this paper we suggest an approach to address the aforementioned problem by using a specialized runtime environment (QVM, for Quality Virtual Machine). QVM efficiently detects defects by continuously monitoring the execution of the application in a production setting. QVM enables the efficient checking of violations of user-specified correctness properties, e.g., typestate safety properties, Java assertions, and heap properties pertaining to ownership.QVM is markedly different from existing techniques for continuous monitoring by using a novel overhead manager which enforces a user-specified overhead budget for quality checks. Existing tools for error detection in the field usually disrupt the operation of the deployed system. QVM, on the other hand, provides a balanced trade off between the cost of the monitoring process and the maintenance of sufficient accuracy for detecting defects. Specifically, the overhead cost of using QVM instead of a standard JVM, is low enough to be acceptable in production environments.We implemented QVM on top of IBM's J9 Java Virtual Machine and used it to detect and fix various errors in real-world applications.},
booktitle = {Proceedings of the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications},
pages = {143–162},
numpages = {20},
keywords = {virtual machines, algorithms, reliability},
location = {Nashville, TN, USA},
series = {OOPSLA '08}
}

@article{10.1145/1449955.1449776,
author = {Arnold, Matthew and Vechev, Martin and Yahav, Eran},
title = {QVM: An Efficient Runtime for Detecting Defects in Deployed Systems},
year = {2008},
issue_date = {September 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/1449955.1449776},
doi = {10.1145/1449955.1449776},
abstract = {Coping with software defects that occur in the post-deployment stage is a challenging problem: bugs may occur only when the system uses a specific configuration and only under certain usage scenarios. Nevertheless, halting production systems until the bug is tracked and fixed is often impossible. Thus, developers have to try to reproduce the bug in laboratory conditions. Often the reproduction of the bug consists of the lion share of the debugging effort.In this paper we suggest an approach to address the aforementioned problem by using a specialized runtime environment (QVM, for Quality Virtual Machine). QVM efficiently detects defects by continuously monitoring the execution of the application in a production setting. QVM enables the efficient checking of violations of user-specified correctness properties, e.g., typestate safety properties, Java assertions, and heap properties pertaining to ownership.QVM is markedly different from existing techniques for continuous monitoring by using a novel overhead manager which enforces a user-specified overhead budget for quality checks. Existing tools for error detection in the field usually disrupt the operation of the deployed system. QVM, on the other hand, provides a balanced trade off between the cost of the monitoring process and the maintenance of sufficient accuracy for detecting defects. Specifically, the overhead cost of using QVM instead of a standard JVM, is low enough to be acceptable in production environments.We implemented QVM on top of IBM's J9 Java Virtual Machine and used it to detect and fix various errors in real-world applications.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {143–162},
numpages = {20},
keywords = {reliability, algorithms, virtual machines}
}

@inproceedings{10.1145/2889160.2889240,
author = {Wang, Shuai and Ali, Shaukat and Yue, Tao and Bakkeli, \O{}yvind and Liaaen, Marius},
title = {Enhancing Test Case Prioritization in an Industrial Setting with Resource Awareness and Multi-Objective Search},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889240},
doi = {10.1145/2889160.2889240},
abstract = {Test case prioritization is an essential part of test execution systems for large organizations developing software systems in the context that their software versions are released very frequently. They must be tested on a variety of compatible hardware with different configurations to ensure correct functioning of a software version on a compatible hardware. In practice, test case execution must not only execute cost-effective test cases in an optimal order, but also optimally allocate required test resources, in order to deliver high quality software releases.To optimize the current test execution system for testing software releases developed for Videoconferencing Systems (VCSs) at Cisco, Norway, in this paper, we propose a resource-aware multi-objective optimization solution with a fitness function defined based on four cost-effectiveness measures. In this context, a set of software releases must be tested on a set of compatible VCS hardware (test resources) by executing a set of cost-effective test cases in an optimal order within a given test cycle constrained by maximum allowed time budget and maximum available test resources. We empirically evaluated seven search algorithms regarding their performance and scalability by comparing with the current practice (random ordering (RO)). The results show that the proposed solution with the best search algorithm (i.e., Random-Weighted Genetic Algorithm) improved the current practice by reducing on average 40.6% of time for test resource allocation and test case execution, improved test resource usage on average by 37.9% and fault detection on average by 60%.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {182–191},
numpages = {10},
keywords = {search, multi-objective optimization, test case prioritization},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3491102.3501903,
author = {Liu, Zhe and Chen, Chunyang and Wang, Junjie and Huang, Yuekai and Hu, Jun and Wang, Qing},
title = {Guided Bug Crush: Assist Manual GUI Testing of Android Apps via Hint Moves},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501903},
doi = {10.1145/3491102.3501903},
abstract = { Mobile apps are indispensable for people’s daily life. Complementing with automated GUI testing, manual testing is the last line of defence for app quality. However, the repeated actions and easily missing of functionalities make manual testing time-consuming and inefficient. Inspired by the game candy crush with flashy candies as hint moves for players, we propose an approach named NaviDroid for navigating testers via highlighted next operations for more effective and efficient testing. Within NaviDroid, we construct an enriched state transition graph with the triggering actions as the edges for two involved states. Based on it, we utilize the dynamic programming algorithm to plan the exploration path, and augment the GUI with visualized hints for testers to quickly explore untested activities and avoid duplicate explorations. The automated experiments demonstrate the high coverage and efficient path planning of NaviDroid and a user study further confirms its usefulness. The NaviDroid can help us develop more robust software that works in more mission-critical settings, not only by performing more thorough testing with the same effort that has been put in before, but also by integrating these techniques into different parts of development pipeline. },
booktitle = {CHI Conference on Human Factors in Computing Systems},
articleno = {557},
numpages = {14},
keywords = {GUI testing, Android App, Quality Assurance, Software Engineering},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3302333.3302344,
author = {Ferreira, Fischer and Diniz, Jo\~{a}o P. and Silva, Cleiton and Figueiredo, Eduardo},
title = {Testing Tools for Configurable Software Systems: A Review-Based Empirical Study},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302344},
doi = {10.1145/3302333.3302344},
abstract = {Configurable software systems are software systems that can be adapted or configured according to a set of features with the goal of increasing reuse and productivity. However, testing configurable systems is very challenging due to the number of configurations to run with each test, leading to a combinatorial explosion in the number of configurations and tests. Currently, several testing techniques and tools have been proposed to deal with this challenge, but their potential practical application remains mostly unexplored. The lack of studies to explore the tools that apply those techniques motivated us to investigate the literature to find testing tools for configurable software systems and to understand how they work. In this paper, we conducted a systematic mapping and identified 34 testing tools for configurable software systems. We first summarized and discussed their main characteristics. We then designed and performed a comparative empirical study of the main sound testing tools found: VarexJ and SPLat. They are considered sound testing techniques because they explore all reachable configurations from a given test. Overall, we observed that VarexJ and SPLat presented distinct results for efficiency while testing the target systems and that, although VarexJ found more errors than SPLat for the majority of the target systems, such result deserves a more in-depth investigation because we expected a higher intersection of errors encountered by them.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {10},
keywords = {Systematic Mapping Study, Testing Configurable Software Systems, Software Product Line},
location = {Leuven, Belgium},
series = {VAMOS '19}
}

@inproceedings{10.1145/3062341.3062364,
author = {Billes, Marina and M\o{}ller, Anders and Pradel, Michael},
title = {Systematic Black-Box Analysis of Collaborative Web Applications},
year = {2017},
isbn = {9781450349888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3062341.3062364},
doi = {10.1145/3062341.3062364},
abstract = { Web applications, such as collaborative editors that allow multiple clients to concurrently interact on a shared resource, are difficult to implement correctly. Existing techniques for analyzing concurrent software do not scale to such complex systems or do not consider multiple interacting clients. This paper presents Simian, the first fully automated technique for systematically analyzing multi-client web applications.  Naively exploring all possible interactions between a set of clients of such applications is practically infeasible. Simian obtains scalability for real-world applications by using a two-phase black-box approach. The application code remains unknown to the analysis and is first explored systematically using a single client to infer potential conflicts between client events triggered in a specific context. The second phase synthesizes multi-client interactions targeted at triggering misbehavior that may result from the potential conflicts, and reports an inconsistency if the clients do not converge to a consistent state.  We evaluate the analysis on three widely used systems, Google Docs, Firepad, and ownCloud Documents, where it reports a variety of inconsistencies, such as incorrect formatting and misplaced text fragments. Moreover, we find that the two-phase approach runs 10x faster compared to exhaustive exploration, making systematic analysis practically applicable. },
booktitle = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {171–184},
numpages = {14},
keywords = {collaborative editing, dynamic analysis, Testing},
location = {Barcelona, Spain},
series = {PLDI 2017}
}

@article{10.1145/3140587.3062364,
author = {Billes, Marina and M\o{}ller, Anders and Pradel, Michael},
title = {Systematic Black-Box Analysis of Collaborative Web Applications},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/3140587.3062364},
doi = {10.1145/3140587.3062364},
abstract = { Web applications, such as collaborative editors that allow multiple clients to concurrently interact on a shared resource, are difficult to implement correctly. Existing techniques for analyzing concurrent software do not scale to such complex systems or do not consider multiple interacting clients. This paper presents Simian, the first fully automated technique for systematically analyzing multi-client web applications.  Naively exploring all possible interactions between a set of clients of such applications is practically infeasible. Simian obtains scalability for real-world applications by using a two-phase black-box approach. The application code remains unknown to the analysis and is first explored systematically using a single client to infer potential conflicts between client events triggered in a specific context. The second phase synthesizes multi-client interactions targeted at triggering misbehavior that may result from the potential conflicts, and reports an inconsistency if the clients do not converge to a consistent state.  We evaluate the analysis on three widely used systems, Google Docs, Firepad, and ownCloud Documents, where it reports a variety of inconsistencies, such as incorrect formatting and misplaced text fragments. Moreover, we find that the two-phase approach runs 10x faster compared to exhaustive exploration, making systematic analysis practically applicable. },
journal = {SIGPLAN Not.},
month = {jun},
pages = {171–184},
numpages = {14},
keywords = {collaborative editing, Testing, dynamic analysis}
}

@inproceedings{10.5555/2819009.2819113,
author = {Clark, David and Feldt, Robert and Poulding, Simon and Yoo, Shin},
title = {Information Transformation: An Underpinning Theory for Software Engineering},
year = {2015},
publisher = {IEEE Press},
abstract = {Software engineering lacks underpinning scientific theories both for the software it produces and the processes by which it does so. We propose that an approach based on information theory can provide such a theory, or rather many theories. We envision that such a benefit will be realised primarily through research based on the quantification of information involved and a mathematical study of the limiting laws that arise. However, we also argue that less formal but more qualitative uses for information theory will be useful.The main argument in support of our vision is based on the fact that both a program and an engineering process to develop such a program are fundamentally processes that transform information. To illustrate our argument we focus on software testing and develop an initial theory in which a test suite is input/output adequate if it achieves the channel capacity of the program as measured by the mutual information between its inputs and its outputs. We outline a number of problems, metrics and concrete strategies for improving software engineering, based on information theoretical analyses. We find it likely that similar analyses and subsequent future research to detail them would be generally fruitful for software engineering.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {599–602},
numpages = {4},
location = {Florence, Italy},
series = {ICSE '15}
}

@inbook{10.1145/3238147.3238224,
author = {Terragni, Valerio and Pezz\`{e}, Mauro},
title = {Effectiveness and Challenges in Generating Concurrent Tests for Thread-Safe Classes},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238224},
abstract = {Developing correct and efficient concurrent programs is difficult and error-prone, due to the complexity of thread synchronization. Often, developers alleviate such problem by relying on thread-safe classes, which encapsulate most synchronization-related challenges. Thus, testing such classes is crucial to ensure the reliability of the concurrency aspects of programs. Some recent techniques and corresponding tools tackle the problem of testing thread-safe classes by automatically generating concurrent tests. In this paper, we present a comprehensive study of the state-of-the-art techniques and an independent empirical evaluation of the publicly available tools. We conducted the study by executing all tools on the JaConTeBe benchmark that contains 47 well-documented concurrency faults. Our results show that 8 out of 47 faults (17%) were detected by at least one tool. By studying the issues of the tools and the generated tests, we derive insights to guide future research on improving the effectiveness of automated concurrent test generation.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {64–75},
numpages = {12}
}

@inproceedings{10.1145/1882291.1882331,
author = {Hemmati, Hadi and Briand, Lionel and Arcuri, Andrea and Ali, Shaukat},
title = {An Enhanced Test Case Selection Approach for Model-Based Testing: An Industrial Case Study},
year = {2010},
isbn = {9781605587912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882291.1882331},
doi = {10.1145/1882291.1882331},
abstract = {In recent years, Model-Based Testing (MBT) has attracted an increasingly wide interest from industry and academia. MBT allows automatic generation of a large and comprehensive set of test cases from system models (e.g., state machines), which leads to the systematic testing of the system. However, even when using simple test strategies, applying MBT in large industrial systems often leads to generating large sets of test cases that cannot possibly be executed within time and cost constraints. In this situation, test case selection techniques are employed to select a subset from the entire test suite such that the selected subset conforms to available resources while maximizing fault detection. In this paper, we propose a new similarity-based selection technique for state machine-based test case selection, which includes a new similarity function using triggers and guards on transitions of state machines and a genetic algorithm-based selection algorithm. Applying this technique on an industrial case study, we show that our proposed approach is more effective in detecting real faults than existing alternatives. We also assess the overall benefits of model-based test case selection in our case study by comparing the fault detection rate of the selected subset with the maximum possible fault detection rate of the original test suite.},
booktitle = {Proceedings of the Eighteenth ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {267–276},
numpages = {10},
keywords = {model-based testing, similarity-based selection, test case selection, genetic algorithms},
location = {Santa Fe, New Mexico, USA},
series = {FSE '10}
}

@inproceedings{10.1145/1978942.1979260,
author = {Ko, Amy J. and Zhang, Xing},
title = {Feedlack Detects Missing Feedback in Web Applications},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979260},
doi = {10.1145/1978942.1979260},
abstract = {While usability methods such as user studies and inspections can reveal a wide range of problems, they do so for only a subset of an application's features and states. We present FeedLack, a tool that explores the full range of web applications' behaviors for one class of usability problems, namely that of missing feedback. It does this by enumerating control flow paths originating from user input, identifying paths that lack output-affecting code. FeedLack was applied to 330 applications; of the 129 that contained input handlers and did not contain syntax errors, 115 were successfully analyzed, resulting in 647 warnings. Of these 36% were missing crucial feedback; 34% were executable and missing feedback, but followed conventions that made feedback inessential; 18% were scenarios that did produce feedback; 12% could not be executed. We end with a discussion of the viability of FeedLack as a usability testing tool.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2177–2186},
numpages = {10},
keywords = {feedback, program analysis, javascript, static analysis},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@article{10.1145/3448977,
author = {Laranjeiro, Nuno and Agnelo, Jo\~{a}o and Bernardino, Jorge},
title = {A Systematic Review on Software Robustness Assessment},
year = {2021},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3448977},
doi = {10.1145/3448977},
abstract = {Robustness is the degree to which a certain system or component can operate correctly in the presence of invalid inputs or stressful environmental conditions. With the increasing complexity and widespread use of computer systems, obtaining assurances regarding their robustness has become of vital importance. This survey discusses the state of the art on software robustness assessment, with emphasis on key aspects like types of systems being evaluated, assessment techniques used, the target of the techniques, the types of faults used, and how system behavior is classified. The survey concludes with the identification of gaps and open challenges related with robustness assessment.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {89},
numpages = {65},
keywords = {robustness evaluation, Software robustness, robustness testing}
}

@inproceedings{10.1145/2970276.2970364,
author = {Li, Xin and Liang, Yongjuan and Qian, Hong and Hu, Yi-Qi and Bu, Lei and Yu, Yang and Chen, Xin and Li, Xuandong},
title = {Symbolic Execution of Complex Program Driven by Machine Learning Based Constraint Solving},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970364},
doi = {10.1145/2970276.2970364},
abstract = { Symbolic execution is a widely-used program analysis technique. It collects and solves path conditions to guide the program traversing. However, due to the limitation of the current constraint solvers, it is difficult to apply symbolic execution on programs with complex path conditions, like nonlinear constraints and function calls. In this paper, we propose a new symbolic execution tool MLB to handle such problem. Instead of relying on the classical constraint solving, in MLB, the feasibility problems of the path conditions are transformed into optimization problems, by minimizing some dissatisfaction degree. The optimization problems are then handled by the underlying optimization solver through machine learning guided sampling and validation. MLB is implemented on the basis of Symbolic PathFinder and encodes not only the simple linear path conditions, but also nonlinear arithmetic operations, and even black-box function calls of library methods, into symbolic path conditions. Experiment results show that MLB can achieve much better coverage on complex real-world programs. },
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {554–559},
numpages = {6},
keywords = {Machine Learning, Symbolic Execution, Complicated Path Condition, Constraint Solving},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@inproceedings{10.5555/782185.782236,
author = {Paradkar, Amit},
title = {On the Experience of Using Cause-Effect Graphs for Software Specification and Test Generation},
year = {1994},
publisher = {IBM Press},
abstract = {The notion of cause-effect graphs (CEGs) has existed for more than two decades, but its use is not yet popular. In this paper, we describe several empirical studies of using cause-effect graphs for the specification and testing of real software, including a boiler control and monitor system, a set of N-version programs for navigation tracking, and a database monitoring system. We present the problems encountered in these empirical studies, the solutions developed to solve them, the evaluation of CEG-based specification and test generation, and the experience of using CEG-based tools.},
booktitle = {Proceedings of the 1994 Conference of the Centre for Advanced Studies on Collaborative Research},
pages = {51},
location = {Toronto, Ontario, Canada},
series = {CASCON '94}
}

