@inproceedings{10.1145/2889160.2889240,
author = {Wang, Shuai and Ali, Shaukat and Yue, Tao and Bakkeli, \O{}yvind and Liaaen, Marius},
title = {Enhancing Test Case Prioritization in an Industrial Setting with Resource Awareness and Multi-Objective Search},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889240},
doi = {10.1145/2889160.2889240},
abstract = {Test case prioritization is an essential part of test execution systems for large organizations developing software systems in the context that their software versions are released very frequently. They must be tested on a variety of compatible hardware with different configurations to ensure correct functioning of a software version on a compatible hardware. In practice, test case execution must not only execute cost-effective test cases in an optimal order, but also optimally allocate required test resources, in order to deliver high quality software releases.To optimize the current test execution system for testing software releases developed for Videoconferencing Systems (VCSs) at Cisco, Norway, in this paper, we propose a resource-aware multi-objective optimization solution with a fitness function defined based on four cost-effectiveness measures. In this context, a set of software releases must be tested on a set of compatible VCS hardware (test resources) by executing a set of cost-effective test cases in an optimal order within a given test cycle constrained by maximum allowed time budget and maximum available test resources. We empirically evaluated seven search algorithms regarding their performance and scalability by comparing with the current practice (random ordering (RO)). The results show that the proposed solution with the best search algorithm (i.e., Random-Weighted Genetic Algorithm) improved the current practice by reducing on average 40.6% of time for test resource allocation and test case execution, improved test resource usage on average by 37.9% and fault detection on average by 60%.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {182–191},
numpages = {10},
keywords = {search, multi-objective optimization, test case prioritization},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3491102.3501903,
author = {Liu, Zhe and Chen, Chunyang and Wang, Junjie and Huang, Yuekai and Hu, Jun and Wang, Qing},
title = {Guided Bug Crush: Assist Manual GUI Testing of Android Apps via Hint Moves},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501903},
doi = {10.1145/3491102.3501903},
abstract = { Mobile apps are indispensable for people’s daily life. Complementing with automated GUI testing, manual testing is the last line of defence for app quality. However, the repeated actions and easily missing of functionalities make manual testing time-consuming and inefficient. Inspired by the game candy crush with flashy candies as hint moves for players, we propose an approach named NaviDroid for navigating testers via highlighted next operations for more effective and efficient testing. Within NaviDroid, we construct an enriched state transition graph with the triggering actions as the edges for two involved states. Based on it, we utilize the dynamic programming algorithm to plan the exploration path, and augment the GUI with visualized hints for testers to quickly explore untested activities and avoid duplicate explorations. The automated experiments demonstrate the high coverage and efficient path planning of NaviDroid and a user study further confirms its usefulness. The NaviDroid can help us develop more robust software that works in more mission-critical settings, not only by performing more thorough testing with the same effort that has been put in before, but also by integrating these techniques into different parts of development pipeline. },
booktitle = {CHI Conference on Human Factors in Computing Systems},
articleno = {557},
numpages = {14},
keywords = {GUI testing, Android App, Quality Assurance, Software Engineering},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3302333.3302344,
author = {Ferreira, Fischer and Diniz, Jo\~{a}o P. and Silva, Cleiton and Figueiredo, Eduardo},
title = {Testing Tools for Configurable Software Systems: A Review-Based Empirical Study},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302344},
doi = {10.1145/3302333.3302344},
abstract = {Configurable software systems are software systems that can be adapted or configured according to a set of features with the goal of increasing reuse and productivity. However, testing configurable systems is very challenging due to the number of configurations to run with each test, leading to a combinatorial explosion in the number of configurations and tests. Currently, several testing techniques and tools have been proposed to deal with this challenge, but their potential practical application remains mostly unexplored. The lack of studies to explore the tools that apply those techniques motivated us to investigate the literature to find testing tools for configurable software systems and to understand how they work. In this paper, we conducted a systematic mapping and identified 34 testing tools for configurable software systems. We first summarized and discussed their main characteristics. We then designed and performed a comparative empirical study of the main sound testing tools found: VarexJ and SPLat. They are considered sound testing techniques because they explore all reachable configurations from a given test. Overall, we observed that VarexJ and SPLat presented distinct results for efficiency while testing the target systems and that, although VarexJ found more errors than SPLat for the majority of the target systems, such result deserves a more in-depth investigation because we expected a higher intersection of errors encountered by them.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {6},
numpages = {10},
keywords = {Systematic Mapping Study, Testing Configurable Software Systems, Software Product Line},
location = {Leuven, Belgium},
series = {VAMOS '19}
}

@inproceedings{10.5555/2819009.2819113,
author = {Clark, David and Feldt, Robert and Poulding, Simon and Yoo, Shin},
title = {Information Transformation: An Underpinning Theory for Software Engineering},
year = {2015},
publisher = {IEEE Press},
abstract = {Software engineering lacks underpinning scientific theories both for the software it produces and the processes by which it does so. We propose that an approach based on information theory can provide such a theory, or rather many theories. We envision that such a benefit will be realised primarily through research based on the quantification of information involved and a mathematical study of the limiting laws that arise. However, we also argue that less formal but more qualitative uses for information theory will be useful.The main argument in support of our vision is based on the fact that both a program and an engineering process to develop such a program are fundamentally processes that transform information. To illustrate our argument we focus on software testing and develop an initial theory in which a test suite is input/output adequate if it achieves the channel capacity of the program as measured by the mutual information between its inputs and its outputs. We outline a number of problems, metrics and concrete strategies for improving software engineering, based on information theoretical analyses. We find it likely that similar analyses and subsequent future research to detail them would be generally fruitful for software engineering.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {599–602},
numpages = {4},
location = {Florence, Italy},
series = {ICSE '15}
}

@inbook{10.1145/3238147.3238224,
author = {Terragni, Valerio and Pezz\`{e}, Mauro},
title = {Effectiveness and Challenges in Generating Concurrent Tests for Thread-Safe Classes},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238224},
abstract = {Developing correct and efficient concurrent programs is difficult and error-prone, due to the complexity of thread synchronization. Often, developers alleviate such problem by relying on thread-safe classes, which encapsulate most synchronization-related challenges. Thus, testing such classes is crucial to ensure the reliability of the concurrency aspects of programs. Some recent techniques and corresponding tools tackle the problem of testing thread-safe classes by automatically generating concurrent tests. In this paper, we present a comprehensive study of the state-of-the-art techniques and an independent empirical evaluation of the publicly available tools. We conducted the study by executing all tools on the JaConTeBe benchmark that contains 47 well-documented concurrency faults. Our results show that 8 out of 47 faults (17%) were detected by at least one tool. By studying the issues of the tools and the generated tests, we derive insights to guide future research on improving the effectiveness of automated concurrent test generation.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {64–75},
numpages = {12}
}

@inproceedings{10.1145/1882291.1882331,
author = {Hemmati, Hadi and Briand, Lionel and Arcuri, Andrea and Ali, Shaukat},
title = {An Enhanced Test Case Selection Approach for Model-Based Testing: An Industrial Case Study},
year = {2010},
isbn = {9781605587912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882291.1882331},
doi = {10.1145/1882291.1882331},
abstract = {In recent years, Model-Based Testing (MBT) has attracted an increasingly wide interest from industry and academia. MBT allows automatic generation of a large and comprehensive set of test cases from system models (e.g., state machines), which leads to the systematic testing of the system. However, even when using simple test strategies, applying MBT in large industrial systems often leads to generating large sets of test cases that cannot possibly be executed within time and cost constraints. In this situation, test case selection techniques are employed to select a subset from the entire test suite such that the selected subset conforms to available resources while maximizing fault detection. In this paper, we propose a new similarity-based selection technique for state machine-based test case selection, which includes a new similarity function using triggers and guards on transitions of state machines and a genetic algorithm-based selection algorithm. Applying this technique on an industrial case study, we show that our proposed approach is more effective in detecting real faults than existing alternatives. We also assess the overall benefits of model-based test case selection in our case study by comparing the fault detection rate of the selected subset with the maximum possible fault detection rate of the original test suite.},
booktitle = {Proceedings of the Eighteenth ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {267–276},
numpages = {10},
keywords = {model-based testing, similarity-based selection, test case selection, genetic algorithms},
location = {Santa Fe, New Mexico, USA},
series = {FSE '10}
}

@inproceedings{10.1145/1993498.1993532,
author = {Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
title = {Finding and Understanding Bugs in C Compilers},
year = {2011},
isbn = {9781450306638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1993498.1993532},
doi = {10.1145/1993498.1993532},
abstract = {Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to find compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our first contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undefined and unspecified behaviors that would destroy its ability to automatically find wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.},
booktitle = {Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {283–294},
numpages = {12},
keywords = {compiler testing, automated testing, compiler defect, random program generation, random testing},
location = {San Jose, California, USA},
series = {PLDI '11}
}

@article{10.1145/1993316.1993532,
author = {Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
title = {Finding and Understanding Bugs in C Compilers},
year = {2011},
issue_date = {June 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/1993316.1993532},
doi = {10.1145/1993316.1993532},
abstract = {Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to find compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our first contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undefined and unspecified behaviors that would destroy its ability to automatically find wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {283–294},
numpages = {12},
keywords = {compiler testing, automated testing, compiler defect, random testing, random program generation}
}

@inproceedings{10.1145/1978942.1979260,
author = {Ko, Amy J. and Zhang, Xing},
title = {Feedlack Detects Missing Feedback in Web Applications},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979260},
doi = {10.1145/1978942.1979260},
abstract = {While usability methods such as user studies and inspections can reveal a wide range of problems, they do so for only a subset of an application's features and states. We present FeedLack, a tool that explores the full range of web applications' behaviors for one class of usability problems, namely that of missing feedback. It does this by enumerating control flow paths originating from user input, identifying paths that lack output-affecting code. FeedLack was applied to 330 applications; of the 129 that contained input handlers and did not contain syntax errors, 115 were successfully analyzed, resulting in 647 warnings. Of these 36% were missing crucial feedback; 34% were executable and missing feedback, but followed conventions that made feedback inessential; 18% were scenarios that did produce feedback; 12% could not be executed. We end with a discussion of the viability of FeedLack as a usability testing tool.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2177–2186},
numpages = {10},
keywords = {feedback, program analysis, javascript, static analysis},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.5555/782185.782236,
author = {Paradkar, Amit},
title = {On the Experience of Using Cause-Effect Graphs for Software Specification and Test Generation},
year = {1994},
publisher = {IBM Press},
abstract = {The notion of cause-effect graphs (CEGs) has existed for more than two decades, but its use is not yet popular. In this paper, we describe several empirical studies of using cause-effect graphs for the specification and testing of real software, including a boiler control and monitor system, a set of N-version programs for navigation tracking, and a database monitoring system. We present the problems encountered in these empirical studies, the solutions developed to solve them, the evaluation of CEG-based specification and test generation, and the experience of using CEG-based tools.},
booktitle = {Proceedings of the 1994 Conference of the Centre for Advanced Studies on Collaborative Research},
pages = {51},
location = {Toronto, Ontario, Canada},
series = {CASCON '94}
}

@inproceedings{10.1145/2025113.2025136,
author = {Baah, George K. and Podgurski, Andy and Harrold, Mary Jean},
title = {Mitigating the Confounding Effects of Program Dependences for Effective Fault Localization},
year = {2011},
isbn = {9781450304436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2025113.2025136},
doi = {10.1145/2025113.2025136},
abstract = {Dynamic program dependences are recognized as important factors in software debugging because they contribute to triggering the effects of faults and propagating the effects to a program's output. The effects of dynamic dependences also produce significant confounding bias when statistically estimating the causal effect of a statement on the occurrence of program failures, which leads to poor fault localization results. This paper presents a novel causal-inference technique for fault localization that accounts for the effects of dynamic data and control dependences and thus, significantly reduces confounding bias during fault localization. The technique employs a new dependence-based causal model together with matching of test executions based on their dynamic dependences. The paper also presents empirical results indicating that the new technique performs significantly better than existing statistical fault-localization techniques as well as our previous fault localization technique based on causal-inference methodology.},
booktitle = {Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering},
pages = {146–156},
numpages = {11},
keywords = {potential outcome model, debugging, causal inference, program analysis, matching, fault localization},
location = {Szeged, Hungary},
series = {ESEC/FSE '11}
}

@inproceedings{10.1145/1368088.1368136,
author = {Siami Namin, Akbar and Andrews, James H. and Murdoch, Duncan J.},
title = {Sufficient Mutation Operators for Measuring Test Effectiveness},
year = {2008},
isbn = {9781605580791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1368088.1368136},
doi = {10.1145/1368088.1368136},
abstract = {Mutants are automatically-generated, possibly faulty variants of programs. The mutation adequacy ratio of a test suite is the ratio of non-equivalent mutants it is able to identify to the total number of non-equivalent mutants. This ratio can be used as a measure of test effectiveness. However, it can be expensive to calculate, due to the large number of different mutation operators that have been proposed for generating the mutants.In this paper, we address the problem of finding a small set of mutation operators which is still sufficient for measuring test effectiveness. We do this by defining a statistical analysis procedure that allows us to identify such a set, together with an associated linear model that predicts mutation adequacy with high accuracy. We confirm the validity of our procedure through cross-validation and the application of other, alternative statistical analyses.},
booktitle = {Proceedings of the 30th International Conference on Software Engineering},
pages = {351–360},
numpages = {10},
keywords = {testing effectiveness, mutation analysis},
location = {Leipzig, Germany},
series = {ICSE '08}
}

@inproceedings{10.1145/1499799.1499923,
author = {Osterweil, Leon J. and Fosdick, Lloyd D.},
title = {Some Experience with DAVE: A Fortran Program Analyzer},
year = {1976},
isbn = {9781450379175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1499799.1499923},
doi = {10.1145/1499799.1499923},
abstract = {This paper describes DAVE, an automatic program testing aid which performs a static analysis of Fortran programs. DAVE analyzes the data flows both within and across subprogram boundaries of Fortran programs, and is able to detect occurrences of uninitialized and dead variables in such programs. The paper shows how this capability facilitates the detection of a wide variety of errors, many of which are often quite subtle. The central analytic mechanism in DAVE is a depth-first search procedure which enables DAVE to execute efficiently. Some experiences with DAVE are described and evaluated and some future work is projected.},
booktitle = {Proceedings of the June 7-10, 1976, National Computer Conference and Exposition},
pages = {909–915},
numpages = {7},
location = {New York, New York},
series = {AFIPS '76}
}

@article{10.1145/966221.966232,
author = {Orso, Alessandro and Porter, Adam},
title = {ICSE Workshop on Remote Analysis and Measurement of Software Systems (RAMSS)},
year = {2003},
issue_date = {November 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/966221.966232},
doi = {10.1145/966221.966232},
abstract = {The goal of this one-day workshop was to bring together researchers and practitioners interested in exploring how the characteristics of today's area of computing (e.g., high connectivity, substantial computing power for the average user, higher demand for and expectation of frequent software updates) can be leveraged to improve software quality and performance.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {nov},
pages = {10},
numpages = {1}
}

@inproceedings{10.1145/1236360.1236387,
author = {Varshney, Maneesh and Xu, Defeng and Srivastava, Mani and Bagrodia, Rajive},
title = {SenQ: A Scalable Simulation and Emulation Environment for Sensor Networks},
year = {2007},
isbn = {9781595936387},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1236360.1236387},
doi = {10.1145/1236360.1236387},
abstract = {Although there is growing interest in the use of physical testbeds to evaluate the performance of applications and protocols for sensor platforms, such studies also encounter significant challenges that include the lack of scalability and repeatability, as well as the inability to represent a diverse set of operational scenarios. On the other hand, simulators can typically address the preceding problems but of-ten lack the high degree of fidelity available to the analysts with physical testbeds. In this paper, we present the design and implementation of SenQ - an accurate and scalable evaluation framework for sensor networks that effectively addresses the preceding challenges. In particular, SenQ integrates sensor network operating systems with a very high-fidelity simulation of wireless networks such that sensor network applications and protocols can be executed, without modifications, in a repeatable manner under a diverse set of scalable environments. SenQ extends beyond the existing suite of simulators and emulators in four key aspects: first, it supports emulation of sensor network applications and protocols in an efficient and exible manner; second, it provides an efficient set of models of diverse sensing phenomena; third, it provides accurate models of both battery power and clock drift effect which have been shown to have a significant impact on sensor network studies; and finally it provides an efficient kernel that allows it to run experiments that provide substantial scalability in both the spatial and temporal contexts.},
booktitle = {Proceedings of the 6th International Conference on Information Processing in Sensor Networks},
pages = {196–205},
numpages = {10},
keywords = {sensor networks, SenQ, simulation, emulation},
location = {Cambridge, Massachusetts, USA},
series = {IPSN '07}
}

@inproceedings{10.1145/1108792.1108801,
author = {Kumar, Naveen and Childers, Bruce R. and Soffa, Mary Lou},
title = {Low Overhead Program Monitoring and Profiling},
year = {2005},
isbn = {1595932399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1108792.1108801},
doi = {10.1145/1108792.1108801},
abstract = {Program instrumentation, inserted either before or during execution, is rapidly becoming a necessary component of many systems. Instrumentation is commonly used to collect information for many diverse analysis applications, such as detecting program invariants, dynamic slicing and alias analysis, software security checking, and computer architecture modeling. Because instrumentation typically has a high run-time overhead, techniques are needed to mitigate the overheads. This paper describes "instrumentation optimizations" that reduce the overhead of profiling for program analysis. Our approach applies transformations to the instrumentation code that reduce the (1) number of instrumentation points executed, (2) cost of instrumentation probes, and (3) cost of instrumentation payload, while maintaining the semantics of the original instrumentation. We present the transformations and apply them for program profiling and computer architecture modeling. We evaluate the optimizations and show that the optimizations improve profiling performance by 1.26-2.63x and architecture modeling performance by 2-3.3x.},
booktitle = {Proceedings of the 6th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering},
pages = {28–34},
numpages = {7},
keywords = {instrumentation optimization, profiling, dynamic binary translation, dynamic instrumentation},
location = {Lisbon, Portugal},
series = {PASTE '05}
}

@article{10.1145/1108768.1108801,
author = {Kumar, Naveen and Childers, Bruce R. and Soffa, Mary Lou},
title = {Low Overhead Program Monitoring and Profiling},
year = {2005},
issue_date = {January 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/1108768.1108801},
doi = {10.1145/1108768.1108801},
abstract = {Program instrumentation, inserted either before or during execution, is rapidly becoming a necessary component of many systems. Instrumentation is commonly used to collect information for many diverse analysis applications, such as detecting program invariants, dynamic slicing and alias analysis, software security checking, and computer architecture modeling. Because instrumentation typically has a high run-time overhead, techniques are needed to mitigate the overheads. This paper describes "instrumentation optimizations" that reduce the overhead of profiling for program analysis. Our approach applies transformations to the instrumentation code that reduce the (1) number of instrumentation points executed, (2) cost of instrumentation probes, and (3) cost of instrumentation payload, while maintaining the semantics of the original instrumentation. We present the transformations and apply them for program profiling and computer architecture modeling. We evaluate the optimizations and show that the optimizations improve profiling performance by 1.26-2.63x and architecture modeling performance by 2-3.3x.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {sep},
pages = {28–34},
numpages = {7},
keywords = {dynamic binary translation, profiling, instrumentation optimization, dynamic instrumentation}
}

@inproceedings{10.1145/3242744.3242747,
author = {Mista, Agust\'{\i}n and Russo, Alejandro and Hughes, John},
title = {Branching Processes for QuickCheck Generators},
year = {2018},
isbn = {9781450358354},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3242744.3242747},
doi = {10.1145/3242744.3242747},
abstract = {In QuickCheck (or, more generally, random testing), it is challenging to control random data generators' distributions---specially when it comes to user-defined algebraic data types (ADT). In this paper, we adapt results from an area of mathematics known as branching processes, and show how they help to analytically predict (at compile-time) the expected number of generated constructors, even in the presence of mutually recursive or composite ADTs. Using our probabilistic formulas, we design heuristics capable of automatically adjusting probabilities in order to synthesize generators which distributions are aligned with users' demands. We provide a Haskell implementation of our mechanism in a tool called DRaGeN and perform case studies with real-world applications. When generating random values, our synthesized QuickCheck generators show improvements in code coverage when compared with those automatically derived by state-of-the-art tools.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Symposium on Haskell},
pages = {1–13},
numpages = {13},
keywords = {Haskell, Branching process, Testing, QuickCheck},
location = {St. Louis, MO, USA},
series = {Haskell 2018}
}

@article{10.1145/3299711.3242747,
author = {Mista, Agust\'{\i}n and Russo, Alejandro and Hughes, John},
title = {Branching Processes for QuickCheck Generators},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/3299711.3242747},
doi = {10.1145/3299711.3242747},
abstract = {In QuickCheck (or, more generally, random testing), it is challenging to control random data generators' distributions---specially when it comes to user-defined algebraic data types (ADT). In this paper, we adapt results from an area of mathematics known as branching processes, and show how they help to analytically predict (at compile-time) the expected number of generated constructors, even in the presence of mutually recursive or composite ADTs. Using our probabilistic formulas, we design heuristics capable of automatically adjusting probabilities in order to synthesize generators which distributions are aligned with users' demands. We provide a Haskell implementation of our mechanism in a tool called DRaGeN and perform case studies with real-world applications. When generating random values, our synthesized QuickCheck generators show improvements in code coverage when compared with those automatically derived by state-of-the-art tools.},
journal = {SIGPLAN Not.},
month = {sep},
pages = {1–13},
numpages = {13},
keywords = {Branching process, Haskell, QuickCheck, Testing}
}

@article{10.1145/3448977,
author = {Laranjeiro, Nuno and Agnelo, Jo\~{a}o and Bernardino, Jorge},
title = {A Systematic Review on Software Robustness Assessment},
year = {2021},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3448977},
doi = {10.1145/3448977},
abstract = {Robustness is the degree to which a certain system or component can operate correctly in the presence of invalid inputs or stressful environmental conditions. With the increasing complexity and widespread use of computer systems, obtaining assurances regarding their robustness has become of vital importance. This survey discusses the state of the art on software robustness assessment, with emphasis on key aspects like types of systems being evaluated, assessment techniques used, the target of the techniques, the types of faults used, and how system behavior is classified. The survey concludes with the identification of gaps and open challenges related with robustness assessment.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {89},
numpages = {65},
keywords = {robustness evaluation, Software robustness, robustness testing}
}

@inproceedings{10.1145/2970276.2970364,
author = {Li, Xin and Liang, Yongjuan and Qian, Hong and Hu, Yi-Qi and Bu, Lei and Yu, Yang and Chen, Xin and Li, Xuandong},
title = {Symbolic Execution of Complex Program Driven by Machine Learning Based Constraint Solving},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970364},
doi = {10.1145/2970276.2970364},
abstract = { Symbolic execution is a widely-used program analysis technique. It collects and solves path conditions to guide the program traversing. However, due to the limitation of the current constraint solvers, it is difficult to apply symbolic execution on programs with complex path conditions, like nonlinear constraints and function calls. In this paper, we propose a new symbolic execution tool MLB to handle such problem. Instead of relying on the classical constraint solving, in MLB, the feasibility problems of the path conditions are transformed into optimization problems, by minimizing some dissatisfaction degree. The optimization problems are then handled by the underlying optimization solver through machine learning guided sampling and validation. MLB is implemented on the basis of Symbolic PathFinder and encodes not only the simple linear path conditions, but also nonlinear arithmetic operations, and even black-box function calls of library methods, into symbolic path conditions. Experiment results show that MLB can achieve much better coverage on complex real-world programs. },
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {554–559},
numpages = {6},
keywords = {Machine Learning, Symbolic Execution, Complicated Path Condition, Constraint Solving},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@article{10.14778/3357377.3357382,
author = {Jung, Jinho and Hu, Hong and Arulraj, Joy and Kim, Taesoo and Kang, Woonhak},
title = {APOLLO: Automatic Detection and Diagnosis of Performance Regressions in Database Systems},
year = {2019},
issue_date = {September 2019},
publisher = {VLDB Endowment},
volume = {13},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/3357377.3357382},
doi = {10.14778/3357377.3357382},
abstract = {The practical art of constructing database management systems (DBMSs) involves a morass of trade-offs among query execution speed, query optimization speed, standards compliance, feature parity, modularity, portability, and other goals. It is no surprise that DBMSs, like all complex software systems, contain bugs that can adversely affect their performance. The performance of DBMSs is an important metric as it determines how quickly an application can take in new information and use it to make new decisions.Both developers and users face challenges while dealing with performance regression bugs. First, developers usually find it challenging to manually design test cases to uncover performance regressions since DBMS components tend to have complex interactions. Second, users encountering performance regressions are often unable to report them, as the regression-triggering queries could be complex and database-dependent. Third, developers have to expend a lot of effort on localizing the root cause of the reported bugs, due to the system complexity and software development complexity.Given these challenges, this paper presents the design of Apollo, a toolchain for automatically detecting, reporting, and diagnosing performance regressions in DBMSs. We demonstrate that Apollo automates the generation of regression-triggering queries, simplifies the bug reporting process for users, and enables developers to quickly pinpoint the root cause of performance regressions. By automating the detection and diagnosis of performance regressions, Apollo reduces the labor cost of developing efficient DBMSs.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {57–70},
numpages = {14}
}

@inproceedings{10.1145/3282373.3282378,
author = {Alabdulkarim, Yazeed and Almaymoni, Marwan and Ghandeharizadeh, Shahram and Huang, Haoyu and Nguyen, Hieu},
title = {Testing Database Applications with Polygraph},
year = {2018},
isbn = {9781450364799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282373.3282378},
doi = {10.1145/3282373.3282378},
abstract = {Diverse applications implement read and write transactions using a data store. It is challenging to evaluate whether transactions that constitute an application provide strong consistency. It requires an end-to-end testing as an application may consist of several components that impact the consistency of data. Polygraph is a conceptual plug-n-play framework to quantify the amount of anomalies produced by an application. We show several use cases of Polygraph for two major application classes: e-commerce and cloud. One long-term objective of Polygraph is to reduce the cost and time required to test a data driven application, so that developers may focus more time and effort on applications' features and requirements.},
booktitle = {Proceedings of the 20th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {200–206},
numpages = {7},
keywords = {Database, Testing, Consistency},
location = {Yogyakarta, Indonesia},
series = {iiWAS2018}
}

