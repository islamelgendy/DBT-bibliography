@inproceedings{10.1145/2806777.2806843,
author = {Coppa, Emilio and Finocchi, Irene},
title = {On Data Skewness, Stragglers, and MapReduce Progress Indicators},
year = {2015},
isbn = {9781450336512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2806777.2806843},
doi = {10.1145/2806777.2806843},
abstract = {We tackle the problem of predicting the performance of MapReduce applications designing accurate progress indicators, which keep programmers informed on the percentage of completed computation time during the execution of a job. This is especially important in pay-as-you-go cloud environments, where slow jobs can be aborted in order to avoid excessive costs. Performance predictions can also serve as a building block for several profile-guided optimizations. By assuming that the running time depends linearly on the input size, state-of-the-art techniques can be seriously harmed by data skewness, load unbalancing, and straggling tasks. We thus design a novel profile-guided progress indicator, called NearestFit, that operates without the linear hypothesis assumption in a fully online way (i.e., without resorting to profile data collected from previous executions). NearestFit exploits a careful combination of nearest neighbor regression and statistical curve fitting techniques. Fine-grained profiles required by our theoretical progress model are approximated through space- and time-efficient data streaming algorithms. We implemented NearestFit on top of Hadoop 2.6.0. An extensive empirical assessment over the Amazon EC2 platform on a variety of benchmarks shows that its accuracy is very good, even when competitors incur non-negligible errors and wide prediction fluctuations.},
booktitle = {Proceedings of the Sixth ACM Symposium on Cloud Computing},
pages = {139–152},
numpages = {14},
keywords = {progress indicators, performance prediction, hadoop, performance profiling, data skewness, MapReduce},
location = {Kohala Coast, Hawaii},
series = {SoCC '15}
}

@inproceedings{10.1145/3384544.3384608,
author = {Nasser, Abdullah B. and Abdul-Qawy, Antar S. H. and Abdullah, Nibras and Hujainah, Fadhl and Zamli, Kamal Z. and Ghanem, Waheed A. H. M.},
title = {Latin Hypercube Sampling Jaya Algorithm Based Strategy for T-Way Test Suite Generation},
year = {2020},
isbn = {9781450376655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384544.3384608},
doi = {10.1145/3384544.3384608},
abstract = {T-way testing is a sampling strategy that generates a subset of test cases from a pool of possible tests. Many t-way testing strategies appear in the literature to-date ranging from general computational ones to meta-heuristic based. Owing to its performance, man the meta-heuristic based t-way strategies have gained significant attention recently (e.g. Particle Swarm Optimization, Genetic Algorithm, Ant Colony Algorithm, Harmony Search, Jaya Algorithm and Cuckoo Search). Jaya Algorithm (JA) is a new metaheuristic algorithm, has been used for solving different problems. However, losing the search's diversity is a common issue in the metaheuristic algorithm. In order to enhance JA's diversity, enhanced Jaya Algorithm strategy called Latin Hypercube Sampling Jaya Algorithm (LHS-JA) for Test Suite Generation is proposed. Latin Hypercube Sampling (LHS) is a sampling approach that can be used efficiently to improve search diversity. To evaluate the efficiency of LHS-JA, LHS-JA is compared against existing metaheuristic-based t-way strategies. Experimental results have shown promising results as LHS-JA can compete with existing t-way strategies.},
booktitle = {Proceedings of the 2020 9th International Conference on Software and Computer Applications},
pages = {105–109},
numpages = {5},
keywords = {Optimization algorithm, T-way Test Suite Generation, Jaya algorithm, Metaheuristic algorithm, Application of Jaya algorithm},
location = {Langkawi, Malaysia},
series = {ICSCA 2020}
}

@article{10.1145/1525880.1525884,
author = {McMinn, Phil and Binkley, David and Harman, Mark},
title = {Empirical Evaluation of a Nesting Testability Transformation for Evolutionary Testing},
year = {2009},
issue_date = {May 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/1525880.1525884},
doi = {10.1145/1525880.1525884},
abstract = {Evolutionary testing is an approach to automating test data generation that uses an evolutionary algorithm to search a test object's input domain for test data. Nested predicates can cause problems for evolutionary testing, because information needed for guiding the search only becomes available as each nested conditional is satisfied. This means that the search process can overfit to early information, making it harder, and sometimes near impossible, to satisfy constraints that only become apparent later in the search. The article presents a testability transformation that allows the evaluation of all nested conditionals at once. Two empirical studies are presented. The first study shows that the form of nesting handled is prevalent in practice. The second study shows how the approach improves evolutionary test data generation.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {11},
numpages = {27},
keywords = {testability transformation, search-based software engineering, Evolutionary testing, test data generation}
}

@inproceedings{10.1145/1879211.1879251,
author = {Cheng, Yung-Pin and Tsai, Han-Yi and Wang, Chih-Shun and Hsueh, Chien-Hsin},
title = {XDIVA: Automatic Animation between Debugging Break Points},
year = {2010},
isbn = {9781450300285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1879211.1879251},
doi = {10.1145/1879211.1879251},
abstract = {xDIVA, a 3D debugging visualization tool, provides a platform by which visualization metaphors are interactive, composable and decoupled from data, i.e. a complicated visualization can be composed and assembled from basic ones, each of which is independently replaceable. Based on the progress of xDIVA, this tool demo paper describes an automatic animation system to generate interpolated frames between key frames, where key frames are snapshots of the 3D scene at breakpoints. This approach does not require users to add or write any animation code and is more feasible for practical use.},
booktitle = {Proceedings of the 5th International Symposium on Software Visualization},
pages = {221–222},
numpages = {2},
keywords = {composable visualization metaphors, software visualization, debugging visualization, key-frame animation, program visualization},
location = {Salt Lake City, Utah, USA},
series = {SOFTVIS '10}
}

@article{10.1145/193209.193226,
author = {Butt, Farooq},
title = {Rapid Development of a Source-Level Debugger for PowerPC Microprocessors},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {12},
issn = {0362-1340},
url = {https://doi.org/10.1145/193209.193226},
doi = {10.1145/193209.193226},
abstract = {As design cycle times in the computer industry decrease, it becomes increasingly important to have a fast, effective software-development environment quickly available so that software may be developed for emergent microprocessors well before general availability. This paper discusses how gdb (an industry-standard source-level debugger) was paired with a software microprocessor simulator for the Motorola PowerPC 601* and PowerPC 603* microprocessors in order to provide a seamless and highly productive compile-edit-debug environment from the time that the PowerPC instruction set was first announced through general availability.},
journal = {SIGPLAN Not.},
month = {dec},
pages = {73–77},
numpages = {5}
}

@inproceedings{10.1145/775832.775927,
author = {Hsu, Yu-Chin and Tabbara, Bassam and Chen, Yirng-An and Tsai, Furshing},
title = {Advanced Techniques for RTL Debugging},
year = {2003},
isbn = {1581136889},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/775832.775927},
doi = {10.1145/775832.775927},
abstract = {Conventional register transfer level (RTL) debugging is based on overlaying simulation results on structural connectivity information of the Hardware Description Language (HDL) source. This process is helpful in locating errors but does little to help designers reason about the how and why. Designers usually have to build a mental image of how data is propagated and used over the simulation run. As designs get more and more complex, there is a need to facilitate this reasoning process, and automate the debugging. In this paper, we present innovative debug techniques to address this shortage in adequate facilities for reasoning about behavior, and debugging errors. Our approach delivers significant technology advances in RTL debugging; it is the first comprehensive and methodical approach of its kind that extracts, analyzes, traces, explores, and queries a design's multi-cycle temporal behavior. We show how our automatic tracing scheme can shorten debugging time by orders of magnitude for unfamiliar designs. We also demonstrate how the advanced debug techniques reduce the number of regression iterations.},
booktitle = {Proceedings of the 40th Annual Design Automation Conference},
pages = {362–367},
numpages = {6},
keywords = {verification, visualization, debug, reasoning, simulation},
location = {Anaheim, CA, USA},
series = {DAC '03}
}

@inproceedings{10.1145/2642937.2653469,
author = {Borg, Markus},
title = {Embrace Your Issues: Compassing the Software Engineering Landscape Using Bug Reports},
year = {2014},
isbn = {9781450330138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2642937.2653469},
doi = {10.1145/2642937.2653469},
abstract = {Software developers in large projects work in complex information landscapes, and staying on top of all relevant software artifacts is challenging. As software systems often evolve for years, a high number of issue reports is typically managed during the lifetime of a system. Efficient management of incoming issue requires successful navigation of the information landscape. In our work, we address two important work tasks involved in issue management: Issue Assignment (IA) and Change Impact Analysis (CIA). IA is the early task of allocating an issue report to a development team. CIA deals with identifying how source code changes affect the software system, a fundamental activity in safety-critical development. Our solution approach is to support navigation, both among development teams and software artifacts, based on information available in historical issue reports. We present how we apply techniques from machine learning and information retrieval to develop recommendation systems. Finally, we report intermediate results from two controlled experiments and an industrial case study.},
booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
pages = {891–894},
numpages = {4},
keywords = {information retrieval, recommendation systems, machine learning, issue management},
location = {Vasteras, Sweden},
series = {ASE '14}
}

@inproceedings{10.1145/2295136.2295169,
author = {Uzun, Emre and Atluri, Vijayalakshmi and Sural, Shamik and Vaidya, Jaideep and Parlato, Gennaro and Ferrara, Anna Lisa and Parthasarathy, Madhusudan},
title = {Analyzing Temporal Role Based Access Control Models},
year = {2012},
isbn = {9781450312950},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2295136.2295169},
doi = {10.1145/2295136.2295169},
abstract = {Today, Role Based Access Control (RBAC) is the de facto model used for advanced access control, and is widely deployed in diverse enterprises of all sizes. Several extensions to the authorization as well as the administrative models for RBAC have been adopted in recent years. In this paper, we consider the temporal extension of RBAC (TRBAC), and develop safety analysis techniques for it. Safety analysis is essential for understanding the implications of security policies both at the stage of specification and modification. Towards this end, in this paper, we first define an administrative model for TRBAC. Our strategy for performing safety analysis is to appropriately decompose the TRBAC analysis problem into multiple subproblems similar to RBAC. Along with making the analysis simpler, this enables us to leverage and adapt existing analysis techniques developed for traditional RBAC. We have adapted and experimented with employing two state of the art analysis approaches developed for RBAC as well as tools developed for software testing. Our results show that our approach is both feasible and flexible.},
booktitle = {Proceedings of the 17th ACM Symposium on Access Control Models and Technologies},
pages = {177–186},
numpages = {10},
keywords = {safety analysis, temporal rbac, access control},
location = {Newark, New Jersey, USA},
series = {SACMAT '12}
}

@inproceedings{10.5555/800054.801972,
author = {Draper, Stephen W. and Norman, Donald A.},
title = {Software Engineering for User Interfaces},
year = {1984},
isbn = {0818605286},
publisher = {IEEE Press},
abstract = { The discipline of Software Engineering can be extended in a natural way to deal with the issues raised by a systematic approach to the design of human-machine interfaces. Two main points are made: that the user should be treated as part of the system being designed, and that projects should be organized to take account of the current (small) state of a priori knowledge about how to design interfaces.  Because the principles of good user-interface design are not yet well specified (and not yet known), interfaces should be developed through an iterative process. This means that it is essential to develop tools for evaluation and debugging of the interface, much the same way as tools have been developed for the evaluation and debugging of program code. We need to develop methods of detecting bugs in the interface and of diagnosing their cause. The tools for testing interfaces should include measures of interface performance, acceptance tests, and benchmarks. Developing useful measures is a non-trivial task, but a start can and should be made. },
booktitle = {Proceedings of the 7th International Conference on Software Engineering},
pages = {214–220},
numpages = {7},
location = {Orlando, Florida, USA},
series = {ICSE '84}
}

@inproceedings{10.1145/1374596.1374610,
author = {Konwinski, Andy and Bent, John and Nunez, James and Quist, Meghan},
title = {Towards an I/O Tracing Framework Taxonomy},
year = {2007},
isbn = {9781595938992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1374596.1374610},
doi = {10.1145/1374596.1374610},
abstract = {There is high demand for I/O tracing in High Performance Computing (HPC). It enables in-depth analysis of distributed applications and file system performance tuning. It also aids distributed application debugging. Finally, it facilitates collaboration within and between government, industrial, and academic institutions by enabling the generation of replayable I/O traces, which can be easily distributed and anonymized as necessary to protect confidential or sensitive information. As a response to this demand for tracing tools, various means of I/O trace generation exist. We first survey the I/O Tracing Framework landscape, exploring three popular such frameworks: LANL-Trace [3], Tracefs [1], and//TRACE [2].We next develop an I/O Tracing Framework taxonomy. The purpose of this taxonomy is to assist I/O Tracing Framework users in formalizing their tracing requirements, and to provide the developers of I/O Tracing Frameworks a language to categorize the functionality and performance of them. The taxonomy categorizes I/O Tracing Framework features such as the type of data captured, trace replayability, and anonymization. The taxonomy also considers elapsed-time overhead and performance overhead. Finally, we provide a case study in the use of our new taxonomy, revisiting all three I/O Tracing Frameworks explored in our survey, to formally classify the features of each.},
booktitle = {Proceedings of the 2nd International Workshop on Petascale Data Storage: Held in Conjunction with Supercomputing '07},
pages = {56–62},
numpages = {7},
keywords = {file systems, tracing, parallel},
location = {Reno, Nevada},
series = {PDSW '07}
}

@inproceedings{10.1145/2370216.2370410,
author = {Kang, Jeong Seok and Park, Hong Seong},
title = {Web-Based Automated Black-Box Testing Framework for Component Based Robot Software},
year = {2012},
isbn = {9781450312240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2370216.2370410},
doi = {10.1145/2370216.2370410},
abstract = {Reliability of component based robot software depends on the quality of each component because any defective components will have a ripple effect on systems built with them. Thus, testing of unit component, composite component and component based robot software is critical for checking the correctness of the software functionality. This paper proposes Web-based automated black-box testing framework for component based robot software. The proposed framework provides automated testing service, testing for different robot platform and distributed test environment, and sharing test resources. We have implemented the proposed framework and evaluated it on the component based front guidance application to output a guidance statement by sensing front obstacles, and control robot wheels by sensing a back user.},
booktitle = {Proceedings of the 2012 ACM Conference on Ubiquitous Computing},
pages = {852–859},
numpages = {8},
keywords = {component based robot software, black-box testing, specification based testing, automated testing framework, distributed test environment},
location = {Pittsburgh, Pennsylvania},
series = {UbiComp '12}
}

@inproceedings{10.5555/3106028.3106036,
author = {Kechagia, Maria and Spinellis, Diomidis},
title = {Type Checking for Reliable APIs},
year = {2017},
isbn = {9781538628058S},
publisher = {IEEE Press},
abstract = {In this paper, we propose to configure at compile time the checking associated with Application Programming Interfaces' methods that can receive possibly malformed values (e.g. erroneous user inputs and problematic retrieved records from databases) and thus cause application execution failures. To achieve this, we design a type system for implementing a pluggable checker on the Java's compiler and find at compile time insufficient checking bugs that can lead to application crashes due to malformed inputs. Our goal is to wrap methods when they receive external inputs so that the former generate checked instead of unchecked exceptions. We believe that our approach can improve Java developers' productivity, by using exception handling only when it is required, and ensure client applications' stability. We want to evaluate our checker by using it to verify the source code of Java projects from the Apache ecosystem. Also, we want to analyze stack traces to validate the identified failures by our checker.},
booktitle = {Proceedings of the 1st International Workshop on API Usage and Evolution},
pages = {15–18},
numpages = {4},
keywords = {type systems, exceptions, application programming interfaces},
location = {Buenos Aires, Argentina},
series = {WAPI '17}
}

@inproceedings{10.1145/3314221.3314635,
author = {Lidbury, Christopher and Donaldson, Alastair F.},
title = {Sparse Record and Replay with Controlled Scheduling},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314635},
doi = {10.1145/3314221.3314635},
abstract = {Modern applications include many sources of nondeterminism, e.g. due to concurrency, signals, and system calls that interact with the external environment. Finding and reproducing bugs in the presence of this nondeterminism has been the subject of much prior work in three main areas: (1) controlled concurrency-testing, where a custom scheduler replaces the OS scheduler to find subtle bugs; (2) record and replay, where sources of nondeterminism are captured and logged so that a failing execution can be replayed for debugging purposes; and (3) dynamic analysis for the detection of data races. We present a dynamic analysis tool for C++ applications, tsan11rec, which brings these strands of work together by integrating controlled concurrency testing and record and replay into the tsan11 framework for C++11 data race detection. Our novel twist on record and replay is a sparse approach, where the sources of nondeterminism to record can be configured per application. We show that our approach is effective at finding subtle concurrency bugs in small applications; is competitive in terms of performance with the state-of-the-art record and replay tool rr on larger applications; succeeds (due to our sparse approach) in replaying the I/O-intensive Zandronum and QuakeSpasm video games, which are out of scope for rr; but (due to limitations of our sparse approach) cannot faithfully replay applications where memory layout nondeterminism significantly affects application behaviour.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {576–593},
numpages = {18},
keywords = {record and replay, controlled concurrency test- ing, data race detection, concurrency},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}

@inproceedings{10.1109/ICSE.2007.87,
author = {Chong, Jan and Hurlbutt, Tom},
title = {The Social Dynamics of Pair Programming},
year = {2007},
isbn = {0769528287},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSE.2007.87},
doi = {10.1109/ICSE.2007.87},
abstract = {This paper presents data from a four month ethnographic study of professional pair programmers from two software development teams. Contrary to the current conception of pair programmers, the pairs in this study did not hew to the separate roles of "driver" and "navigator". Instead, the observed programmers moved together through different phases of the task, considering and discussing issues at the same strategic "range" or level of abstraction and in largely the same role. This form of interaction was reinforced by frequent switches in keyboard control during pairing and the use of dual keyboards. The distribution of expertise among the members of a pair had a strong influence on the tenor of pair programming interaction. Keyboard control had a consistent secondary effect on decision-making within the pair. These findings have implications for software development managers and practitioners as well as for the design of software development tools.},
booktitle = {Proceedings of the 29th International Conference on Software Engineering},
pages = {354–363},
numpages = {10},
series = {ICSE '07}
}

@inproceedings{10.1145/1085130.1085147,
author = {Kumar, Naveen and Childers, Bruce R. and Soffa, Mary Lou},
title = {Tdb: A Source-Level Debugger for Dynamically Translated Programs},
year = {2005},
isbn = {1595930507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1085130.1085147},
doi = {10.1145/1085130.1085147},
abstract = {Debugging techniques have evolved over the years in response to changes in programming languages, implementation techniques, and user needs. A new type of implementation vehicle for software has emerged that, once again, requires new debugging techniques. Software dynamic translation (SDT) has received much attention due to compelling applications of the technology, including software security checking, binary translation, and dynamic optimization. Using SDT, program code changes dynamically, and thus, debugging techniques developed for statically generated code cannot be used to debug these applications. In this paper, we describe a new debug architecture for applications executing with SDT systems. The architecture provides features that create the illusion that the source program is being debugged, while allowing the SDT system to modify the executing code. We incorporated this architecture in a new tool, called tdb, that integrates a SDT system, Strata, with a widely used debugger, gdb. We evaluated tdb in the context of a code security checker. The results show that a dynami-cally translated program can be debugged at the source level and that the approach does not overly increase the run-time perfor-mance or memory demands of the debugger.},
booktitle = {Proceedings of the Sixth International Symposium on Automated Analysis-Driven Debugging},
pages = {123–132},
numpages = {10},
keywords = {dynamic binary translation, debugging, dynamic instrumentation},
location = {Monterey, California, USA},
series = {AADEBUG'05}
}

@inproceedings{10.1145/3426425.3426946,
author = {van Heerden, Phillip and Raselimo, Moeketsi and Sagonas, Konstantinos and Fischer, Bernd},
title = {Grammar-Based Testing for Little Languages: An Experience Report with Student Compilers},
year = {2020},
isbn = {9781450381765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426425.3426946},
doi = {10.1145/3426425.3426946},
abstract = {We report on our experience in using various grammar-based test suite generation methods to test 61 single-pass compilers that undergraduate students submitted for the practical project of a computer architecture course.  We show that (1) all test suites constructed systematically following different grammar coverage criteria fall far behind the instructor's test suite in achieved code coverage, in the number of triggered semantic errors, and in detected failures and crashes; (2) a medium-sized positive random test suite triggers more crashes than the instructor's test suite, but achieves lower code coverage and triggers fewer non-crashing errors; and (3) a combination of the systematic and random test suites performs as well or better than the instructor's test suite in all aspects and identifies errors or crashes in every single submission.  We then develop a light-weight extension of the basic grammar-based testing framework to capture contextual constraints, by encoding scoping and typing information as ``semantic mark-up tokens'' in the grammar rules. These mark-up tokens are interpreted by a small generic core engine when the tests are rendered, and tests with a syntactic structure that cannot be completed into a valid program by choosing appropriate identifiers are discarded. % We formalize individual error models by overwriting individual mark-up tokens, and generate tests that are guaranteed to break specific contextual properties of the language. We show that a fully automatically generated random test suite with 15 error models achieves roughly the same coverage as the instructor's test suite, and outperforms it in the number of triggered semantic errors and detected failures and crashes. Moreover, all failing tests indicate real errors, and we have detected errors even in the instructor's reference implementation.},
booktitle = {Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {253–269},
numpages = {17},
keywords = {random testing, property-based testing, semantic fuzzing, Structure-aware fuzzing},
location = {Virtual, USA},
series = {SLE 2020}
}

@inproceedings{10.1145/2737924.2737986,
author = {Lidbury, Christopher and Lascu, Andrei and Chong, Nathan and Donaldson, Alastair F.},
title = {Many-Core Compiler Fuzzing},
year = {2015},
isbn = {9781450334686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2737924.2737986},
doi = {10.1145/2737924.2737986},
abstract = { We address the compiler correctness problem for many-core systems through novel applications of fuzz testing to OpenCL compilers. Focusing on two methods from prior work, random differential testing and testing via equivalence modulo inputs (EMI), we present several strategies for random generation of deterministic, communicating OpenCL kernels, and an injection mechanism that allows EMI testing to be applied to kernels that otherwise exhibit little or no dynamically-dead code. We use these methods to conduct a large, controlled testing campaign with respect to 21 OpenCL (device, compiler) configurations, covering a range of CPU, GPU, accelerator, FPGA and emulator implementations. Our study provides independent validation of claims in prior work related to the effectiveness of random differential testing and EMI testing, proposes novel methods for lifting these techniques to the many-core setting and reveals a significant number of OpenCL compiler bugs in commercial implementations. },
booktitle = {Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {65–76},
numpages = {12},
keywords = {OpenCL, random testing, GPUs, metamor- phic testing, concurrency, Compilers},
location = {Portland, OR, USA},
series = {PLDI '15}
}

@article{10.1145/2813885.2737986,
author = {Lidbury, Christopher and Lascu, Andrei and Chong, Nathan and Donaldson, Alastair F.},
title = {Many-Core Compiler Fuzzing},
year = {2015},
issue_date = {June 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/2813885.2737986},
doi = {10.1145/2813885.2737986},
abstract = { We address the compiler correctness problem for many-core systems through novel applications of fuzz testing to OpenCL compilers. Focusing on two methods from prior work, random differential testing and testing via equivalence modulo inputs (EMI), we present several strategies for random generation of deterministic, communicating OpenCL kernels, and an injection mechanism that allows EMI testing to be applied to kernels that otherwise exhibit little or no dynamically-dead code. We use these methods to conduct a large, controlled testing campaign with respect to 21 OpenCL (device, compiler) configurations, covering a range of CPU, GPU, accelerator, FPGA and emulator implementations. Our study provides independent validation of claims in prior work related to the effectiveness of random differential testing and EMI testing, proposes novel methods for lifting these techniques to the many-core setting and reveals a significant number of OpenCL compiler bugs in commercial implementations. },
journal = {SIGPLAN Not.},
month = {jun},
pages = {65–76},
numpages = {12},
keywords = {concurrency, random testing, OpenCL, Compilers, metamor- phic testing, GPUs}
}

@inproceedings{10.1145/1858996.1859059,
author = {Schulte, Eric and Forrest, Stephanie and Weimer, Westley},
title = {Automated Program Repair through the Evolution of Assembly Code},
year = {2010},
isbn = {9781450301169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858996.1859059},
doi = {10.1145/1858996.1859059},
abstract = {A method is described for automatically repairing legacy software at the assembly code level using evolutionary computation. The technique is demonstrated on Java byte code and x86 assembly programs, showing how to find program variations that correct defects while retaining desired behavior. Test cases are used to demonstrate the defect and define required functionality. The paper explores advantages of assembly-level repair over earlier work at the source code level - the ability to repair programs written in many different languages; and the ability to repair bugs that were previously intractable. The paper reports experimental results showing reasonable performance of assembly language repair even on non-trivial programs},
booktitle = {Proceedings of the IEEE/ACM International Conference on Automated Software Engineering},
pages = {313–316},
numpages = {4},
keywords = {evolutionary computation, fault localization, legacy software, assembly code, program repair, bytecode},
location = {Antwerp, Belgium},
series = {ASE '10}
}

@inproceedings{10.1145/800175.809860,
author = {Moffat, David V.},
title = {Conformant Arrays and Strong Typing},
year = {1981},
isbn = {0897910494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800175.809860},
doi = {10.1145/800175.809860},
abstract = {Many persons have criticized—or defended— Pascal [1] for its lack of conformant arrays [2,3]. A conformant array is a formal parameter array whose bounds will conform to those of an actual parameter array. (The element types of both must be the same.) The lack of this feature is due to a desire for efficient compilation and execution. It is enforced by Pascal's convention that the index or bounds specification of an array is an integral part of the type of the array. For example, in:TYPE LIST=ARRAY[1..10] OF REAL;LOST=ARRAY[1..5] OF REAL;VAR LI: LIST;LO: LOST;LA: ARRAY[1. 10 ] OF REAL;FUNCTION SUM(A: LIST): REAL;it can be seen that the array bounds are nowhere specified in the parameter declaration; they are buried within the type definition. Thus, the call SUM(LI) is syntactically correct, but SUM(LO) is not, because the type of LO does not match the formal parameter. The call SUM(LA) is not correct, because LA has an anonymous (unnamed) type that matches (by convention) no other types. There is no way to generalize the SUM procedure to accept various arrays of reals.},
booktitle = {Proceedings of the ACM '81 Conference},
pages = {161–163},
numpages = {3},
series = {ACM '81}
}

@inproceedings{10.1145/2814270.2814303,
author = {Bielik, Pavol and Raychev, Veselin and Vechev, Martin},
title = {Scalable Race Detection for Android Applications},
year = {2015},
isbn = {9781450336895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814270.2814303},
doi = {10.1145/2814270.2814303},
abstract = { We present a complete end-to-end dynamic analysis system for finding data races in mobile Android applications. The capabilities of our system significantly exceed the state of the art: our system can analyze real-world application interactions in minutes rather than hours, finds errors inherently beyond the reach of existing approaches, while still (critically) reporting very few false positives. Our system is based on three key concepts: (i) a thorough happens-before model of Android-specific concurrency, (ii) a scalable analysis algorithm for efficiently building and querying the happens-before graph, and (iii) an effective set of domain-specific filters that reduce the number of reported data races by several orders of magnitude. We evaluated the usability and performance of our system on 354 real-world Android applications (e.g., Facebook). Our system analyzes a minute of end-user interaction with the application in about 24 seconds, while current approaches take hours to complete. Inspecting the results for 8 large open-source applications revealed 15 harmful bugs of diverse kinds. Some of the bugs we reported were confirmed and fixed by developers. },
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {332–348},
numpages = {17},
keywords = {Data Races, Happens-before, Non-determinism, Android},
location = {Pittsburgh, PA, USA},
series = {OOPSLA 2015}
}

@article{10.1145/2858965.2814303,
author = {Bielik, Pavol and Raychev, Veselin and Vechev, Martin},
title = {Scalable Race Detection for Android Applications},
year = {2015},
issue_date = {October 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2858965.2814303},
doi = {10.1145/2858965.2814303},
abstract = { We present a complete end-to-end dynamic analysis system for finding data races in mobile Android applications. The capabilities of our system significantly exceed the state of the art: our system can analyze real-world application interactions in minutes rather than hours, finds errors inherently beyond the reach of existing approaches, while still (critically) reporting very few false positives. Our system is based on three key concepts: (i) a thorough happens-before model of Android-specific concurrency, (ii) a scalable analysis algorithm for efficiently building and querying the happens-before graph, and (iii) an effective set of domain-specific filters that reduce the number of reported data races by several orders of magnitude. We evaluated the usability and performance of our system on 354 real-world Android applications (e.g., Facebook). Our system analyzes a minute of end-user interaction with the application in about 24 seconds, while current approaches take hours to complete. Inspecting the results for 8 large open-source applications revealed 15 harmful bugs of diverse kinds. Some of the bugs we reported were confirmed and fixed by developers. },
journal = {SIGPLAN Not.},
month = {oct},
pages = {332–348},
numpages = {17},
keywords = {Data Races, Happens-before, Non-determinism, Android}
}

