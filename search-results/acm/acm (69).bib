@inproceedings{10.1145/2814270.2814281,
author = {Zheng, Yudi and Bulej, Lubom\'{\i}r and Binder, Walter},
title = {Accurate Profiling in the Presence of Dynamic Compilation},
year = {2015},
isbn = {9781450336895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2814270.2814281},
doi = {10.1145/2814270.2814281},
abstract = { Many profilers based on bytecode instrumentation yield wrong results in the presence of an optimizing dynamic compiler, either due to not being aware of optimizations such as stack allocation and method inlining, or due to the inserted code disrupting such optimizations. To avoid such perturbations, we present a novel technique to make any profiler implemented at the bytecode level aware of optimizations performed by the dynamic compiler. We implement our approach in a state-of-the-art Java virtual machine and demonstrate its significance with concrete profilers. We quantify the impact of escape analysis on allocation profiling, object life-time analysis, and the impact of method inlining on callsite profiling. We illustrate how our approach enables new kinds of profilers, such as a profiler for non-inlined callsites, and a testing framework for locating performance bugs in dynamic compiler implementations. },
booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {433–450},
numpages = {18},
keywords = {Dynamic compilers, bytecode instrumentation, profiling},
location = {Pittsburgh, PA, USA},
series = {OOPSLA 2015}
}

@article{10.1145/2858965.2814281,
author = {Zheng, Yudi and Bulej, Lubom\'{\i}r and Binder, Walter},
title = {Accurate Profiling in the Presence of Dynamic Compilation},
year = {2015},
issue_date = {October 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2858965.2814281},
doi = {10.1145/2858965.2814281},
abstract = { Many profilers based on bytecode instrumentation yield wrong results in the presence of an optimizing dynamic compiler, either due to not being aware of optimizations such as stack allocation and method inlining, or due to the inserted code disrupting such optimizations. To avoid such perturbations, we present a novel technique to make any profiler implemented at the bytecode level aware of optimizations performed by the dynamic compiler. We implement our approach in a state-of-the-art Java virtual machine and demonstrate its significance with concrete profilers. We quantify the impact of escape analysis on allocation profiling, object life-time analysis, and the impact of method inlining on callsite profiling. We illustrate how our approach enables new kinds of profilers, such as a profiler for non-inlined callsites, and a testing framework for locating performance bugs in dynamic compiler implementations. },
journal = {SIGPLAN Not.},
month = {oct},
pages = {433–450},
numpages = {18},
keywords = {profiling, Dynamic compilers, bytecode instrumentation}
}

@inproceedings{10.1145/1370256.1370279,
author = {Roy, Chanchal K. and Cordy, James R.},
title = {Towards a Mutation-Based Automatic Framework for Evaluating Code Clone Detection Tools},
year = {2008},
isbn = {9781605581019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370256.1370279},
doi = {10.1145/1370256.1370279},
abstract = {In the last decade, a great many code clone detection tools have been proposed. Such a large number of tools calls for a quantitative comparison, and there have been several attempts to empirically evaluate and compare many of the state-of-the-art tools. However, a recent study shows that there are several factors that could influence the the validity of the results of such comparisons. In order to overcome the effects of such factors (at least in part), in this student poster paper we outline a mutation-based controlled frame-work for evaluating clone detection tools using edit-based mutation operators that model cloning actions. While the framework is not yet completely implemented and as yet we do not have experimental data, we anticipate that such a framework will provide a useful contribution to the community by providing a more solid objective foundation for tool evaluation.},
booktitle = {Proceedings of the 2008 C3S2E Conference},
pages = {137–140},
numpages = {4},
keywords = {framework, clone detection techniques, maintenance, evaluation, mutation analysis, software engineering},
location = {Montreal, Quebec, Canada},
series = {C3S2E '08}
}

@inproceedings{10.1145/2950290.2950347,
author = {Kim, Chung Hwan and Rhee, Junghwan and Lee, Kyu Hyung and Zhang, Xiangyu and Xu, Dongyan},
title = {PerfGuard: Binary-Centric Application Performance Monitoring in Production Environments},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2950347},
doi = {10.1145/2950290.2950347},
abstract = { Diagnosis of performance problems is an essential part of software development and maintenance. This is in particular a challenging problem to be solved in the production environment where only program binaries are available with limited or zero knowledge of the source code. This problem is compounded by the integration with a significant number of third-party software in most large-scale applications. Existing approaches either require source code to embed manually constructed logic to identify performance problems or support a limited scope of applications with prior manual analysis. This paper proposes an automated approach to analyze application binaries and instrument the binary code transparently to inject and apply performance assertions on application transactions. Our evaluation with a set of large-scale application binaries without access to source code discovered 10 publicly known real world performance bugs automatically and shows that PerfGuard introduces very low overhead (less than 3% on Apache and MySQL server) to production systems. },
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {595–606},
numpages = {12},
keywords = {Performance diagnosis, post-development testing},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/2858930.2858936,
author = {Saeed, Ahmed and Ahmadinia, Ali and Just, Mike},
title = {Tag-Protector: An Effective and Dynamic Detection of Out-of-Bound Memory Accesses},
year = {2016},
isbn = {9781450340656},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858930.2858936},
doi = {10.1145/2858930.2858936},
abstract = {Programming languages permitting immediate memory accesses through pointers often result in applications having memory-related errors, which may lead to unpredictable failures and security vulnerabilities. A light-weight solution is presented in this paper to tackle such illegal memory accesses dynamically in C/C++ based applications. We propose a new and effective method of instrumenting an application's source code at compile time in order to detect out-of-bound memory accesses. It is based on creating tags, to be coupled with each memory allocation and then placing additional tag checking instructions for each access made to the memory. The proposed solution is evaluated by instrumenting applications from the BugBench benchmark suite and publicly available benchmark software, Runtime Intrusion Prevention Evaluator (RIPE), detecting all the bugs successfully. The performance and memory overhead is further analysed by instrumenting and executing real world applications.},
booktitle = {Proceedings of the Third Workshop on Cryptography and Security in Computing Systems},
pages = {31–36},
numpages = {6},
keywords = {Compile-time code instrumentation, illegal memory accesses, buffer overflows},
location = {Prague, Czech Republic},
series = {CS2 '16}
}

@inproceedings{10.1145/3190508.3190552,
author = {Li, Jiaxin and Chen, Yuxi and Liu, Haopeng and Lu, Shan and Zhang, Yiming and Gunawi, Haryadi S. and Gu, Xiaohui and Lu, Xicheng and Li, Dongsheng},
title = {Pcatch: Automatically Detecting Performance Cascading Bugs in Cloud Systems},
year = {2018},
isbn = {9781450355841},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3190508.3190552},
doi = {10.1145/3190508.3190552},
abstract = {Distributed systems have become the backbone of modern clouds. Users often expect high scalability and performance isolation from distributed systems. Unfortunately, a type of poor software design, which we refer to as performance cascading bugs (PCbugs), can often cause the slowdown of non-scalable code in one job to propagate, causing global performance degradation and even threatening system availability.This paper presents a tool, PCatch, that can automatically predict PCbugs by analyzing system execution under small-scale workloads. PCatch contains three key components in predicting PCbugs. It uses program analysis to identify code regions whose execution time can potentially increase dramatically with the workload size; it adapts the traditional happens-before model to reason about software resource contention and performance dependency relationship; it uses dynamic tracking to identify whether the slowdown propagation is contained in one job or not. Our evaluation using representative distributed systems, Cassandra, Hadoop MapReduce, HBase, and HDFS, shows that PCatch can accurately predict PCbugs based on small-scale workload execution.},
booktitle = {Proceedings of the Thirteenth EuroSys Conference},
articleno = {7},
numpages = {14},
keywords = {cloud computing, performance bugs, bug detection, distributed systems, cascading problems},
location = {Porto, Portugal},
series = {EuroSys '18}
}

@inproceedings{10.1145/3468264.3473932,
author = {Metzman, Jonathan and Szekeres, L\'{a}szl\'{o} and Simon, Laurent and Sprabery, Read and Arya, Abhishek},
title = {FuzzBench: An Open Fuzzer Benchmarking Platform and Service},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473932},
doi = {10.1145/3468264.3473932},
abstract = {Fuzzing is a key tool used to reduce bugs in production software. At Google, fuzzing has uncovered tens of thousands of bugs. Fuzzing is also a popular subject of academic research. In 2020 alone, over 120 papers were published on the topic of improving, developing, and evaluating fuzzers and fuzzing techniques. Yet, proper evaluation of fuzzing techniques remains elusive. The community has struggled to converge on methodology and standard tools for fuzzer evaluation. To address this problem, we introduce FuzzBench as an open-source turnkey platform and free service for evaluating fuzzers. It aims to be easy to use, fast, reliable, and provides reproducible experiments. Since its release in March 2020, FuzzBench has been widely used both in industry and academia, carrying out more than 150 experiments for external users. It has been used by several published and in-the-work papers from academic groups, and has had real impact on the most widely used fuzzing tools in industry. The presented case studies suggest that FuzzBench is on its way to becoming a standard fuzzer benchmarking platform.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1393–1403},
numpages = {11},
keywords = {testing, fuzz testing, fuzzing, benchmarking, software security},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{10.1145/2876441,
author = {Alimadadi, Saba and Sequeira, Sheldon and Mesbah, Ali and Pattabiraman, Karthik},
title = {Understanding JavaScript Event-Based Interactions with Clematis},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/2876441},
doi = {10.1145/2876441},
abstract = {Web applications have become one of the fastest-growing types of software systems today. Despite their popularity, understanding the behavior of modern web applications is still a challenging endeavor for developers during development and maintenance tasks. The challenges mainly stem from the dynamic, event-driven, and asynchronous nature of the JavaScript language. We propose a generic technique for capturing low-level event-based interactions in a web application and mapping those to a higher-level behavioral model. This model is then transformed into an interactive visualization, representing episodes of triggered causal and temporal events, related JavaScript code executions, and their impact on the dynamic DOM state. Our approach, implemented in a tool called Clematis, allows developers to easily understand the complex dynamic behavior of their application at three different semantic levels of granularity. Furthermore, Clematis helps developers bridge the gap between test cases and program code by localizing the fault related to a test assertion. The results of our industrial controlled experiment show that Clematis is capable of improving the comprehension task accuracy by 157% while reducing the task completion time by 47%. A follow-up experiment reveals that Clematis improves the fault localization accuracy of developers by a factor of two.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {may},
articleno = {12},
numpages = {38},
keywords = {event-based interactions, web applications, Program comprehension, JavaScript, fault localization}
}

@inproceedings{10.5555/227726.227798,
author = {Eickelmann, Nancy S. and Richardson, Debra J.},
title = {An Evaluation of Software Test Environment Architectures},
year = {1996},
isbn = {0818672463},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Software test environments (STEs) provide a means of automating the test process and integrating testing tools to support required testing capabilities across the test process. Specifically, STEs may support test planning, test management, test measurement, test failure analysis, test development and test execution. The software architecture of an STE describes the allocation of the environment's functions to specific implementation structures. An STE's architecture can facilitate or impede modifications such as changes to processing algorithms, data representation or functionality. Performance and reusability are also subject to architecturally imposed constraints. Evaluation of an STE's architecture can provide insight into modifiability, extensibility, portability and reusability of the STE. This paper proposes a reference architecture for STEs. Its analytical value is demonstrated by using SAAM (Software Architectural Analysis Method) to compare three software test environments: PROTest II (PROLOG Test Environment, Version II), TAOS (Testing with Analysis and Oracle Support), and CITE (CONVEX Integrated Test Environment).},
booktitle = {Proceedings of the 18th International Conference on Software Engineering},
pages = {353–364},
numpages = {12},
keywords = {programming environments, performance, modifications, functionality, test management, test development, data representation, software architecture, reusability, program testing, Version II, SAAM, CONVEX Integrated Test Environment, modifiability, testing tools, software portability, test planning, test failure analysis, extensibility, computer aided software engineering, software test environment architectures, reference architecture, Testing with Analysis and Oracle Support, PROTest II, TAOS, CITE, processing algorithms, software performance evaluation, portability, test measurement, implementation structures, environment functions allocation, test process automation, test execution, software reusability, architecturally imposed constraints, PROLOG Test Environment, Software Architectural Analysis Method},
location = {Berlin, Germany},
series = {ICSE '96}
}

@inproceedings{10.1145/3071178.3071189,
author = {Lachmann, Remo and Felderer, Michael and Nieke, Manuel and Schulze, Sandro and Seidl, Christoph and Schaefer, Ina},
title = {Multi-Objective Black-Box Test Case Selection for System Testing},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071189},
doi = {10.1145/3071178.3071189},
abstract = {Testing is a fundamental task to ensure software quality. Regression testing aims to ensure that changes to software do not introduce new failures. As resources are often limited and testing comprises a vast amount of test cases, different regression strategies have been proposed to reduce testing effort by selecting or prioritizing important test cases, e.g., code coverage (to ensure a sufficient testing depth). However, in system testing, source code is often not available creating a black-box system. In this paper, we introduce an automated, multi-objective test case selection technique in black-box systems using genetic algorithms. We define seven different objectives, based on meta-data, allowing a flexible test case selection for a variety of systems. For evaluation, we apply our technique on two different subject systems assessing the feasibility and suitability of our test case selection approach. Results indicate that our approach is applicable based on different data available and is able to outperform random test case selection and retest-all.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1311–1318},
numpages = {8},
keywords = {test case selection, system testing, black-box testing, search-based testing},
location = {Berlin, Germany},
series = {GECCO '17}
}

@inproceedings{10.1145/2638404.2638470,
author = {Shahriar, Hossain and Batchu, Sheetal},
title = {Towards Mutation-Based Testing of Column-Oriented Database Queries},
year = {2014},
isbn = {9781450329231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2638404.2638470},
doi = {10.1145/2638404.2638470},
abstract = {There has been tremendous growth over the last few years of applications employing column-oriented databases (a common type of non-relational database) to store unstructured or semi-structured data. These applications have queries present in the implementation which need to be tested. Despite many literature works focus on testing relational database applications having SQL queries, there has been very little effort in testing of applications having non-relational database queries, in particular, column-oriented database queries. This paper proposes to apply fault injection-based testing approach (mutation analysis) for Cassandra, which is a popular column-oriented non-relational database. We propose a set of mutation operators for queries written in Cassandra Query Language (CQL) and mutant killing criteria. We also perform an initial evaluation for two types of CQL commands: key space and columnfamily creation and management. Our proposed approach will be the beginning step for developers and practitioners for applying fault injection based testing concept in the vast area of testing applications having non-relational database queries.},
booktitle = {Proceedings of the 2014 ACM Southeast Regional Conference},
articleno = {11},
numpages = {6},
keywords = {non-relational database testing, non-relational database, software, software validation, mutation-based testing, cassandra query language},
location = {Kennesaw, Georgia},
series = {ACM SE '14}
}

@inbook{10.1109/CGO51591.2021.9370317,
author = {Yuan, Ting and Li, Guangwei and Lu, Jie and Liu, Chen and Li, Lian and Xue, Jingling},
title = {GoBench: A Benchmark Suite of Real-World Go Concurrency Bugs},
year = {2021},
isbn = {9781728186139},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CGO51591.2021.9370317},
abstract = {Go, a fast growing programming language, is often considered as "the programming language of the cloud". The language provides a rich set of synchronization primitives, making it easy to write concurrent programs with great parallelism. However, the rich set of primitives also introduces many bugs.We build GoBench, the first benchmark suite for Go concurrency bugs. Currently, GoBench consists of 82 real bugs from 9 popular open source applications and 103 bug kernels. The bug kernels are carefully extracted and simplified from 67 out of these 82 bugs and 36 additional bugs reported in a recent study to preserve their bug-inducing complexities as much as possible. These bugs cover a variety of concurrency issues, both traditional and Go-specific. We believe GoBench will be instrumental in helping researchers understand concurrency bugs in Go and develop effective tools for their detection. We have therefore evaluated a range of representative concurrency error detection tools using GoBench. Our evaluation has revealed their limitations and provided insights for making further improvements.},
booktitle = {Proceedings of the 2021 IEEE/ACM International Symposium on Code Generation and Optimization},
pages = {187–199},
numpages = {13}
}

@inproceedings{10.1145/2593501.2593503,
author = {Guo, Chenkai and Xu, Jing and Yang, Hongji and Zeng, Ying and Xing, Shuang},
title = {An Automated Testing Approach for Inter-Application Security in Android},
year = {2014},
isbn = {9781450328586},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593501.2593503},
doi = {10.1145/2593501.2593503},
abstract = { Recently, Google Android has occupied a major market share of mobile phone systems as a result of its openness for developers and richness for users. By the distribution channels of the Android market, both development and use of Android applications soar. However, the low development threshold of applications leads to weak security awareness of developers. Moreover, Android applications lack strict security standards, resulting that security crisis has become increasingly prominent. For now, an application's biggest security threat falls on its messaging mechanism between components. Once permission’s verification is neglected, it is easy to be exploited by attackers, causing immeasurable loss. We analyze the security mechanism of Android inter-application components, and accordingly construct the security rules. Specifically, a compositional approach including static and dynamic automated testing techniques is proposed to detect the security vulnerabilities caused by messaging between components. In our approach, the static part obtains rough results and some parameter information. After that, the dynamic part automatically generates attack cases for verifying these results. This approach can be used not only to discover potential weaknesses within inter-application components but also to automatically simulate attack behaviors. Thereby, the detection results’ effectiveness can be verified. },
booktitle = {Proceedings of the 9th International Workshop on Automation of Software Test},
pages = {8–14},
numpages = {7},
keywords = {mobile phone security, Android, automated testing},
location = {Hyderabad, India},
series = {AST 2014}
}

@article{10.1145/3483424,
author = {Notaro, Paolo and Cardoso, Jorge and Gerndt, Michael},
title = {A Survey of AIOps Methods for Failure Management},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3483424},
doi = {10.1145/3483424},
abstract = {Modern society is increasingly moving toward complex and distributed computing systems. The increase in scale and complexity of these systems challenges O&amp;M teams that perform daily monitoring and repair operations, in contrast with the increasing demand for reliability and scalability of modern applications. For this reason, the study of automated and intelligent monitoring systems has recently sparked much interest across applied IT industry and academia. Artificial Intelligence for IT Operations (AIOps) has been proposed to tackle modern IT administration challenges thanks to Machine Learning, AI, and Big Data. However, AIOps as a research topic is still largely unstructured and unexplored, due to missing conventions in categorizing contributions for their data requirements, target goals, and components. In this work, we focus on AIOps for Failure Management (FM), characterizing and describing 5 different categories and 14 subcategories of contributions, based on their time intervention window and the target problem being solved. We review 100 FM solutions, focusing on applicability requirements and the quantitative results achieved, to facilitate an effective application of AIOps solutions. Finally, we discuss current development problems in the areas covered by AIOps and delineate possible future trends for AI-based failure management.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {nov},
articleno = {81},
numpages = {45},
keywords = {failure management, IT operations and maintenance, AIOps, artificial intelligence}
}

@inproceedings{10.1145/1081870.1081969,
author = {Jeske, Daniel R. and Samadi, Behrokh and Lin, Pengyue J. and Ye, Lan and Cox, Sean and Xiao, Rui and Younglove, Ted and Ly, Minh and Holt, Douglas and Rich, Ryan},
title = {Generation of Synthetic Data Sets for Evaluating the Accuracy of Knowledge Discovery Systems},
year = {2005},
isbn = {159593135X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1081870.1081969},
doi = {10.1145/1081870.1081969},
abstract = {Information Discovery and Analysis Systems (IDAS) are designed to correlate multiple sources of data and use data mining techniques to identify potential significant events. Application domains for IDAS are numerous and include the emerging area of homeland security.Developing test cases for an IDAS requires background data sets into which hypothetical future scenarios can be overlaid. The IDAS can then be measured in terms of false positive and false negative error rates. Obtaining the test data sets can be an obstacle due to both privacy issues and also the time and cost associated with collecting a diverse set of data sources.In this paper, we give an overview of the design and architecture of an IDAS Data Set Generator (IDSG) that enables a fast and comprehensive test of an IDAS. The IDSG generates data using statistical and rule-based algorithms and also semantic graphs that represent interdependencies between attributes. A credit card transaction application is used to illustrate the approach.},
booktitle = {Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining},
pages = {756–762},
numpages = {7},
keywords = {information discovery, data generation, data mining},
location = {Chicago, Illinois, USA},
series = {KDD '05}
}

@inproceedings{10.1145/2961111.2962584,
author = {Wang, Junjie and Cui, Qiang and Wang, Qing and Wang, Song},
title = {Towards Effectively Test Report Classification to Assist Crowdsourced Testing},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962584},
doi = {10.1145/2961111.2962584},
abstract = {Context: Automatic classification of crowdsourced test reports is important due to their tremendous sizes and large proportion of noises. Most existing approaches towards this problem focus on examining the performance of different machine learning or information retrieval techniques, and most are evaluated on open source dataset. However, our observation reveals that these approaches generate poor and unstable performances on real industrial crowdsourced testing data. We further analyze the deep reason and find that industrial data have significant local bias, which degrades existing approaches.Goal: We aim at designing an approach to overcome the local bias in industrial data and automatically classifying true fault from the large amounts of crowdsourced reports.Method: We propose a cluster-based classification approach, which first clusters similar reports together and then builds classifiers based on most similar clusters with ensemble method.Results: Evaluation is conducted on 15,095 test reports of 35 industrial projects from Chinese largest crowdsourced testing platform and results are promising, with 0.89 precision and 0.97 recall on average. In addition, our approach improves the existing baselines by 17% - 63% in average precision and 15% - 61% in average recall.Conclusions: Results imply that our approach can effectively discriminate true fault from large amounts of crowdsourced reports, which can reduce the effort required for manual inspection and facilitate project management in crowdsourced testing. To the best of our knowledge, this is the first work to address the test report classification problem in real industrial crowdsourced testing practice.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {6},
numpages = {10},
keywords = {Crowdsourced testing, Cluster, Report classification},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@article{10.1145/1668862.1668863,
author = {Alvaro, Alexandre and Santana de Almeida, Eduardo and Romero de Lemos Meira, Silvio},
title = {A Software Component Quality Framework},
year = {2010},
issue_date = {January 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/1668862.1668863},
doi = {10.1145/1668862.1668863},
abstract = {One of the major problems with Component-Based Software Engineering (CBSE) is the quality of the components used in a system. The reliability of a component-based software system depends on the reliability of the components that is made of. In CBSE, the proper search, selection and evaluation process of components is considered the cornerstone for the development of any effective component-based system. So far the software industry was concentrated on the functional aspects of components, leaving aside the difficult task of assessing their quality. In this way, we propose a software component quality framework to evaluate the quality of software components in an efficient way. Moreover, an experimental study was accomplished in order to evaluate the viability of the proposed framework.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {1–18},
numpages = {18}
}

@article{10.1145/2631685,
author = {Qiu, Dong and Li, Bixin and Ji, Shunhui and Leung, Hareton},
title = {Regression Testing of Web Service: A Systematic Mapping Study},
year = {2014},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/2631685},
doi = {10.1145/2631685},
abstract = {Web service is a widely used implementation technique under the paradigm of Service-Oriented Architecture (SOA). A service-based system is subjected to continuous evolution and regression testing is required to check whether new faults have been introduced. Based on the current scientific work of web service regression testing, this survey aims to identify gaps in current research and suggests some promising areas for further study. To this end, we performed a broad automatic search on publications in the selected electronic databases published from 2000 to 2013. Through our careful review and manual screening, a total of 30 papers have been selected as primary studies for answering our research questions. We presented a qualitative analysis of the findings, including stakeholders, challenges, standards, techniques, and validations employed in these primary studies. Our main results include the following: (1) Service integrator is the key stakeholder that largely impacts how regression testing is performed. (2) Challenges of cost and autonomy issues have been studied heavily. However, more emphasis should be put on the other challenges, such as test timing, dynamics, privacy, quota constraints, and concurrency issues. (3) Orchestration-based services have been largely studied, while little attention has been paid to either choreography-based services or semantic-based services. (4) An appreciable amount of web service regression testing techniques have been proposed, including 48 test case prioritization techniques, 10 test selection techniques, two test suite minimization techniques, and another collaborative technique. (5) Many regression test techniques have not been theoretically proven or experimentally analyzed, which limits their application in large-scale systems. We believe that our survey has identified gaps in current research work and reveals new insights for the future work.},
journal = {ACM Comput. Surv.},
month = {aug},
articleno = {21},
numpages = {46},
keywords = {test case prioritization, Regression testing, test suite minimization, test case selection, web service}
}

@article{10.1145/3428279,
author = {Rigger, Manuel and Su, Zhendong},
title = {Finding Bugs in Database Systems via Query Partitioning},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428279},
doi = {10.1145/3428279},
abstract = {Logic bugs in Database Management Systems (DBMSs) are bugs that cause an incorrect result for a given query, for example, by omitting a row that should be fetched. These bugs are critical, since they are likely to go unnoticed by users. We propose Query Partitioning, a general and effective approach for finding logic bugs in DBMSs. The core idea of Query Partitioning is to, starting from a given original query, derive multiple, more complex queries (called partitioning queries), each of which computes a partition of the result. The individual partitions are then composed to compute a result set that must be equivalent to the original query's result set. A bug in the DBMS is detected when these result sets differ. Our intuition is that due to the increased complexity, the partitioning queries are more likely to stress the DBMS and trigger a logic bug than the original query. As a concrete instance of a partitioning strategy, we propose Ternary Logic Partitioning (TLP), which is based on the observation that a boolean predicate p can either evaluate to TRUE, FALSE, or NULL. Accordingly, a query can be decomposed into three partitioning queries, each of which computes its result on rows or intermediate results for which p, NOT p, and p IS NULL hold. This technique is versatile, and can be used to test WHERE, GROUP BY, as well as HAVING clauses, aggregate functions, and DISTINCT queries. As part of an extensive testing campaign, we found 175 bugs in widely-used DBMSs such as MySQL, TiDB, SQLite, and CockroachDB, 125 of which have been fixed. Notably, 77 of these were logic bugs, while the remaining were error and crash bugs. We expect that the effectiveness and wide applicability of Query Partitioning will lead to its broad adoption in practice, and the formulation of additional partitioning strategies.},
journal = {Proc. ACM Program. Lang.},
month = {nov},
articleno = {211},
numpages = {30},
keywords = {three-valued logic, database testing, DBMS testing, test oracle}
}

@inproceedings{10.1145/3453483.3454079,
author = {Morihata, Akimasa and Sato, Shigeyuki},
title = {Reverse Engineering for Reduction Parallelization via Semiring Polynomials},
year = {2021},
isbn = {9781450383912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453483.3454079},
doi = {10.1145/3453483.3454079},
abstract = {Parallel reduction, which summarizes a given dataset, e.g., the total, average, and maximum, plays a crucial role in parallel programming. This paper presents a new approach, reverse engineering, to automatically discovering nontrivial parallel reductions in sequential programs. The body of the sequential reduction loop is regarded as a black box, and its input-output behaviors are sampled. If the behaviors correspond to a set of linear polynomials over a semiring, a divide-and-conquer parallel reduction is generated. Auxiliary reverse-engineering methods enable a long and nested loop body to be decomposed, which makes our parallelization scheme applicable to various types of reduction loops. This approach is not only simple and efficient but also agnostic to the details of the input program. Its potential is demonstrated through several use case scenarios. A proof-of-concept implementation successfully inferred linear polynomials for nearly all of the 74 benchmarks exhaustively collected from the literature. These characteristics and experimental results demonstrate the promise of the proposed approach, despite its inherent unsoundness.},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {820–834},
numpages = {15},
keywords = {reverse engineering, reduction loop, program synthesis, parallelization, semiring},
location = {Virtual, Canada},
series = {PLDI 2021}
}

@inproceedings{10.1145/3180155.3180175,
author = {Beller, Moritz and Spruit, Niels and Spinellis, Diomidis and Zaidman, Andy},
title = {On the Dichotomy of Debugging Behavior among Programmers},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180175},
doi = {10.1145/3180155.3180175},
abstract = {Debugging is an inevitable activity in most software projects, often difficult and more time-consuming than expected, giving it the nickname the "dirty little secret of computer science." Surprisingly, we have little knowledge on how software engineers debug software problems in the real world, whether they use dedicated debugging tools, and how knowledgeable they are about debugging. This study aims to shed light on these aspects by following a mixed-methods research approach. We conduct an online survey capturing how 176 developers reflect on debugging. We augment this subjective survey data with objective observations on how 458 developers use the debugger included in their integrated development environments (IDEs) by instrumenting the popular Eclipse and IntelliJ IDEs with the purpose-built plugin WatchDog 2.0. To clarify the insights and discrepancies observed in the previous steps, we followed up by conducting interviews with debugging experts and regular debugging users. Our results indicate that IDE-provided debuggers are not used as often as expected, as "printf debugging" remains a feasible choice for many programmers. Furthermore, both knowledge and use of advanced debugging features are low. These results call to strengthen hands-on debugging experience in computer science curricula and have already refined the implementation of modern IDE debuggers.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {572–583},
numpages = {12},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

