@inproceedings{10.1145/2970276.2970300,
author = {Wang, Junjie and Wang, Song and Cui, Qiang and Wang, Qing},
title = {Local-Based Active Classification of Test Report to Assist Crowdsourced Testing},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970300},
doi = {10.1145/2970276.2970300},
abstract = { In crowdsourced testing, an important task is to identify the test reports that actually reveal fault - true fault, from the large number of test reports submitted by crowd workers. Most existing approaches towards this problem utilized supervised machine learning techniques, which often require users to manually label a large amount of training data. Such process is time-consuming and labor-intensive. Thus, reducing the onerous burden of manual labeling while still being able to achieve good performance is crucial. Active learning is one potential technique to address this challenge, which aims at training a good classifier with as few labeled data as possible. Nevertheless, our observation on real industrial data reveals that existing active learning approaches generate poor and unstable performances on crowdsourced testing data. We analyze the deep reason and find that the dataset has significant local biases. To address the above problems, we propose LOcal-based Active ClassiFication (LOAF) to classify true fault from crowdsourced test reports. LOAF recommends a small portion of instances which are most informative within local neighborhood, and asks user their labels, then learns classifiers based on local neighborhood. Our evaluation on 14,609 test reports of 34 commercial projects from one of the Chinese largest crowdsourced testing platforms shows that our proposed LOAF can generate promising results. In addition, its performance is even better than existing supervised learning approaches which built on large amounts of labelled historical data. Moreover, we also implement our approach and evaluate its usefulness using real-world case studies. The feedbacks from testers demonstrate its practical value. },
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {190–201},
numpages = {12},
keywords = {Crowdsourced Testing, Active Learning, Test Report Classification},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@article{10.1145/1568613.1568620,
author = {Elliott, Chip and Falk, Aaron},
title = {An Update on the GENI Project},
year = {2009},
issue_date = {July 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {0146-4833},
url = {https://doi.org/10.1145/1568613.1568620},
doi = {10.1145/1568613.1568620},
abstract = {Environment for Network Innovations. Early prototypes of GENI are starting to come online as an end-to-end system and network researchers are invited to participate by engaging in the design process or using GENI to conduct experiments.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {jun},
pages = {28–34},
numpages = {7},
keywords = {prototyping, testbed, experimental research, network science and}
}

@inproceedings{10.1145/2950290.2950308,
author = {Hanam, Quinn and Brito, Fernando S. de M. and Mesbah, Ali},
title = {Discovering Bug Patterns in JavaScript},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2950308},
doi = {10.1145/2950290.2950308},
abstract = { JavaScript has become the most popular language used by developers for client and server side programming. The language, however, still lacks proper support in the form of warnings about potential bugs in the code. Most bug finding tools in use today cover bug patterns that are discovered by reading best practices or through developer intuition and anecdotal observation. As such, it is still unclear which bugs happen frequently in practice and which are important for developers to be fixed. We propose a novel semi-automatic technique, called BugAID, for discovering the most prevalent and detectable bug patterns. BugAID is based on unsupervised machine learning using language-construct-based changes distilled from AST differencing of bug fixes in the code. We present a large-scale study of common bug patterns by mining 105K commits from 134 server-side JavaScript projects. We discover 219 bug fixing change types and discuss 13 pervasive bug patterns that occur across multiple projects and can likely be prevented with better tool support. Our findings are useful for improving tools and techniques to prevent common bugs in JavaScript, guiding tool integration for IDEs, and making developers aware of common mistakes involved with programming in JavaScript. },
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {144–156},
numpages = {13},
keywords = {Node.js, JavaScript, data mining, Bug patterns, static analysis},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/3180155.3180166,
author = {Cha, Sooyoung and Hong, Seongjoon and Lee, Junhee and Oh, Hakjoo},
title = {Automatically Generating Search Heuristics for Concolic Testing},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180166},
doi = {10.1145/3180155.3180166},
abstract = {We present a technique to automatically generate search heuristics for concolic testing. A key challenge in concolic testing is how to effectively explore the program's execution paths to achieve high code coverage in a limited time budget. Concolic testing employs a search heuristic to address this challenge, which favors exploring particular types of paths that are most likely to maximize the final coverage. However, manually designing a good search heuristic is nontrivial and typically ends up with suboptimal and unstable outcomes. The goal of this paper is to overcome this shortcoming of concolic testing by automatically generating search heuristics. We define a class of search heuristics, namely a parameterized heuristic, and present an algorithm that efficiently finds an optimal heuristic for each subject program. Experimental results with open-source C programs show that our technique successfully generates search heuristics that significantly outperform existing manually-crafted heuristics in terms of branch coverage and bug-finding.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1244–1254},
numpages = {11},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1145/1995376.1995394,
author = {De Moura, Leonardo and Bj\o{}rner, Nikolaj},
title = {Satisfiability modulo Theories: Introduction and Applications},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/1995376.1995394},
doi = {10.1145/1995376.1995394},
abstract = {Checking the satisfiability of logical formulas, SMT solvers scale orders of magnitude beyond custom ad hoc solvers.},
journal = {Commun. ACM},
month = {sep},
pages = {69–77},
numpages = {9}
}

@inproceedings{10.1145/3338906.3338964,
author = {Cha, Sooyoung and Oh, Hakjoo},
title = {Concolic Testing with Adaptively Changing Search Heuristics},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338964},
doi = {10.1145/3338906.3338964},
abstract = {We present Chameleon, a new approach for adaptively changing search heuristics during concolic testing. Search heuristics play a central role in concolic testing as they mitigate the path-explosion problem by focusing on particular program paths that are likely to increase code coverage as quickly as possible. A variety of techniques for search heuristics have been proposed over the past decade. However, existing approaches are limited in that they use the same search heuristics throughout the entire testing process, which is inherently insufficient to exercise various execution paths. Chameleon overcomes this limitation by adapting search heuristics on the fly via an algorithm that learns new search heuristics based on the knowledge accumulated during concolic testing. Experimental results show that the transition from the traditional non-adaptive approaches to ours greatly improves the practicality of concolic testing in terms of both code coverage and bug-finding.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {235–245},
numpages = {11},
keywords = {Dynamic Symbolic Execution, Concolic Testing, Online Learning},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1145/2557833.2560578,
author = {Kausler, Scott and Sherman, Elena},
title = {User-Defined Backtracking Criteria for Symbolic Execution},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2557833.2560578},
doi = {10.1145/2557833.2560578},
abstract = {Symbolic execution is a path-sensitive program analysis technique that aids users with program verification. To avoid exploring infeasible paths, symbolic execution checks the prefix of a current path for feasibility by adding a branch constraint to the path prefix and passing the formula to an off-the-shelf SMT solver for an evaluation. If the solver returns SAT/UNSAT, then the prefix is marked as feasible/infeasible.However, the solver can also return an UNKNOWN result, which means it cannot evaluate the formula. In addition, an operation occurring before a constraint can cause over-approximation that propagates to the solver's result. Moreover, symbolic execution might time out the solver if it takes too long to run. A symbolic execution tool might handle these uncertainties by backtracking or by continuing its exploration of the prefix.This paper examines the behavior of path constraints beyond uncertain backtracking points. String and integer constraints are collected from concrete program execution via dynamic symbolic execution. These constraints are used to analyze how over- approximation in a path prefix affects the completeness of its extensions. We also examine variations in time required to decide a path constraint. Our findings suggest that a custom backtracking criteria defined by the user does improve the completeness of symbolic execution.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {feb},
pages = {1–5},
numpages = {5},
keywords = {constraint analysis, constraint solving, symbolic execution}
}

@inproceedings{10.1145/3341069.3341070,
author = {Xu, Hefang and Su, Caihong and Wu, Shaoyu and Tang, Dongping},
title = {Survey of Testing Methods of O2O Catering Platform},
year = {2019},
isbn = {9781450371858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341069.3341070},
doi = {10.1145/3341069.3341070},
abstract = {The particularity of the Web application of catering O2O platform makes its testing challenging, but the current research on its testing is relatively weak compared with the research on its design and development.This paper summarizes the research progress of Web platform testing methods in recent years.The Basic test contents and technologies, typical test models and automated testing tools of existing platforms are summarized.The current research hotspots and difficulties are analyzed, including the optimization of test models, the improvement and development of automated testing tools, the guarantee of test comprehensiveness, safety, stability and efficiency.Finally, the future research directions of the testing methods of catering O2O Web platform are discussed from three aspects: testing content, testing methods and testing tools.},
booktitle = {Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference},
pages = {220–224},
numpages = {5},
keywords = {Automated Testing Tools, Testing methods, Catering O2O platform},
location = {Guangzhou, China},
series = {HPCCT 2019}
}

@inproceedings{10.1145/2020390.2020392,
author = {Bell, Robert M. and Ostrand, Thomas J. and Weyuker, Elaine J.},
title = {Does Measuring Code Change Improve Fault Prediction?},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020392},
doi = {10.1145/2020390.2020392},
abstract = {Background: Several studies have examined code churn as a variable for predicting faults in large software systems. High churn is usually associated with more faults appearing in code that has been changed frequently.Aims: We investigate the extent to which faults can be predicted by the degree of churn alone, whether other code characteristics occur together with churn, and which combinations of churn and other characteristics provide the best predictions. We also investigate different types of churn, including both additions to and deletions from code, as well as overall amount of change to code.Method: We have mined the version control database of a large software system to collect churn and other software measures from 18 successive releases of the system. We examine the frequency of faults plotted against various code characteristics, and evaluate a diverse set of prediction models based on many different combinations of independent variables, including both absolute and relative churn.Results: Churn measures based on counts of lines added, deleted, and modified are very effective for fault prediction. Individually, counts of adds and modifications outperform counts of deletes, while the sum of all three counts was most effective. However, these counts did not improve prediction accuracy relative to a model that included a simple count of the number of times that a file had been changed in the prior release.Conclusions: Including a measure of change in the prior release is an essential component of our fault prediction method. Various measures seem to work roughly equivalently.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {2},
numpages = {8},
keywords = {code churn, software faults, fault prediction, fault-percentile average, empirical study},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@inproceedings{10.1145/3519939.3523457,
author = {Polito, Guillermo and Ducasse, St\'{e}phane and Tesone, Pablo},
title = {Interpreter-Guided Differential JIT Compiler Unit Testing},
year = {2022},
isbn = {9781450392655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3519939.3523457},
doi = {10.1145/3519939.3523457},
abstract = {Modern language implementations using Virtual Machines feature diverse execution engines such as byte-code interpreters and machine-code dynamic translators, a.k.a. JIT compilers. Validating such engines requires not only validating each in isolation, but also that they are functionally equivalent. Tests should be duplicated for each execution engine, exercising the same execution paths on each of them.  

In this paper, we present a novel automated testing ap- proach for virtual machines featuring byte-code interpreters. Our solution uses concolic meta-interpretation: it applies concolic testing to a byte-code interpreter to explore all pos- sible execution interpreter paths and obtain a list of concrete values that explore such paths. We then use such values to apply differential testing on the VM interpreter and JIT compiler. This solution is based on two insights: (1) both the interpreter and compiler implement the same language semantics and (2) interpreters are simple executable specifications of those semantics and thus promising targets to (meta-) interpretation using concolic testing. We validated it on 4 different compilers of the open-source Pharo Virtual Machine and found 468 differences between them, produced by 91 different causes, organized in 6 different categories.},
booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {981–992},
numpages = {12},
keywords = {interpreters, virtual machine, JIT compilers, concolic testing},
location = {San Diego, CA, USA},
series = {PLDI 2022}
}

@inproceedings{10.1145/2889160.2889239,
author = {Salvaneschi, Paolo},
title = {System Testing of Repository-Style Software: An Experience Report},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889239},
doi = {10.1145/2889160.2889239},
abstract = {System testing based on a black box approach is a common industrial practice in information systems. Despite its widespread use, however, little guidance is available for testing engineers facing the problem of selecting the best test strategy. In previous work, we proposed to adopt functional models and related testing patterns according to the architectural style of the application under test. In this paper, we present an industrial study that applies this technique to system testing of repository based applications.We define a set of functional models abstracting different concerns of software applications: hierarchy of functions, business processes and states/transitions of application objects. The models are used to derive the functional test cases through the definition of test patterns. We applied this approach in an industrial context for over 5 years.In this paper, we analyze a data set of 37 test projects including about 22000 test cases and 1500 failures. We relate failures to the originating defect types. The study confirms that a system test strategy that uses multiple functional models according to the architectural style of the software application generates a better cost/benefit ratio than the use of just one model. The explanation is that -- despite a small overlap -- each model detects specific types of software defects. The results of the study can guide testing engineers in selecting the best system test strategy and significantly improve the efficiency of their work.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {172–181},
numpages = {10},
keywords = {software defects, system test, multiple models},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00049,
author = {Zhu, Junjie and Long, Teng and Memon, Atif},
title = {Automatically Authoring Regression Tests for Machine-Learning Based Systems},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00049},
doi = {10.1109/ICSE-SEIP52600.2021.00049},
abstract = {Two key design characteristics of machine learning (ML) systems---their ever-improving nature, and learning-based emergent functional behavior---create a moving target, posing new challenges for authoring/maintaining functional regression tests. We identify four specific challenges and address them by developing a new general methodology to automatically author and maintain tests. In particular, we use the volume of production data to periodically refresh our large corpus of test inputs and expected outputs; we use perturbation of the data to obtain coverage-adequate tests; and we use clustering to help identify patterns of failures that are indicative of software bugs. We demonstrate our methodology on an ML-based context-aware Speller. Our coverage-adequate, approx. 1 million regression test cases, automatically authored and maintained for Speller (1) are virtually maintenance free, (2) detect a higher number of Speller failures than previous manually-curated tests, (3) have better coverage of previously unknown functional boundaries of the ML component, and (4) lend themselves to automatic failure triaging by clustering and prioritizing subcategories of tests with over-represented failures. We identify several systematic failure patterns which were due to previously undetected bugs in the Speller, e.g., (1) when the user misses the first letter in a short word, and (2) when the user mistakenly inserts a character in the last token of an address; these have since been fixed.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {374–383},
numpages = {10},
keywords = {ML-based testing, ML testing, spelling correction},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@inbook{10.1145/3468264.3468544,
author = {Zhu, Qihao and Sun, Zeyu and Xiao, Yuan-an and Zhang, Wenjie and Yuan, Kang and Xiong, Yingfei and Zhang, Lu},
title = {A Syntax-Guided Edit Decoder for Neural Program Repair},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468544},
abstract = {Automated Program Repair (APR) helps improve the efficiency of software development and maintenance. Recent APR techniques use deep learning, particularly the encoder-decoder architecture, to generate patches. Though existing DL-based APR approaches have proposed different encoder architectures, the decoder remains to be the standard one, which generates a sequence of tokens one by one to replace the faulty statement. This decoder has multiple limitations: 1) allowing to generate syntactically incorrect programs, 2) inefficiently representing small edits, and 3) not being able to generate project-specific identifiers.  In this paper, we propose Recoder, a syntax-guided edit decoder with placeholder generation. Recoder is novel in multiple aspects: 1) Recoder generates edits rather than modified code, allowing efficient representation of small edits; 2) Recoder is syntax-guided, with the novel provider/decider architecture to ensure the syntactic correctness of the patched program and accurate generation; 3) Recoder generates placeholders that could be instantiated as project-specific identifiers later.  We conduct experiments to evaluate Recoder on 395 bugs from Defects4J v1.2, 420 additional bugs from Defects4J v2.0, 297 bugs from IntroClassJava and 40 bugs from QuixBugs. Our results show that Recoder repairs 53 bugs on Defects4J v1.2, which achieves 26.2% (11 bugs) improvement over the previous state-of-the-art approach for single-hunk bugs (TBar). Importantly, to our knowledge, Recoder is the first DL-based APR approach that has outperformed the traditional APR approaches on this benchmark. Furthermore, Recoder repairs 19 bugs on the additional bugs from Defects4J v2.0, which is 137.5% (11 bugs) more than TBar and 850% (17 bugs) more than SimFix. Recoder also achieves 775% (31 bugs) and 30.8% (4 bugs) improvement on IntroClassJava and QuixBugs over the baselines respectively. These results suggest that Recoder has better generalizability than existing APR approaches.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {341–353},
numpages = {13}
}

@inproceedings{10.1109/ICPC.2017.5,
author = {Azadmanesh, Mohammad Reza and Hauswirth, Matthias and Van De Vanter, Michael L.},
title = {Language-Independent Information Flow Tracking Engine for Program Comprehension Tools},
year = {2017},
isbn = {9781538605356},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICPC.2017.5},
doi = {10.1109/ICPC.2017.5},
abstract = {Program comprehension tools are often developed for a specific programming language. Developing such a tool from scratch requires significant effort. In this paper, we report on our experience developing a language-independent framework that enables the creation of program comprehension tools, specifically tools gathering insight from deep dynamic analysis, with little effort. Our framework is language independent, because it is built on top of Truffle, an open-source platform, developed in Oracle Labs, for implementing dynamic languages in the form of AST interpreters. Our framework supports the creation of a diverse variety of program comprehension techniques, such as query, program slicing, and back-in-time debugging, because it is centered around a powerful information-flow tracking engine.Tools developed with our framework get access to the information-flow through a program execution. While it is possible to develop similarly powerful tools without our framework, for example by tracking information-flow through bytecode instrumentation, our approach leads to information that is closer to source code constructs, thus more comprehensible by the user.To demonstrate the effectiveness of our framework, we applied it to two of Truffle-based languages namely Simple Language and TruffleRuby, and we distill our experience into guidelines for developers of other Truffle-based languages who want to develop program comprehension tools for their language.},
booktitle = {Proceedings of the 25th International Conference on Program Comprehension},
pages = {346–355},
numpages = {10},
location = {Buenos Aires, Argentina},
series = {ICPC '17}
}

@article{10.1145/1921532.1921559,
author = {Aichernig, Bernhard K. and Brandl, Harald and J\"{o}bstl, Elisabeth and Krenn, Willibald},
title = {UML in Action: A Two-Layered Interpretation for Testing},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/1921532.1921559},
doi = {10.1145/1921532.1921559},
abstract = {This paper presents a novel model-based test case generation approach that automatically derives test cases from UML state machines. UML is given a two-layered formal semantics by (1) mapping UML class diagrams and state charts to Back's Action Systems, (2) by interpreting these action systems as labeled transition systems. The first semantics provides a formal framework to capture the object-oriented machinery: classes, objects, inheritance, transitions, time-outs, signals, nested and parallel regions. The second mapping represents the tester's view on the interface in terms of input and output actions. Tretman's input-output conformance relation (ioco) forms the basis of our fault models. Mutation analysis on the models is used to generate test cases. A car alarm system serves as a running example},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {1–8},
numpages = {8}
}

@inproceedings{10.1145/2647908.2655980,
author = {Samih, Hamza and Bogusch, Ralf},
title = {MPLM - MaTeLo Product Line Manager: [Relating Variability Modelling and Model-Based Testing]},
year = {2014},
isbn = {9781450327398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2647908.2655980},
doi = {10.1145/2647908.2655980},
abstract = {The diversity of requirements elicited from different customers leads to the development of many variants. Furthermore, compliance with safety standards as mandated for safety-critical systems requires high test efforts for each variant. Model-based testing aims to reduce test efforts by automatically generating test cases from test models.In this paper, we introduce variability management to usage models, a widely used model-based testing formalism. We present an approach that allows to derive usage model variants from a desired set of features and thus generate test cases for each variant. The approach is integrated in the industrial model-based testing tool chain MaTeLo and exemplified using an industrial case study from the aerospace domain.},
booktitle = {Proceedings of the 18th International Software Product Line Conference: Companion Volume for Workshops, Demonstrations and Tools - Volume 2},
pages = {138–142},
numpages = {5},
keywords = {OVM, MaTeLo, model-based testing, product line engineering, variability, feature, product line requirements, usage model variant, variant, model-based testing tool, product line manager, variability model, product line usage model},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2970276.2970311,
author = {Ben Abdessalem, Raja and Nejati, Shiva and Briand, Lionel C. and Stifter, Thomas},
title = {Testing Advanced Driver Assistance Systems Using Multi-Objective Search and Neural Networks},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970311},
doi = {10.1145/2970276.2970311},
abstract = { Recent years have seen a proliferation of complex Advanced Driver Assistance Systems (ADAS), in particular, for use in autonomous cars. These systems consist of sensors and cameras as well as image processing and decision support software components. They are meant to help drivers by providing proper warnings or by preventing dangerous situations. In this paper, we focus on the problem of design time testing of ADAS in a simulated environment. We provide a testing approach for ADAS by combining multi-objective search with surrogate models developed based on neural networks. We use multi-objective search to guide testing towards the most critical behaviors of ADAS. Surrogate modeling enables our testing approach to explore a larger part of the input search space within limited computational resources. We characterize the condition under which the multi-objective search algorithm behaves the same with and without surrogate modeling, thus showing the accuracy of our approach. We evaluate our approach by applying it to an industrial ADAS system. Our experiment shows that our approach automatically identifies test cases indicating critical ADAS behaviors. Further, we show that combining our search algorithm with surrogate modeling improves the quality of the generated test cases, especially under tight and realistic computational resources. },
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {63–74},
numpages = {12},
keywords = {Neural Networks, Advanced Driver Assistance Systems, Multi-Objective Search Optimization, Surrogate Modeling, Simulation},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@inproceedings{10.1145/2851613.2851686,
author = {Griffioen-Both, Fiemke and Spruit, Sandor and Fitrianie, Siska and Beun, Robbert Jan and Lancee, Jaap},
title = {Testing for Mobile E-Health Interventions},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851686},
doi = {10.1145/2851613.2851686},
abstract = {Evaluating interaction that spans several weeks, between a virtual coach and a human patient on a mobile behavior intervention is virtually impossible. Traditional laboratory-based user testing is too tedious and expensive, and allows only the testing of a limited amount of different scenarios. Ideally, the test results of a mobile behavior intervention application cover a clear understanding of: (i) different user models, (ii) adaptive behavior of the coach, and (iii) different levels abstraction from multiple stakeholder viewpoints. Towards this goal, we address challenges posed by the domain and devised an automated testing environment using a simulator that mimics the behavior of a patient during the process of behavior change based on scenarios. The simulation results, i.e. context sensitive user interaction (on the application) at different phases and stages of a six-week insomnia therapy, can be recorded and presented to stakeholders for the application quality assessment and analysis.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {137–142},
numpages = {6},
keywords = {mobile application testing, user simulations, e-health app testing},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1145/2728606.2728650,
author = {Nguyen, Luan Viet and Schilling, Christian and Bogomolov, Sergiy and Johnson, Taylor T.},
title = {HyRG: A Random Generation Tool for Affine Hybrid Automata},
year = {2015},
isbn = {9781450334334},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2728606.2728650},
doi = {10.1145/2728606.2728650},
abstract = {In this poster, we present methods for randomly generating hybrid automata with affine differential equations, invariants, guards, and assignments. Selecting an arbitrary affine function from the set of all affine functions results in a low likelihood of generating hybrid automata with diverse and interesting behaviors, as there are an uncountable number of elements in the set of all affine functions. Instead, we partition the set of all affine functions into potentially interesting classes and randomly select elements from these classes. For example, we partition the set of all affine differential equations by using restrictions on eigenvalues such as those that yield stable, unstable, etc. equilibrium points. We partition the components describing discrete behavior (guards, assignments, and invariants) to allow either time-dependent or state-dependent switching, and in particular provide the ability to generate subclasses of piecewise-affine hybrid automata. Our preliminary experimental results with a prototype tool called HyRG (Hybrid Random Generator) illustrate the feasibility of this generation method to automatically create standard hybrid automaton examples like the bouncing ball and thermostat.},
booktitle = {Proceedings of the 18th International Conference on Hybrid Systems: Computation and Control},
pages = {289–290},
numpages = {2},
keywords = {program generation, hybrid automata},
location = {Seattle, Washington},
series = {HSCC '15}
}

@inproceedings{10.1145/2351676.2351750,
author = {Hine, Cameron and Schneider, Jean-Guy and Han, Jun and Versteeg, Steve},
title = {Quokka: Visualising Interactions of Enterprise Software Environment Emulators},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351750},
doi = {10.1145/2351676.2351750},
abstract = { Enterprise software systems operate in large-scale, heterogeneous, distributed environments which makes assessment of non-functional properties, such as scalability and robustness, of those systems particularly challenging. Enterprise environment emulators can provide test-beds representative of real environments using only a few physical hosts thereby allowing assessment of the non-functional properties of enterprise software systems. To date, analysing outcomes of these tests has been an ad hoc and somewhat tedious affair; largely based on manual and/or script-assisted inspection of interaction logs. Quokka visualises emulations significantly aiding analysis and comprehension. Emulated interactions can be viewed live (in real-time) as well as be replayed at a later stage, furthermore, basic charts are used to aggregate and summarise emulations, helping to identify performance and scalability issues. },
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {370–373},
numpages = {4},
keywords = {Scalability, Visualisation, Enterprise Software Emulation, Service Virtualization},
location = {Essen, Germany},
series = {ASE 2012}
}

