@inproceedings{10.1145/568760.568763,
author = {Pedrycz, Witold},
title = {Computational Intelligence as an Emerging Paradigm of Software Engineering},
year = {2002},
isbn = {1581135564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/568760.568763},
doi = {10.1145/568760.568763},
abstract = {Software Engineering is inherently knowledge intensive. Software processes and products are human centered. The technology of Computational Intelligence (CI) intensively exploits various mechanisms of interaction with humans and processes domain knowledge with intent of building intelligent systems. As commonly perceived, CI dwells on three highly synergistic technologies of neural networks, fuzzy sets (or granular computing, in general) and evolutionary optimization. As the software complexity grows and the diversity of software systems skyrocket, it becomes apparent that there is a genuine need for a solid, efficient, designer-oriented vehicle to support software analysis, design, and implementation at various levels. The research agenda makes CI a highly compatible and appealing vehicle to address the needs of knowledge rich environment of Software Engineering. The objective of this study is to identify and discuss synergistic links emerging between Software Engineering and Computational Intelligence. We show how CI --- based models contribute to the methodology of constructing models of software processes and products. Several selected examples (including software cost estimation, quality, and software measures) are included.},
booktitle = {Proceedings of the 14th International Conference on Software Engineering and Knowledge Engineering},
pages = {7–14},
numpages = {8},
keywords = {uncertainty representation, data visualization, software quality, neural networks, genetic optimization, computational intelligence, synergy, granular computing},
location = {Ischia, Italy},
series = {SEKE '02}
}

@inproceedings{10.1145/237091.237111,
author = {Vander Zanden, Bradley T. and Venckus, Scott A.},
title = {An Empirical Study of Constraint Usage in Graphical Applications},
year = {1996},
isbn = {0897917987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/237091.237111},
doi = {10.1145/237091.237111},
booktitle = {Proceedings of the 9th Annual ACM Symposium on User Interface Software and Technology},
pages = {137–146},
numpages = {10},
keywords = {debugging, profiling, one-way constraints, graphical applications, toolkits, optimization},
location = {Seattle, Washington, USA},
series = {UIST '96}
}

@inproceedings{10.1145/3092282.3098206,
author = {Jasper, Marc and Fecke, Maximilian and Steffen, Bernhard and Schordan, Markus and Meijer, Jeroen and Pol, Jaco van de and Howar, Falk and Siegel, Stephen F.},
title = {The RERS 2017 Challenge and Workshop (Invited Paper)},
year = {2017},
isbn = {9781450350778},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3092282.3098206},
doi = {10.1145/3092282.3098206},
abstract = { RERS is an annual verification challenge that focuses on LTL and reachability properties of reactive systems. In 2017, RERS was extended to a one day workshop that in addition to the original challenge program also featured an invited talk about possible future developments. As a satellite of ISSTA and SPIN, the 2017 RERS Challenge itself increased emphasis on the parallel benchmark problems which, like their sequential counterparts, were generated using property-preserving transformations in order to scale their level of difficulty. The first half of the RERS workshop focused on the 2017 benchmark profiles, the evaluation of the received contributions, and short presentations of each participating team. The second half comprised discussions about attractive problem scenarios for future benchmarks, like race detection, the topic of the invited talk, and about systematic ways to leverage a tool's performance based on competition benchmarks and machine learning. },
booktitle = {Proceedings of the 24th ACM SIGSOFT International SPIN Symposium on Model Checking of Software},
pages = {11–20},
numpages = {10},
keywords = {race analysis, property-preservation, model checking, modal transition systems, verification, temporal logic, benchmark generation},
location = {Santa Barbara, CA, USA},
series = {SPIN 2017}
}

@inproceedings{10.1145/3064176.3064183,
author = {Fonseca, Pedro and Zhang, Kaiyuan and Wang, Xi and Krishnamurthy, Arvind},
title = {An Empirical Study on the Correctness of Formally Verified Distributed Systems},
year = {2017},
isbn = {9781450349383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3064176.3064183},
doi = {10.1145/3064176.3064183},
abstract = {Recent advances in formal verification techniques enabled the implementation of distributed systems with machine-checked proofs. While results are encouraging, the importance of distributed systems warrants a large scale evaluation of the results and verification practices.This paper thoroughly analyzes three state-of-the-art, formally verified implementations of distributed systems: Iron-Fleet, Verdi, and Chapar. Through code review and testing, we found a total of 16 bugs, many of which produce serious consequences, including crashing servers, returning incorrect results to clients, and invalidating verification guarantees. These bugs were caused by violations of a wide-range of assumptions on which the verified components relied. Our results revealed that these assumptions referred to a small fraction of the trusted computing base, mostly at the interface of verified and unverified components. Based on our observations, we have built a testing toolkit called PK, which focuses on testing these parts and is able to automate the detection of 13 (out of 16) bugs.},
booktitle = {Proceedings of the Twelfth European Conference on Computer Systems},
pages = {328–343},
numpages = {16},
location = {Belgrade, Serbia},
series = {EuroSys '17}
}

@article{10.1145/2909480,
author = {Beschastnikh, Ivan and Wang, Patty and Brun, Yuriy and Ernst, Michael D.},
title = {Debugging Distributed Systems},
year = {2016},
issue_date = {August 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {59},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/2909480},
doi = {10.1145/2909480},
abstract = {ShiViz is a new distributed system debugging visualization tool.},
journal = {Commun. ACM},
month = {jul},
pages = {32–37},
numpages = {6}
}

@inproceedings{10.1145/2899415.2899423,
author = {Tang, Terry and Smith, Rebecca and Rixner, Scott and Warren, Joe},
title = {Data-Driven Test Case Generation for Automated Programming Assessment},
year = {2016},
isbn = {9781450342315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2899415.2899423},
doi = {10.1145/2899415.2899423},
abstract = {Building high-quality test cases for programming problems is an important part of any well-built Automated Programming Assessment System. Traditionally, test cases are created by human experts or using machine auto-generation methods based on the problem definition and sample solutions. Unfortunately, the human approach can not anticipate the numerous ways that programmers can construct erroneous solutions. The machine auto-generation methods are complex, problem-specific, and time-consuming.This paper proposes a fast, simple method for generating high-quality test sets for a programming problem from an existing collection of student solutions for that problem. This paper demonstrates the effectiveness of the proposed method in online programming course assessments. The experiments showed that, when applied to large collections of such programs, the method produces concise, human-understandable test sets that provide better coverage than test sets built by experts with rich teaching experience.},
booktitle = {Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education},
pages = {260–265},
numpages = {6},
keywords = {data-driven, automatic test case generation, mooc, automated programming assessment system},
location = {Arequipa, Peru},
series = {ITiCSE '16}
}

@inbook{10.1145/3387940.3391460,
author = {Byun, Taejoon and Rayadurgam, Sanjai},
title = {Manifold-Based Test Generation for Image Classifiers},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391460},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {221},
numpages = {1}
}

@inproceedings{10.1109/IAT.2006.61,
author = {Bosse, Tibor and Lam, Dung N. and Barber, K. Suzanne},
title = {Empirical Analysis for Agent System Comprehension and Verification},
year = {2006},
isbn = {0769527485},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/IAT.2006.61},
doi = {10.1109/IAT.2006.61},
abstract = {Comprehending and verifying agent system behavior is an arduous task when dealing with complex multi-agent systems whose behaviors are sophisticated. This paper presents an approach resulting from collaboration between the Tracer Tool and the TTL Checker, which together automate the analysis and verification of an implemented system's behavior, with the aim of aiding the user in redesigning, debugging, and maintaining the agent system. The Tracer Tool ensures that the user's comprehension of the system behavior is accurate and provides explanations of anomalous behavior, which can be detected as a failed behavioral property by the TTL Checker. The integrated approach has been applied to an agent-based system in an Unmanned Aerial Vehicles domain.},
booktitle = {Proceedings of the IEEE/WIC/ACM International Conference on Intelligent Agent Technology},
pages = {723–729},
numpages = {7},
series = {IAT '06}
}

@inproceedings{10.1109/SC.2010.27,
author = {Chen, Zhezhe and Gao, Qi and Zhang, Wenbin and Qin, Feng},
title = {FlowChecker: Detecting Bugs in MPI Libraries via Message Flow Checking},
year = {2010},
isbn = {9781424475599},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SC.2010.27},
doi = {10.1109/SC.2010.27},
abstract = {Many MPI libraries have suffered from software bugs, which severely impact the productivity of a large number of users. This paper presents a new method called FlowChecker for detecting communication-related bugs inMPI libraries. The main idea is to extract program intentions of message passing (MPintentions), and to check whether theseMP-intentions are fulfilled correctly by the underlying MPI libraries, i.e., whether messages are delivered correctly from specified sources to specified destinations. If not, FlowChecker reports the bugs and provides diagnostic information. We have built a FlowChecker prototype on Linux and evaluated it with five real-world bug cases in three widely-used MPI libraries, including Open MPI, MPICH2, and MVAPICH2. Our experimental results show that FlowChecker effectively detects all five evaluated bug cases and provides useful diagnostic information. Additionally, our experiments with HPL and NPB show that FlowChecker incurs low runtime overhead (0.9-9.7% on three MPI libraries).},
booktitle = {Proceedings of the 2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis},
pages = {1–11},
numpages = {11},
series = {SC '10}
}

@inproceedings{10.1109/ICSE43902.2021.00137,
author = {Sotiropoulos, Thodoris and Chaliasos, Stefanos and Atlidakis, Vaggelis and Mitropoulos, Dimitris and Spinellis, Diomidis},
title = {Data-Oriented Differential Testing of Object-Relational Mapping Systems},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00137},
doi = {10.1109/ICSE43902.2021.00137},
abstract = {We introduce, what is to the best of our knowledge, the first approach for systematically testing Object-Relational Mapping (ORM) systems. Our approach leverages differential testing to establish a test oracle for ORM-specific bugs. Specifically, we first generate random relational database schemas, set up the respective databases, and then, we query these databases using the APIs of the ORM systems under test. To tackle the challenge that ORMs lack a common input language, we generate queries written in an abstract query language. These abstract queries are translated into concrete, executable ORM queries, which are ultimately used to differentially test the correctness of target implementations. The effectiveness of our method heavily relies on the data inserted to the underlying databases. Therefore, we employ a solver-based approach for producing targeted database records with respect to the constraints of the generated queries. We implement our approach as a tool, called CYNTHIA, which found 28 bugs in five popular ORM systems. The vast majority of these bugs are confirmed (25 / 28), more than half were fixed (20 / 28), and three were marked as release blockers by the corresponding developers.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1535–1547},
numpages = {13},
keywords = {Object-Relational Mapping, Automated Testing, Differential Testing},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1145/3309578.3309580,
author = {Shalamova, Nadya and Rice-Bailey, Tammy and Wikoff, Katherine},
title = {Evolving Skill Sets and Job Pathways of Technical Communicators},
year = {2019},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3309578.3309580},
doi = {10.1145/3309578.3309580},
abstract = {Recent research in technical communication (TC) indicates that the field has become more varied than ever in terms of job titles, job skills, and levels of involvement in the design and production process. Here, we examine this diversity by detailing the results of a small-scale anonymous survey of individuals who are currently working as technical communicators (TCs). The purpose of our survey was to discover what job titles people who identify as TCs have held and the skills required of those positions. The study was conducted using the online survey platform Qualtrics. Survey results found that TCs occupy jobs and use skills that are often quite different from "traditional" TC careers. Results further support previous research that these roles and responsibilities continue to evolve. However, results also suggest that this evolution is more sweeping than previously realized---moving TCs away from not only the traditional technical writing role but also the "technical communicator" role as it has been understood for the past 20--25 years.},
journal = {Commun. Des. Q. Rev},
month = {jan},
pages = {14–24},
numpages = {11},
keywords = {career paths, technical communication, skills, job titles}
}

@inproceedings{10.1145/3472883.3487016,
author = {Gulzar, Muhammad Ali and Kim, Miryung},
title = {OptDebug: Fault-Inducing Operation Isolation for Dataflow Applications},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3487016},
doi = {10.1145/3472883.3487016},
abstract = {Fault-isolation is extremely challenging in large scale data processing in cloud environments. Data provenance is a dominant existing approach to isolate data records responsible for a given output. However, data provenance concerns fault isolation only in the data-space, as opposed to fault isolation in the code-space---how can we precisely localize operations or APIs responsible for a given suspicious or incorrect result?We present OptDebug that identifies fault-inducing operations in a dataflow application using three insights. First, debugging is easier with a small-scale input than a large-scale input. So it uses data provenance to simplify the original input records to a smaller set leading to test failures and test successes. Second, keeping track of operation provenance is crucial for debugging. Thus, it leverages automated taint analysis to propagate the lineage of operations downstream with individual records. Lastly, each operation may contribute to test failures to a different degree. Thus OptDebug ranks each operation's spectra---the relative participation frequency in failing vs. passing tests. In our experiments, OptDebug achieves 100% recall and 86% precision in terms of detecting faulty operations and reduces the debugging time by 17x compared to a na\"{\i}ve approach. Overall, OptDebug shows great promise in improving developer productivity in today's complex data processing pipelines by obviating the need to re-execute the program repetitively with different inputs and manually examine program traces to isolate buggy code.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {359–372},
numpages = {14},
keywords = {data intensive scalable computing, debugging, bug isolation, taint analysis},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@inproceedings{10.1145/3321705.3329828,
author = {Chen, Yaohui and Mu, Dongliang and Xu, Jun and Sun, Zhichuang and Shen, Wenbo and Xing, Xinyu and Lu, Long and Mao, Bing},
title = {PTrix: Efficient Hardware-Assisted Fuzzing for COTS Binary},
year = {2019},
isbn = {9781450367523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3321705.3329828},
doi = {10.1145/3321705.3329828},
abstract = {Despite its effectiveness in uncovering software defects, American Fuzzy Lop (AFL), one of the best grey-box fuzzers, is inefficient when fuzz-testing source-unavailable programs. AFL's binary-only fuzzing mode, QEMU-AFL, is typically 2-5\texttimes{} slower than its source- available fuzzing mode. The slowdown is largely caused by the heavy dynamic instrumentation. Recent fuzzing techniques use Intel Processor Tracing (PT), a light-weight tracing feature supported by recent Intel CPUs, to re- move the need of dynamic instrumentation. However, we found that these PT-based fuzzing techniques are even slower than QEMU-AFL when fuzzing real-world programs, making them less effective than QEMU-AFL. This poor performance is caused by the slow extraction of code coverage information from highly compressed PT traces. In this work, we present the design and implementation of PTrix, which fully unleashes the benefits of PT for fuzzing via three novel techniques. First, PTrix introduces a scheme to highly parallel the processing of PT trace and target program execution. Second, it directly takes decoded PT trace as feedback for fuzzing, avoiding the expensive reconstruction of code coverage information. Third, PTrix maintains the new feedback with stronger feedback than edge-based code coverage, which helps reach new code space and defects that AFL may not. We evaluated PTrix by comparing its performance with the state- of-the-art fuzzers. Our results show that, given the same amount of time, PTrix achieves a significantly higher fuzzing speed and reaches into code regions missed by the other fuzzers. In addition, PTrix identifies 35 new vulnerabilities in a set of previously well- fuzzed binaries, showing its ability to complement existing fuzzers.},
booktitle = {Proceedings of the 2019 ACM Asia Conference on Computer and Communications Security},
pages = {633–645},
numpages = {13},
keywords = {Intel PT, fuzzing, path-sensitive},
location = {Auckland, New Zealand},
series = {Asia CCS '19}
}

@inproceedings{10.1145/3338906.3338956,
author = {Kalhauge, Christian Gram and Palsberg, Jens},
title = {Binary Reduction of Dependency Graphs},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338956},
doi = {10.1145/3338906.3338956},
abstract = {Delta debugging is a technique for reducing a failure-inducing input to a small input that reveals the cause of the failure. This has been successful for a wide variety of inputs including C programs, XML data, and thread schedules. However, for input that has many internal dependencies, delta debugging scales poorly. Such input includes C#, Java, and Java bytecode and they have presented a major challenge for input reduction until now. In this paper, we show that the core challenge is a reduction problem for dependency graphs, and we present a general strategy for reducing such graphs. We combine this with a novel algorithm for reduction called Binary Reduction in a tool called J-Reduce for Java bytecode. Our experiments show that our tool is 12x faster and achieves more reduction than delta debugging on average. This enabled us to create and submit short bug reports for three Java bytecode decompilers.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {556–566},
numpages = {11},
keywords = {reduction, dependencies, Debugging},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/1985793.1985975,
author = {Gu, Zhongxian and Barr, Earl T. and Su, Zhendong},
title = {BQL: Capturing and Reusing Debugging Knowledge},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985975},
doi = {10.1145/1985793.1985975},
abstract = {When fixing a bug, a programmer tends to search for similar bugs that have been resolved in the past. A fix for a similar bug may help him fix his bug or at least understand his bug. We designed and implemented the Bug Query Language (BQL) and its accompanying tools to help users search for similar bugs to aid debugging. This paper demonstrates the main features of the BQL infrastructure. We populated BQL with bugs collected from open-source projects and show that BQL could have helped users to fix real-world bugs.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {1001–1003},
numpages = {3},
keywords = {reusing debugging knowledge, bql},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.1145/2788993.2789841,
author = {Cullina, Eoin and Conboy, Kieran and Morgan, Lorraine},
title = {Measuring the Crowd: A Preliminary Taxonomy of Crowdsourcing Metrics},
year = {2015},
isbn = {9781450336666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2788993.2789841},
doi = {10.1145/2788993.2789841},
abstract = {Crowdsourcing initiatives benefit from tapping into diversity. A vast plethora of disparate individuals, organizations, frameworks and skillsets can all play a role in sourcing solutions to a challenge. Nevertheless, while crowdsourcing has become a pervasive phenomenon, there is a paucity of research that addresses how the crowdsourcing process is measured. Whereas research has advanced various taxonomies of crowdsourcing none to date have specifically addressed the issue of measuring either specific stages of the crowdsourcing process or the process as a whole. As a first step towards achieving this goal, this research-in-progress paper examines crowdsourcing at the operational level with a view towards (i) identifying the parts of the process (ii) identifying what can be measured and (iii) categorising operational metrics to facilitate deployment in practice. The taxonomy advanced is overarching in nature and can be deployed across disciplines. Furthermore, the preliminary taxonomy presented will offer practitioners a comprehensive list of metrics that will enable them to facilitate comparison across various crowdsourcing initiatives.},
booktitle = {Proceedings of the 11th International Symposium on Open Collaboration},
articleno = {7},
numpages = {10},
keywords = {metrics, taxonomy generation, crowdsourcing},
location = {San Francisco, California},
series = {OpenSym '15}
}

@inproceedings{10.1145/3229616.3229617,
author = {Prabhu, Santhosh and Chaudhry, Gohar Irfan and Godfrey, Brighten and Caesar, Matthew},
title = {High-Coverage Testing of Softwarized Networks},
year = {2018},
isbn = {9781450359122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229616.3229617},
doi = {10.1145/3229616.3229617},
abstract = {Network operators face a challenge of ensuring correctness as networks grow more complex, in terms of scale and increasingly in terms of diversity of software components. Network-wide verification approaches can spot errors, but assume a simplified abstraction of the functionality of individual network devices, which may deviate from the real implementation. In this paper, we propose a technique for high-coverage testing of end-to-end network correctness using the real software that is deployed in these networks. Our design is effectively a hybrid, using an explicit-state model checker to explore all network-wide execution paths and event orderings, but executing real software as subroutines for each device. We show that this approach can detect correctness issues that would be missed both by existing verification and testing approaches, and a prototype implementation suggests the technique can scale to larger networks with reasonable performance.},
booktitle = {Proceedings of the 2018 Workshop on Security in Softwarized Networks: Prospects and Challenges},
pages = {46–52},
numpages = {7},
keywords = {Correctness, Network Verification},
location = {Budapest, Hungary},
series = {SecSoN '18}
}

@inproceedings{10.1145/1882362.1882446,
author = {Wright, Hyrum K. and Kim, Miryung and Perry, Dewayne E.},
title = {Validity Concerns in Software Engineering Research},
year = {2010},
isbn = {9781450304276},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1882362.1882446},
doi = {10.1145/1882362.1882446},
abstract = {Empirical studies that use software repository artifacts have become popular in the last decade due to the ready availability of open source project archives. In this paper, we survey empirical studies in the last three years of ICSE and FSE proceedings, and categorize these studies in terms of open source projects vs. proprietary source projects and the diversity of subject programs used in these studies. Our survey has shown that almost half (49%) of recent empirical studies used solely open source projects. Existing studies either draw general conclusions from these results or explicitly disclaim any conclusions that can extend beyond specific subject software.We conclude that researchers in empirical software engineering must consider the external validity concerns that arise from using only several well-known open source software projects, and that discussion of data source selection is an important discussion topic in software engineering research. Furthermore, we propose a community research infrastructure for software repository benchmarks and sharing the empirical analysis results, in order to address external validity concerns and to raise the bar for empirical software engineering research that analyzes software artifacts.},
booktitle = {Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research},
pages = {411–414},
numpages = {4},
keywords = {external validity, empirical study, open source software},
location = {Santa Fe, New Mexico, USA},
series = {FoSER '10}
}

@inproceedings{10.1145/1006147.1006187,
author = {Cargill, Thomas A.},
title = {The Blit Debugger: Preliminary Draft},
year = {1983},
isbn = {0897911113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1006147.1006187},
doi = {10.1145/1006147.1006187},
abstract = {This paper describes the evolution to date of a flexible debugger for C programs on the Blit, a multi-processing bitmap terminal. The debugger is of interest for the following reasons:-- it is assisted by the terminal software's elegant separation of the debugger process from its subject process.-- it resides autonomously in the terminal and is bound dynamically to arbitrary subject processes.-- it executes asynchronously with its subject.-- its implementation is distributed as a small process in the terminal and a large process in the host timesharing system.-- its user interface uses graphics and a mouse.An opinion about the most fruitful direction for further application of graphics is offered.},
booktitle = {Proceedings of the Symposium on High-Level Debugging},
pages = {190–200},
numpages = {11},
location = {Pacific Grove, California},
series = {SIGSOFT '83}
}

@article{10.1145/1006140.1006187,
author = {Cargill, Thomas A.},
title = {The Blit Debugger: Preliminary Draft},
year = {1983},
issue_date = {August 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1006140.1006187},
doi = {10.1145/1006140.1006187},
abstract = {This paper describes the evolution to date of a flexible debugger for C programs on the Blit, a multi-processing bitmap terminal. The debugger is of interest for the following reasons:-- it is assisted by the terminal software's elegant separation of the debugger process from its subject process.-- it resides autonomously in the terminal and is bound dynamically to arbitrary subject processes.-- it executes asynchronously with its subject.-- its implementation is distributed as a small process in the terminal and a large process in the host timesharing system.-- its user interface uses graphics and a mouse.An opinion about the most fruitful direction for further application of graphics is offered.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {mar},
pages = {190–200},
numpages = {11}
}

@article{10.1145/1006142.1006187,
author = {Cargill, Thomas A.},
title = {The Blit Debugger: Preliminary Draft},
year = {1983},
issue_date = {August 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/1006142.1006187},
doi = {10.1145/1006142.1006187},
abstract = {This paper describes the evolution to date of a flexible debugger for C programs on the Blit, a multi-processing bitmap terminal. The debugger is of interest for the following reasons:-- it is assisted by the terminal software's elegant separation of the debugger process from its subject process.-- it resides autonomously in the terminal and is bound dynamically to arbitrary subject processes.-- it executes asynchronously with its subject.-- its implementation is distributed as a small process in the terminal and a large process in the host timesharing system.-- its user interface uses graphics and a mouse.An opinion about the most fruitful direction for further application of graphics is offered.},
journal = {SIGPLAN Not.},
month = {mar},
pages = {190–200},
numpages = {11}
}

@article{10.1145/3363562,
author = {Chen, Junjie and Patra, Jibesh and Pradel, Michael and Xiong, Yingfei and Zhang, Hongyu and Hao, Dan and Zhang, Lu},
title = {A Survey of Compiler Testing},
year = {2020},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3363562},
doi = {10.1145/3363562},
abstract = {Virtually any software running on a computer has been processed by a compiler or a compiler-like tool. Because compilers are such a crucial piece of infrastructure for building software, their correctness is of paramount importance. To validate and increase the correctness of compilers, significant research efforts have been devoted to testing compilers. This survey article provides a comprehensive summary of the current state-of-the-art of research on compiler testing. The survey covers different aspects of the compiler testing problem, including how to construct test programs, what test oracles to use for determining whether a compiler behaves correctly, how to execute compiler tests efficiently, and how to help compiler developers take action on bugs discovered by compiler testing. Moreover, we survey work that empirically studies the strengths and weaknesses of current compiler testing research and practice. Based on the discussion of existing work, we outline several open challenges that remain to be addressed in future work.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {4},
numpages = {36},
keywords = {Compiler testing, test optimization, test program generation, compiler debugging, test oracle}
}

