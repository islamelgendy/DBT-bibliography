@inproceedings{10.1145/2771783.2771785,
author = {Le, Vu and Sun, Chengnian and Su, Zhendong},
title = {Randomized Stress-Testing of Link-Time Optimizers},
year = {2015},
isbn = {9781450336208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2771783.2771785},
doi = {10.1145/2771783.2771785},
abstract = { Link-time optimization (LTO) is an increasingly important and adopted modern optimization technology. It is currently supported by many production compilers, including GCC, LLVM, and Microsoft Visual C/C++. Despite its complexity, but because it is more recent, LTO is relatively less tested compared to the more mature, traditional optimizations. To evaluate and help improve the quality of LTO, we present the first extensive effort to stress-test the LTO components of GCC and LLVM, the two most widely-used production C compilers. In 11 months, we have discovered and reported 37 bugs (12 in GCC; 25 in LLVM). Developers have confirmed 21 of our bugs, and fixed 11 of them. Our core technique is differential testing and realized in the tool Proteus. We leverage existing compiler testing tools (Csmith and Orion) to generate single-file test programs and address two important challenges specific for LTO testing. First, to thoroughly exercise LTO, Proteus automatically transforms a single-file program into multiple compilation units and stochastically assigns each an optimization level. Second, for effective bug reporting, we develop a practical mechanism to reduce LTO bugs involving multiple files. Our results clearly demonstrate Proteus’s utility; we plan to make ours a continuous effort in validating link-time optimizers. },
booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
pages = {327–337},
numpages = {11},
keywords = {Compiler testing, link-time optimizer, automated testing},
location = {Baltimore, MD, USA},
series = {ISSTA 2015}
}

@inproceedings{10.1145/3371676.3371703,
author = {Zhang, Zufa and Dai, Jianqiang and Zhao, Lingling and Qin, Songling},
title = {A Web Services Testing Approach Based on Difference Measurement and Adaptive Random Testing},
year = {2019},
isbn = {9781450376624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371676.3371703},
doi = {10.1145/3371676.3371703},
abstract = {Nowadays, people's demand for Web services is increasing, but in the process of obtaining these services, there are some problems in the service, which have not been detected, resulting in a poor experience. Therefore, this paper proposes a difference measurement method based on FSCS (Fixed Sized Candidate Set) algorithm, which improves the traditional ART (Adaptive Random Testing) algorithm. By comparing the differences of each method in Web Services, the farthest method is selected for testing, which improves the testing efficiency and improves the service experience. The method first selects one of the multiple services that may have a potential error service for testing, each time picks the farthest service in the combined service, and then selects the farthest method from the service as a test case, and then measures the differences between the methods in the service, compare the test results with the expected results, so that the problems in the service can be effectively detected. The experimental results show that the proposed method based on difference metric and adaptive random test can detect the existing methods in the service and improve the detection efficiency.},
booktitle = {Proceedings of the 2019 the 9th International Conference on Communication and Network Security},
pages = {1–5},
numpages = {5},
keywords = {testing system, adaptive random testing, Web Services, diversity, Software testing},
location = {Chongqing, China},
series = {ICCNS 2019}
}

@inproceedings{10.1145/3395363.3397356,
author = {Pradel, Michael and Murali, Vijayaraghavan and Qian, Rebecca and Machalica, Mateusz and Meijer, Erik and Chandra, Satish},
title = {Scaffle: Bug Localization on Millions of Files},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3397356},
doi = {10.1145/3395363.3397356},
abstract = {Despite all efforts to avoid bugs, software sometimes crashes in the field, leaving crash traces as the only information to localize the problem. Prior approaches on localizing where to fix the root cause of a crash do not scale well to ultra-large scale, heterogeneous code bases that contain millions of code files written in multiple programming languages. This paper presents Scaffle, the first scalable bug localization technique, which is based on the key insight to divide the problem into two easier sub-problems. First, a trained machine learning model predicts which lines of a raw crash trace are most informative for localizing the bug. Then, these lines are fed to an information retrieval-based search engine to retrieve file paths in the code base, predicting which file to change to address the crash. The approach does not make any assumptions about the format of a crash trace or the language that produces it. We evaluate Scaffle with tens of thousands of crash traces produced by a large-scale industrial code base at Facebook that contains millions of possible bug locations and that powers tools used by billions of people. The results show that the approach correctly predicts the file to fix for 40% to 60% (50% to 70%) of all crash traces within the top-1 (top-5) predictions. Moreover, Scaffle improves over several baseline approaches, including an existing classification-based approach, a scalable variant of existing information retrieval-based approaches, and a set of hand-tuned, industrially deployed heuristics.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {225–236},
numpages = {12},
keywords = {machine learning, software crashes, Bug localization},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inproceedings{10.1145/1390630.1390647,
author = {Buse, Raymond P.L. and Weimer, Westley R.},
title = {A Metric for Software Readability},
year = {2008},
isbn = {9781605580500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390630.1390647},
doi = {10.1145/1390630.1390647},
abstract = {In this paper, we explore the concept of code readability and investigate its relation to software quality. With data collected from human annotators, we derive associations between a simple set of local code features and human notions of readability. Using those features, we construct an automated readability measure and show that it can be 80% effective, and better than a human on average, at predicting readability judgments. Furthermore, we show that this metric correlates strongly with two traditional measures of software quality, code changes and defect reports. Finally, we discuss the implications of this study on programming language design and engineering practice. For example, our data suggests that comments, in of themselves, are less important than simple blank lines to local judgments of readability.},
booktitle = {Proceedings of the 2008 International Symposium on Software Testing and Analysis},
pages = {121–130},
numpages = {10},
keywords = {software maintenance, program understanding, software readability, code metrics, FindBugs, machine learning},
location = {Seattle, WA, USA},
series = {ISSTA '08}
}

@inbook{10.1145/3460319.3464813,
author = {Luo, Sicheng and Xu, Hui and Bi, Yanxiang and Wang, Xin and Zhou, Yangfan},
title = {Boosting Symbolic Execution via Constraint Solving Time Prediction (Experience Paper)},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464813},
abstract = {Symbolic execution is an essential approach for automated test case generation. However, the approach is generally not scalable to large programs. One critical reason is that the constraint solving problems in symbolic execution are generally hard. Consequently, the symbolic execution process may get stuck in solving such hard problems. To mitigate this issue, symbolic execution tools generally rely on a timeout threshold to terminate the solving. Such a timeout is generally set to a fixed, predefined value, e.g., five minutes in angr. Nevertheless, how to set a proper timeout is critical to the tool’s efficiency. This paper proposes an approach to tackle the problem by predicting the time required for solving a constraint model so that the symbolic execution engine could base on the information to determine whether to continue the current solving process. Due to the cost of the prediction itself, our approach triggers the predictor only when the solving time has exceeded a relatively small value. We have shown that such a predictor can achieve promising performance with several different machine learning models and datasets. By further employing an adaptive design, the predictor can achieve an F1-score ranging from 0.743 to 0.800 on these datasets. We then apply the predictor to eight programs and conduct simulation experiments. Results show that the efficiency of constraint solving for symbolic execution can be improved by 1.25x to 3x, depending on the distribution of the hardness of their constraint models.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {336–347},
numpages = {12}
}

@inproceedings{10.1145/2001420.2001448,
author = {Pradel, Michael and Gross, Thomas R.},
title = {Detecting Anomalies in the Order of Equally-Typed Method Arguments},
year = {2011},
isbn = {9781450305624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2001420.2001448},
doi = {10.1145/2001420.2001448},
abstract = {In statically-typed programming languages, the compiler ensures that method arguments are passed in the expected order by checking the type of each argument. However, calls to methods with multiple equally-typed parameters slip through this check. The uncertainty about the correct argument order of equally-typed arguments can cause various problems, for example, if a programmer accidentally reverses two arguments. We present an automated, static program analysis that detects such problems without any input except for the source code of a program. The analysis leverages the observation that programmer-given identifier names convey information about the semantics of arguments, which can be used to assign equally-typed arguments to their expected position. We evaluate the approach with a large corpus of Java programs and show that our analysis finds relevant anomalies with a precision of 76%.},
booktitle = {Proceedings of the 2011 International Symposium on Software Testing and Analysis},
pages = {232–242},
numpages = {11},
keywords = {maintenance, method arguments, static analysis, anomaly detection, automated program analysis},
location = {Toronto, Ontario, Canada},
series = {ISSTA '11}
}

@inproceedings{10.1145/3460319.3464838,
author = {Mahadewa, Kulani and Zhang, Yanjun and Bai, Guangdong and Bu, Lei and Zuo, Zhiqiang and Fernando, Dileepa and Liang, Zhenkai and Dong, Jin Song},
title = {Identifying Privacy Weaknesses from Multi-Party Trigger-Action Integration Platforms},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464838},
doi = {10.1145/3460319.3464838},
abstract = {With many trigger-action platforms that integrate Internet of Things (IoT) systems and online services, rich functionalities transparently connecting digital and physical worlds become easily accessible for the end users. On the other hand, such facilities incorporate multiple parties whose data control policies may radically differ and even contradict each other, and thus privacy violations may arise throughout the lifecycle (e.g., generation and transmission) of triggers and actions. In this work, we conduct an in-depth study on the privacy issues in multi-party trigger-action integration platforms (TAIPs). We first characterize privacy violations that may arise with the integration of heterogeneous systems and services. Based on this knowledge, we propose Taifu, a dynamic testing approach to identify privacy weaknesses from the TAIP. The key insight of Taifu is that the applets which actually program the trigger-action rules can be used as test cases to explore the behavior of the TAIP. We evaluate the effectiveness of our approach by applying it on the TAIPs that are built around the IFTTT platform. To our great surprise, we find that privacy violations are prevalent among them. Using the automatically generated 407 applets, each from a different TAIP, Taifu detects 194 cases with access policy breaches, 218 access control missing, 90 access revocation missing, 15 unintended flows, and 73 over-privilege access.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {2–15},
numpages = {14},
keywords = {Internet of Things, Testing, Privacy},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1145/186258.187206,
author = {Corbett, James C.},
title = {An Empirical Evaluation of Three Methods for Deadlock Analysis of Ada Tasking Programs},
year = {1994},
isbn = {0897916832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/186258.187206},
doi = {10.1145/186258.187206},
abstract = {Static analysis of Ada tasking programs has been hindered by the well known state explosion problem that arises in the verification of concurrent systems. Many different techniques have been proposed to combat this state explosion. All proposed methods excel on certain kinds of systems, but there is little empirical data comparing the performance of the methods. In this paper, we select one representative from each of three very different approaches to the state explosion problem: partial-orders (representing state-space reductions), symbolic model checking (representing OBDD-based approaches), and inequality necessary conditions (representing integer programming-based approaches). We apply the methods to several scalable concurrency examples from the literature and to one real Ada tasking program. The results of these experiments are presented and their significance is discussed.},
booktitle = {Proceedings of the 1994 ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {204–215},
numpages = {12},
location = {Seattle, Washington, USA},
series = {ISSTA '94}
}

@inproceedings{10.1145/3460319.3464830,
author = {Xu, Tongtong and Pan, Minxue and Pei, Yu and Li, Guiyin and Zeng, Xia and Zhang, Tian and Deng, Yuetang and Li, Xuandong},
title = {GUIDER: GUI Structure and Vision Co-Guided Test Script Repair for Android Apps},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464830},
doi = {10.1145/3460319.3464830},
abstract = {GUI testing is an essential part of regression testing for Android apps. For regression GUI testing to remain effective, it is important that obsolete GUI test scripts get repaired after the app has evolved. In this paper, we propose a novel approach named GUIDER to automated repair of GUI test scripts for Android apps. The key novelty of the approach lies in the utilization of both structural and visual information of widgets on app GUIs to better understand what widgets of the base version app become in the updated version. A supporting tool has been implemented for the approach. Experiments conducted on the popular messaging and social media app WeChat show that GUIDER is both effective and efficient. Repairs produced by GUIDER enabled 88.8% and 54.9% more test actions to run correctly than those produced by existing approaches to GUI test repair that rely solely on visual or structural information of app GUIs.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {191–203},
numpages = {13},
keywords = {test script repair, GUI analysis, Android testing},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1145/1390630.1390670,
author = {Bultan, Tevfik and Xie, Tao},
title = {Workshop on Testing, Analysis and Verification of Web Software (TAV-WEB 2008)},
year = {2008},
isbn = {9781605580500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1390630.1390670},
doi = {10.1145/1390630.1390670},
abstract = {TAV-WEB 2008 is the third in a series of workshops that focus on testing, analysis and verification of web software. The goal of these workshops has been to bring together researchers from academic, research, and industrial communities interested in the emerging area of dependable Web software development, to present and discuss their recent research results.},
booktitle = {Proceedings of the 2008 International Symposium on Software Testing and Analysis},
pages = {311–312},
numpages = {2},
keywords = {web applications, web services},
location = {Seattle, WA, USA},
series = {ISSTA '08}
}

@article{10.1145/3511701,
author = {Biagiola, Matteo and Tonella, Paolo},
title = {Testing the Plasticity of Reinforcement Learning Based Systems},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3511701},
doi = {10.1145/3511701},
abstract = {The data set available for pre-release training of a machine learning based system is often not representative of all possible execution contexts that the system will encounter in the field. Reinforcement Learning (RL) is a prominent approach among those that support continual learning, i.e., learning continually in the field, in the post-release phase. No study has so far investigated any method to test the plasticity of RL based systems, i.e., their capability to adapt to an execution context that may deviate from the training one. We propose an approach to test the plasticity of RL based systems. The output of our approach is a quantification of the adaptation and anti-regression capabilities of the system, obtained by computing the adaptation frontier of the system in a changed environment. We visualize such frontier as an adaptation/anti-regression heatmap in two dimensions, or as a clustered projection when more than two dimensions are involved. In this way, we provide developers with information on the amount of changes that can be accommodated by the continual learning component of the system, which is key to decide if online, in-the-field learning can be safely enabled or not.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jan},
keywords = {reinforcement learning, software testing, empirical software engineering}
}

@inproceedings{10.5555/2821339.2821352,
author = {Boussaa, Mohamed and Barais, Olivier and Suny\'{e}, Gerson and Baudry, Beno\^{\i}t},
title = {A Novelty Search Approach for Automatic Test Data Generation},
year = {2015},
publisher = {IEEE Press},
abstract = {In search-based structural testing, metaheuristic search techniques have been frequently used to automate the test data generation. In Genetic Algorithms (GAs) for example, test data are rewarded on the basis of an objective function that represents generally the number of statements or branches covered. However, owing to the wide diversity of possible test data values, it is hard to find the set of test data that can satisfy a specific coverage criterion. In this paper, we introduce the use of Novelty Search (NS) algorithm to the test data generation problem based on statement-covered criteria. We believe that such approach to test data generation is attractive because it allows the exploration of the huge space of test data within the input domain. In this approach, we seek to explore the search space without regard to any objectives. In fact, instead of having a fitness-based selection, we select test cases based on a novelty score showing how different they are compared to all other solutions evaluated so far.},
booktitle = {Proceedings of the Eighth International Workshop on Search-Based Software Testing},
pages = {40–43},
numpages = {4},
location = {Florence, Italy},
series = {SBST '15}
}

@inbook{10.1145/3460319.3464842,
author = {Qin, Shisong and Zhang, Chao and Chen, Kaixiang and Li, Zheming},
title = {IDEV: Exploring and Exploiting Semantic Deviations in ARM Instruction Processing},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464842},
abstract = {ARM has become the most competitive processor architecture. Many platforms or tools are developed to execute or analyze ARM instructions, including various commercial CPUs, emulators, and binary analysis tools. However, they have deviations when processing the same ARM instructions, and little attention has been paid to systematically analyze such semantic deviations, not to mention the security implications of such deviations. In this paper, we conduct an empirical study on the ARM Instruction Semantic Deviation (ISDev) issue. First, we classify this issue into several categories and analyze the security implications behind them. Then, we further demonstrate several novel attacks which utilize the ISDev issue, including stealthy targeted attacks and targeted defense evasion. Such attacks could exploit the semantic deviations to generate malware that is specific to certain platforms or able to detect and bypass certain detection solutions. We have developed a framework iDEV to systematically explore the ISDev issue in existing ARM instructions processing tools and platforms via differential testing. We have evaluated iDEV on four hardware devices, the QEMU emulator, and five disassemblers which could process the ARMv7-A instruction set. The evaluation results show that, over six million instructions could cause dynamic executors (i.e., CPUs and QEMU) to present different runtime behaviors, and over eight million instructions could cause static disassemblers yielding different decoding results, and over one million instructions cause inconsistency between dynamic executors and static disassemblers. After analyzing the root causes of each type of deviation, we point out they are mostly due to ARM unpredictable instructions and program defects.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {580–592},
numpages = {13}
}

@inbook{10.1145/3460319.3464807,
author = {Chen, Zhe and Wang, Chong and Yan, Junqi and Sui, Yulei and Xue, Jingling},
title = {Runtime Detection of Memory Errors with Smart Status},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464807},
abstract = {C is a dominant language for implementing system software. Unfortunately, its support for low-level control of memory often leads to memory errors. Dynamic analysis tools, which have been widely used for detecting memory errors at runtime, are not yet satisfactory as they cannot deterministically and completely detect some types of memory errors, e.g., segment confusion errors, sub-object overflows, use-after-frees, and memory leaks. We propose Smatus, short for smart status, a new dynamic analysis approach that supports comprehensive runtime detection of memory errors. The key innovation is to create and maintain a small status node for each memory object. Our approach tracks not only the bounds of each pointer’s referent but also the status and reference count of the referent in its status node, where the status represents the liveness and segment type of the referent. A status node is smart as it is automatically destroyed when it becomes useless. To the best of our knowledge, Smatus represents the most comprehensive approach of its kind. In terms of effectiveness (for detecting more kinds of errors), Smatus outperforms state-of-the-art tools, Google’s AddressSanitizer, SoftBoundCETS and Valgrind. In terms of performance, Smatus outperforms SoftBoundCETS and Valgrind in terms of both time and memory overheads incurred, and is on par with AddressSanitizer in terms of the time and memory overheads tradeoff (with much lower memory overhead incurred).},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {296–308},
numpages = {13}
}

@inproceedings{10.1145/75308.75333,
author = {Richardson, D. and Aha, S. and Osterweil, L.},
title = {Integrating Testing Techniques through Process Programming},
year = {1989},
isbn = {0897913426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75308.75333},
doi = {10.1145/75308.75333},
abstract = {Integration of multiple testing techniques is required to demonstrate high quality of software. Technique integration has four basic goals: reduced development costs, incremental testing capabilities, extensive error detection, and cost-effective application. We are experimenting with the use of process programming as a mechanism for integrating testing techniques. Having set out to develop a process that provides adequate coverage and comprehensive fault detection, we proposed synergistic use of DATA FLOW testing and RELAY to achieve all four goals. We developed a testing process program much as we would develop a software product from requirements through design to implementation and evaluation. We found process programming to be effective for explicitly integrating the techniques and achieving the desired synergism. Used in this way, process programming also mitigates many of the other problems that plague testing in the software development process.},
booktitle = {Proceedings of the ACM SIGSOFT '89 Third Symposium on Software Testing, Analysis, and Verification},
pages = {219–228},
numpages = {10},
location = {Key West, Florida, USA},
series = {TAV3}
}

@article{10.1145/75309.75333,
author = {Richardson, D. and Aha, S. and Osterweil, L.},
title = {Integrating Testing Techniques through Process Programming},
year = {1989},
issue_date = {Dec. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {8},
issn = {0163-5948},
url = {https://doi.org/10.1145/75309.75333},
doi = {10.1145/75309.75333},
abstract = {Integration of multiple testing techniques is required to demonstrate high quality of software. Technique integration has four basic goals: reduced development costs, incremental testing capabilities, extensive error detection, and cost-effective application. We are experimenting with the use of process programming as a mechanism for integrating testing techniques. Having set out to develop a process that provides adequate coverage and comprehensive fault detection, we proposed synergistic use of DATA FLOW testing and RELAY to achieve all four goals. We developed a testing process program much as we would develop a software product from requirements through design to implementation and evaluation. We found process programming to be effective for explicitly integrating the techniques and achieving the desired synergism. Used in this way, process programming also mitigates many of the other problems that plague testing in the software development process.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {nov},
pages = {219–228},
numpages = {10}
}

@inproceedings{10.1109/ESEM.2017.16,
author = {Santos, Ronnie E. S. and Magalh\~{a}es, Cleyton V. C. and Correia-Neto, Jorge S. and da Silva, Fabio Q. B. and Capretz, Luiz Fernando and Souza, Rodrigo E. C.},
title = {Would You like to Motivate Software Testers? Ask Them How},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ESEM.2017.16},
doi = {10.1109/ESEM.2017.16},
abstract = {Context. Considering the importance of software testing to the development of high quality and reliable software systems, this paper aims to investigate how can work-related factors influence the motivation of software testers. Method. We applied a questionnaire that was developed using a previous theory of motivation and satisfaction of software engineers to conduct a survey-based study to explore and understand how professional software testers perceive and value work-related factors that could influence their motivation at work. Results. With a sample of 80 software testers we observed that software testers are strongly motivated by variety of work, creative tasks, recognition for their work, and activities that allow them to acquire new knowledge, but in general the social impact of this activity has low influence on their motivation. Conclusion. This study discusses the difference of opinions among software testers, regarding work-related factors that could impact their motivation, which can be relevant for managers and leaders in software engineering practice.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {95–104},
numpages = {10},
keywords = {motivation, software testing, software engineering},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}

@inproceedings{10.1145/3213846.3213876,
author = {Le, Tien-Duy B. and Lo, David},
title = {Deep Specification Mining},
year = {2018},
isbn = {9781450356992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213846.3213876},
doi = {10.1145/3213846.3213876},
abstract = {Formal specifcations are essential but usually unavailable in software systems. Furthermore, writing these specifcations is costly and requires skills from developers. Recently, many automated techniques have been proposed to mine specifcations in various formats including fnite-state automaton (FSA). However, more works in specifcation mining are needed to further improve the accuracy of the inferred specifcations. In this work, we propose Deep Specifcation Miner (DSM), a new approach that performs deep learning for mining FSA-based specifcations. Our proposed approach uses test case generation to generate a richer set of execution traces for training a Recurrent Neural Network Based Language Model (RNNLM). From these execution traces, we construct a Prefx Tree Acceptor (PTA) and use the learned RNNLM to extract many features. These features are subsequently utilized by clustering algorithms to merge similar automata states in the PTA for constructing a number of FSAs. Then, our approach performs a model selection heuristic to estimate F-measure of FSAs and returns the one with the highest estimated Fmeasure. We execute DSM to mine specifcations of 11 target library classes. Our empirical analysis shows that DSM achieves an average F-measure of 71.97%, outperforming the best performing baseline by 28.22%. We also demonstrate the value of DSM in sandboxing Android apps.},
booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {106–117},
numpages = {12},
keywords = {Specification Mining, Deep Learning},
location = {Amsterdam, Netherlands},
series = {ISSTA 2018}
}

@inproceedings{10.1109/ICSE-NIER.2019.00031,
author = {Li, Zenan and Ma, Xiaoxing and Xu, Chang and Cao, Chun},
title = {Structural Coverage Criteria for Neural Networks Could Be Misleading},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2019.00031},
doi = {10.1109/ICSE-NIER.2019.00031},
abstract = {There is a dramatically increasing interest in the quality assurance for DNN-based systems in the software engineering community. An emerging hot topic in this direction is structural coverage criteria for testing neural networks, which are inspired by coverage metrics used in conventional software testing. In this short paper, we argue that these criteria could be misleading because of the fundamental differences between neural networks and human written programs. Our preliminary exploration shows that (1) adversarial examples are pervasively distributed in the finely divided space defined by such coverage criteria, while available natural samples are very sparse, and as a consequence, (2) previously reported fault-detection "capabilities" conjectured from high coverage testing are more likely due to the adversary-oriented search but not the real "high" coverage.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {89–92},
numpages = {4},
keywords = {software testing, coverage, neural networks},
location = {Montreal, Quebec, Canada},
series = {ICSE-NIER '19}
}

@inproceedings{10.1145/3092703.3092730,
author = {Chen, Yizhen and Ying, Ming and Liu, Daren and Alim, Adil and Chen, Feng and Chen, Mei-Hwa},
title = {Effective Online Software Anomaly Detection},
year = {2017},
isbn = {9781450350761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3092703.3092730},
doi = {10.1145/3092703.3092730},
abstract = {While automatic online software anomaly detection is crucial for ensuring the quality of production software, current techniques are mostly inefficient and ineffective. For online software, its inputs are usually provided by the users at runtime and the validity of the outputs cannot be automatically verified without a predefined oracle. Furthermore, some online anomalous behavior may be caused by the anomalies in the execution context, rather than by any code defect, which are even more difficult to detect. Existing approaches tackle this problem by identifying certain properties observed from the executions of the software during a training process and using them to monitor online software behavior. However, they may require a large execution overhead for monitoring the properties, which limits the applicability of these approaches for online monitoring. We present a methodology that applies effective algorithms to select a close to optimal set of anomaly-revealing properties, which enables online anomaly detection with minimal execution overhead. Our empirical results show that an average of 76.5% of anomalies were detected by using at most 5.5% of execution overhead.},
booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {136–146},
numpages = {11},
keywords = {Program invariant, sensor placement algorithms, software anomaly detection},
location = {Santa Barbara, CA, USA},
series = {ISSTA 2017}
}

@inproceedings{10.1145/1878537.1878684,
author = {Marinho, Marcelo and Maciel, Paulo and Sousa, Erica and Maciel, Teresa and Andrade, Ermeson},
title = {Performance Evaluation of Test Process Based on Stochastic Models},
year = {2010},
isbn = {9781450300698},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
url = {https://doi.org/10.1145/1878537.1878684},
doi = {10.1145/1878537.1878684},
abstract = {The demand for high quality software has motivated a definition of methods and techniques. As a result, the interest in software testing activities has been growing over the last few years. Software companies currently seek low cost testing procedures and at the same, with great capacity to handle mistakes. In this article, concepts related to testing processes are mapped in Stochastic Petri Nets(SPN) which provides a formal representation for measures used in performance analysis.},
booktitle = {Proceedings of the 2010 Spring Simulation Multiconference},
articleno = {141},
numpages = {6},
keywords = {software testing, stochastic Petri net, UML},
location = {Orlando, Florida},
series = {SpringSim '10}
}

