@inproceedings{10.1145/2610384.2628055,
author = {Just, Ren\'{e} and Jalali, Darioush and Ernst, Michael D.},
title = {Defects4J: A Database of Existing Faults to Enable Controlled Testing Studies for Java Programs},
year = {2014},
isbn = {9781450326452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2610384.2628055},
doi = {10.1145/2610384.2628055},
abstract = { Empirical studies in software testing research may not be comparable, reproducible, or characteristic of practice. One reason is that real bugs are too infrequently used in software testing research. Extracting and reproducing real bugs is challenging and as a result hand-seeded faults or mutants are commonly used as a substitute. This paper presents Defects4J, a database and extensible framework providing real bugs to enable reproducible studies in software testing research. The initial version of Defects4J contains 357 real bugs from 5 real-world open source pro- grams. Each real bug is accompanied by a comprehensive test suite that can expose (demonstrate) that bug. Defects4J is extensible and builds on top of each program’s version con- trol system. Once a program is configured in Defects4J, new bugs can be added to the database with little or no effort. Defects4J features a framework to easily access faulty and fixed program versions and corresponding test suites. This framework also provides a high-level interface to common tasks in software testing research, making it easy to con- duct and reproduce empirical studies. Defects4J is publicly available at http://defects4j.org. },
booktitle = {Proceedings of the 2014 International Symposium on Software Testing and Analysis},
pages = {437–440},
numpages = {4},
keywords = {testing framework, Bug database, real bugs},
location = {San Jose, CA, USA},
series = {ISSTA 2014}
}

@inproceedings{10.1109/GI.2019.00011,
author = {Ding, Zhen Yu and Lyu, Yiwei and Timperley, Christopher S. and Goues, Claire Le},
title = {Leveraging Program Invariants to Promote Population Diversity in Search-Based Automatic Program Repair},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/GI.2019.00011},
doi = {10.1109/GI.2019.00011},
abstract = {Search-based automatic program repair has shown promise in reducing the cost of defects in real-world software. However, to date, such techniques have typically been most successful when constructing short or single-edit repairs. This is true even when techniques make use of heuristic search strategies, like genetic programming, that in principle support the construction of patches of arbitrary length. One key reason is that the fitness function traditionally depends entirely on test cases, which are poor at identifying partially correct solutions and lead to a fitness landscape with many plateaus. We propose a novel fitness function that optimizes for both functionality and semantic diversity, characterized using learned invariants over intermediate behavior. Our early results show that this new approach improves semantic diversity and fitness granularity, but does not statistically significantly improve repair performance.},
booktitle = {Proceedings of the 6th International Workshop on Genetic Improvement},
pages = {2–9},
numpages = {8},
keywords = {invariant analysis, fitness function, program semantics, genetic programming, automated program repair},
location = {Montreal, Quebec, Canada},
series = {GI '19}
}

@inproceedings{10.1145/3460319.3464802,
author = {Haq, Fitash Ul and Shin, Donghwan and Briand, Lionel C. and Stifter, Thomas and Wang, Jun},
title = {Automatic Test Suite Generation for Key-Points Detection DNNs Using Many-Objective Search (Experience Paper)},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464802},
doi = {10.1145/3460319.3464802},
abstract = {Automatically detecting the positions of key-points (e.g., facial key-points or finger key-points) in an image is an essential problem in many applications, such as driver's gaze detection and drowsiness detection in automated driving systems. With the recent advances of Deep Neural Networks (DNNs), Key-Points detection DNNs (KP-DNNs) have been increasingly employed for that purpose. Nevertheless, KP-DNN testing and validation have remained a challenging problem because KP-DNNs predict many independent key-points at the same time---where each individual key-point may be critical in the targeted application---and images can vary a great deal according to many factors.  In this paper, we present an approach to automatically generate test data for KP-DNNs using many-objective search. In our experiments, focused on facial key-points detection DNNs developed for an industrial automotive application, we show that our approach can generate test suites to severely mispredict, on average, more than 93% of all key-points. In comparison, random search-based test data generation can only severely mispredict 41% of them. Many of these mispredictions, however, are not avoidable and should not therefore be considered failures. We also empirically compare state-of-the-art, many-objective search algorithms and their variants, tailored for test suite generation. Furthermore, we investigate and demonstrate how to learn specific conditions, based on image characteristics (e.g., head posture and skin color), that lead to severe mispredictions. Such conditions serve as a basis for risk analysis or DNN retraining.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {91–102},
numpages = {12},
keywords = {many-objective search algorithm, deep neural network, software testing, Key-point detection},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.5555/2821339.2821355,
author = {Ma, Lei and Artho, Cyrille and Zhang, Cheng and Sato, Hiroyuki and Hagiya, Masami and Tanabe, Yoshinori and Yamamoto, Mitsuharu},
title = {GRT at the SBST 2015 Tool Competition},
year = {2015},
publisher = {IEEE Press},
abstract = {GRT (Guided Random Testing) is an automatic test generation tool for Java code, which leverages static and dynamic program analysis to guide run-time test generation. In this paper, we summarize competition results and experiences of GRT in participating in SBST 2015, where GRT ranked first with a score of 203.73 points over 63 Java classes from 10 packages of 9 open-source software projects.},
booktitle = {Proceedings of the Eighth International Workshop on Search-Based Software Testing},
pages = {48–51},
numpages = {4},
keywords = {automatic test case generation, software testing, program analysis, random testing},
location = {Florence, Italy},
series = {SBST '15}
}

@inbook{10.1145/3340433.3342825,
author = {Kessel, Marcus and Atkinson, Colin},
title = {A Platform for Diversity-Driven Test Amplification},
year = {2019},
isbn = {9781450368506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340433.3342825},
abstract = {Test amplification approaches take a manually written set of tests (input/output mappings) and enhance their effectiveness for some clearly defined engineering goal such as detecting faults. Conceptually, they can either achieve this in a ``black box'' way using only the initial ``seed'' tests or in a ``white box'' way utilizing additional inputs such as the source code or specification of the software under test. However, no fully black box approach to test amplification is currently available even though they can be used to enhance white box approaches. In this paper we introduce a new approach that uses the seed tests to search for existing redundant implementations of the software under test and leverages them as oracles in the generation and evaluation of new tests. The approach can therefore be used as a stand alone black box test amplification method or in tandem with other methods. In this paper we explain the approach, describe its synergies with other approaches and provide some evidence for its practical feasibility.},
booktitle = {Proceedings of the 10th ACM SIGSOFT International Workshop on Automating TEST Case Design, Selection, and Evaluation},
pages = {35–41},
numpages = {7}
}

@inbook{10.1145/3293882.3330552,
author = {Kechagia, Maria and Devroey, Xavier and Panichella, Annibale and Gousios, Georgios and van Deursen, Arie},
title = {Effective and Efficient API Misuse Detection via Exception Propagation and Search-Based Testing},
year = {2019},
isbn = {9781450362245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293882.3330552},
abstract = {Application Programming Interfaces (APIs) typically come with (implicit) usage constraints. The violations of these constraints (API misuses) can lead to software crashes. Even though there are several tools that can detect API misuses, most of them suffer from a very high rate of false positives. We introduce Catcher, a novel API misuse detection approach that combines static exception propagation analysis with automatic search-based test case generation to effectively and efficiently pinpoint crash-prone API misuses in client applications. We validate Catcher against 21 Java applications, targeting misuses of the Java platform's API. Our results indicate that Catcher is able to generate test cases that uncover 243 (unique) API misuses that result in crashes. Our empirical evaluation shows that Catcher can detect a large number of misuses (77 cases) that would remain undetected by the traditional coverage-based test case generator EvoSuite. Additionally, on average, Catcher is eight times faster than EvoSuite in generating test cases for the identified misuses. Finally, we find that the majority of the exceptions triggered by Catcher are unexpected to developers, i.e., not only unhandled in the source code but also not listed in the documentation of the client applications.},
booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {192–203},
numpages = {12}
}

@inproceedings{10.1145/566172.566202,
author = {Chen, T. Y. and Tse, T. H. and Zhou, Zhiquan},
title = {Semi-Proving: An Integrated Method Based on Global Symbolic Evaluation and Metamorphic Testing},
year = {2002},
isbn = {1581135629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/566172.566202},
doi = {10.1145/566172.566202},
abstract = {We present a semi-proving method for verifying necessary conditions for program correctness. Our approach is based on the integration of global symbolic evaluation and metamorphic testing. It is relatively easier than conventional program proving, and helps to alleviate the problem that software testing cannot show the absence of faults.},
booktitle = {Proceedings of the 2002 ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {191–195},
numpages = {5},
keywords = {semi-proving, program proving, program testing, metamorphic testing, symbolic execution, global symbolic evaluation},
location = {Roma, Italy},
series = {ISSTA '02}
}

@article{10.1145/566171.566202,
author = {Chen, T. Y. and Tse, T. H. and Zhou, Zhiquan},
title = {Semi-Proving: An Integrated Method Based on Global Symbolic Evaluation and Metamorphic Testing},
year = {2002},
issue_date = {July 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/566171.566202},
doi = {10.1145/566171.566202},
abstract = {We present a semi-proving method for verifying necessary conditions for program correctness. Our approach is based on the integration of global symbolic evaluation and metamorphic testing. It is relatively easier than conventional program proving, and helps to alleviate the problem that software testing cannot show the absence of faults.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jul},
pages = {191–195},
numpages = {5},
keywords = {metamorphic testing, program proving, symbolic execution, global symbolic evaluation, program testing, semi-proving}
}

@inproceedings{10.1145/337180.337864,
author = {Littlewood, Bev and Strigini, Lorenzo},
title = {Fault Tolerance via Diversity against Design Faults (Tutorial Session): Design Principles and Reliability Assessment},
year = {2000},
isbn = {1581132069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/337180.337864},
doi = {10.1145/337180.337864},
abstract = {Research results indicate that (as usual in software engineering) these question can only be answered with reference to each specific application context and that diversity is no “silver bullet”. But diversity is an attractive option, made more interesting by current trends like the preference for COTS items, and it is important for practitioners to go beyond the summary opinions and misunderstanding that surround it.This tutorial is designed for people involved in system design, acceptance or certification, especially in companies with high dependability requirements or plans to improve on current levels to move into more demanding markets. It is also appropriate for researchers in software engineering wishing to obtain an up-to-date view of knowledge in this area.This tutorial describes:the motivations behind the use of software fault tolerance, and thus the circumstances in which it should be considered as a possible choice;what design schemes one may adopt, and which issues a designer needs to be aware of, for effective application. We present both examples of industrial use and explanations of the important design choices and trade-offs. In this part, we cover the widely published solutions of N-version programming and recovery blocks, but also describe the various options available to a designer, and interesting specific solutions adopted in the railway and aviation industry, and scheme for applications to safety systems. We discuss the factors that may decide the scheme to be adopted and the design of adjudication between conflicting results;“what one should really believe” about the effectiveness of software fault tolerance in improving reliability, beyond the controversy and the misunderstandings surrounding it. We give a picture, assembled from more than 10 years of research, of what evidence has really been produced for and against software diversity. We explain the weaknesses of the extreme opinions voiced for and against software fault tolerance, and discuss the criteria that should affect practical decisions about using it, about how to improve its effectiveness by appropriate decisions in developing alternate versions of software components, and about its value for system acceptance.},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering},
pages = {835},
location = {Limerick, Ireland},
series = {ICSE '00}
}

@article{10.1145/2430536.2430540,
author = {Hemmati, Hadi and Arcuri, Andrea and Briand, Lionel},
title = {Achieving Scalable Model-Based Testing through Test Case Diversity},
year = {2013},
issue_date = {February 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/2430536.2430540},
doi = {10.1145/2430536.2430540},
abstract = {The increase in size and complexity of modern software systems requires scalable, systematic, and automated testing approaches. Model-based testing (MBT), as a systematic and automated test case generation technique, is being successfully applied to verify industrial-scale systems and is supported by commercial tools. However, scalability is still an open issue for large systems, as in practice there are limits to the amount of testing that can be performed in industrial contexts. Even with standard coverage criteria, the resulting test suites generated by MBT techniques can be very large and expensive to execute, especially for system level testing on real deployment platforms and network facilities. Therefore, a scalable MBT technique should be flexible regarding the size of the generated test suites and should be easily accommodated to fit resource and time constraints. Our approach is to select a subset of the generated test suite in such a way that it can be realistically executed and analyzed within the time and resource constraints, while preserving the fault revealing power of the original test suite to a maximum extent. In this article, to address this problem, we introduce a family of similarity-based test case selection techniques for test suites generated from state machines. We evaluate 320 different similarity-based selection techniques and then compare the effectiveness of the best similarity-based selection technique with other common selection techniques in the literature. The results based on two industrial case studies, in the domain of embedded systems, show significant benefits and a large improvement in performance when using a similarity-based approach. We complement these analyses with further studies on the scalability of the technique and the effects of failure rate on its effectiveness. We also propose a method to identify optimal tradeoffs between the number of test cases to run and fault detection.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {mar},
articleno = {6},
numpages = {42},
keywords = {Test case selection, similarity function, model-based testing, test case minimization, search-based software engineering}
}

@inproceedings{10.1145/566172.566209,
author = {Sreenivas, Ashok},
title = {Panel Discussion: Is ISSTA Testing Research Relevant to Industrial Users?},
year = {2002},
isbn = {1581135629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/566172.566209},
doi = {10.1145/566172.566209},
abstract = {We discuss the direct relevance of on-going testing research to the 'users' of the research, namely the industrial practitioners. The current state-of-the-practice in software testing is quite ad-hoc and provides little or no assertions about the quality of the delivered software product. We propose the view that research that is aligned with formal approaches to software development is the best bet to achieve this goal.},
booktitle = {Proceedings of the 2002 ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {208–209},
numpages = {2},
location = {Roma, Italy},
series = {ISSTA '02}
}

@article{10.1145/566171.566209,
author = {Sreenivas, Ashok},
title = {Panel Discussion: Is ISSTA Testing Research Relevant to Industrial Users?},
year = {2002},
issue_date = {July 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/566171.566209},
doi = {10.1145/566171.566209},
abstract = {We discuss the direct relevance of on-going testing research to the 'users' of the research, namely the industrial practitioners. The current state-of-the-practice in software testing is quite ad-hoc and provides little or no assertions about the quality of the delivered software product. We propose the view that research that is aligned with formal approaches to software development is the best bet to achieve this goal.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jul},
pages = {208–209},
numpages = {2}
}

@article{10.1145/3476105,
author = {Parry, Owain and Kapfhammer, Gregory M. and Hilton, Michael and McMinn, Phil},
title = {A Survey of Flaky Tests},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3476105},
doi = {10.1145/3476105},
abstract = {Tests that fail inconsistently, without changes to the code under test, are described as flaky. Flaky tests do not give a clear indication of the presence of software bugs and thus limit the reliability of the test suites that contain them. A recent survey of software developers found that 59% claimed to deal with flaky tests on a monthly, weekly, or daily basis. As well as being detrimental to developers, flaky tests have also been shown to limit the applicability of useful techniques in software testing research. In general, one can think of flaky tests as being a threat to the validity of any methodology that assumes the outcome of a test only depends on the source code it covers. In this article, we systematically survey the body of literature relevant to flaky test research, amounting to 76 papers. We split our analysis into four parts: addressing the causes of flaky tests, their costs and consequences, detection strategies, and approaches for their mitigation and repair. Our findings and their implications have consequences for how the software-testing community deals with test flakiness, pertinent to practitioners and of interest to those wanting to familiarize themselves with the research area.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {oct},
articleno = {17},
numpages = {74},
keywords = {software testing, Flaky tests}
}

@inproceedings{10.1145/3194718.3194722,
author = {Choudhary, Ankur and Agrawal, Arun Prakash and Kaur, Arvinder},
title = {An Effective Approach for Regression Test Case Selection Using Pareto Based Multi-Objective Harmony Search},
year = {2018},
isbn = {9781450357418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194718.3194722},
doi = {10.1145/3194718.3194722},
abstract = {Regression testing is a way of catching bugs in new builds and releases to avoid the product risks. Corrective, progressive, retest all and selective regression testing are strategies to perform regression testing. Retesting all existing test cases is one of the most reliable approaches but it is costly in terms of time and effort. This limitation opened a scope to optimize regression testing cost by selecting only a subset of test cases that can detect faults in optimal time and effort. This paper proposes Pareto based Multi-Objective Harmony Search approach for regression test case selection from an existing test suite to achieve some test adequacy criteria. Fault coverage, unique faults covered and algorithm execution time are utilised as performance measures to achieve optimization criteria. The performance evaluation of proposed approach is performed against Bat Search and Cuckoo Search optimization. The results of statistical tests indicate significant improvement over existing approaches.},
booktitle = {Proceedings of the 11th International Workshop on Search-Based Software Testing},
pages = {13–20},
numpages = {8},
keywords = {regression testing, software testing, harmony search, test case selection, bat search optimization, optimization, cuckoo search optimization},
location = {Gothenburg, Sweden},
series = {SBST '18}
}

@inproceedings{10.1145/2993288.2993290,
author = {Martins, Alexandre L. and de Melo, Ana C. V.},
title = {Can You Certify Your Software to MC/DC? A Static Analysis Approach to Account for the Number Test Cases},
year = {2016},
isbn = {9781450347662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993288.2993290},
doi = {10.1145/2993288.2993290},
abstract = {Software testing is an important task in systems development to certify the quality of the final product. If it is not properly applied, we can end up with low-quality systems. On the other hand, applying rigorous software testing techniques can spend nearly 40-50% of the system development cost. The issue is: how to provide a good software quality, by means of testing techniques, and keep the overall system cost under control?This paper presents a study on the cost of applying the Modified Condition/Decision Coverage (MC/DC) (proposed by NASA1 and used by FAA2 [19]) to software by accounting for the number of test cases that need to be generated. In order to achieve our goal, we collected the MC/DC coverage requirements in a set of open source software to estimate the cost of this criterion application in terms of the number of test cases.},
booktitle = {Proceedings of the 1st Brazilian Symposium on Systematic and Automated Software Testing},
articleno = {3},
numpages = {7},
keywords = {software, testing, MC/DC, coverage, quality},
location = {Maringa, Parana, Brazil},
series = {SAST}
}

@inproceedings{10.1145/2001420.2001461,
author = {Namin, Akbar Siami and Kakarla, Sahitya},
title = {The Use of Mutation in Testing Experiments and Its Sensitivity to External Threats},
year = {2011},
isbn = {9781450305624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2001420.2001461},
doi = {10.1145/2001420.2001461},
abstract = {Mutation analysts has emerged as a standard approach for empirical assessment of testing techniques. The test practitioners decide about cost-effectiveness of testing strategies based on the number of mutants the testing techniques detect. Though fundamental rigor to empirical software testing, the use of mutants in the absence of real-world faults has raised the concern of whether mutants and real faults exhibit similar properties. This paper revisits this important concern and disseminates interesting findings regarding mutants and whether these synthetic faults can predict fault detection ability of test suites. The results of controlled experiments conducted in this paper show that mutation when used in testing experiments is highly sensitive to external threats caused by some influential factors including mutation operators, test suite size, and programming languages. This paper raises the awareness message of the use of mutation in testing experiment and suggests that any interpretation or generalization of experimental findings based on mutation should be justified according to the influential factors involved.},
booktitle = {Proceedings of the 2011 International Symposium on Software Testing and Analysis},
pages = {342–352},
numpages = {11},
keywords = {real faults, mutation testing, mutants, hand-seeded faults, experimental design, statistical analysis},
location = {Toronto, Ontario, Canada},
series = {ISSTA '11}
}

@article{10.1145/3447265,
author = {Men\'{e}ndez, H\'{e}ctor D. and Jahangirova, Gunel and Sarro, Federica and Tonella, Paolo and Clark, David},
title = {Diversifying Focused Testing for Unit Testing},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3447265},
doi = {10.1145/3447265},
abstract = {Software changes constantly, because developers add new features or modifications. This directly affects the effectiveness of the test suite associated with that software, especially when these new modifications are in a specific area that no test case covers. This article tackles the problem of generating a high-quality test suite to cover repeatedly a given point in a program, with the ultimate goal of exposing faults possibly affecting the given program point. Both search-based software testing and constraint solving offer ready, but low-quality, solutions to this: Ideally, a maximally diverse covering test set is required, whereas search and constraint solving tend to generate test sets with biased distributions. Our approach, Diversified Focused Testing (DFT), uses a search strategy inspired by G\"{o}delTest. We artificially inject parameters into the code branching conditions and use a bi-objective search algorithm to find diverse inputs by perturbing the injected parameters, while keeping the path conditions still satisfiable. Our results demonstrate that our technique, DFT, is able to cover a desired point in the code at least 90% of the time. Moreover, adding diversity improves the bug detection and the mutation killing abilities of the test suites. We show that DFT achieves better results than focused testing, symbolic execution, and random testing by achieving from 3% to 70% improvement in mutation score and up to 100% improvement in fault detection across 105 software subjects.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
articleno = {44},
numpages = {24},
keywords = {focused testing, G\"{o}delTest, Testing, DFT, diversity}
}

@inproceedings{10.1145/3305160.3305186,
author = {Setiani, Novi and Ferdiana, Ridi and Santosa, Paulus Insap and Hartanto, Rudy},
title = {Literature Review on Test Case Generation Approach},
year = {2019},
isbn = {9781450366427},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3305160.3305186},
doi = {10.1145/3305160.3305186},
abstract = {Test case generation is a testing stage that requires the greatest resources among other stages so it has significant impact on the effectiveness and efficiency of software testing. Test case is a pair of input and output that will be executed by the tester whose aim is reveal the failures in software under test (SUT). For decades, this topic has become one of the most active topics in research on software testing. It has been proved by a variety of techniques and diverse tools proposed. In last decade, research in the field of test case generation experienced some progress. Nowadays, software testing is challenged to be able to test complex computation software that intensively interact with another system. The aim of this study is to give an up-to-date and overview of research in test case generation researches.},
booktitle = {Proceedings of the 2nd International Conference on Software Engineering and Information Management},
pages = {91–95},
numpages = {5},
keywords = {software testing, Test case, test case generation},
location = {Bali, Indonesia},
series = {ICSIM 2019}
}

@inproceedings{10.1145/3092703.3092720,
author = {Yaneva, Vanya and Rajan, Ajitha and Dubach, Christophe},
title = {Compiler-Assisted Test Acceleration on GPUs for Embedded Software},
year = {2017},
isbn = {9781450350761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3092703.3092720},
doi = {10.1145/3092703.3092720},
abstract = {Embedded software is found everywhere from our highly visible mobile devices to the confines of our car in the form of smart sensors. Embedded software companies are under huge pressure to produce safe applications that limit risks, and testing is absolutely critical to alleviate concerns regarding safety and user privacy. This requires using large test suites throughout the development process, increasing time-to-market and ultimately hindering competitivity. Speeding up test execution is, therefore, of paramount importance for embedded software developers. This is traditionally achieved by running, in parallel, multiple tests on large-scale clusters of computers. However, this approach is costly in terms of infrastructure maintenance and energy consumed, and is at times inconvenient as developers have to wait for their tests to be scheduled on a shared resource. We propose to look at exploiting GPUs (Graphics Processing Units) for running embedded software testing. GPUs are readily available in most computers and offer tremendous amounts of parallelism, making them an ideal target for embedded software testing. In this paper, we demonstrate, for the first time, how test executions of embedded C programs can be automatically performed on a GPU, without involving the end user. We take a compiler-assisted approach which automatically compiles the C program into GPU kernels for parallel execution of the input tests. Using this technique, we achieve an average speedup of 16\texttimes{} when compared to CPU execution of input tests across nine programs from an industry standard embedded benchmark suite.},
booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {35–45},
numpages = {11},
keywords = {Functional testing, Automated testing, Compilers, Embedded software, GPUs},
location = {Santa Barbara, CA, USA},
series = {ISSTA 2017}
}

@inproceedings{10.1145/2792404.2792406,
author = {Fouch\'{e}, Sandro and Mangle, Andrew H.},
title = {Code Hunt as Platform for Gamification of Cybersecurity Training},
year = {2015},
isbn = {9781450337113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2792404.2792406},
doi = {10.1145/2792404.2792406},
abstract = { The nation needs more cybersecurity professionals. Beyond just a general shortage, women, African Americans, and Latino Americans are underrepresented in the field. This not only contributes to the scarcity of qualified cybersecurity professionals, but the absence of diversity leads to a lack of perspective and differing viewpoints. Part of the problem is that cybersecurity suffers from barriers to entry that include expensive training, exclusionary culture, and the need for costly infrastructure. In order for students to start learning about cybersecurity, access to training, infrastructure and subject matter experts is imperative. The existing Code Hunt framework, used to help students master programming, could be a springboard to help reduce the challenges facing students interested in cybersecurity. Code Hunt offers gamification, community supported development, and a cloud infrastructure that provides an on-ramp to immediate learning. Leveraging Code Hunt's structured gaming model can addresses these weaknesses and makes cybersecurity training more accessible to those without the means or inclination to participate in more traditional cybersecurity competitions. },
booktitle = {Proceedings of the 1st International Workshop on Code Hunt Workshop on Educational Software Engineering},
pages = {9–11},
numpages = {3},
keywords = {Software Testing, Cybersecurity, Gamification, Education},
location = {Baltimore, MD, USA},
series = {CHESE 2015}
}

@inproceedings{10.1145/2338965.2336779,
author = {Hong, Shin and Ahn, Jaemin and Park, Sangmin and Kim, Moonzoo and Harrold, Mary Jean},
title = {Testing Concurrent Programs to Achieve High Synchronization Coverage},
year = {2012},
isbn = {9781450314541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2338965.2336779},
doi = {10.1145/2338965.2336779},
abstract = { The effectiveness of software testing is often assessed by measuring coverage of some aspect of the software, such as its code. There is much research aimed at increasing code coverage of sequential software. However, there has been little research on increasing coverage for concurrent software. This paper presents a new technique that aims to achieve high coverage of concurrent programs by generating thread schedules to cover uncovered coverage requirements. Our technique first estimates synchronization-pair coverage requirements, and then generates thread schedules that are likely to cover uncovered coverage requirements. This paper also presents a description of a prototype tool that we implemented in Java, and the results of a set of studies we performed using the tool on a several open-source programs. The results show that, for our subject programs, our technique achieves higher coverage faster than random testing techniques; the estimation-based heuristic contributes substantially to the effectiveness of our technique. },
booktitle = {Proceedings of the 2012 International Symposium on Software Testing and Analysis},
pages = {210–220},
numpages = {11},
location = {Minneapolis, MN, USA},
series = {ISSTA 2012}
}

@inproceedings{10.1145/2897010.2897015,
author = {Soltani, Mozhan and Panichella, Annibale and van Deursen, Arie},
title = {Evolutionary Testing for Crash Reproduction},
year = {2016},
isbn = {9781450341660},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897010.2897015},
doi = {10.1145/2897010.2897015},
abstract = {Manual crash reproduction is a labor-intensive and time-consuming task. Therefore, several solutions have been proposed in literature for automatic crash reproduction, including generating unit tests via symbolic execution and mutation analysis. However, various limitations adversely affect the capabilities of the existing solutions in covering a wider range of crashes because generating helpful tests that trigger specific execution paths is particularly challenging.In this paper, we propose a new solution for automatic crash reproduction based on evolutionary unit test generation techniques. The proposed solution exploits crash data from collected stack traces to guide search-based algorithms toward the generation of unit test cases that can reproduce the original crashes. Results from our preliminary study on real crashes from Apache Commons libraries show that our solution can successfully reproduce crashes which are not reproducible by two other state-of-art techniques.},
booktitle = {Proceedings of the 9th International Workshop on Search-Based Software Testing},
pages = {1–4},
numpages = {4},
keywords = {genetic algorithm, test case generation, crash reproduction, search-based software testing},
location = {Austin, Texas},
series = {SBST '16}
}

