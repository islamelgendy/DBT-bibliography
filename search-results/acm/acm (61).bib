@inproceedings{10.1145/3328433.3328455,
author = {Mattis, Toni and D\"{u}rsch, Falco and Hirschfeld, Robert},
title = {Faster Feedback through Lexical Test Prioritization},
year = {2019},
isbn = {9781450362573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328433.3328455},
doi = {10.1145/3328433.3328455},
abstract = {Immediacy and continuity of feedback are desirable properties during programming. Automated tests are a widely used practice to gain feedback on whether test authors' expectations are consistent with an implementation. With growing test suites, feedback becomes less immediate and is obtained less frequently because of that. The objective of test prioritization is to choose an order of tests that catches errors as early as possible, ideally within a time frame that we can consider live.Research in test prioritization often relies on dynamic analysis, which is expensive to obtain. Newer approaches focus on most recently edited source code locations and propose IR (information retrieval) approaches that regard a change to the software as query against a collection of tests.We study the capability of the IR approach to reduce testing time in the presence of faults using the example of open-source Python projects, identify trade-offs in classical TF-IDF-based IR frameworks, and propose different approaches that consider lexical and semantic context of a change, including topic modeling.We conclude that even simple IR strategies achieve immediate error detection, especially when tests themselves were edited alongside program code. We further discuss applications of this approach in live programming environments, where change granularity does not leave sufficient time to run a test suite entirely.},
booktitle = {Proceedings of the Conference Companion of the 3rd International Conference on Art, Science, and Engineering of Programming},
articleno = {21},
numpages = {10},
keywords = {testing, information retrieval, feedback, topic models},
location = {Genova, Italy},
series = {Programming '19}
}

@inproceedings{10.1109/AST.2007.6,
author = {Bertolino, Antonia and Gao, Jinghua and Marchetti, Eda and Polini, Andrea},
title = {Automatic Test Data Generation for XML Schema-Based Partition Testing},
year = {2007},
isbn = {0769529712},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/AST.2007.6},
doi = {10.1109/AST.2007.6},
abstract = {We present the XML-based Partition Testing (XPT) approach for the automatic generation of XML instances from a XML Schema. The approach is inspired by the well-known Category Partition method for black-box testing. The generated instances can be used for inter-operability testing of applications that expect in input conforming XML instances, as well as for other interesting purposes, such as database population, XML Schema benchmarking, web services testing, and so on. The implementation of XPT in a prototype tool called TAXI is described. To limit the number of generated instances, TAXI also incorporates practical strategies for handling element weights and type values.},
booktitle = {Proceedings of the Second International Workshop on Automation of Software Test},
pages = {4},
series = {AST '07}
}

@inproceedings{10.1145/2464996.2465000,
author = {Park, Chang Seo and Sen, Koushik and Iancu, Costin},
title = {Scaling Data Race Detection for Partitioned Global Address Space Programs},
year = {2013},
isbn = {9781450321303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2464996.2465000},
doi = {10.1145/2464996.2465000},
abstract = {Contemporary and future programming languages for HPC promote hybrid parallelism and shared memory abstractions using a global address space. In this programming style, data races occur easily and are notoriously hard to find. Existing state-of-the-art data race detectors exhibit 10X-100X performance degradation and do not handle hybrid parallelism. In this paper we present the first complete implementation of data race detection at scale for UPC programs. Our implementation tracks local and global memory references in the program and it uses two techniques to reduce the overhead: 1) hierarchical function and instruction level sampling; and 2) exploiting the runtime persistence of aliasing and locality specific to Partitioned Global Address Space applications. The results indicate that both techniques are required in practice: well optimized instruction sampling introduces overheads as high as 6500% (65X slowdown), while each technique in separation is able to reduce it only to 1000% (10X slowdown). When applying the optimizations in conjunction our tool finds all previously known data races in our benchmark programs with at most 50% overhead when running on 2048 cores. Furthermore, while previous results illustrate the benefits of function level sampling, our experiences show that this technique does not work for scientific programs: instruction sampling or a hybrid approach is required.},
booktitle = {Proceedings of the 27th International ACM Conference on International Conference on Supercomputing},
pages = {47–58},
numpages = {12},
keywords = {data race, sampling, tracing, instrumentation overhead},
location = {Eugene, Oregon, USA},
series = {ICS '13}
}

@inproceedings{10.1145/3180374.3181331,
author = {Li, Yuting and Su, Jianmin and Yang, Xiaoxing},
title = {Multi-Objective vs. Single-Objective Approaches for Software Defect Prediction},
year = {2018},
isbn = {9781450354318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180374.3181331},
doi = {10.1145/3180374.3181331},
abstract = {Software defect prediction employs attributes of software modules to identify defect-prone modules and thus improves software reliability by allocating testing resources more efficiently. Realizing that single-objective methods might be insufficient for solving defect prediction problems, some researchers have proposed multi-objective learning approaches, and proved better performance of multi-objective than single-objective methods. However, existing compared single-objective methods optimize a completely different goal from goals of multi-objective approaches, which might lead to bias. In this paper, we compare a multi-objective approach that optimizes two objectives and a single-objective approach that directly optimizes a trade-off of the two objectives, in order to further investigate the comparison of multi-objective and single-objective approaches. The conclusion will help to appropriately choose multi-objective or single-objective learning approaches for defect prediction.},
booktitle = {Proceedings of the 2018 2nd International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {122–127},
numpages = {6},
keywords = {single-objective learning, software defect prediction, Multi-objective learning, cost, effectiveness},
location = {Wuhan, China},
series = {ICMSS 2018}
}

@inproceedings{10.1145/1134285.1134437,
author = {Ma, Yu-Seung and Harrold, Mary Jean and Kwon, Yong-Rae},
title = {Evaluation of Mutation Testing for Object-Oriented Programs},
year = {2006},
isbn = {1595933751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1134285.1134437},
doi = {10.1145/1134285.1134437},
abstract = {The effectiveness of mutation testing depends heavily on the types of faults that the mutation operators are designed to represent. Thus, the quality of the mutation operators is key to mutation testing. Although, mutation operators for object-oriented languages have previously been presented, little research has been done to show the usefulness of the class mutation operators. To assess the usefulness of class mutation operators, we conducted two empirical studies. In the first study, we examine the number and kinds of mutants that are generated for object-oriented programs. In the second study, we investigate the way in which class mutation operators model faults that are not detected by traditional mutation testing. We conducted our studies using a well-known object-oriented system, BCEL.},
booktitle = {Proceedings of the 28th International Conference on Software Engineering},
pages = {869–872},
numpages = {4},
location = {Shanghai, China},
series = {ICSE '06}
}

@inproceedings{10.1145/3275245.3275257,
author = {Siqueira, Bento R. and J\'{u}nior, Misael Costa and Ferrari, Fabiano C. and Santib\'{a}\~{n}ez, Daniel S. M. and Menotti, Ricardo and Camargo, Valter V.},
title = {Experimenting with a Multi-Approach Testing Strategy for Adaptive Systems},
year = {2018},
isbn = {9781450365659},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3275245.3275257},
doi = {10.1145/3275245.3275257},
abstract = {Context: Testing adaptive systems (ASs) is particularly challenging due to certain characteristics such as the high number of possible configurations, runtime adaptations and the interactions between the system and its surrounding environment. Therefore, the combination of different testing approaches in order to compose a strategy is expected to improve the quality of the designed test suites. Objective: To devise and experiment with a testing strategy for ASs that relies on particular characteristics of these systems. Method: We ranked testing approaches for ASs and devised a strategy that is composed of the three top-ranked ones. The rankings address the challenges that can be mitigated by the approaches, activities from a typical testing process, and characteristics observed in some AS implementations. The strategy was applied to two adaptive systems for mobile devices. Results: The approach was applied to both systems. We observed partial gains in terms of fault detection and structural coverage when results are analysed separately for each system, even though no improvements were obtained with the application of the third approach. Conclusion: The strategy, despite being incipient, is promising and motivates a deeper analysis of results and new experiment rounds. Furthermore, it can evolve as long as the rankings are updated with new approaches.},
booktitle = {Proceedings of the 17th Brazilian Symposium on Software Quality},
pages = {111–120},
numpages = {10},
keywords = {testing challenges, Adaptive systems, testing strategy},
location = {Curitiba, Brazil},
series = {SBQS}
}

@inproceedings{10.1145/2591062.2591192,
author = {Hoseini, Salman and Hamou-Lhadj, Abdelwahab and Desrosiers, Patrick and Tapp, Martin},
title = {Software Feature Location in Practice: Debugging Aircraft Simulation Systems},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591192},
doi = {10.1145/2591062.2591192},
abstract = { In this paper, we report on a study that we have conducted at CAE, one of the largest civil aircraft simulation companies in the world, in which we have developed a feature location approach to help software engineers debug simulation scenarios. A simulation scenario consists of a set of software components, configured in a certain way. A simulation fails when it does not behave as intended. This is typically a sign of a configuration problem. To detect configuration errors, we propose FELODE (Feature Location for Debugging), an approach that uses a single trace combined with user queries. When applied to CAE systems, FELODE achieves in average a precision of 50% and a recall of up to 100%. },
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {225–234},
numpages = {10},
keywords = {Feature Location, Avionic Systems, Debugging, Trace Analysis},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@inproceedings{10.1145/2095050.2095099,
author = {Kell, Stephen and Irwin, Conrad},
title = {Virtual Machines Should Be Invisible},
year = {2011},
isbn = {9781450311830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2095050.2095099},
doi = {10.1145/2095050.2095099},
abstract = {Current VM designs prioritise implementor freedom and performance, at the expense of other concerns of the end programmer. We motivate an alternative approach to VM design aiming to be unobtrusive in general, and prioritising two key concerns specifically: foreign function interfacing and support for runtime analysis tools (such as debuggers, profilers etc.). We describe our experiences building a Python VM in this manner, and identify some simple constraints that help enable low-overhead foreign function interfacing and direct use of native tools. We then discuss how to extend this towards a higher-performance VM suitable for Java or similar languages.},
booktitle = {Proceedings of the Compilation of the Co-Located Workshops on DSM'11, TMC'11, AGERE! 2011, AOOPES'11, NEAT'11, &amp; VMIL'11},
pages = {289–296},
numpages = {8},
keywords = {native code, interoperability, dwarf, python, ffi, debugging},
location = {Portland, Oregon, USA},
series = {SPLASH '11 Workshops}
}

@article{10.1145/3392031,
author = {Xue, Yinxing and Li, Yan-Fu},
title = {Multi-Objective Integer Programming Approaches for Solving the Multi-Criteria Test-Suite Minimization Problem: Towards Sound and Complete Solutions of a Particular Search-Based Software-Engineering Problem},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3392031},
doi = {10.1145/3392031},
abstract = {Test-suite minimization is one key technique for optimizing the software testing process. Due to the need to balance multiple factors, multi-criteria test-suite minimization (MCTSM) becomes a popular research topic in the recent decade. The MCTSM problem is typically modeled as integer linear programming (ILP) problem and solved with weighted-sum single objective approach. However, there is no existing approach that can generate sound (i.e., being Pareto-optimal) and complete (i.e., covering the entire Pareto front) Pareto-optimal solution set, to the knowledge of the authors. In this work, we first prove that the ILP formulation can accurately model the MCTSM problem and then propose the multi-objective integer programming (MOIP) approaches to solve it. We apply our MOIP approaches on three specific MCTSM problems and compare the results with those of the cutting-edge methods, namely, NonlinearFormulation_LinearSolver (NF_LS) and two Multi-Objective Evolutionary Algorithms (MOEAs). The results show that our MOIP approaches can always find sound and complete solutions on five subject programs, using similar or significantly less time than NF_LS and two MOEAs do. The current experimental results are quite promising, and our approaches have the potential to be applied for other similar search-based software engineering problems.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jun},
articleno = {20},
numpages = {50},
keywords = {Regression testing, CWMOIP, ε-constraint method, big-M method, multi-objective integer programming, test-suite minimization, search-based software engineering}
}

@inproceedings{10.5555/2663370.2663380,
author = {Betz, Robin M. and Walker, Ross C.},
title = {Implementing Continuous Integration Software in an Established Computational Chemistry Software Package},
year = {2013},
isbn = {9781467362610},
publisher = {IEEE Press},
abstract = {Continuous integration is the software engineering principle of rapid and automated development and testing. We identify several key points of continuous integration and demonstrate how they relate to the needs of computational science projects by discussing the implementation and relevance of these principles to AMBER, a large and widely used molecular dynamics software package. The use of a continuous integration server has both improved collaboration and communication between AMBER developers, who are globally distributed, as well as making failure and benchmark information that would be time consuming for individual developers to obtain by themselves, available in real time. Continuous integration servers currently available are aimed at the software engineering community and can be difficult to adapt to the needs of computational science projects, however as demonstrated in this paper the effort payoff can be rapid since uncommon errors are found and contributions from geographically separated researchers are unified into one easily-accessible web-based interface.},
booktitle = {Proceedings of the 5th International Workshop on Software Engineering for Computational Science and Engineering},
pages = {68–74},
numpages = {7},
location = {San Francisco, California},
series = {SE-CSE '13}
}

@inproceedings{10.1145/3445814.3446727,
author = {Ahmad, Adil and Lee, Sangho and Fonseca, Pedro and Lee, Byoungyoung},
title = {Kard: Lightweight Data Race Detection with per-Thread Memory Protection},
year = {2021},
isbn = {9781450383172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445814.3446727},
doi = {10.1145/3445814.3446727},
abstract = {Finding data race bugs in multi-threaded programs has proven challenging. A promising direction is to use dynamic detectors that monitor the program’s execution for data races. However, despite extensive work on dynamic data race detection, most proposed systems for commodity hardware incur prohibitive overheads due to expensive compiler instrumentation of memory accesses; hence, they are not efficient enough to be used in all development and testing settings.  KARD is a lightweight system that dynamically detects data races caused by inconsistent lock usage—when a program concurrently accesses the same memory object using different locks or only some of the concurrent accesses are synchronized using a common lock. Unlike existing detectors, KARD does not monitor memory accesses using expensive compiler instrumentation. Instead, KARD leverages commodity per-thread memory protection, Intel Memory Protection Keys (MPK). Using MPK, KARD ensures that a shared object is only accessible to a single thread in its critical section, and captures all violating accesses from other concurrent threads. KARD overcomes various limitations of MPK by introducing key-enforced race detection, employing consolidated unique page allocation, carefully managing protection keys, and automatically pruning out non-racy or redundant violations. Our evaluation shows that KARD detects all data races caused by inconsistent lock usage and has a low geometric mean execution time overhead: 7.0% on PARSEC and SPLASH-2x benchmarks and 5.3% on a set of real-world applications (NGINX, memcached, pigz, and Aget).},
booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {647–660},
numpages = {14},
keywords = {data race, memory protection, lock, concurrency},
location = {Virtual, USA},
series = {ASPLOS 2021}
}

@inproceedings{10.1145/2591062.2591179,
author = {Vierhauser, Michael and Rabiser, Rick and Gr\"{u}nbacher, Paul},
title = {A Case Study on Testing, Commissioning, and Operation of Very-Large-Scale Software Systems},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591179},
doi = {10.1145/2591062.2591179},
abstract = { An increasing number of software systems today are very-large-scale software systems (VLSS) with system-of-systems (SoS) architectures. Due to their heterogeneity and complexity VLSS are difficult to understand and analyze, which results in various challenges for development and evolution. Existing software engineering processes, methods, and tools do not sufficiently address the characteristics of VLSS. Also, there are only a few empirical studies on software engineering for VLSS. We report on results of an exploratory case study involving engineers and technical project managers of an industrial automation VLSS for metallurgical plants. The paper provides empirical evidence on how VLSS are tested, commissioned, and operated in practice. The paper discusses practical challenges and reports industrial requirements regarding process and tool support. In particular, software processes and tools need to provide general guidance at the VLSS level as well as specific methods and tools for systems that are part of the VLSS. Processes and tools need to support multi-disciplinary engineering across system boundaries. Furthermore, managing variability and evolution is success-critical in VLSS verification and validation. },
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {125–134},
numpages = {10},
keywords = {Verification and Validation, Case Study, Very-Large-Scale Software Systems},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@inproceedings{10.1145/2491411.2491450,
author = {Machiry, Aravind and Tahiliani, Rohan and Naik, Mayur},
title = {Dynodroid: An Input Generation System for Android Apps},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491450},
doi = {10.1145/2491411.2491450},
abstract = { We present a system Dynodroid for generating relevant inputs to unmodified Android apps. Dynodroid views an app as an event-driven program that interacts with its environment by means of a sequence of events through the Android framework. By instrumenting the framework once and for all, Dynodroid monitors the reaction of an app upon each event in a lightweight manner, using it to guide the generation of the next event to the app. Dynodroid also allows interleaving events from machines, which are better at generating a large number of simple inputs, with events from humans, who are better at providing intelligent inputs.  We evaluated Dynodroid on 50 open-source Android apps, and compared it with two prevalent approaches: users manually exercising apps, and Monkey, a popular fuzzing tool. Dynodroid, humans, and Monkey covered 55%, 60%, and 53%, respectively, of each app's Java source code on average. Monkey took 20X more events on average than Dynodroid. Dynodroid also found 9 bugs in 7 of the 50 apps, and 6 bugs in 5 of the top 1,000 free apps on Google Play. },
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {224–234},
numpages = {11},
keywords = {GUI testing, testing event-driven programs, Android},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@inproceedings{10.1145/2307636.2307661,
author = {Pathak, Abhinav and Jindal, Abhilash and Hu, Y. Charlie and Midkiff, Samuel P.},
title = {What is Keeping My Phone Awake? Characterizing and Detecting No-Sleep Energy Bugs in Smartphone Apps},
year = {2012},
isbn = {9781450313018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2307636.2307661},
doi = {10.1145/2307636.2307661},
abstract = {Despite their immense popularity in recent years, smartphones are and will remain severely limited by their battery life. Preserving this critical resource has driven smartphone OSes to undergo a paradigm shift in power management: by default every component, including the CPU, stays off or in an idle state, unless the app explicitly instructs the OS to keep it on! Such a policy encumbers app developers to explicitly juggle power control APIs exported by the OS to keep the components on, during their active use by the app and off otherwise. The resulting power-encumbered programming unavoidably gives rise to a new class of software energy bugs on smartphones called no-sleep bugs, which arise from mis-handling power control APIs by apps or the framework and result in significant and unexpected battery drainage.This paper makes the first advances towards understanding and automatically detecting software energy bugs on smartphones. It makes the following three contributions: (1) we present the first comprehensive study of real world no-sleep energy bug characteristics; (2) we propose the first automatic solution to detect these bugs based on the classic reaching definitions dataflow analysis algorithm; (3) we provide experimental data showing that our tool accurately detected all 17 known instances of no-sleep bugs and found 34 new bugs in the 73 apps examined.},
booktitle = {Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services},
pages = {267–280},
numpages = {14},
keywords = {smartphones, energy-bug, nosleep-bug, energy, mobile},
location = {Low Wood Bay, Lake District, UK},
series = {MobiSys '12}
}

@inbook{10.1145/3468264.3468600,
author = {Wong, Chu-Pan and Santiesteban, Priscila and K\"{a}stner, Christian and Le Goues, Claire},
title = {VarFix: Balancing Edit Expressiveness and Search Effectiveness in Automated Program Repair},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468600},
abstract = {Automatically repairing a buggy program is essentially a search problem, searching for code transformations that pass a set of tests. Various search strategies have been explored, but they either navigate the search space in an ad hoc way using heuristics, or systemically but at the cost of limited edit expressiveness in the kinds of supported program edits. In this work, we explore the possibility of systematically navigating the search space without sacrificing edit expressiveness. The key enabler of this exploration is variational execution, a dynamic analysis technique that has been shown to be effective at exploring many similar executions in large search spaces. We evaluate our approach on IntroClassJava and Defects4J, showing that a systematic search is effective at leveraging and combining fixing ingredients to find patches, including many high-quality patches and multi-edit patches.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {354–366},
numpages = {13}
}

@inproceedings{10.5555/2819261.2819285,
author = {Winter, Stefan and Piper, Thorsten and Schwahn, Oliver and Natella, Roberto and Suri, Neeraj and Cotroneo, Domenico},
title = {GRINDER: On Reusability of Fault Injection Tools},
year = {2015},
publisher = {IEEE Press},
abstract = {Fault Injection (FI) is an established testing technique to assess the fault-tolerance of computer systems. FI tests are usually highly automated for efficiency and to prevent human error from affecting result reliability. Most existing FI automation tools have been built for a specific application domain, i.e., a certain system under test (SUT) and fault types to test the SUT against, which significantly restricts their reusability.To improve reusability, generalist fault injection tools have been developed to decouple SUT-independent functionality from SUT-specific code. Unfortunately, existing generalist tools often embed subtle and implicit assumptions about the target system that affect their reusability. Furthermore, no assessments have been conducted how much effort the SUT-specific adaptation of generalist tools entails in comparison to re-implementation from scratch. In this paper, we present GRINDER, an open-source, highly-reusable FI tool, and report on its applicability in two very different systems (the Android OS in an emulated environment, and a real-time AUTOSAR system) under four different FI scenarios.},
booktitle = {Proceedings of the 10th International Workshop on Automation of Software Test},
pages = {75–79},
numpages = {5},
keywords = {robustness testing, test automation, fault injection, software reuse, test tools},
location = {Florence, Italy},
series = {AST '15}
}

@inproceedings{10.1109/ASE.2019.00028,
author = {Sondhi, Devika and Purandare, Rahul},
title = {Segate: Unveiling Semantic Inconsistencies between Code and Specification of String Inputs},
year = {2019},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00028},
doi = {10.1109/ASE.2019.00028},
abstract = {Automated testing techniques are often assessed on coverage based metrics. However, despite giving good coverage, the test cases may miss the gap between functional specification and the code implementation. This gap may be subtle in nature, arising due to the absence of logical checks, either in the implementation or in the specification, resulting in inconsistencies in the input definition. The inconsistencies may be prevalent especially for structured inputs, commonly specified using string-based data types. Our study on defects reported over popular libraries reveals that such gaps may not be limited to input validation checks. We propose a test generation technique for structured string inputs where we infer inconsistencies in input definition to expose semantic gaps in the method under test and the method specification. We assess this technique using our tool Segate, Semantic Gap Tester. Segate uses static analysis and automaton modeling to infer the gap and generate test cases. On our benchmark dataset, comprising of defects reported in 15 popular open-source libraries, written in Java, Segate was able to generate tests to expose 80% of the defects.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {200–212},
numpages = {13},
keywords = {testing, automaton modeling, static analysis, data flow analysis, string input generation, regular expression},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/2508075.2514881,
author = {Ohmann, Peter},
title = {CSI: Crash Scene Investigation},
year = {2013},
isbn = {9781450319959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508075.2514881},
doi = {10.1145/2508075.2514881},
abstract = {Prior work proposes inexpensive, tunable tracing of acyclic paths and callsite coverage to enhance post-failure memory dumps. To better understand this data, current work investigates the benefit of each piece of traced data independently, their interplay, future low-cost data to collect, and further analysis uses of the post-mortem data.},
booktitle = {Proceedings of the 2013 Companion Publication for Conference on Systems, Programming, &amp; Applications: Software for Humanity},
pages = {123–124},
numpages = {2},
keywords = {core dumps, program slicing, failure analysis},
location = {Indianapolis, Indiana, USA},
series = {SPLASH '13}
}

@article{10.1145/3360603,
author = {Celik, Ahmet and Nie, Pengyu and Rossbach, Christopher J. and Gligoric, Milos},
title = {Design, Implementation, and Application of GPU-Based Java Bytecode Interpreters},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {OOPSLA},
url = {https://doi.org/10.1145/3360603},
doi = {10.1145/3360603},
abstract = {We present the design and implementation of GVM, the first system for executing Java bytecode entirely on GPUs. GVM is ideal for applications that execute a large number of short-living tasks, which share a significant fraction of their codebase and have similar execution time. GVM uses novel algorithms, scheduling, and data layout techniques to adapt to the massively parallel programming and execution model of GPUs. We apply GVM to generate and execute tests for Java projects. First, we implement a sequence-based test generation on top of GVM and design novel algorithms to avoid redundant test sequences. Second, we use GVM to execute randomly generated test cases. We evaluate GVM by comparing it with two existing Java bytecode interpreters (Oracle JVM and Java Pathfinder), as well as with the Oracle JVM with just-in-time (JIT) compiler, which has been engineered and optimized for over twenty years. Our evaluation shows that sequence-based test generation on GVM outperforms both Java Pathfinder and Oracle JVM interpreter. Additionally, our results show that GVM performs as well as running our parallel sequence-based test generation algorithm using JVM with JIT with many CPU threads. Furthermore, our evaluation on several classes from open-source projects shows that executing randomly generated tests on GVM outperforms sequential execution on JVM interpreter and JVM with JIT.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {177},
numpages = {28},
keywords = {Complete matching, Graphics Processing Unit, Shape matching, Java bytecode interpreter, Sequence-based test generation}
}

@inproceedings{10.1145/2839509.2844626,
author = {Politz, Joe Gibbs and Collard, Joseph M. and Guha, Arjun and Fisler, Kathi and Krishnamurthi, Shriram},
title = {The Sweep: Essential Examples for In-Flow Peer Review},
year = {2016},
isbn = {9781450336857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2839509.2844626},
doi = {10.1145/2839509.2844626},
abstract = {In in-flow peer review, students provide feedback to one another on intermediate artifacts on their way to a final submission. Prior work has studied examples and tests as a potentially useful initial artifact for review. Unfortunately, large test suites are onerous to produce and especially to review. We instead propose the notion of a sweep, an artificially constrained set of tests that illustrates common and interesting behavior. We present experimental data across several courses that show that sweeps have reasonable quality, and are also a good target for peer review; for example, students usually (over half the time) suggest new tests to one another in a review.},
booktitle = {Proceedings of the 47th ACM Technical Symposium on Computing Science Education},
pages = {243–248},
numpages = {6},
keywords = {testing, example-first programming, peer review, code review},
location = {Memphis, Tennessee, USA},
series = {SIGCSE '16}
}

