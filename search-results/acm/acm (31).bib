@inproceedings{10.1145/3205651.3208230,
author = {Mironovich, Vladimir and Buzdalov, Maxim and Vyatkin, Valeriy},
title = {From Fitness Landscape Analysis to Designing Evolutionary Algorithms: The Case Study in Automatic Generation of Function Block Applications},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208230},
doi = {10.1145/3205651.3208230},
abstract = {Search-based software engineering, a discipline that often requires finding optimal solutions, can be a viable source for problems that bridge theory and practice of evolutionary computation. In this research we consider one such problem: generation of data connections in a distributed control application designed according to the IEC 61499 industry standard.We perform the analysis of the fitness landscape of this problem and find why exactly the simplistic (1 + 1) evolutionary algorithm is slower than expected when finding an optimal solution to this problem. To counteract, we develop a population-based algorithm that explicitly maximises diversity among the individuals in the population. We show that this measure indeed helps to improve the running times.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1902–1905},
numpages = {4},
keywords = {evolutionary computation, program synthesis, search-based software engineering, population diversity},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@inproceedings{10.1109/ICSE.2017.66,
author = {Perez, Alexandre and Abreu, Rui and van Deursen, Arie},
title = {A Test-Suite Diagnosability Metric for Spectrum-Based Fault Localization Approaches},
year = {2017},
isbn = {9781538638682},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2017.66},
doi = {10.1109/ICSE.2017.66},
abstract = {Current metrics for assessing the adequacy of a test-suite plainly focus on the number of components (be it lines, branches, paths) covered by the suite, but do not explicitly check how the tests actually exercise these components and whether they provide enough information so that spectrum-based fault localization techniques can perform accurate fault isolation. We propose a metric, called DDU, aimed at complementing adequacy measurements by quantifying a test-suite's diagnosability, i.e., the effectiveness of applying spectrum-based fault localization to pinpoint faults in the code in the event of test failures. Our aim is to increase the value generated by creating thorough test-suites, so they are not only regarded as error detection mechanisms but also as effective diagnostic aids that help widely-used fault-localization techniques to accurately pinpoint the location of bugs in the system. Our experiments show that optimizing a test suite with respect to DDU yields a 34% gain in spectrum-based fault localization report accuracy when compared to the standard branch-coverage metric.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering},
pages = {654–664},
numpages = {11},
keywords = {diagnosability, coverage, testing},
location = {Buenos Aires, Argentina},
series = {ICSE '17}
}

@inproceedings{10.1145/2338966.2336805,
author = {Yang, Shengqian and Yan, Dacong and Xu, Guoqing and Rountev, Atanas},
title = {Dynamic Analysis of Inefficiently-Used Containers},
year = {2012},
isbn = {9781450314558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2338966.2336805},
doi = {10.1145/2338966.2336805},
abstract = { The goal of this work is to identify suspicious usage of containers, as an indicator of potential performance inefficiencies. To analyze container-related behavior and performance, we propose a dynamic analysis that tracks and records the flow of element objects to/from container objects. The observed interactions among containers and their elements is captured by a container-element flow graph. This graph is then analyzed by three detectors of potential container inefficiencies, based on certain patterns of suspicious behavior. In a promising initial study, this approach uncovered a number of performance problems in realistic Java applications. },
booktitle = {Proceedings of the Ninth International Workshop on Dynamic Analysis},
pages = {30–35},
numpages = {6},
location = {Minneapolis, MN, USA},
series = {WODA 2012}
}

@article{10.1145/3511805,
author = {Ram\'{\i}rez, Aurora and Feldt, Robert and Romero, Jos\'{e} Ra\'{u}l},
title = {A Taxonomy of Information Attributes for Test Case Prioritisation: Applicability, Machine Learning},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3511805},
doi = {10.1145/3511805},
abstract = {Most software companies have extensive test suites and re-run parts of them continuously to ensure recent changes have no adverse effects. Since test suites are costly to execute, industry needs methods for test case prioritisation (TCP). Recently, TCP methods use machine learning (ML) to exploit the information known about the system under test (SUT) and its test cases. However, the value added by ML-based TCP methods should be critically assessed with respect to the cost of collecting the information. This paper analyses two decades of TCP research, and presents a taxonomy of 91 information attributes that have been used. The attributes are classified with respect to their information sources and the characteristics of their extraction process. Based on this taxonomy, TCP methods validated with industrial data and those applying ML are analysed in terms of information availability, attribute combination and definition of data features suitable for ML. Relying on a high number of information attributes, assuming easy access to SUT code and simplified testing environments are identified as factors that might hamper industrial applicability of ML-based TCP. The TePIA taxonomy provides a reference framework to unify terminology and evaluate alternatives considering the cost-benefit of the information attributes.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jan},
keywords = {machine learning, test case prioritisation, regression testing, taxonomy, industry}
}

@article{10.1145/2659118.2659125,
author = {Agarwal, Pragya and Agrawal, Arun Prakash},
title = {Fault-Localization Techniques for Software Systems: A Literature Review},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2659118.2659125},
doi = {10.1145/2659118.2659125},
abstract = {Software is a major component of any computer system. To maintain the quality of software, early fault localization is necessary. Many different fault-localization methods have been used by researchers. Ideally, methods for fault-localization are used in such a way that one is able to detect as many faults as possible using the least resources. But, in general, it is hard to predict a test suite's fault-localization capability. This paper gives a review of the previous studies that are related to software fault-localization methods. It reviews various journal and conference papers on localization of faults and various methods for localization of faults proposed in the literature.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {sep},
pages = {1–8},
numpages = {8},
keywords = {software systems, debugging, test-case prioritization methods, fault localization}
}

@inproceedings{10.1145/3023956.3023963,
author = {Halin, Axel and Nuttinck, Alexandre and Acher, Mathieu and Devroey, Xavier and Perrouin, Gilles and Heymans, Patrick},
title = {Yo Variability! JHipster: A Playground for Web-Apps Analyses},
year = {2017},
isbn = {9781450348119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3023956.3023963},
doi = {10.1145/3023956.3023963},
abstract = {Though variability is everywhere, there has always been a shortage of publicly available cases for assessing variability-aware tools and techniques as well as supports for teaching variability-related concepts. Historical software product lines contains industrial secrets their owners do not want to disclose to a wide audience. The open source community contributed to large-scale cases such as Eclipse, Linux kernels, or web-based plugin systems (Drupal, WordPress). To assess accuracy of sampling and prediction approaches (bugs, performance), a case where all products can be enumerated is desirable. As configuration issues do not lie within only one place but are scattered across technologies and assets, a case exposing such diversity is an additional asset. To this end, we present in this paper our efforts in building an explicit product line on top of JHipster, an industrial open-source Web-app configurator that is both manageable in terms of configurations (≈ 163,000) and diverse in terms of technologies used. We present our efforts in building a variability-aware chain on top of JHipster's configurator and lessons learned using it as a teaching case at the University of Rennes. We also sketch the diversity of analyses that can be performed with our infrastructure as well as early issues found using it. Our long term goal is both to support students and researchers studying variability analysis and JHipster developers in the maintenance and evolution of their tools.},
booktitle = {Proceedings of the Eleventh International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {44–51},
numpages = {8},
keywords = {case study, variability-related analyses, web-apps},
location = {Eindhoven, Netherlands},
series = {VAMOS '17}
}

@inproceedings{10.1145/3468264.3473935,
author = {Ye, Jiaming and Chen, Ke and Xie, Xiaofei and Ma, Lei and Huang, Ruochen and Chen, Yingfeng and Xue, Yinxing and Zhao, Jianjun},
title = {An Empirical Study of GUI Widget Detection for Industrial Mobile Games},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473935},
doi = {10.1145/3468264.3473935},
abstract = {With the widespread adoption of smartphones in our daily life, mobile games experienced increasing demand over the past years. Meanwhile, the quality of mobile games has been continuously drawing more and more attention, which can greatly affect the player experience. For better quality assurance, general-purpose testing has been extensively studied for mobile apps. However, due to the unique characteristic of mobile games, existing mobile testing techniques may not be directly suitable and applicable. To better understand the challenges in mobile game testing, in this paper, we first initiate an early step to conduct an empirical study towards understanding the challenges and pain points of mobile game testing process at our industrial partner NetEase Games. Specifically, we first conduct a survey from the mobile test development team at NetEase Games via both scrum interviews and questionnaires. We found that accurate and effective GUI widget detection for mobile games could be the pillar to boost the automation of mobile game testing and other downstream analysis tasks in practice.  We then continue to perform comparative studies to investigate the effectiveness of state-of-the-art general-purpose mobile app GUI widget detection methods in the context of mobile games. To this end, we also develop a technique to automatically collect GUI widgets region information of industrial mobile games, which is equipped with a heuristic-based data cleaning method for quality refinement of the labeling results. Our evaluation shows that: (1) Existing GUI widget detection methods for general-purpose mobile apps cannot perform well on industrial mobile games. (2) Mobile game exhibits obvious difference from other general-purpose mobile apps in the perspective GUI widgets. Our further in-depth analysis reveals high diversity and density characteristics of mobile game GUI widgets could be the major reasons that post the challenges for existing methods, which calls for new research methods and better industry practices. To enable further research along this line, we construct the very first GUI widget detection benchmark, specially designed for mobile games, incorporating both our collected dataset and the state-of-the-art widget detection methods for mobile apps, which could also be the basis for further study of many downstream quality assurance tasks (e.g., testing and analysis) for mobile games.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1427–1437},
numpages = {11},
keywords = {Game Testing, Deep Learning, GUI Detection},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/2663887.2663906,
author = {Zhao, Mingyi and Grossklags, Jens and Chen, Kai},
title = {An Exploratory Study of White Hat Behaviors in a Web Vulnerability Disclosure Program},
year = {2014},
isbn = {9781450331524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663887.2663906},
doi = {10.1145/2663887.2663906},
abstract = {White hats are making significant contributions to cybersecurity by submitting vulnerability discovery reports to public vulnerability disclosure programs and company-initiated vulnerability reward programs. In this paper, we study white hat behaviors by analyzing a 3.5-year dataset which documents the contributions of 3254 white hats and their submitted 16446 Web vulnerability reports. Our dataset is collected from Wooyun, the predominant Web vulnerability disclosure program in China. We first show that Wooyun is continuously attracting new contributors from the white hat community. We then examine white hats' contributions along several dimensions. In particular, we provide evidence about the diversity inside Wooyun's white hat community and discuss the importance of this diversity for vulnerability discovery. Our results suggest that more participation, and thereby more diversity, contributes to higher productivity of the vulnerability discovery process.},
booktitle = {Proceedings of the 2014 ACM Workshop on Security Information Workers},
pages = {51–58},
numpages = {8},
keywords = {vulnerability discovery, behavior, vulnerability disclosure},
location = {Scottsdale, Arizona, USA},
series = {SIW '14}
}

@inproceedings{10.1145/3107091.3107095,
author = {Alipour, Mohammad Amin},
title = {Fault Injection in the Internet of Things Applications},
year = {2017},
isbn = {9781450351126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3107091.3107095},
doi = {10.1145/3107091.3107095},
abstract = { Internet of Things comprises a large proportion of cyber-physical systems where a group of interconnected sensors and actuators, usually with cloud backends, are used to perform a task. Vendors of Internet of Things devices provide programming frameworks to help users—usually with little knowledge of embedded or distributed systems—to develop their applications. Most of these frameworks provide an event-based abstraction of the underlying cyber-physical systems.  In this paper, we propose a preliminary set of faults for fault injection in event-based Internet of Things as a part of our ongoing investigation into the testing of Internet of Things applications. These faults intend to enhance the awareness of the programmers about the situations that might arise in the wild. },
booktitle = {Proceedings of the 1st ACM SIGSOFT International Workshop on Testing Embedded and Cyber-Physical Systems},
pages = {9–11},
numpages = {3},
keywords = {Fault Injection, Internet of Things, Smart Home},
location = {Santa Barbara, CA, USA},
series = {TECPS 2017}
}

@article{10.1145/3485533,
author = {Su, Ting and Yan, Yichen and Wang, Jue and Sun, Jingling and Xiong, Yiheng and Pu, Geguang and Wang, Ke and Su, Zhendong},
title = {Fully Automated Functional Fuzzing of Android Apps for Detecting Non-Crashing Logic Bugs},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {OOPSLA},
url = {https://doi.org/10.1145/3485533},
doi = {10.1145/3485533},
abstract = {Android apps are GUI-based event-driven software and have become ubiquitous in recent years. Obviously, functional correctness is critical for an app’s success. However, in addition to crash bugs, non-crashing functional bugs (in short as “non-crashing bugs” in this work) like inadvertent function failures, silent user data lost and incorrect display information are prevalent, even in popular, well-tested apps. These non-crashing functional bugs are usually caused by program logic errors and manifest themselves on the graphic user interfaces (GUIs). In practice, such bugs pose significant challenges in effectively detecting them because (1) current practices heavily rely on expensive, small-scale manual validation (the lack of automation); and (2) modern fully automated testing has been limited to crash bugs (the lack of test oracles). This paper fills this gap by introducing independent view fuzzing, a novel, fully automated approach for detecting non-crashing functional bugs in Android apps. Inspired by metamorphic testing, our key insight is to leverage the commonly-held independent view property of Android apps to manufacture property-preserving mutant tests from a set of seed tests that validate certain app properties. The mutated tests help exercise the tested apps under additional, adverse conditions. Any property violations indicate likely functional bugs for further manual confirmation. We have realized our approach as an automated, end-to-end functional fuzzing tool, Genie. Given an app, (1) Genie automatically detects non-crashing bugs without requiring human-provided tests and oracles (thus fully automated); and (2) the detected non-crashing bugs are diverse (thus general and not limited to specific functional properties), which set Genie apart from prior work. We have evaluated Genie on 12 real-world Android apps and successfully uncovered 34 previously unknown non-crashing bugs in their latest releases — all have been confirmed, and 22 have already been fixed. Most of the detected bugs are nontrivial and have escaped developer (and user) testing for at least one year and affected many app releases, thus clearly demonstrating Genie’s effectiveness. According to our analysis, Genie achieves a reasonable true positive rate of 40.9%, while these 34 non-crashing bugs could not be detected by prior fully automated GUI testing tools (as our evaluation confirms). Thus, our work complements and enhances existing manual testing and fully automated testing for crash bugs.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {156},
numpages = {31},
keywords = {Logic bugs, Non-crashing functional bugs, GUI testing, Android apps}
}

@inproceedings{10.1145/3191697.3213801,
author = {Marra, Matteo},
title = {Debugging Support for Big Data Processing Applications},
year = {2018},
isbn = {9781450355131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3191697.3213801},
doi = {10.1145/3191697.3213801},
abstract = {Current trends in Big Data processing indicate that the volume, velocity and variety of data are increasing quickly due to an explosion on diversity and number of sources of information. This poses challenges for Big Data frameworks to be able to meet the new requirements of the emerging real-time streaming data processing applications. This research project focuses on the academic study of integrated development environments and debugging tools to assist the software development of Big Data applications.},
booktitle = {Conference Companion of the 2nd International Conference on Art, Science, and Engineering of Programming},
pages = {241–242},
numpages = {2},
keywords = {Debugging, Big Data, Tools, Meta-Level Interfaces},
location = {Nice, France},
series = {Programming'18 Companion}
}

@inbook{10.1145/3238147.3238227,
author = {Cha, Sooyoung and Lee, Seonho and Oh, Hakjoo},
title = {Template-Guided Concolic Testing via Online Learning},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238227},
abstract = {We present template-guided concolic testing, a new technique for effectively reducing the search space in concolic testing. Addressing the path-explosion problem has been a significant challenge in concolic testing. Diverse search heuristics have been proposed to mitigate this problem but using search heuristics alone is not sufficient to substantially improve code coverage for real-world programs. The goal of this paper is to complement existing techniques and achieve higher coverage by exploiting templates in concolic testing. In our approach, a template is a partially symbolized input vector whose job is to reduce the search space. However, choosing a right set of templates is nontrivial and significantly affects the final performance of our approach. We present an algorithm that automatically learns useful templates online, based on data collected from previous runs of concolic testing. The experimental results with open-source programs show that our technique achieves greater branch coverage and finds bugs more effectively than conventional concolic testing.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {408–418},
numpages = {11}
}

@article{10.1145/3428261,
author = {Winterer, Dominik and Zhang, Chengyu and Su, Zhendong},
title = {On the Unusual Effectiveness of Type-Aware Operator Mutations for Testing SMT Solvers},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428261},
doi = {10.1145/3428261},
abstract = {We propose type-aware operator mutation, a simple, but unusually effective approach for testing SMT solvers. The key idea is to mutate operators of conforming types within the seed formulas to generate well-typed mutant formulas. These mutant formulas are then used as the test cases for SMT solvers. We realized type-aware operator mutation within the OpFuzz tool and used it to stress-test Z3 and CVC4, two state-of-the-art SMT solvers. Type-aware operator mutations are unusually effective: During one year of extensive testing with OpFuzz, we reported 1092 bugs on Z3’s and CVC4’s respective GitHub issue trackers, out of which 819 unique bugs were confirmed and 685 of the confirmed bugs were fixed by the developers. The detected bugs are highly diverse — we found bugs of many different types (soundness bugs, invalid model bugs, crashes, etc.), logics and solver configurations. We have further conducted an in-depth study of the bugs found by OpFuzz. The study results show that the bugs found by OpFuzz are of high quality. Many of them affect core components of the SMT solvers’ codebases, and some required major changes for the developers to fix. Among the 819 confirmed bugs found by OpFuzz,184 were soundness bugs, the most critical bugs in SMT solvers,and 489 were in the default modes of the solvers. Notably, OpFuzz found 27 critical soundness bugs in CVC4, which has proved to be a very stable SMT solver.},
journal = {Proc. ACM Program. Lang.},
month = {nov},
articleno = {193},
numpages = {25},
keywords = {Fuzz testing, Type-aware operator mutation, SMT solvers}
}

@inproceedings{10.1145/3267809.3267841,
author = {Las-Casas, Pedro and Mace, Jonathan and Guedes, Dorgival and Fonseca, Rodrigo},
title = {Weighted Sampling of Execution Traces: Capturing More Needles and Less Hay},
year = {2018},
isbn = {9781450360111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267809.3267841},
doi = {10.1145/3267809.3267841},
abstract = {End-to-end tracing has emerged recently as a valuable tool to improve the dependability of distributed systems, by performing dynamic verification and diagnosing correctness and performance problems. Contrary to logging, end-to-end traces enable coherent sampling of the entire execution of specific requests, and this is exploited by many deployments to reduce the overhead and storage requirements of tracing. This sampling, however, is usually done uniformly at random, which dedicates a large fraction of the sampling budget to common, 'normal' executions, while missing infrequent, but sometimes important, erroneous or anomalous executions. In this paper we define the representative trace sampling problem, and present a new approach, based on clustering of execution graphs, that is able to bias the sampling of requests to maximize the diversity of execution traces stored towards infrequent patterns. In a preliminary, but encouraging work, we show how our approach chooses to persist representative and diverse executions, even when anomalous ones are very infrequent.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {326–332},
numpages = {7},
keywords = {weighted sampling, distributed tracing},
location = {Carlsbad, CA, USA},
series = {SoCC '18}
}

@article{10.1145/2180921.2180936,
author = {Jiang, Shujuan and Zhang, Yanmei and Yi, Dandan},
title = {Test Data Generation Approach for Basis Path Coverage},
year = {2012},
issue_date = {May 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/2180921.2180936},
doi = {10.1145/2180921.2180936},
abstract = {On the basis of determining the feasibility of paths, this paper proposes an evolutionary approach to generating test data for feasible basis path coverage. First, the structure of the program under test is expressed by a control flow graph, and the target paths are encoded into the form of hybrid-coding that efficiently combines the statement label with the outcome of a conditional statement (i.e. T or F). Then, the genetic algorithm is employed to generate test data for multiple paths coverage, and the fitness function of an input data (an individual) takes into account the degree of the execution track matching the target paths. Finally, the proposed approach is applied in several benchmark programs. The experimental results show that the proposed approach cannot only avoid redundant test but also improve the efficiency of test data generation effectively},
journal = {SIGSOFT Softw. Eng. Notes},
month = {may},
pages = {1–7},
numpages = {7},
keywords = {test data generation, genetic algorithm, feasible basis path coverage, control flow graph}
}

@inproceedings{10.1145/2875913.2875926,
author = {Yan, Minzhi and Sun, Hailong and Liu, Xudong},
title = {Efficient Testing of Web Services with Mobile Crowdsourcing},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875926},
doi = {10.1145/2875913.2875926},
abstract = {Nowadays, online Internet services are pervasive and can be invoked from diverse locations in anytime with multitudinous devices. Conventional testing approaches for online services like Web services are conducted by professional tester or developers and cannot simulate the real world running environment of a service. Fortunately, crowdtesting technology brings us promising hope and has acquired increasing interests and adoption because it can recruit plenty of end users to test services under real world environment with low cost. Meanwhile, improved mobile network techniques make crowdsourcing happen anywhere and anytime. In this paper, we present iTest which combines mobile crowdsourcing and web service testing together to support the performance testing of web services. iTest is a framework for service developers to submit their web services and conveniently get the test results from the crowd testers. Firstly, we analyze the key problems need to be solved in a mobile crowdtesting platform; secondly, the architecture of iTest framework and the workflow in it are presented; Thirdly, we perform experiments to illustrate that both the way to access network and tester's location influence the performance of web service, and formulate the tester selection problem as a Set Cover Problem and propose a greedy algorithm for solving this problem; Next, experimental evaluation of the tester selection algorithm is performed to illustrate its efficiency. Finally, we conclude our work and provide the directions for future work.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {157–165},
numpages = {9},
keywords = {mobile crowdsourcing, set cover, Web service testing, web service, crowd testing},
location = {Wuhan, China},
series = {Internetware '15}
}

@article{10.1145/3542946,
author = {Khanfir, Ahmed and Koyuncu, Anil and Papadakis, Mike and Cordy, Maxime and Bissyand\'{e}, Tegawende F. and Klein, Jacques and Le Traon, Yves},
title = {<span class="smallcaps SmallerCapital">iBiR</span>: Bug Report Driven Fault Injection},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3542946},
doi = {10.1145/3542946},
abstract = {Much research on software engineering relies on experimental studies based on fault injection. Fault injection, however, is not often relevant to emulate real-world software faults since it “blindly” injects large numbers of faults. It remains indeed challenging to inject few but realistic faults that target a particular functionality in a program. In this work, we introduce iBiR, a fault injection tool that addresses this challenge by exploring change patterns associated to user-reported faults. To inject realistic faults, we create mutants by re-targeting a bug report driven automated program repair system, i.e., reversing its code transformation templates. iBiR is further appealing in practice since it requires deep knowledge of neither code nor tests, but just of the program’s relevant bug reports. Thus, our approach focuses the fault injection on the feature targeted by the bug report. We assess iBiR by considering the Defects4J dataset. Experimental results show that our approach outperforms the fault injection performed by traditional mutation testing in terms of semantic similarity with the original bug, when applied at either system or class levels of granularity, and provides better, statistically significant, estimations of test effectiveness (fault detection). Additionally, when injecting 100 faults, iBiR injects faults that couple with the real ones in  around 36% of the cases, while mutation testing achieves less than  4%.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {may},
keywords = {Bug Reports, Mutation, Fault Injection, Information Retrieval}
}

@article{10.1145/1022494.1022546,
author = {Williams, Laurie},
title = {On the Need for a Process for Making Reliable Quality Comparisons with Industrial Data},
year = {2004},
issue_date = {September 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/1022494.1022546},
doi = {10.1145/1022494.1022546},
abstract = {Many factors influence quality data obtained from industrial case studies making comparisons difficult. In this paper, two longitudinal industrial case study experiences are shared which illustrate the complications that can arise. The first is a case study of an IBM team that transitioned to the use of test-driven development. The primary quality measure was functional verification test defects normalized by lines of code. The second case study was performed with an Extreme Programming team at Sabre Airline Solutions. Both test defects and field defects were compared. In both case studies, differences existed which made the comparisons indicative but not absolute.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {sep},
pages = {1–4},
numpages = {4}
}

@inbook{10.1145/3368089.3409754,
author = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
title = {Is Neuron Coverage a Meaningful Measure for Testing Deep Neural Networks?},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409754},
abstract = {Recent effort to test deep learning systems has produced an intuitive and compelling test criterion called neuron coverage (NC), which resembles the notion of traditional code coverage. NC measures the proportion of neurons activated in a neural network and it is implicitly assumed that increasing NC improves the quality of a test suite. In an attempt to automatically generate a test suite that increases NC, we design a novel diversity promoting regularizer that can be plugged into existing adversarial attack algorithms. We then assess whether such attempts to increase NC could generate a test suite that (1) detects adversarial attacks successfully, (2) produces natural inputs, and (3) is unbiased to particular class predictions. Contrary to expectation, our extensive evaluation finds that increasing NC actually makes it harder to generate an effective test suite: higher neuron coverage leads to fewer defects detected, less natural inputs, and more biased prediction preferences. Our results invoke skepticism that increasing neuron coverage may not be a meaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection, naturalness, and output impartiality in tandem.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {851–862},
numpages = {12}
}

@article{10.1145/3360585,
author = {Bader, Johannes and Scott, Andrew and Pradel, Michael and Chandra, Satish},
title = {Getafix: Learning to Fix Bugs Automatically},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {OOPSLA},
url = {https://doi.org/10.1145/3360585},
doi = {10.1145/3360585},
abstract = {Static analyzers help find bugs early by warning about recurring bug categories. While fixing these bugs still remains a mostly manual task in practice, we observe that fixes for a specific bug category often are repetitive. This paper addresses the problem of automatically fixing instances of common bugs by learning from past fixes. We present Getafix, an approach that produces human-like fixes while being fast enough to suggest fixes in time proportional to the amount of time needed to obtain static analysis results in the first place.  Getafix is based on a novel hierarchical clustering algorithm that summarizes fix patterns into a hierarchy ranging from general to specific patterns. Instead of an expensive exploration of a potentially large space of candidate fixes, Getafix uses a simple yet effective ranking technique that uses the context of a code change to select the most appropriate fix for a given bug.  Our evaluation applies Getafix to 1,268 bug fixes for six bug categories reported by popular static analyzers for Java, including null dereferences, incorrect API calls, and misuses of particular language constructs. The approach predicts exactly the human-written fix as the top-most suggestion between 12% and 91% of the time, depending on the bug category. The top-5 suggestions contain fixes for 526 of the 1,268 bugs. Moreover, we report on deploying the approach within Facebook, where it contributes to the reliability of software used by billions of people. To the best of our knowledge, Getafix is the first industrially-deployed automated bug-fixing tool that learns fix patterns from past, human-written fixes to produce human-like fixes.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {159},
numpages = {27},
keywords = {Automated program repair, Code transform, Patch generation}
}

