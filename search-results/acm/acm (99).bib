@inproceedings{10.1145/3510309.3510343,
author = {Wang, Meijuan and Liu, Peng and Yang, Xiaochun},
title = {Exploration and Practice of Cultivating Students' Innovative Ability Based on MuRobotSys},
year = {2021},
isbn = {9781450385800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510309.3510343},
doi = {10.1145/3510309.3510343},
abstract = {With the continuous changes in modern undergraduate education, personnel training, and education methods, the significance of innovation ability in comprehensive quality training has become a normalized goal. The simulation platform's experimental learning can provide the foundation for the integrated teaching model's training of engineering project simulation ability as well as training of innovative ideas and divergent thinking. Therefore, the development and practice of engineering projects based on the simulation platform are common experimental methods in teaching. This article locates the innovative talent training concept of “high comprehensive quality and strong practical ability,” which is based on the MURobotSys simulation platform to carry out robot innovation teaching, put forward and practice the “Three-layers” teaching system, under the traction of innovative practical teaching and robot competition. Providing a complete, reasonable and efficient teaching system for the cultivation of students’ innovative ability has important significance and effect on the cultivation of students’ innovative ability.},
booktitle = {2021 4th International Conference on Education Technology Management},
pages = {213–218},
numpages = {6},
keywords = {Robot, MURobotSys simulation platform, Constructivist learning theory, Innovative teaching},
location = {Tokyo, Japan},
series = {ICETM'21}
}

@inproceedings{10.1145/3312662.3312670,
author = {Ding, Yuxin and Zhong, Deming and Xu, Zhi and Zhao, Yukun and Sun, Rui and Guo, Rui},
title = {An Airborne Software CMA Application Method Based on ARP4761},
year = {2019},
isbn = {9781450361897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3312662.3312670},
doi = {10.1145/3312662.3312670},
abstract = {Common Mode Analysis (CMA) is an important part of the civil aircraft system safety assessment, which runs through the whole process of aircraft design and manufacturing. Common mode analysis is used to verify the independence of systems, functions, or components to meet safety requirements. At present, common-mode analysis research focuses on the hardware in the system, and there are few studies on common-mode analysis of software, and a relatively complete method has not yet been formed. In recent years, the role, scale, and complexity of software in the aviation field have been rising, and many problems have also arisen. For example, the application of the Integrated Modular Avionics (IMA) system has greatly increased the comprehensiveness and complexity of aircraft functions. This can lead to an increased probability of fault propagation, potentially leading to common mode failure of the software. Analysis of the common mode failure of software has become a potential future demand for the aviation industry. Based on the analysis method of common mode analysis in Guidelines and Methods for Conducting the Safety Assessment Process on Civil Airborne Systems and Equipment (ARP4761), this paper presents a common mode analysis method that can be used for aviation airborne software. It can solve the common mode analysis problem of aviation airborne software and reduce the safety problems caused by software common mode.},
booktitle = {Proceedings of the 2019 3rd International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {1–8},
numpages = {8},
keywords = {Software safety, Airborne Software, ARP4761, CMA},
location = {Wuhan, China},
series = {ICMSS 2019}
}

@inproceedings{10.1145/3393672.3398493,
author = {Mbenza, Patrick and Burny, Nicolas},
title = {Computing Aesthetics of Concrete User Interfaces},
year = {2020},
isbn = {9781450379847},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3393672.3398493},
doi = {10.1145/3393672.3398493},
abstract = {Since aesthetics of a graphical user interface have become a sub-factor of the ISO 25010 standard on software quality, organisations start wondering how to practically evaluate this property in a consistent way. To address this challenge, we present a process for computing aesthetics at the level of a Concrete User Interface instead of Final User Interface to make it platform independent. This process consists of performing the following steps: reverse engineer a final user interface into its concrete equivalent, optionally edit it, and automatically compute ten aesthetic metrics at the level of concrete user interfaces.},
booktitle = {Companion Proceedings of the 12th ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
articleno = {4},
numpages = {8},
keywords = {metrics/measures, usability testing, aesthetics},
location = {Sophia Antipolis, France},
series = {EICS '20 Companion}
}

@inproceedings{10.1109/ICPC.2019.00043,
author = {Schnappinger, Markus and Osman, Mohd Hafeez and Pretschner, Alexander and Fietzke, Arnaud},
title = {Learning a Classifier for Prediction of Maintainability Based on Static Analysis Tools},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICPC.2019.00043},
doi = {10.1109/ICPC.2019.00043},
abstract = {Static Code Analysis Tools are a popular aid to monitor and control the quality of software systems. Still, these tools only provide a large number of measurements that have to be interpreted by the developers in order to obtain insights about the actual quality of the software. In cooperation with professional quality analysts, we manually inspected source code from three different projects and evaluated its maintainability. We then trained machine learning algorithms to predict the human maintainability evaluation of program classes based on code metrics. The code metrics include structural metrics such as nesting depth, cloning information and abstractions like the number of code smells. We evaluated this approach on a dataset of more than 115,000 Lines of Code. Our model is able to predict up to 81% of the threefold labels correctly and achieves a precision of 80%. Thus, we believe this is a promising contribution towards automated maintainability prediction. In addition, we analyzed the attributes in our created dataset and identified the features with the highest predictive power, i.e. code clones, method length, and the number of alerts raised by the tool Teamscale. This insight provides valuable help for users needing to prioritize tool measurements.},
booktitle = {Proceedings of the 27th International Conference on Program Comprehension},
pages = {243–248},
numpages = {6},
keywords = {software maintenance, static code analysis, software quality, maintenance tools, code comprehension},
location = {Montreal, Quebec, Canada},
series = {ICPC '19}
}

@inproceedings{10.1145/604251.604257,
author = {Mueller, Gary and Borzuchowski, Janet},
title = {Extreme Embedded a Report from the Front Line},
year = {2002},
isbn = {1581134711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/604251.604257},
doi = {10.1145/604251.604257},
abstract = {Many embedded development environments are stuck somewhere in the backwash of software technology. Structured programming practices, with the artifacts of those methodologies liberally scattered about, are the norm in these environments. The world has changed since structured methodologies first emerged, with shorter and shorter market windows and increasingly sophisticated customers demanding more and more capabilities at lower and lower cost. Embedded system development must also adapt to these market imperatives to stay competitive. This paper describes the challenges, obstacles, and successes encountered in applying eXtreme Programming on an embedded legacy product with a team of seasoned, veteran C programmers.},
booktitle = {OOPSLA 2002 Practitioners Reports},
pages = {1–ff},
keywords = {eXtreme programming, embedded},
location = {Seattle, Washington},
series = {OOPSLA '02}
}

@inproceedings{10.1145/2866614.2866627,
author = {Devroey, Xavier and Perrouin, Gilles and Legay, Axel and Schobbens, Pierre-Yves and Heymans, Patrick},
title = {Search-Based Similarity-Driven Behavioural SPL Testing},
year = {2016},
isbn = {9781450340199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2866614.2866627},
doi = {10.1145/2866614.2866627},
abstract = {Dissimilar test cases have been proven to be effective to reveal faults in software systems. In the Software Product Line (SPL) context, this criterion has been applied successfully to mimic combinatorial interaction testing in an efficient and scalable manner by selecting and prioritising most dissimilar configurations of feature models using evolutionary algorithms. In this paper, we extend dissimilarity to behavioural SPL models (FTS) in a search-based approach, and evaluate its effectiveness in terms of product and fault coverage. We investigate different distances as well as as single-objective algorithms, (dissimilarity on actions, random, all-actions). Our results on four case studies show the relevance of dissimilarity-based test generation for behavioural SPL models, especially on the largest case-study where no other approach can match it.},
booktitle = {Proceedings of the Tenth International Workshop on Variability Modelling of Software-Intensive Systems},
pages = {89–96},
numpages = {8},
keywords = {Dissimilarity Testing, Featured Transition System, Software Product Line Testing},
location = {Salvador, Brazil},
series = {VaMoS '16}
}

@article{10.1145/3358227,
author = {Luo, Zhengxiong and Zuo, Feilong and Jiang, Yu and Gao, Jian and Jiao, Xun and Sun, Jiaguang},
title = {Polar: Function Code Aware Fuzz Testing of ICS Protocol},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3358227},
doi = {10.1145/3358227},
abstract = {Industrial Control System (ICS) protocols are widely used to build communications among system components. Compared with common internet protocols, ICS protocols have more control over remote devices by carrying a specific field called “function code”, which assigns what the receive end should do. Therefore, it is of vital importance to ensure their correctness. However, traditional vulnerability detection techniques such as fuzz testing are challenged by the increasing complexity of these diverse ICS protocols. In this paper, we present a function code aware fuzzing framework — Polar, which automatically extracts semantic information from the ICS protocol and utilizes this information to accelerate security vulnerability detection. Based on static analysis and dynamic taint analysis, Polar&nbsp;initiates the values of the function code field and identifies some vulnerable operations. Then, novel semantic aware mutation and selection strategies are designed to optimize the fuzzing procedure. For evaluation, we implement Polar&nbsp;on top of two popular fuzzers — AFL and AFLFast, and conduct experiments on several widely used ICS protocols such as Modbus, IEC104, and IEC 61850. Results show that, compared with AFL and AFLFast, Polar&nbsp; achieves the same code coverage and bug detection numbers at the speed of 1.5X-12X. It also gains increase with 0%--91% more paths within 24 hours. Furthermore, Polar&nbsp;has exposed 10 previously unknown vulnerabilities in those protocols, 6 of which have been assigned unique CVE identifiers in the US National Vulnerability Database.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {oct},
articleno = {93},
numpages = {22},
keywords = {Fuzz testing, vulnerability detection, industrial control system protocol, function code}
}

@inbook{10.1145/3417990.3419484,
author = {Babikian, Aren A.},
title = {Automated Generation of Test Scenario Models for the System-Level Safety Assurance of Autonomous Vehicles},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3419484},
abstract = {Autonomous vehicles controlled by advanced machine learning techniques are significantly gaining in popularity. However, the safety engineering practices currently used in such vehicles are not capable of justifying that AI techniques would prevent unsafe situations with a designated level of confidence and reliability. One related challenge is the perpetually changing environment that autonomous vehicles must interact with, which must be taken into consideration when deriving test suites for their safety assurance. As a result, a common approach for testing autonomous vehicles involves subjecting them to test scenarios and evaluating their system-level quality of service. As it stands, such system-level testing approaches do exist but only at a prototypical and conceptual level: these approaches cannot handle complex system-level traffic scenarios and related coverage criteria. I plan to address this challenge through my PhD studies by (1) defining situation coverage as an abstract coverage criteria for autonomous vehicle testing, (2) evaluating situation coverage of existing test suites obtained by off-the-shelf simulation tools, and (3) proposing a test suite generation approach that provides test scenarios with increasing situation coverage as output.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {24},
numpages = {7}
}

@inproceedings{10.1145/2915970.2915973,
author = {Cartaxo, Bruno},
title = {Integrating Evidence from Systematic Reviews with Software Engineering Practice through Evidence Briefings},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2915973},
doi = {10.1145/2915970.2915973},
abstract = {This paper proposes the questions and method to conduct a research intending to promote the first steps towards a better integration between evidence from systematic reviews and software engineering practice. First, we are planning to conduct a tertiary study to identify systematic reviews in software engineering. Second, we intend to investigate how those reviews relate to practitioners' issues reported in a leading software engineering Question &amp; Answer platform. Third, we plan to generate and evaluate Evidence Briefings from those reviews in order to establish a medium to transfer knowledge acquired from systematic reviews to practice. This paper also presents some preliminary results from pilot studies we have been conducting.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {6},
numpages = {4},
keywords = {evidence briefings, systematic reviews, evidence-based software engineering, knowledge transfer, stackexchange},
location = {Limerick, Ireland},
series = {EASE '16}
}

@inproceedings{10.1007/978-3-642-36757-1_2,
author = {Mussa, Mohamed and Khendek, Ferhat},
title = {Identification and Selection of Interaction Test Scenarios for Integration Testing},
year = {2012},
isbn = {9783642367564},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-36757-1_2},
doi = {10.1007/978-3-642-36757-1_2},
abstract = {Integration testing checks for compatibility and interoperability between the components in the system. Integration test models are, typically, generated independently from the other testing level models. In our research, we aim at a model-based framework across unit, integration, and acceptance level testing. This paper contributes to this framework and for the generation of integration test models from unit test models. More precisely, we focus on component interaction test scenarios identification and selection. Following our approach, at each integration step, unit test cases with interaction scenarios involving the component and the context are identified, selected and merged to build the integration test model for the next step. Unit test stubs and drivers are reused in the integration test model. Redundant test cases are eliminated from the generated test models.},
booktitle = {Proceedings of the 7th International Conference on System Analysis and Modeling: Theory and Practice},
pages = {16–33},
numpages = {18},
keywords = {testing, components, interactions, model based testing, integration},
location = {Innsbruck, Austria},
series = {SAM'12}
}

@inproceedings{10.1145/3456887.3457455,
author = {Wang, Xueyan},
title = {Establishment on Comprehensive Quality Evaluation Index System of Computer Major College Students},
year = {2021},
isbn = {9781450389969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3456887.3457455},
doi = {10.1145/3456887.3457455},
abstract = {Aiming at the current situation of computer major talent training and the lack of unified evaluation standard for employers, this article follows the principles of "scientificity, system optimization, general comparability, practicality and guidance"; the evaluation index system structure model constructed by five first-level indexes, including technology, software engineering, and innovation ability. Each first-level index contains several second-level indexes; the weight of the index system is calculated based on the analytic hierarchy process, and the calculation results are analyzed. The research results of this article guide colleges and educational training institutions to formulate reasonable talent training programs, and have important guiding significance for training computer major with high comprehensive quality.},
booktitle = {2021 2nd International Conference on Computers, Information Processing and Advanced Education},
pages = {1027–1031},
numpages = {5},
keywords = {college students, comprehensive quality, evaluation index system, Computer major},
location = {Ottawa, ON, Canada},
series = {CIPAE 2021}
}

@inproceedings{10.1145/3371647.3371672,
author = {Yang, Yi and Yu, Dekuang},
title = {Research and Practice of Outcome Directed SPOC Teaching Model},
year = {2019},
isbn = {9781450372251},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371647.3371672},
doi = {10.1145/3371647.3371672},
abstract = {SPOC has its advantages in reshaping the traditional class teaching by providing learners with curriculum resources online, and learners manage self-learning as the mainstay. But currently problems have arisen as many instructors find it really not so convenient to monitor the learners on time and get their feedback promptly during the learning process. To overcome these obstacles, this paper introduced Outcome Directed education methodology, supported by constructivist learning theory, distributed cognitive theory, collaborative learning theory and activity theory, and constructed the Outcome Directed SPOC (0DS) model, which includes the design, development and evaluation system of SPOC teaching. This model has been applied in practice in the field of software technology. According to the professional requirements, the characteristics of students and of the curriculum, reasonable teaching strategies were designed by the guidance of the outcome requirements and the ability indicators to be reached, and a variety of teaching methods were appropriate taken use of. The teaching practice showed that ODS could promote the achievement of learning goals by improving the learners' capability of self-learning, self-discipline and problem solving.},
booktitle = {Proceedings of the 2019 3rd International Conference on Education and E-Learning},
pages = {46–51},
numpages = {6},
keywords = {teaching strategies, Outcome Directed SPOC (ODS) model, capability cultivation, software technology, learning effect},
location = {Barcelona, Spain},
series = {ICEEL 2019}
}

@inproceedings{10.1145/3342195.3387525,
author = {Piao, Guangyuan and Nicholson, Patrick K. and Lugones, Diego},
title = {Env2Vec: Accelerating VNF Testing with Deep Learning},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342195.3387525},
doi = {10.1145/3342195.3387525},
abstract = {The adoption of fast-paced practices for developing virtual network functions (VNFs) allows for continuous software delivery and creates a market advantage for network operators. This adoption, however, is problematic for testing engineers that need to assure, in shorter development cycles, certain quality of highly-configurable product releases running on heterogeneous clouds. Machine learning (ML) can accelerate testing workflows by detecting performance issues in new software builds. However, the overhead of maintaining several models for all combinations of build types, network configurations, and other stack parameters, can quickly become prohibitive and make the application of ML infeasible.We propose Env2Vec, a deep learning architecture that combines contextual features with historical resource usage, and characterizes the various stack parameters that influence the test execution within an embedding space, which allows it to generalize model predictions to previously unseen environments. We integrate a single ML model in the testing workflow to automatically debug errors and pinpoint performance bottlenecks. Results obtained with real testing data show an accuracy between 86.2%-100%, while reducing the false alarm rate by 20.9%-38.1% when reporting performance issues compared to state-of-the-art approaches.},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {41},
numpages = {16},
location = {Heraklion, Greece},
series = {EuroSys '20}
}

@inproceedings{10.5555/2819009.2819078,
author = {Simpson, Andrew and Martin, Andrew and Cremers, Cas and Flechais, Ivan and Martinovic, Ivan and Rasmussen, Kasper},
title = {Experiences in Developing and Delivering a Programme of Part-Time Education in Software and Systems Security},
year = {2015},
publisher = {IEEE Press},
abstract = {We report upon our experiences in developing and delivering a programme of part-time education in Software and Systems Security at the University of Oxford. The MSc in Software and Systems Security is delivered as part of the Software Engineering Programme at Oxford --- a collection of one-week intensive courses aimed at individuals who are responsible for the procurement, development, deployment and maintenance of large-scale software-based systems. We expect that our experiences will be useful to those considering a similar journey.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {435–444},
numpages = {10},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3369255.3369265,
author = {Yang, Yi and Yu, Dekuang},
title = {Reform and Practice Path of Composite Personnel Cultivation Model for Postgraduates},
year = {2019},
isbn = {9781450372541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369255.3369265},
doi = {10.1145/3369255.3369265},
abstract = {Postgraduate education of professional degree aims to cultivate innovative talents with both theory and practice capabilities. In order to achieve the training goal and enhance students' engineering practical ability and innovative spirit, this paper proposed a reform plan, including design of integrated training methods for graduate education of professional degrees, reconstruction of core courses and teaching content, building of a three-stage personnel training process, carrying out of distinctive project training by a multi-level joint training support platform, and implementation of a school-enterprise collaborative process guidance and evaluation mechanism.},
booktitle = {Proceedings of the 2019 11th International Conference on Education Technology and Computers},
pages = {111–114},
numpages = {4},
keywords = {support platform, evaluation mechanism, collaborative process guidance, Postgraduates cultivation},
location = {Amsterdam, Netherlands},
series = {ICETC 2019}
}

@inproceedings{10.1145/3507971.3507977,
author = {Jiang, Jinman and Ma, Rui and Wang, Xiajing and He, Jinyuan and Tian, Donghai and Li, Jiating},
title = {MOAFL: Potential Seed Selection with Multi-Objective Particle Swarm Optimization},
year = {2021},
isbn = {9781450385190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3507971.3507977},
doi = {10.1145/3507971.3507977},
abstract = {Fuzzing has become one of the most widely used technology for discovering software vulnerabilities thanks to its effectiveness. However, even the state-of-the-art fuzzers are not very efficient at identifying promising seeds. Coverage-guided fuzzers like American Fuzzy Lop (AFL) usually employ single criterion to evaluate the quality of seeds that may pass up potential seeds. To overcome this problem, we design a potential seed selection scheme, called MOAFL. The key idea is to measure seed potential utilizing multiple objectives and prioritize promising seeds that are more likely to generate interesting seeds via mutation. More specifically, MOAFL leverages lightweight swarm intelligence techniques like Multi-Objective Particle Swarm Optimization (MOPSO) to handle multi-criteria seed selection, which allows MOAFL to choose promising seeds effectively. We implement this scheme based on AFL and our evaluations on LAVA-M dataset and 7 popular real-world programs demonstrate that MOAFL significantly increases the code coverage over AFL.},
booktitle = {2021 the 7th International Conference on Communication and Information Processing (ICCIP)},
pages = {26–31},
numpages = {6},
keywords = {Multiple Criteria, Seed Selection, AFL, Multi-Objective Particle Swarm Optimization (MOPSO)},
location = {Beijing, China},
series = {ICCIP 2021}
}

@inproceedings{10.1145/2753524.2753533,
author = {Stewart, Craig A. and Barnett, William K. and Wernert, Eric A. and Wernert, Julie A. and Welch, Von and Knepper, Richard},
title = {Sustained Software for Cyberinfrastructure: Analyses of Successful Efforts with a Focus on NSF-Funded Software},
year = {2015},
isbn = {9781450335669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2753524.2753533},
doi = {10.1145/2753524.2753533},
abstract = {Reliable software that provides needed functionality is clearly essential for an effective distributed cyberinfrastructure (CI) that supports comprehensive, balanced, and flexible distributed CI. Effective distributed cyberinfrastructure, in turn, supports science and engineering applications. The purpose of this study was to understand what factors lead to software projects being well sustained over the long run, focusing on software created with funding from the US National Science Foundation (NSF) and/or used by researchers funded by the NSF. We surveyed NSF-funded researchers and performed in-depth studies of software projects that have been sustained over many years. Successful projects generally used open-source software licenses and employed good software engineering practices and test practices. However, many projects that have not been well sustained over time also met these criteria. The features that stood out about successful projects included deeply committed leadership and some sort of user forum or conference at least annually. In some cases, software project leaders have employed multiple financial strategies over the course of a decades-old software project. Such well-sustained software is used in major distributed CI projects that support thousands of users, and this software is critical to the operation of major distributed CI facilities in the US. The findings of our study identify some characteristics of software that is relevant to the NSF-supported research community, and that has been sustained over many years.},
booktitle = {Proceedings of the 1st Workshop on The Science of Cyberinfrastructure: Research, Experience, Applications and Models},
pages = {63–72},
numpages = {10},
keywords = {cyberinfrastructure software, reusability, sustainability, open-source business models, software sustainability},
location = {Portland, Oregon, USA},
series = {SCREAM '15}
}

@inproceedings{10.1145/3442188.3445918,
author = {Hutchinson, Ben and Smart, Andrew and Hanna, Alex and Denton, Emily and Greer, Christina and Kjartansson, Oddur and Barnes, Parker and Mitchell, Margaret},
title = {Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445918},
doi = {10.1145/3442188.3445918},
abstract = {Datasets that power machine learning are often used, shared, and reused with little visibility into the processes of deliberation that led to their creation. As artificial intelligence systems are increasingly used in high-stakes tasks, system development and deployment practices must be adapted to address the very real consequences of how model development data is constructed and used in practice. This includes greater transparency about data, and accountability for decisions made when developing it. In this paper, we introduce a rigorous framework for dataset development transparency that supports decision-making and accountability. The framework uses the cyclical, infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields documents that facilitate improved communication and decision-making, as well as drawing attention to the value and necessity of careful data work. The proposed framework makes visible the often overlooked work and decisions that go into dataset creation, a critical step in closing the accountability gap in artificial intelligence and a critical/necessary resource aligned with recent work on auditing processes.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {560–575},
numpages = {16},
keywords = {requirements engineering, datasets, machine learning},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@inproceedings{10.1145/3446871.3469743,
author = {Young, Nick and Krishnamurthi, Shriram},
title = {Early Post-Secondary Student Performance of Adversarial Thinking},
year = {2021},
isbn = {9781450383264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3446871.3469743},
doi = {10.1145/3446871.3469743},
abstract = {Motivation. “Adversarial thinking” (at) is viewed as a central idea in cybersecurity. We believe a similar idea carries over into other critical areas as well, such as understanding the perils of social networks and machine learning. Objectives. What kinds of at can we expect of early post-secondary computing students? In particular, can they meaningfully analyze computing systems that are well beyond their technical ken? Is their analysis limited to only a social or only a technical space? Method. In an introductory post-secondary course, we study student responses to questions designed to exercise at, broadly defined. To do this we develop a rubric that provides insight into desirable content. Results. We find that these students are fairly strong at at. They are regularly able to adopt an adversarial or empathetic viewpoint and analyze quite sophisticated systems. Most of all, they can meaningfully do so (a) outside an explicit cybersecurity context, (b) even from an introductory level, and (c) well before they understand well the key technologies under evaluation. On the other hand, we also find several instances where students do not explore systems as much as they could, and fail to reference other material they know, which could be evidence of lack of transfer. In addition, our rubric would benefit from refinement that would enable a more sophisticated analysis of student responses. Discussion. Our work provides a baseline evaluation of what we can expect from students. It suggests that at can be introduced early in the curriculum, and in contexts outside computer security. },
booktitle = {Proceedings of the 17th ACM Conference on International Computing Education Research},
pages = {213–224},
numpages = {12},
keywords = {security, functional fixedness, creativity, adversarial thinking},
location = {Virtual Event, USA},
series = {ICER 2021}
}

@article{10.1145/2699682,
author = {Blem, Emily and Menon, Jaikrishnan and Vijayaraghavan, Thiruvengadam and Sankaralingam, Karthikeyan},
title = {ISA Wars: Understanding the Relevance of ISA Being RISC or CISC to Performance, Power, and Energy on Modern Architectures},
year = {2015},
issue_date = {March 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {0734-2071},
url = {https://doi.org/10.1145/2699682},
doi = {10.1145/2699682},
abstract = {RISC versus CISC wars raged in the 1980s when chip area and processor design complexity were the primary constraints and desktops and servers exclusively dominated the computing landscape. Today, energy and power are the primary design constraints and the computing landscape is significantly different: Growth in tablets and smartphones running ARM (a RISC ISA) is surpassing that of desktops and laptops running x86 (a CISC ISA). Furthermore, the traditionally low-power ARM ISA is entering the high-performance server market, while the traditionally high-performance x86 ISA is entering the mobile low-power device market. Thus, the question of whether ISA plays an intrinsic role in performance or energy efficiency is becoming important again, and we seek to answer this question through a detailed measurement-based study on real hardware running real applications. We analyze measurements on seven platforms spanning three ISAs (MIPS, ARM, and x86) over workloads spanning mobile, desktop, and server computing. Our methodical investigation demonstrates the role of ISA in modern microprocessors’ performance and energy efficiency. We find that ARM, MIPS, and x86 processors are simply engineering design points optimized for different levels of performance, and there is nothing fundamentally more energy efficient in one ISA class or the other. The ISA being RISC or CISC seems irrelevant.},
journal = {ACM Trans. Comput. Syst.},
month = {mar},
articleno = {3},
numpages = {34},
keywords = {technology scaling, Power, energy efficiency}
}

