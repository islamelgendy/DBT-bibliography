@inproceedings{10.1145/2993270.2993271,
author = {Comb\'{e}fis, S\'{e}bastien and Schils, Arnaud},
title = {Automatic Programming Error Class Identification with Code Plagiarism-Based Clustering},
year = {2016},
isbn = {9781450344029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993270.2993271},
doi = {10.1145/2993270.2993271},
abstract = { Online platforms to learn programming are very popular nowadays. These platforms must automatically assess codes submitted by the learners and must provide good quality feedbacks in order to support their learning. Classical techniques to produce useful feedbacks include using unit testing frameworks to perform systematic functional tests of the submitted codes or using code quality assessment tools. This paper explores how to automatically identify error classes by clustering a set of submitted codes, using code plagiarism detection tools to measure the similarity between the codes. The proposed approach and analysis framework are presented in the paper, along with a first experiment using the Code Hunt dataset. },
booktitle = {Proceedings of the 2nd International Code Hunt Workshop on Educational Software Engineering},
pages = {1–6},
numpages = {6},
keywords = {Code Similarity, Education, Automatic Code Assessment},
location = {Seattle, WA, USA},
series = {CHESE 2016}
}

@inproceedings{10.1145/197694.197724,
author = {Barbasch, Cheryl and Egnor, Dan},
title = {Always One More Bug: Applying AdaWise to Improve Ada Code},
year = {1994},
isbn = {0897916662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/197694.197724},
doi = {10.1145/197694.197724},
abstract = {AdaWise, a set of tools currently under development at ORA, performs automatic checks to verify the absence of common run-time errors affecting the correctness or portability of Ada programs. The tools can be applied to programs of arbitrary size, and they are conservative—that is, the absence of a warning guarantees the absence of a problem. If AdaWise issues a warning, there is a potential error that should be investigated by the programmer. AdaWise checks at compile-time for such potential errors as incorrect order dependence and erroneous execution due to improper aliasing. These errors are not detected by typical compilers. We ran two of the tools on several publicly available Ada software products to determine if the tools issue useful warnings without  bombarding the user with “false positives.” We found that AdaWise generated a small number of total warnings, and that false positives usually indicated areas of weakness in the products tested.This paper describes our preliminary tests using the AdaWise toolset, and analyzes the warnings that were issued.},
booktitle = {Proceedings of the Conference on TRI-Ada '94},
pages = {228–235},
numpages = {8},
location = {Baltimore, Maryland, USA},
series = {TRI-Ada '94}
}

@inproceedings{10.1145/581339.581414,
author = {Maccari, Alessandro},
title = {Experiences in Assessing Product Family Software Architecture for Evolution},
year = {2002},
isbn = {158113472X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/581339.581414},
doi = {10.1145/581339.581414},
abstract = {Software architecture assessments are a means to detect architectural problems before the bulk of development work is done. They facilitate planning of improvement activities early in the lifecycle and allow limiting the changes on any existing software. This is particularly beneficial when the architecture has been planned to (or already does) support a whole product family, or a set of products that share common requirements, architecture, components or code. As the family requirements evolve and new products are added, the need to assess the evolvability of the existing architecture is vital. I illustrate two assessment case studies I have recently worked on in the mobile telephone software domain: the Symbian operating system platform and the network resource access control software system. The former assessment has been carried out as a task within the European project ESAPS, while the latter has been performed solely by Nokia. By means of simple experimental data, I show evidence of the usefulness of architectural assessment as rated by the participating stakeholders. Both assessments have led to the identification of previously unknown architectural defects, and to the consequent planning of improvement initiatives. In both cases, stakeholders noted that a number of side benefits, including improvement of communication and architectural documentation, were also of considerable importance. I illustrate the lessons we have learned, and outline suggestions for future research and experimentation.},
booktitle = {Proceedings of the 24th International Conference on Software Engineering},
pages = {585–592},
numpages = {8},
location = {Orlando, Florida},
series = {ICSE '02}
}

@inproceedings{10.5555/2486788.2486881,
author = {Roy Choudhary, Shauvik and Prasad, Mukul R. and Orso, Alessandro},
title = {X-PERT: Accurate Identification of Cross-Browser Issues in Web Applications},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = { Due to the increasing popularity of web applications, and the number of browsers and platforms on which such applications can be executed, cross-browser incompatibilities (XBIs) are becoming a serious concern for organizations that develop web-based software. Most of the techniques for XBI detection developed to date are either manual, and thus costly and error-prone, or partial and imprecise, and thus prone to generating both false positives and false negatives. To address these limitations of existing techniques, we developed X-PERT, a new automated, precise, and comprehensive approach for XBI detection. X-PERT combines several new and existing differencing techniques and is based on our findings from an extensive study of XBIs in real-world web applications. The key strength of our approach is that it handles each aspects of a web application using the differencing technique that is best suited to accurately detect XBIs related to that aspect. Our empirical evaluation shows that X-PERT is effective in detecting real-world XBIs, improves on the state of the art, and can provide useful support to developers for the diagnosis and (eventually) elimination of XBIs. },
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {702–711},
numpages = {10},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/3437992.3439934,
author = {Annenkov, Danil and Milo, Mikkel and Nielsen, Jakob Botsch and Spitters, Bas},
title = {Extracting Smart Contracts Tested and Verified in Coq},
year = {2021},
isbn = {9781450382991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437992.3439934},
doi = {10.1145/3437992.3439934},
abstract = {We implement extraction of Coq programs to functional languages based on MetaCoq's certified erasure. As part of this, we implement an optimisation pass removing unused arguments. We prove the pass correct wrt. a conventional call-by-value operational semantics of functional languages. We apply this to two functional smart contract languages, Liquidity and Midlang, and to the functional language Elm.  Our development is done in the context of the ConCert framework that enables smart contract verification. We contribute a verified boardroom voting smart contract featuring maximum voter privacy such that each vote is kept private except under collusion of all other parties.  We also integrate property-based testing into ConCert using QuickChick and our development is the first to support testing properties of interacting smart contracts. We test several complex contracts such as a DAO-like contract, an escrow contract, an implementation of a Decentralized Finance (DeFi) contract which includes a custom token standard (Tezos FA2), and more.  In total, this gives us a way to write dependent programs in Coq, test them semi-automatically, verify, and then extract to functional smart contract languages, while retaining a small trusted computing base of only MetaCoq and the pretty-printers into these languages.},
booktitle = {Proceedings of the 10th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {105–121},
numpages = {17},
keywords = {smart contracts, proof assistants, formal verification, software correctness, blockchain, Coq, code extraction, certified programming, property-based testing},
location = {Virtual, Denmark},
series = {CPP 2021}
}

@inproceedings{10.1145/1566445.1566541,
author = {Vejandla, Pavan K. and Sherrell, Linda B.},
title = {Why an AI Research Team Adopted XP Practices},
year = {2009},
isbn = {9781605584218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1566445.1566541},
doi = {10.1145/1566445.1566541},
abstract = {In this paper, researchers describe their early experiences of using agile techniques while developing a solution to a specific, multi-objective real world problem called the United States Navy Sailors' Assignment Problem (SAP). Because the investigators are working in a research environment where the results produced at intermediate stages cause the requirements to continually change, an agile software development methodology was deemed most appropriate. Although the research team applied several agile practices, the paper emphasizes their experiences when performing test-first or test-driven development (TDD). When applying test-first development, the programmer writes test cases in the designated programming language prior to composing functional code. The objective during code implementation is to write code to pass a particular test case. Thus, the activities of specifying test cases, coding, and testing comprise an iterative process. As a part of this work, the authors compare test-driven development to the more traditional approaches of testing.},
booktitle = {Proceedings of the 47th Annual Southeast Regional Conference},
articleno = {72},
numpages = {4},
keywords = {extreme programming (XP), evolutionary multiobjective optimization, sailors' assignment problem, informed initialization algorithm, agile software development, test-driven development (TDD)},
location = {Clemson, South Carolina},
series = {ACM-SE 47}
}

@inproceedings{10.1145/3412452.3423573,
author = {Cernat, Marina and Staicu, Adelina Nicoleta and Stefanescu, Alin},
title = {Towards Automated Testing of RPA Implementations},
year = {2020},
isbn = {9781450381017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412452.3423573},
doi = {10.1145/3412452.3423573},
abstract = {Robotic Process Automation (RPA) is a technology that has grown tremendously in the last years, due to its usability in the area of process automation. An essential part of any software development process is quality assurance, so testing will be very important for RPA processes. However, the classical software techniques are not always suitable for the RPA software robots due to the mix of the graphical description of the robots and their implementations. In this short paper, we describe the state of the practice for testing of software robots and propose some ideas of test automation using model-based testing.},
booktitle = {Proceedings of the 11th ACM SIGSOFT International Workshop on Automating TEST Case Design, Selection, and Evaluation},
pages = {21–24},
numpages = {4},
keywords = {RPA testing, Model-based testing, Test automation, Robotic Process Automation (RPA)},
location = {Virtual, USA},
series = {A-TEST 2020}
}

@inproceedings{10.1145/2591062.2591114,
author = {Martinez, Matias and Weimer, Westley and Monperrus, Martin},
title = {Do the Fix Ingredients Already Exist? An Empirical Inquiry into the Redundancy Assumptions of Program Repair Approaches},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591114},
doi = {10.1145/2591062.2591114},
abstract = { Much initial research on automatic program repair has focused on experimental results to probe their potential to find patches and reduce development effort. Relatively less effort has been put into understanding the hows and whys of such approaches. For example, a critical assumption of the GenProg technique is that certain bugs can be fixed by copying and re-arranging existing code. In other words, GenProg assumes that the fix ingredients already exist elsewhere in the code. In this paper, we formalize these assumptions around the concept of ``temporal redundancy''. A temporally redundant commit is only composed of what has already existed in previous commits. Our experiments show that a large proportion of commits that add existing code are temporally redundant. This validates the fundamental redundancy assumption of GenProg. },
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {492–495},
numpages = {4},
keywords = {mining software repositories, automatic software repair},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@inproceedings{10.1145/2617548.2617550,
author = {Seaton, Chris and Van De Vanter, Michael L. and Haupt, Michael},
title = {Debugging at Full Speed},
year = {2014},
isbn = {9781450329163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2617548.2617550},
doi = {10.1145/2617548.2617550},
abstract = {Debugging support for highly optimized execution environments is notoriously difficult to implement. The Truffle/Graal platform for implementing dynamic languages offers an opportunity to resolve the apparent trade-off between debugging and high performance.Truffle/Graal-implemented languages are expressed as abstract syntax tree (AST) interpreters. They enjoy competitive performance through platform support for type specialization, partial evaluation, and dynamic optimization/deoptimization. A prototype debugger for Ruby, implemented on this platform, demonstrates that basic debugging services can be implemented with modest effort and without significant impact on program performance. Prototyped functionality includes breakpoints, both simple and conditional, at lines and at local variable assignments.The debugger interacts with running programs by inserting additional nodes at strategic AST locations; these are semantically transparent by default, but when activated can observe and interrupt execution. By becoming in effect part of the executing program, these "wrapper" nodes are subject to full runtime optimization, and they incur zero runtime overhead when debugging actions are not activated. Conditions carry no overhead beyond evaluation of the expression, which is optimized in the same way as user code, greatly improving the prospects for capturing rarely manifested bugs. When a breakpoint interrupts program execution, the platform automatically restores the full execution state of the program (expressed as Java data structures), as if running in the unoptimized AST interpreter. This then allows full introspection of the execution data structures such as the AST and method activation frames when in the interactive debugger console.Our initial evaluation indicates that such support could be permanently enabled in production environments.},
booktitle = {Proceedings of the Workshop on Dynamic Languages and Applications},
pages = {1–13},
numpages = {13},
keywords = {deoptimization, Truffle, virtual machines},
location = {Edinburgh, United Kingdom},
series = {Dyla'14}
}

@inproceedings{10.1145/68210.69232,
author = {Bruegge, Bernd and Gross, Thomas},
title = {A Program Debugger for a Systolic Array: Design and Implementation},
year = {1988},
isbn = {0897912969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/68210.69232},
doi = {10.1145/68210.69232},
abstract = {The Warp machine consists of a programmable linear systolic array connected to a general-purpose workstation host. Warp can be accessed either locally from this host or remotely from a large number of workstations connected to a local area network. Since the linear arrangement of the cells in the array restricts direct input and output with the host to the boundary cells, a source language debugger is important for program development. The Warp debugger is integrated into the Warp Programming Environment (WPE) which provides a uniform interface to the Warp machine. The debugger presents a conventional debugging model that includes breakpoints for individual cells as well as the inspection of the local state of each of the cells in the array. Although this user model is fairly simple, the implementation had to overcome several problems resulting from the parallel architecture of the machine and the distributed architecture of the programming environment.},
booktitle = {Proceedings of the 1988 ACM SIGPLAN and SIGOPS Workshop on Parallel and Distributed Debugging},
pages = {174–182},
numpages = {9},
location = {Madison, Wisconsin, USA},
series = {PADD '88}
}

@article{10.1145/69215.69232,
author = {Bruegge, Bernd and Gross, Thomas},
title = {A Program Debugger for a Systolic Array: Design and Implementation},
year = {1988},
issue_date = {Jan. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/69215.69232},
doi = {10.1145/69215.69232},
abstract = {The Warp machine consists of a programmable linear systolic array connected to a general-purpose workstation host. Warp can be accessed either locally from this host or remotely from a large number of workstations connected to a local area network. Since the linear arrangement of the cells in the array restricts direct input and output with the host to the boundary cells, a source language debugger is important for program development. The Warp debugger is integrated into the Warp Programming Environment (WPE) which provides a uniform interface to the Warp machine. The debugger presents a conventional debugging model that includes breakpoints for individual cells as well as the inspection of the local state of each of the cells in the array. Although this user model is fairly simple, the implementation had to overcome several problems resulting from the parallel architecture of the machine and the distributed architecture of the programming environment.},
journal = {SIGPLAN Not.},
month = {nov},
pages = {174–182},
numpages = {9}
}

@inproceedings{10.1145/3426425.3426935,
author = {Barraball, Chelsea and Raselimo, Moeketsi and Fischer, Bernd},
title = {An Interactive Feedback System for Grammar Development (Tool Paper)},
year = {2020},
isbn = {9781450381765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426425.3426935},
doi = {10.1145/3426425.3426935},
abstract = {We describe gtutr, an interactive feedback system designed to assist students in developing context-free grammars and corresponding ANTLR parsers. It intelligently controls students' access to a large test suite for the target language. After each submission, gtutr analyzes any failing tests and uses the Needleman-Wunsch sequence alignment algorithm over the tests' rule traces to identify and eliminate similar failing tests. This reduces the redundancy in the feedback  given to the students and prevents them from being overloaded. gtutr uses simple gamification to encourage independent problem solving by students: it gives as little information as possible, and students need to prompt the system for further details such as failing tests similar to or different from already seen tests, or even for hints about rules that are the most likely to contain faults. It tracks the students' information requests and uses this to attenuate marks following an instructor-set penalty schema. The system also visualizes test outcomes over multiple submissions, helping students to keep track of the effects of their changes as their grammar development progresses.},
booktitle = {Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {101–107},
numpages = {7},
keywords = {fault localization, Compiler courses},
location = {Virtual, USA},
series = {SLE 2020}
}

@inproceedings{10.1145/3168829,
author = {Fu, Xinwei and Lee, Dongyoon and Jung, Changhee},
title = {NAdroid: Statically Detecting Ordering Violations in Android Applications},
year = {2018},
isbn = {9781450356176},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168829},
doi = {10.1145/3168829},
abstract = {Modern mobile applications use a hybrid concurrency model. In this model, events are handled sequentially by event loop(s), and long-running tasks are offloaded to other threads. Concurrency errors in this hybrid concurrency model can take multiple forms: traditional atomicity and ordering violations between threads, as well as ordering violations between event callbacks on a single event loop.  This paper presents nAdroid, a static ordering violation detector for Android applications. Using our threadification technique, nAdroid statically models event callbacks as threads. Threadification converts ordering violations between event callbacks into ordering violations between threads, after which state-of-the-art thread-based race detection tools can be applied. nAdroid then applies a combination of sound and unsound filters, based on the Android concurrency model and its happens-before relation, to prune out false and benign warnings.  We evaluated nAdroid with 27 open source Android applications. Experimental results show that nAdroid detects 88 (at least 58 new) harmful ordering violations, and outperforms the state-of-the-art static technique with fewer false negatives and false positives.},
booktitle = {Proceedings of the 2018 International Symposium on Code Generation and Optimization},
pages = {62–74},
numpages = {13},
keywords = {Ordering violation, Android, Threadification, Debugging, Data race, Static analysis, Use-after-free},
location = {Vienna, Austria},
series = {CGO 2018}
}

@inproceedings{10.1145/1629575.1629587,
author = {Xu, Wei and Huang, Ling and Fox, Armando and Patterson, David and Jordan, Michael I.},
title = {Detecting Large-Scale System Problems by Mining Console Logs},
year = {2009},
isbn = {9781605587523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629575.1629587},
doi = {10.1145/1629575.1629587},
abstract = {Surprisingly, console logs rarely help operators detect problems in large-scale datacenter services, for they often consist of the voluminous intermixing of messages from many software components written by independent developers. We propose a general methodology to mine this rich source of information to automatically detect system runtime problems. We first parse console logs by combining source code analysis with information retrieval to create composite features. We then analyze these features using machine learning to detect operational problems. We show that our method enables analyses that are impossible with previous methods because of its superior ability to create sophisticated features. We also show how to distill the results of our analysis to an operator-friendly one-page decision tree showing the critical messages associated with the detected problems. We validate our approach using the Darkstar online game server and the Hadoop File System, where we detect numerous real problems with high accuracy and few false positives. In the Hadoop case, we are able to analyze 24 million lines of console logs in 3 minutes. Our methodology works on textual console logs of any size and requires no changes to the service software, no human input, and no knowledge of the software's internals.},
booktitle = {Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles},
pages = {117–132},
numpages = {16},
keywords = {monitoring, statistical learning, console log analysis, source code analysis, pca, problem detection, tracing},
location = {Big Sky, Montana, USA},
series = {SOSP '09}
}

@inproceedings{10.1145/68210.69217,
author = {Bates, Peter},
title = {Debugging Heterogeneous Distributed Systems Using Event-Based Models of Behavior},
year = {1988},
isbn = {0897912969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/68210.69217},
doi = {10.1145/68210.69217},
abstract = {Event Based Behavioral Abstraction (EBBA) is a high-level debugging approach which treats debugging as a process of creating models of actual behavior from the activity of the system and comparing these to models of expected system behavior. The differences between the actual and expected models are used to characterize erroneous system behavior and direct further investigation.A set of EBBA-based tools has been implemented that users can employ to construct libraries of behavior models and investigate the behavior of an errorful system through these models. EBBA evolves naturally as a cooperative distributed program that can take better advantage of computational power available in a network computer system to enhance debugging tool transparency, reduce latency and uncertainty for fundamental debugging activities and accommodate diverse, heterogeneous architectures.},
booktitle = {Proceedings of the 1988 ACM SIGPLAN and SIGOPS Workshop on Parallel and Distributed Debugging},
pages = {11–22},
numpages = {12},
location = {Madison, Wisconsin, USA},
series = {PADD '88}
}

@article{10.1145/69215.69217,
author = {Bates, Peter},
title = {Debugging Heterogeneous Distributed Systems Using Event-Based Models of Behavior},
year = {1988},
issue_date = {Jan. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/69215.69217},
doi = {10.1145/69215.69217},
abstract = {Event Based Behavioral Abstraction (EBBA) is a high-level debugging approach which treats debugging as a process of creating models of actual behavior from the activity of the system and comparing these to models of expected system behavior. The differences between the actual and expected models are used to characterize erroneous system behavior and direct further investigation.A set of EBBA-based tools has been implemented that users can employ to construct libraries of behavior models and investigate the behavior of an errorful system through these models. EBBA evolves naturally as a cooperative distributed program that can take better advantage of computational power available in a network computer system to enhance debugging tool transparency, reduce latency and uncertainty for fundamental debugging activities and accommodate diverse, heterogeneous architectures.},
journal = {SIGPLAN Not.},
month = {nov},
pages = {11–22},
numpages = {12}
}

@inproceedings{10.5555/2820518.2820552,
author = {Choetkiertikul, Morakot and Dam, Hoa Khanh and Tran, Truyen and Ghose, Aditya},
title = {Characterization and Prediction of Issue-Related Risks in Software Projects},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {Identifying risks relevant to a software project and planning measures to deal with them are critical to the success of the project. Current practices in risk assessment mostly rely on high-level, generic guidance or the subjective judgements of experts. In this paper, we propose a novel approach to risk assessment using historical data associated with a software project. Specifically, our approach identifies patterns of past events that caused project delays, and uses this knowledge to identify risks in the current state of the project. A set of risk factors characterizing "risky" software tasks (in the form of issues) were extracted from five open source projects: Apache, Duraspace, JBoss, Moodle, and Spring. In addition, we performed feature selection using a sparse logistic regression model to select risk factors with good discriminative power. Based on these risk factors, we built predictive models to predict if an issue will cause a project delay. Our predictive models are able to predict both the risk impact (i.e. the extend of the delay) and the likelihood of a risk occurring. The evaluation results demonstrate the effectiveness of our predictive models, achieving on average 48%--81% precision, 23%--90% recall, 29%--71% F-measure, and 70%--92% Area Under the ROC Curve. Our predictive models also have low error rates: 0.39--0.75 for Macro-averaged Mean Cost-Error and 0.7--1.2 for Macro-averaged Mean Absolute Error.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {280–291},
numpages = {12},
location = {Florence, Italy},
series = {MSR '15}
}

@article{10.1145/3241744,
author = {Troya, Javier and Segura, Sergio and Parejo, Jose Antonio and Ruiz-Cort\'{e}s, Antonio},
title = {Spectrum-Based Fault Localization in Model Transformations},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3241744},
doi = {10.1145/3241744},
abstract = {Model transformations play a cornerstone role in Model-Driven Engineering (MDE), as they provide the essential mechanisms for manipulating and transforming models. The correctness of software built using MDE techniques greatly relies on the correctness of model transformations. However, it is challenging and error prone to debug them, and the situation gets more critical as the size and complexity of model transformations grow, where manual debugging is no longer possible.Spectrum-Based Fault Localization (SBFL) uses the results of test cases and their corresponding code coverage information to estimate the likelihood of each program component (e.g., statements) of being faulty. In this article we present an approach to apply SBFL for locating the faulty rules in model transformations. We evaluate the feasibility and accuracy of the approach by comparing the effectiveness of 18 different state-of-the-art SBFL techniques at locating faults in model transformations. Evaluation results revealed that the best techniques, namely Kulcynski2, Mountford, Ochiai, and Zoltar, lead the debugger to inspect a maximum of three rules to locate the bug in around 74% of the cases. Furthermore, we compare our approach with a static approach for fault localization in model transformations, observing a clear superiority of the proposed SBFL-based method.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {sep},
articleno = {13},
numpages = {50},
keywords = {debugging, spectrum-based, Model transformation, testing, fault localization}
}

@inproceedings{10.5555/2818754.2818783,
author = {Lee, Yun Young and Marinov, Darko and Johnson, Ralph E.},
title = {Tempura: Temporal Dimension for IDEs},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Modern integrated development environments (IDEs) make many software engineering tasks easier by providing automated programming support such as code completion and navigation. However, such support -- and therefore IDEs as a whole -- operate on one revision of the code at a time, and leave handling of code history to external tools or plugins, such as EGit for Eclipse. For example, when a method is removed from a class, developers can no longer find the method through code completion. This forces developers to manually switch across different revisions or resort to using external tools when they need to learn about previous code revisions.We propose a novel approach of adding a temporal dimension to IDEs, enabling code completion and navigation to operate on multiple revisions of code at a time. We previously introduced the idea of temporal code completion and navigation, and presented a vision for how that idea may be realized. This paper realizes that vision by implementing and evaluating a prototype tool called Tempura. We describe our algorithm for processing and indexing historical code information from repositories for Tempura, and demonstrate Tempura's scalability with three large Eclipse projects. We also evaluate Tempura's usability through a controlled user study. The study participants learned about the code history with more accuracy when using Tempura compared to EGit. Although the sample size was not large enough to provide strong statistical significance, the results show a promising outlook for our approach.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {212–222},
numpages = {11},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/2818754.2818775,
author = {Gopan, Denis and Driscoll, Evan and Nguyen, Ducson and Naydich, Dimitri and Loginov, Alexey and Melski, David},
title = {Data-Delineation in Software Binaries and Its Application to Buffer-Overrun Discovery},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Detecting memory-safety violations in binaries is complicated by the lack of knowledge of the intended data layout, i.e., the locations and sizes of objects. We present lightweight, static, heuristic analyses for recovering the intended layout of data in a stripped binary. Comparison against DWARF debugging information shows high precision and recall rates for inferring source-level object boundaries. On a collection of benchmarks, our analysis eliminates a third to a half of incorrect object boundaries identified by an IDA Pro-inspired heuristic, while retaining nearly all valid object boundaries.In addition to measuring their accuracy directly, we evaluate the effect of using the recovered data for improving the precision of static buffer-overrun detection in the defect-detection tool CodeSonar/x86. We demonstrate that CodeSonar's false-positive rate drops by about 80% across our internal evaluation suite for the tool, while our approximation of CodeSonar's recall only degrades about 25%.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {145–155},
numpages = {11},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/2837476.2837478,
author = {Ullah, Faheem and Gross, Thomas R.},
title = {Profiling for Detecting Performance Anomalies in Concurrent Software},
year = {2015},
isbn = {9781450339100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2837476.2837478},
doi = {10.1145/2837476.2837478},
abstract = { Understanding and identifying performance problems is difficult for parallel applications, but is an essential part of software development for parallel systems. In addition to the same problems that exist when analysing sequential programs, software development tools for parallel systems must handle the large number of execution engines (cores) that result in different (possibly non-deterministic) schedules for different executions. Understanding where exactly a concurrent program spends its time (esp. if some aspects of the program paths depend on input data) is the first step towards improving program quality. State-of-the-art profilers, however, aid developers in performance diagnosis by providing hotness information at the level of a class or method (function) and usually report data for just a single program execution. This paper presents a profiling and analysis technique that consolidates execution information for multiple program executions. Currently, our tool's focus is on execution time (CPU cycles) but other metrics (stall cycles for functional units, cache miss rates, etc) are possible, provided such data can be obtained from the processor's monitoring unit. To detect the location of performance anomalies that are worth addressing, the average amount of time spent inside a code block, along with the statistical range of the minimum and maximum amount of time spent, is taken into account. The technique identifies performance bottlenecks at the fine-grained level of a basic block. It can indicate the probability of such a performance bottleneck appearing during actual program executions. The technique utilises profiling information across a range of inputs and tries to induce performance bottlenecks by delaying random memory accesses. The approach is evaluated by performing experiments on the data compression tool pbzip2, the multi-threaded download accelerator axel, the open source security scanner Nmap and Apache httpd web server. An experimental evaluation shows the tool to be effective in detecting performance bottlenecks at the level of a basic block. Modifications in the block that is identified by the tool result in performance improvement of over 2.6x in one case, compared to the original version of the program. The performance overhead incurred by the tool is a reasonable 2-7x in majority of the cases. },
booktitle = {Proceedings of the 2nd International Workshop on Software Engineering for Parallel Systems},
pages = {11–20},
numpages = {10},
keywords = {Software defects, Localisation, Profiling, Parallel programming, Dynamic binary instrumentation, Performance bugs, Measurement},
location = {Pittsburgh, PA, USA},
series = {SEPS 2015}
}

@inproceedings{10.1145/3106237.3106270,
author = {Hilton, Michael and Nelson, Nicholas and Tunnell, Timothy and Marinov, Darko and Dig, Danny},
title = {Trade-Offs in Continuous Integration: Assurance, Security, and Flexibility},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106270},
doi = {10.1145/3106237.3106270},
abstract = { Continuous integration (CI) systems automate the compilation, building, and testing of software. Despite CI being a widely used activity in software engineering, we do not know what motivates developers to use CI, and what barriers and unmet needs they face. Without such knowledge, developers make easily avoidable errors, tool builders invest in the wrong direction, and researchers miss opportunities for improving the practice of CI. We present a qualitative study of the barriers and needs developers face when using CI. We conduct semi-structured interviews with developers from different industries and development scales. We triangulate our findings by running two surveys. We find that developers face trade-offs between speed and certainty (Assurance), between better access and information security (Security), and between more configuration options and greater ease of use (Flexi- bility). We present implications of these trade-offs for developers, tool builders, and researchers. },
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {197–207},
numpages = {11},
keywords = {Automated Testing, Continuous Integration},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

