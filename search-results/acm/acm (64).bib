@inproceedings{10.1145/3338906.3338912,
author = {He, Sen and Manns, Glenna and Saunders, John and Wang, Wei and Pollock, Lori and Soffa, Mary Lou},
title = {A Statistics-Based Performance Testing Methodology for Cloud Applications},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338912},
doi = {10.1145/3338906.3338912},
abstract = {The low cost of resource ownership and flexibility have led users to increasingly port their applications to the clouds. To fully realize the cost benefits of cloud services, users usually need to reliably know the execution performance of their applications. However, due to the random performance fluctuations experienced by cloud applications, the black box nature of public clouds and the cloud usage costs, testing on clouds to acquire accurate performance results is extremely difficult. In this paper, we present a novel cloud performance testing methodology called PT4Cloud. By employing non-parametric statistical approaches of likelihood theory and the bootstrap method, PT4Cloud provides reliable stop conditions to obtain highly accurate performance distributions with confidence bands. These statistical approaches also allow users to specify intuitive accuracy goals and easily trade between accuracy and testing cost. We evaluated PT4Cloud with 33 benchmark configurations on Amazon Web Service and Chameleon clouds. When compared with performance data obtained from extensive performance tests, PT4Cloud provides testing results with 95.4% accuracy on average while reducing the number of test runs by 62%. We also propose two test execution reduction techniques for PT4Cloud, which can reduce the number of test runs by 90.1% while retaining an average accuracy of 91%. We compared our technique to three other techniques and found that our results are much more accurate.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {188–199},
numpages = {12},
keywords = {resource contention, cloud computing, performance testing, non- parametric statistics},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/1352135.1352315,
author = {Janzen, David and Saiedian, Hossein},
title = {Test-Driven Learning in Early Programming Courses},
year = {2008},
isbn = {9781595937995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1352135.1352315},
doi = {10.1145/1352135.1352315},
abstract = {Coercing new programmers to adopt disciplined development practices such as thorough unit testing is a challenging endeavor. Test-driven development (TDD) has been proposed as a solution to improve both software design and testing. Test-driven learning (TDL) has been proposed as a pedagogical approach for teaching TDD without imposing significant additional instruction time.This research evaluates the effects of students using a test-first (TDD) versus test-last approach in early programming courses, and considers the use of TDL on a limited basis in CS1 and CS2. Software testing, programmer productivity, programmer performance, and programmer opinions are compared between test-first and test-last programming groups. Results from this research indicate that a test-first approach can increase student testing and programmer performance, but that early programmers are very reluctant to adopt a test-first approach, even after having positive experiences using TDD. Further, this research demonstrates that TDL can be applied in CS1/2, but suggests that a more pervasive implementation of TDL may be necessary to motivate and establish disciplined testing practice among early programmers.},
booktitle = {Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education},
pages = {532–536},
numpages = {5},
keywords = {test-driven development, test-driven learning, cs1, pedagogy},
location = {Portland, OR, USA},
series = {SIGCSE '08}
}

@article{10.1145/1352322.1352315,
author = {Janzen, David and Saiedian, Hossein},
title = {Test-Driven Learning in Early Programming Courses},
year = {2008},
issue_date = {March 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0097-8418},
url = {https://doi.org/10.1145/1352322.1352315},
doi = {10.1145/1352322.1352315},
abstract = {Coercing new programmers to adopt disciplined development practices such as thorough unit testing is a challenging endeavor. Test-driven development (TDD) has been proposed as a solution to improve both software design and testing. Test-driven learning (TDL) has been proposed as a pedagogical approach for teaching TDD without imposing significant additional instruction time.This research evaluates the effects of students using a test-first (TDD) versus test-last approach in early programming courses, and considers the use of TDL on a limited basis in CS1 and CS2. Software testing, programmer productivity, programmer performance, and programmer opinions are compared between test-first and test-last programming groups. Results from this research indicate that a test-first approach can increase student testing and programmer performance, but that early programmers are very reluctant to adopt a test-first approach, even after having positive experiences using TDD. Further, this research demonstrates that TDL can be applied in CS1/2, but suggests that a more pervasive implementation of TDL may be necessary to motivate and establish disciplined testing practice among early programmers.},
journal = {SIGCSE Bull.},
month = {mar},
pages = {532–536},
numpages = {5},
keywords = {test-driven development, test-driven learning, pedagogy, cs1}
}

@inproceedings{10.1145/3386901.3388916,
author = {Yi, Edgardo Barsallo and Zhang, Heng and Maji, Amiya K. and Xu, Kefan and Bagchi, Saurabh},
title = {Vulcan: Lessons on Reliability of Wearables through State-Aware Fuzzing},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388916},
doi = {10.1145/3386901.3388916},
abstract = {As we look to use Wear OS (formerly known as Android Wear) devices for fitness and health monitoring, it is important to evaluate the reliability of its ecosystem. The goal of this paper is to understand the reliability weak spots in Wear OS ecosystem. We develop a state-aware fuzzing tool, Vulcan, without any elevated privileges, to uncover these weak spots by fuzzing Wear OS apps. We evaluate the outcomes due to these weak spots by fuzzing 100 popular apps downloaded from Google Play Store. The outcomes include causing specific apps to crash, causing the running app to become unresponsive, and causing the device to reboot. We finally propose a proof-of-concept mitigation solution to address the system reboot issue.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {391–403},
numpages = {13},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1109/ASE.2013.6693120,
author = {Kifetew, Fitsum Meshesha and Jin, Wei and Tiella, Roberto and Orso, Alessandro and Tonella, Paolo},
title = {SBFR: A Search Based Approach for Reproducing Failures of Programs with Grammar Based Input},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693120},
doi = {10.1109/ASE.2013.6693120},
abstract = {Reproducing field failures in-house, a step developers must perform when assigned a bug report, is an arduous task. In most cases, developers must be able to reproduce a reported failure using only a stack trace and/or some informal description of the failure. The problem becomes even harder for the large class of programs whose input is highly structured and strictly specified by a grammar. To address this problem, we present SBFR, a search-based failure-reproduction technique for programs with structured input. SBFR formulates failure reproduction as a search problem. Starting from a reported failure and a limited amount of dynamic information about the failure, SBFR exploits the potential of genetic programming to iteratively find legal inputs that can trigger the failure.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {604–609},
numpages = {6},
location = {Silicon Valley, CA, USA},
series = {ASE'13}
}

@inproceedings{10.1145/3064176.3064188,
author = {Davis, James and Thekumparampil, Arun and Lee, Dongyoon},
title = {Node.Fz: Fuzzing the Server-Side Event-Driven Architecture},
year = {2017},
isbn = {9781450349383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3064176.3064188},
doi = {10.1145/3064176.3064188},
abstract = {The importance of the Event-Driven Architecture (EDA) has never been greater. Web servers and the IoT alike have begun to adopt the EDA, and the popular server-side EDA framework, Node.js, boasts the world's largest package ecosystem. While multi-threaded programming has been well studied in the literature, concurrency bug characteristics and useful development tools remain largely unexplored for server-side EDA-based applications.We present the first (to the best of our knowledge) concurrency bug characteristic study of real world open-source event-driven applications, based in Node.js. Like multithreaded programs, event-driven programs are prone to concurrency bugs like atomicity violations and order violations. Our study shows the forms that atomicity violations and ordering violations take in the EDA context, and points out the limitations of existing concurrency error detection tools developed for client-side EDA applications.Based on our bug study, we propose Node.fz, a novel testing aid for server-side event-driven programs. Node.fz is a schedule fuzzing test tool for event-driven programs, embodied for server-side Node.js programs. Node.fz randomly perturbs the execution of a Node.js program, allowing Node.js developers to explore a variety of possible schedules. Thanks to its low overhead, Node.fz enables a developer to explore a broader "schedule space" with the same test time budget, ensuring that applications will be stable in a wide variety of deployment conditions. We show that Node.fz can expose known bugs much more frequently than vanilla Node.js, and that it can uncover new bugs.},
booktitle = {Proceedings of the Twelfth European Conference on Computer Systems},
pages = {145–160},
numpages = {16},
location = {Belgrade, Serbia},
series = {EuroSys '17}
}

@article{10.1145/3480248,
author = {Tr\"{u}b, Roman and Da Forno, Reto and Daschinger, Lukas and Biri, Andreas and Beutel, Jan and Thiele, Lothar},
title = {Non-Intrusive Distributed Tracing of Wireless IoT Devices with the FlockLab&nbsp;2 Testbed},
year = {2021},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
issn = {2691-1914},
url = {https://doi.org/10.1145/3480248},
doi = {10.1145/3480248},
abstract = {Testbeds for wireless IoT devices facilitate testing and validation of distributed target nodes. A testbed usually provides methods to control, observe, and log the execution of the software. However, most of the methods used for tracing the execution require code instrumentation and change essential properties of the observed system. Methods that are non-intrusive are typically not applicable in a distributed fashion due to a lack of time synchronization or necessary hardware/software support. In this article, we present a tracing system for validating time-critical software running on multiple distributed wireless devices that does not require code instrumentation, is non-intrusive and is designed to trace the distributed state of an entire network. For this purpose, we make use of the on-chip debug and trace hardware that is part of most modern microcontrollers. We introduce a testbed architecture as well as models and methods that accurately synchronize the timestamps of observations collected by distributed observers. In a case study, we demonstrate how the tracing system can be applied to observe the distributed state of a flooding-based low-power communication protocol for wireless sensor networks. The presented non-intrusive tracing system is implemented as a service of the publicly accessible open source FlockLab&nbsp;2 testbed.},
journal = {ACM Trans. Internet Things},
month = {oct},
articleno = {5},
numpages = {31},
keywords = {testbed, IoT, Distributed debugging, wireless sensor network, FlockLab, on-chip debug and trace}
}

@inproceedings{10.5555/2486788.2486804,
author = {Pham, Raphael and Singer, Leif and Liskin, Olga and Figueira Filho, Fernando and Schneider, Kurt},
title = {Creating a Shared Understanding of Testing Culture on a Social Coding Site},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = { Many software development projects struggle with creating and communicating a testing culture that is appropriate for the project's needs. This may degrade software quality by leaving defects undiscovered. Previous research suggests that social coding sites such as GitHub provide a collaborative environment with a high degree of social transparency. This makes developers' actions and interactions more visible and traceable. We conducted interviews with 33 active users of GitHub to investigate how the increased transparency found on GitHub influences developers' testing behaviors. Subsequently, we validated our findings with an online questionnaire that was answered by 569 members of GitHub. We found several strategies that software developers and managers can use to positively influence the testing behavior in their projects. However, project owners on GitHub may not be aware of them. We report on the challenges and risks caused by this and suggest guidelines for promoting a sustainable testing culture in software development projects. },
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {112–121},
numpages = {10},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/3368089.3409679,
author = {Gopinath, Rahul and Mathis, Bj\"{o}rn and Zeller, Andreas},
title = {Mining Input Grammars from Dynamic Control Flow},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409679},
doi = {10.1145/3368089.3409679},
abstract = {One of the key properties of a program is its input specification. Having a formal input specification can be critical in fields such as vulnerability analysis, reverse engineering, software testing, clone detection, or refactoring. Unfortunately, accurate input specifications for typical programs are often unavailable or out of date.  In this paper, we present a general algorithm that takes a program and a small set of sample inputs and automatically infers a readable context-free grammar capturing the input language of the program. We infer the syntactic input structure only by observing access of input characters at different locations of the input parser. This works on all stack based recursive descent input parsers, including parser combinators, and works entirely without program specific heuristics. Our Mimid prototype produced accurate and readable grammars for a variety of evaluation subjects, including complex languages such as JSON, TinyC, and JavaScript.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {172–183},
numpages = {12},
keywords = {fuzzing, control-flow, context-free grammar, dynamic analysis, dataflow},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.5555/2486788.2486855,
author = {Meng, Na and Kim, Miryung and McKinley, Kathryn S.},
title = {LASE: Locating and Applying Systematic Edits by Learning from Examples},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = { Adding features and fixing bugs often require sys- tematic edits that make similar, but not identical, changes to many code locations. Finding all the relevant locations and making the correct edits is a tedious and error-prone process for developers. This paper addresses both problems using edit scripts learned from multiple examples. We design and implement a tool called LASE that (1) creates a context-aware edit script from two or more examples, and uses the script to (2) automatically identify edit locations and to (3) transform the code. We evaluate LASE on an oracle test suite of systematic edits from Eclipse JDT and SWT. LASE finds edit locations with 99% precision and 89% recall, and transforms them with 91% accuracy. We also evaluate LASE on 37 example systematic edits from other open source programs and find LASE is accurate and effective. Furthermore, we confirmed with developers that LASE found edit locations which they missed. Our novel algorithm that learns from multiple examples is critical to achieving high precision and recall; edit scripts created from only one example produce too many false positives, false negatives, or both. Our results indicate that LASE should help developers in automating systematic editing. Whereas most prior work either suggests edit locations or performs simple edits, LASE is the first to do both for nontrivial program edits. },
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {502–511},
numpages = {10},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/2648511.2648513,
author = {Harman, M. and Jia, Y. and Krinke, J. and Langdon, W. B. and Petke, J. and Zhang, Y.},
title = {Search Based Software Engineering for Software Product Line Engineering: A Survey and Directions for Future Work},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648513},
doi = {10.1145/2648511.2648513},
abstract = {This paper presents a survey of work on Search Based Software Engineering (SBSE) for Software Product Lines (SPLs). We have attempted to be comprehensive, in the sense that we have sought to include all papers that apply computational search techniques to problems in software product line engineering. Having surveyed the recent explosion in SBSE for SPL research activity, we highlight some directions for future work. We focus on suggestions for the development of recent advances in genetic improvement, showing how these might be exploited by SPL researchers and practitioners: Genetic improvement may grow new products with new functional and non-functional features and graft these into SPLs. It may also merge and parameterise multiple branches to cope with SPL branchmania.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {5–18},
numpages = {14},
keywords = {program synthesis, SPL, genetic programming, SBSE},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/2362536.2362567,
author = {Savolainen, Juha and Mannion, Mike and Kuusela, Juha},
title = {Developing Platforms for Multiple Software Product Lines},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362567},
doi = {10.1145/2362536.2362567},
abstract = {Many approaches to software product line engineering have been founded on the development of a single product line platform. However as customer requirements change and new products are added to the product line, software producers recognize that the platform cannot be "stretched" indefinitely and a significant problem is striking a balance between development efficiency by increasing platform commonality and customer dissatisfaction from products with additional undesirable features and properties.One alternative is to develop multiple product lines (MPLs). However the challenge remains about what to include in a multiple product line platform. Drawing upon industrial experience of working with 4 companies, this paper explores the characteristics of the contexts in which MPLs are a viable alternative development strategy and then proposes a framework of approaches to platform development.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {220–228},
numpages = {9},
keywords = {software reuse, industrial experience, multiple product lines},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1109/ICSE.2009.5070516,
author = {Buse, Raymond P. L. and Weimer, Westley},
title = {The Road Not Taken: Estimating Path Execution Frequency Statically},
year = {2009},
isbn = {9781424434534},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSE.2009.5070516},
doi = {10.1109/ICSE.2009.5070516},
abstract = {A variety of compilers, static analyses, and testing frameworks rely heavily on path frequency information. Uses for such information range from optimizing transformations to bug finding. Path frequencies are typically obtained through profiling, but that approach is severely restricted: it requires running programs in an indicative environment, and on indicative test inputs. We present a descriptive statistical model of path frequency based on features that can be readily obtained from a program's source code. Our model is over 90% accurate with respect to several benchmarks, and is sufficient for selecting the 5% of paths that account for over half of a program's total runtime. We demonstrate our technique's robustness by measuring its performance as a static branch predictor, finding it to be more accurate than previous approaches on average. Finally, our qualitative analysis of the model provides insight into which source-level features indicate “hot paths.”},
booktitle = {Proceedings of the 31st International Conference on Software Engineering},
pages = {144–154},
numpages = {11},
series = {ICSE '09}
}

@inproceedings{10.1145/3281411.3281436,
author = {Zheng, Peng and Benson, Theophilus and Hu, Chengchen},
title = {P4Visor: Lightweight Virtualization and Composition Primitives for Building and Testing Modular Programs},
year = {2018},
isbn = {9781450360807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3281411.3281436},
doi = {10.1145/3281411.3281436},
abstract = {Programmable data planes, PDPs, enable an unprecedented level of flexibility and have emerged as a promising alternative to existing data planes. Despite the rapid development and prototyping cycles that PDPs promote, the existing PDP ecosystem lacks appropriate abstractions and algorithms to support these rapid testing and deployment life-cycles. In this paper, we propose P4Visor, a lightweight virtualization abstraction that provides testing primitives as a first-order citizen of the PDP ecosystem. P4Visor can efficiently support multiple PDP programs through a combination of compiler optimizations and program analysis-based algorithms. P4Visor s algorithm improves over state-of-the-art techniques by significantly reducing the resource overheads associated with embedding numerous versions of a PDP program into hardware. To demonstrate the efficiency and viability of P4Visor, we implemented and evaluated P4Visor on both a software switch and an FPGA-based hardware switch using fourteen different PDP programs. Our results demonstrate that P4Visor introduces minimal overheads (less than 1%) and is one order of magnitude more efficient than existing PDPs primitives for concurrently supporting multiple programs.},
booktitle = {Proceedings of the 14th International Conference on Emerging Networking EXperiments and Technologies},
pages = {98–111},
numpages = {14},
keywords = {code merge, testing, programmable data plane},
location = {Heraklion, Greece},
series = {CoNEXT '18}
}

@inproceedings{10.1145/2254064.2254126,
author = {Pradel, Michael and Gross, Thomas R.},
title = {Fully Automatic and Precise Detection of Thread Safety Violations},
year = {2012},
isbn = {9781450312059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2254064.2254126},
doi = {10.1145/2254064.2254126},
abstract = {Concurrent, object-oriented programs often use thread-safe library classes. Existing techniques for testing a thread-safe class either rely on tests using the class, on formal specifications, or on both. Unfortunately, these techniques often are not fully automatic as they involve the user in analyzing the output. This paper presents an automatic testing technique that reveals concurrency bugs in supposedly thread-safe classes. The analysis requires as input only the class under test and reports only true positives. The key idea is to generate tests in which multiple threads call methods on a shared instance of the tested class. If a concurrent test exhibits an exception or a deadlock that cannot be triggered in any linearized execution of the test, the analysis reports a thread safety violation. The approach is easily applicable, because it is independent of hand-written tests and explicit specifications. The analysis finds 15 concurrency bugs in popular Java libraries, including two previously unknown bugs in the Java standard library.},
booktitle = {Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {521–530},
numpages = {10},
keywords = {testing, thread safety, concurrent test generation},
location = {Beijing, China},
series = {PLDI '12}
}

@article{10.1145/2345156.2254126,
author = {Pradel, Michael and Gross, Thomas R.},
title = {Fully Automatic and Precise Detection of Thread Safety Violations},
year = {2012},
issue_date = {June 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/2345156.2254126},
doi = {10.1145/2345156.2254126},
abstract = {Concurrent, object-oriented programs often use thread-safe library classes. Existing techniques for testing a thread-safe class either rely on tests using the class, on formal specifications, or on both. Unfortunately, these techniques often are not fully automatic as they involve the user in analyzing the output. This paper presents an automatic testing technique that reveals concurrency bugs in supposedly thread-safe classes. The analysis requires as input only the class under test and reports only true positives. The key idea is to generate tests in which multiple threads call methods on a shared instance of the tested class. If a concurrent test exhibits an exception or a deadlock that cannot be triggered in any linearized execution of the test, the analysis reports a thread safety violation. The approach is easily applicable, because it is independent of hand-written tests and explicit specifications. The analysis finds 15 concurrency bugs in popular Java libraries, including two previously unknown bugs in the Java standard library.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {521–530},
numpages = {10},
keywords = {thread safety, concurrent test generation, testing}
}

@article{10.1145/3460082,
author = {Zhang, Qingzhao and Hong, David Ke and Zhang, Ze and Chen, Qi Alfred and Mahlke, Scott and Mao, Z. Morley},
title = {A Systematic Framework to Identify Violations of Scenario-Dependent Driving Rules in Autonomous Vehicle Software},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
url = {https://doi.org/10.1145/3460082},
doi = {10.1145/3460082},
abstract = {Safety compliance is paramount to the safe deployment of autonomous vehicle (AV) technologies in real-world transportation systems. As AVs will share road infrastructures with human drivers and pedestrians, it is an important requirement for AVs to obey standard driving rules. Existing AV software testing methods, including simulation and road testing, only check fundamental safety rules such as collision avoidance and safety distance. Scenario-dependent driving rules, including crosswalk and intersection rules, are more complicated because the expected driving behavior heavily depends on the surrounding circumstances. However, a testing framework is missing for checking scenario-dependent driving rules on various AV software.In this paper, we design and implement a systematic framework AVChecker for identifying violations of scenario-dependent driving rules in AV software using formal methods. AVChecker represents both the code logic of AV software and driving rules in proposed formal specifications and leverages satisfiability modulo theory (SMT) solvers to identify driving rule violations. To improve the automation of systematic rule-based checking, AVChecker provides a powerful user interface for writing driving rule specifications and applies static code analysis to extract rule-related code logic from the AV software codebase. Evaluations on two open-source AV software platforms, Baidu Apollo and Autoware, uncover 19 true violations out of 28 real-world driving rules covering crosswalks, traffic lights, stop signs, and intersections. Seven of the violations can lead to severe risks of a collision with pedestrians or blocking traffic.},
journal = {Proc. ACM Meas. Anal. Comput. Syst.},
month = {jun},
articleno = {15},
numpages = {25},
keywords = {software system, formal methods, autonomous vehicle}
}

@article{10.1145/1281421.1281425,
author = {Farooq, Ayaz and Dumke, Reiner R.},
title = {Research Directions in Verification &amp; Validation Process Improvement},
year = {2007},
issue_date = {July 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1281421.1281425},
doi = {10.1145/1281421.1281425},
abstract = {Software process establishment, evaluation and improvement are key research areas in the software engineering field today. Extensive research has been carried out and many different kinds of approaches exist to improve the software process and even more efforts are underway. Verification &amp; validation process, which is part of the broader software process activities, plays a vital role in quality and profitability of the developed product but is believed to consume major portion of the development expenses and resources. Probably, research towards improving the verification &amp; validation process has not been as actively directed as compared to software process improvement research. This paper identifies several potential future research directions towards improving verification and validation process.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jul},
pages = {3–es},
numpages = {4},
keywords = {software process improvement, testing maturity model, TMM, software process, STP, test process improvement, SP, SPI, V&amp;V, software test process, verification &amp; validation process}
}

@inproceedings{10.1145/3338906.3338980,
author = {Lu, Yifei and Pan, Minxue and Zhai, Juan and Zhang, Tian and Li, Xuandong},
title = {Preference-Wise Testing for Android Applications},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338980},
doi = {10.1145/3338906.3338980},
abstract = {Preferences, the setting options provided by Android, are an essential part of Android apps. Preferences allow users to change app features and behaviors dynamically, and therefore, need to be thoroughly tested. Unfortunately, the specific preferences used in test cases are typically not explicitly specified, forcing testers to manually set options or blindly try different option combinations. To effectively test the impacts of different preference options, this paper presents PREFEST, as a preference-wise enhanced automatic testing approach, for Android apps. Given a set of test cases, PREFEST can locate the preferences that may affect the test cases with a static and dynamic combined analysis on the app under test, and execute these test cases only under necessary option combinations. The evaluation shows that PREFEST can improve 6.8% code coverage and 12.3% branch coverage and find five more real bugs compared to testing with the original test cases. The test cost is reduced by 99% for both the number of test cases and the testing time, compared to testing under pairwise combination of options.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {268–278},
numpages = {11},
keywords = {Android apps, preference-wise testing, Android testing},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.5555/2819009.2819039,
author = {Theisen, Christopher and Herzig, Kim and Morrison, Patrick and Murphy, Brendan and Williams, Laurie},
title = {Approximating Attack Surfaces with Stack Traces},
year = {2015},
publisher = {IEEE Press},
abstract = {Security testing and reviewing efforts are a necessity for software projects, but are time-consuming and expensive to apply. Identifying vulnerable code supports decision-making during all phases of software development. An approach for identifying vulnerable code is to identify its attack surface, the sum of all paths for untrusted data into and out of a system. Identifying the code that lies on the attack surface requires expertise and significant manual effort. This paper proposes an automated technique to empirically approximate attack surfaces through the analysis of stack traces. We hypothesize that stack traces from user-initiated crashes have several desirable attributes for measuring attack surfaces. The goal of this research is to aid software engineers in prioritizing security efforts by approximating the attack surface of a system via stack trace analysis. In a trial on Windows 8, the attack surface approximation selected 48.4% of the binaries and contained 94.6% of known vulnerabilities. Compared with vulnerability prediction models (VPMs) run on the entire codebase, VPMs run on the attack surface approximation improved recall from .07 to .1 for binaries and from .02 to .05 for source files. Precision remained at .5 for binaries, while improving from .5 to .69 for source files.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {199–208},
numpages = {10},
keywords = {stack traces, models, security, vulnerability, reliability, testing, attack surface},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/1159733.1159763,
author = {Wagner, Stefan},
title = {A Literature Survey of the Quality Economics of Defect-Detection Techniques},
year = {2006},
isbn = {1595932186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1159733.1159763},
doi = {10.1145/1159733.1159763},
abstract = {Over the last decades, a considerable amount of empirical knowledge about the efficiency of defect-detection techniques has been accumulated. Also a few surveys have summarised those studies with different focuses, usually for a specific type of technique. This work reviews the results of empirical studies and associates them with a model of software quality economics. This allows a better comparison of the different techniques and supports the application of the model in practice as several parameters can be approximated with typical average values. The main contributions are the provision of average values of several interesting quantities w.r.t. defect detection and the identification of areas that need further research because of the limited knowledge available.},
booktitle = {Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering},
pages = {194–203},
numpages = {10},
keywords = {quality cost, cost/benefit, software quality economics, defectdetection techniques, literature survey},
location = {Rio de Janeiro, Brazil},
series = {ISESE '06}
}

@inproceedings{10.1145/3468264.3468539,
author = {Rabin, Md Rafiqul Islam and Hellendoorn, Vincent J. and Alipour, Mohammad Amin},
title = {Understanding Neural Code Intelligence through Program Simplification},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468539},
doi = {10.1145/3468264.3468539},
abstract = {A wide range of code intelligence (CI) tools, powered by deep neural networks, have been developed recently to improve programming productivity and perform program analysis. To reliably use such tools, developers often need to reason about the behavior of the underlying models and the factors that affect them. This is especially challenging for tools backed by deep neural networks. Various methods have tried to reduce this opacity in the vein of "transparent/interpretable-AI". However, these approaches are often specific to a particular set of network architectures, even requiring access to the network's parameters. This makes them difficult to use for the average programmer, which hinders the reliable adoption of neural CI systems. In this paper, we propose a simple, model-agnostic approach to identify critical input features for models in CI systems, by drawing on software debugging research, specifically delta debugging. Our approach, SIVAND, uses simplification techniques that reduce the size of input programs of a CI model while preserving the predictions of the model. We show that this approach yields remarkably small outputs and is broadly applicable across many model architectures and problem domains. We find that the models in our experiments often rely heavily on just a few syntactic features in input programs. We believe that SIVAND's extracted features may help understand neural CI systems' predictions and learned behavior.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {441–452},
numpages = {12},
keywords = {Program Simplification, Models of Code, Interpretable AI},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

