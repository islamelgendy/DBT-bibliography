@inproceedings{10.1145/3129790.3129822,
author = {Nakagawa, Elisa Yumi and Allian, Ana and Oliveira, Brauner and Sena, Bruno and Paes, Carlos and Lana, Cristiane and Feitosa, Daniel and Santos, Daniel and Zaniro, D\^{e}nis and Dias, Di\'{o}genes and Horita, Fl\'{a}vio and Affonso, Frank Jos\'{e} and Abdalla, Gabriel and Vicente, Isabella and Duarte, Leonardo and Felizardo, Katia and Garc\'{e}s, Lina and Oliveira, Lucas and Gon\c{c}alves, Marcelo and Morais, Maria Gabriela and Guessi, Milena and Silva, Nilson and Bianchi, Thiago and Volpato, Tiago and Neto, Valdemar V. Graciano and Zani, Vinicius and Manzano, Wallace},
title = {Software Architecture and Reference Architecture of Software-Intensive Systems and Systems-of-Systems: Contributions to the State of the Art},
year = {2017},
isbn = {9781450352178},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3129790.3129822},
doi = {10.1145/3129790.3129822},
abstract = {Complex software-intensive systems are more and more required as a solution for diverse critical application domains; at the same time, software architecture and also reference architecture have attracted attention as means to more adequately produce and evolve such systems. The main goal of this paper is to summarize our principal contributions in software architecture and reference architecture of software-intensive systems, including Systems-of-Systems. We intend this work can also inspire the opening of other related research lines towards founding the sustainability of such software-intensive systems.},
booktitle = {Proceedings of the 11th European Conference on Software Architecture: Companion Proceedings},
pages = {4–11},
numpages = {8},
keywords = {software architecture, system-of-systems, reference architecture},
location = {Canterbury, United Kingdom},
series = {ECSA '17}
}

@inproceedings{10.1145/2976749.2978383,
author = {Argyros, George and Stais, Ioannis and Jana, Suman and Keromytis, Angelos D. and Kiayias, Aggelos},
title = {SFADiff: Automated Evasion Attacks and Fingerprinting Using Black-Box Differential Automata Learning},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978383},
doi = {10.1145/2976749.2978383},
abstract = {Finding differences between programs with similar functionality is an important security problem as such differences can be used for fingerprinting or creating evasion attacks against security software like Web Application Firewalls (WAFs) which are designed to detect malicious inputs to web applications. In this paper, we present SFADIFF, a black-box differential testing framework based on Symbolic Finite Automata (SFA) learning. SFADIFF can automatically find differences between a set of programs with comparable functionality. Unlike existing differential testing techniques, instead of searching for each difference individually, SFADIFF infers SFA models of the target programs using black-box queries and systematically enumerates the differences between the inferred SFA models. All differences between the inferred models are checked against the corresponding programs. Any difference between the models, that does not result in a difference between the corresponding programs, is used as a counterexample for further refinement of the inferred models. SFADIFF's model-based approach, unlike existing differential testing tools, also support fully automated root cause analysis in a domain-independent manner.We evaluate SFADIFF in three different settings for finding discrepancies between: (i) three TCP implementations, (ii) four WAFs, and (iii) HTML/JavaScript parsing implementations in WAFs and web browsers. Our results demonstrate that SFADIFF is able to identify and enumerate the differences systematically and efficiently in all these settings. We show that SFADIFF is able to find differences not only between different WAFs but also between different versions of the same WAF. SFADIFF is also able to discover three previously-unknown differences between the HTML/JavaScript parsers of two popular WAFs (PHPIDS 0.7 and Expose 2.4.0) and the corresponding parsers of Google Chrome, Firefox, Safari, and Internet Explorer. We confirm that all these differences can be used to evade the WAFs and launch successful cross-site scripting attacks.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1690–1701},
numpages = {12},
keywords = {evasion attacks, fingerprints, differential testing, automata learning, web application firewalls},
location = {Vienna, Austria},
series = {CCS '16}
}

@inproceedings{10.1145/2076732.2076790,
author = {Kirat, Dhilung and Vigna, Giovanni and Kruegel, Christopher},
title = {BareBox: Efficient Malware Analysis on Bare-Metal},
year = {2011},
isbn = {9781450306720},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2076732.2076790},
doi = {10.1145/2076732.2076790},
abstract = {Present-day malware analysis techniques use both virtualized and emulated environments to analyze malware. The reason is that such environments provide isolation and system restoring capabilities, which facilitate automated analysis of malware samples. However, there exists a class of malware, called VM-aware malware, which is capable of detecting such environments and then hide its malicious behavior to foil the analysis. Because of the artifacts introduced by virtualization or emulation layers, it has always been and will always be possible for malware to detect virtual environments.The definitive way to observe the actual behavior of VM-aware malware is to execute them in a system running on real hardware, which is called a "bare-metal" system. However, after each analysis, the system must be restored back to the previous clean state. This is because running a malware program can leave the system in an instable/insecure state and/or interfere with the results of a subsequent analysis run. Most of the available state-of-the-art system restore solutions are based on disk restoring and require a system reboot. This results in a significant downtime between each analysis. Because of this limitation, efficient automation of malware analysis in bare-metal systems has been a challenge.This paper presents the design, implementation, and evaluation of a malware analysis framework for bare-metal systems that is based on a fast and rebootless system restore technique. Live system restore is accomplished by restoring the entire physical memory of the analysis operating system from another, small operating system that runs outside of the target OS. By using this technique, we were able to perform a rebootless restore of a live Windows system, running on commodity hardware, within four seconds. We also analyzed 42 malware samples from seven different malware families, that are known to be "silent" in a virtualized or emulated environments, and all of them showed their true malicious behavior within our bare-metal analysis environment.},
booktitle = {Proceedings of the 27th Annual Computer Security Applications Conference},
pages = {403–412},
numpages = {10},
keywords = {system restore, bare metal, dynamic malware analysis, VM-aware},
location = {Orlando, Florida, USA},
series = {ACSAC '11}
}

@article{10.1145/3106164,
author = {Jiang, He and Chen, Xin and He, Tieke and Chen, Zhenyu and Li, Xiaochen},
title = {Fuzzy Clustering of Crowdsourced Test Reports for Apps},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3106164},
doi = {10.1145/3106164},
abstract = {DevOps is a new approach to drive a seamless Application (App) cycle from development to delivery. As a critical part to promote the successful implementation of DevOps, testing can significantly improve team productivity and reliably deliver user experience. However, it is difficult to use traditional testing to cover diverse mobile phones, network environments, operating systems, and so on. Hence, many large companies crowdsource their App testing tasks to workers from open platforms. In crowdsourced testing, test reports submitted by workers may be highly redundant, and their quality may vary sharply. Meanwhile, multi-bug test reports may be submitted, and their root causes are hard to diagnose. Hence, it is a time-consuming and tedious task for developers to manually inspect these test reports. To help developers address the above challenges, we issue the new problem of Fuzzy Clustering Test Reports (FULTER). Aiming to resolve FULTER, a series of barriers need to be overcome. In this study, we propose a new framework named Test Report Fuzzy Clustering Framework (TERFUR) by aggregating redundant and multi-bug test reports into clusters to reduce the number of inspected test reports. First, we construct a filter to remove invalid test reports to break through the invalid barrier. Then, a preprocessor is built to enhance the descriptions of short test reports to break through the uneven barrier. Last, a two-phase merging algorithm is proposed to partition redundant and multi-bug test reports into clusters that can break through the multi-bug barrier. Experimental results over 1,728 test reports from five industrial Apps show that TERFUR can cluster test reports by up to 78.15% in terms of AverageP, 78.41% in terms of AverageR, and 75.82% in terms of AverageF1 and outperform comparative methods by up to 31.69%, 33.06%, and 24.55%, respectively. In addition, the effectiveness of TERFUR is validated in prioritizing test reports for manual inspection.},
journal = {ACM Trans. Internet Technol.},
month = {feb},
articleno = {18},
numpages = {28},
keywords = {fuzzy clustering, duplicate detection, test report, unsupervised method, Crowdsourced testing}
}

@inproceedings{10.1145/3235715.3235746,
author = {Fletcher, Kathryn},
title = {ITS Advanced Support Team: Swiss Army Knife or Ticket Dumpster?},
year = {2018},
isbn = {9781450355827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3235715.3235746},
doi = {10.1145/3235715.3235746},
abstract = {At West Virginia University, Information Technology Services provides centralized enterprise resources and services, while additional independent IT groups provide support for individual colleges and units. ITS Advanced Support is a second-tier specialized support team of eleven individuals with diverse skills that supports over 80 software applications. In addition to responding to escalated and specialized support tickets, we serve as application administrators for select systems and participate in testing new applications and software upgrades. In this paper, I will summarize the creation of our multi-purpose Advanced Support Team, describe what we do, and explain how our team fits in the ITS organization chart and support processes. I will describe what is working well and the challenges we face juggling multiple roles and support topics.},
booktitle = {Proceedings of the 2018 ACM SIGUCCS Annual Conference},
pages = {135–138},
numpages = {4},
keywords = {team building, end-user support, reorganization, application administration, ticket escalation procedures},
location = {Orlando, Florida, USA},
series = {SIGUCCS '18}
}

@inproceedings{10.1145/3460120.3484740,
author = {Yun, Insu and Song, Woosun and Min, Seunggi and Kim, Taesoo},
title = {HardsHeap: A Universal and Extensible Framework for Evaluating Secure Allocators},
year = {2021},
isbn = {9781450384544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460120.3484740},
doi = {10.1145/3460120.3484740},
abstract = {Secure allocators have been extensively studied to mitigate heap vulnerabilities. They employ safe designs and randomized mechanisms to stop or mitigate heap exploitation. Despite extensive research efforts, secure allocators can only be evaluated by with theoretical analysis or pre-defined data sets, which are insufficient to effectively reflect powerful adversaries in the real world.In this paper, we present HardsHeap, an automatic tool for evaluating secure allocators. The key idea of HardsHeap is to use random testing (i.e., fuzzing) to evaluate secure allocators. To handle the diverse properties of secure allocators, HardsHeap supports an extensible framework, making it easy to write a validation logic for each property. Moreover, HardsHeap employs sampling-based testing, which enables us to evaluate a probabilistic mechanism prevalent in secure allocators. To eliminate redundancy in findings from HardsHeap, we devise a new technique called Statistical Significance Delta Debugging (SSDD), which extends the existing delta debugging for stochastically reproducible test cases.We evaluated HardsHeap to 10 secure allocators. Consequently, we found 56 interesting test cases, including several unsecure yet underestimated behaviors for handling large objects in secure allocators. Moreover, we discovered 10 implementation bugs. One of the bugs is integer overflow in secure allocators, making them even more invulnerable than ordinary allocators. Our evaluation also shows that SSDD successfully reduces test cases by 37.2% on average without a loss of reproducibility.},
booktitle = {Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
pages = {379–392},
numpages = {14},
keywords = {fuzzing, secure allocators, automatic exploit generation, delta debugging},
location = {Virtual Event, Republic of Korea},
series = {CCS '21}
}

@inproceedings{10.1145/99186.99275,
author = {Zannis, Marie and Mateik, Deborah},
title = {Centering on the Student Computer User (the Evolution of a Peer Training Program at the University of Maryland)},
year = {1990},
isbn = {0897914066},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/99186.99275},
doi = {10.1145/99186.99275},
abstract = {Three years ago, the University of Maryland Computer Science Center sought a suitable pool of trainers to meet the computer training needs of the student population. Since full-time professional staff were already over-committed to other training and consulting programs it was necessary to look elsewhere. The Computer Science Center has found a viable alternative in training qualified students to teach their peers.The Peer Training Program at the University of Maryland has evolved over three school years and has made various changes in that time. In keeping with the University's stated policy of commitment to computer literacy for its 28,000 on-campus students, the Computer Science Center holds evening and weekend classes regularly throughout the spring and fall semesters. Summer classes, which were well received when instituted in 1989, are offered on weekday afternoons and evenings. Most of the classes are offered in an in-house training facility. Peer Training classes are a means of equipping students to use WAM (Workstations at Maryland) public computing labs and acquainting them with some workstation software. One class, however, teaches remote communication with the University's mainframes from a home computer and covers file transfer on both the Macintosh and IBM computers. A once-a-semester word processing lab makes the Peer Training staff available to consult with students working on term papers and projects.In seeking to serve a large and diverse student body the program has experienced challenges at each stage of its growth. The authors discuss these challenges and explain how policies in scheduling, registration, communications, training, documentation, and teaching evaluation have evolved to meet these challenges. Online registration, new hardware, expansion of schedule and staff evaluation procedures are some of the areas in which there have been positive changes within the program. Increased extradepartmental demands have resulted in offering several classes out-of-house. This has added to administrative and trainer responsibilities but has extended the reach of the Center's training programs and has been a positive public relations effort.Current concerns include growing needs for additional trainers, class attendance, and changes in support staff. Advice is offered for those in the stages of planning a Peer Training Program on a college or university campus.},
booktitle = {Proceedings of the 18th Annual ACM SIGUCCS Conference on User Services},
pages = {427–433},
numpages = {7},
location = {Cincinnati, Ohio, USA},
series = {SIGUCCS '90}
}

@inproceedings{10.1145/2414721.2414727,
author = {Spinellis, Diomidis and Karakoidas, Vassilios and Louridas, Panos},
title = {Comparative Language Fuzz Testing: Programming Languages vs. Fat Fingers},
year = {2012},
isbn = {9781450316316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2414721.2414727},
doi = {10.1145/2414721.2414727},
abstract = {We explore how programs written in ten popular programming languages are affected by small changes of their source code. This allows us to analyze the extend to which these languages allow the detection of simple errors at compile or at run time. Our study is based on a diverse corpus of programs written in several programming languages systematically perturbed using a mutation-based fuzz generator. The results we obtained prove that languages with weak type systems are significantly likelier than languages that enforce strong typing to let fuzzed programs compile and run, and, in the end, produce erroneous results. More importantly, our study also demonstrates the potential of comparative language fuzz testing for evaluating programming language designs.},
booktitle = {Proceedings of the ACM 4th Annual Workshop on Evaluation and Usability of Programming Languages and Tools},
pages = {25–34},
numpages = {10},
keywords = {fuzzing, comparison, rosetta stone, programming languages},
location = {Tucson, Arizona, USA},
series = {PLATEAU '12}
}

@inproceedings{10.5555/318773.318939,
author = {Gargantini, Angelo and Heitmeyer, Constance},
title = {Using Model Checking to Generate Tests from Requirements Specifications},
year = {1999},
isbn = {3540665382},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Recently, many formal methods, such as the SCR (Software Cost Reduction) requirements method, have been proposed for improving the quality of software specifications. Although improved specifications are valuable, the ultimate objective of software development is to produce software that satisfies its requirements. To evaluate the correctness of a software implementation, one can apply black-box testing to determine whether the implementation, given a sequence of system inputs, produces the correct system outputs. This paper describes a specification-based method for constructing a suite of test sequences, where a test sequence is a sequence of inputs and outputs for testing a software implementation. The test sequences are derived from a tabular SCR requirements specification containing diverse data types, i.e., integer, boolean, and enumerated types. From the functions defined in the SCR specification, the method forms a collection of predicates called branches, which “cover” all possible software behaviors described by the specification. Based on these predicates, the method then derives a suite of test sequences by using a model checker's ability to construct counterexamples. The paper presents the results of applying our method to four specifications, including a sizable component of a contractor specification of a real system.},
booktitle = {Proceedings of the 7th European Software Engineering Conference Held Jointly with the 7th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {146–162},
numpages = {17},
location = {Toulouse, France},
series = {ESEC/FSE-7}
}

@article{10.1145/318774.318939,
author = {Gargantini, Angelo and Heitmeyer, Constance},
title = {Using Model Checking to Generate Tests from Requirements Specifications},
year = {1999},
issue_date = {Nov. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/318774.318939},
doi = {10.1145/318774.318939},
abstract = {Recently, many formal methods, such as the SCR (Software Cost Reduction) requirements method, have been proposed for improving the quality of software specifications. Although improved specifications are valuable, the ultimate objective of software development is to produce software that satisfies its requirements. To evaluate the correctness of a software implementation, one can apply black-box testing to determine whether the implementation, given a sequence of system inputs, produces the correct system outputs. This paper describes a specification-based method for constructing a suite of test sequences, where a test sequence is a sequence of inputs and outputs for testing a software implementation. The test sequences are derived from a tabular SCR requirements specification containing diverse data types, i.e., integer, boolean, and enumerated types. From the functions defined in the SCR specification, the method forms a collection of predicates called branches, which “cover” all possible software behaviors described by the specification. Based on these predicates, the method then derives a suite of test sequences by using a model checker's ability to construct counterexamples. The paper presents the results of applying our method to four specifications, including a sizable component of a contractor specification of a real system.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {oct},
pages = {146–162},
numpages = {17}
}

@proceedings{10.1145/2542128,
title = {MobileDeLi '13: Proceedings of the 2013 ACM Workshop on Mobile Development Lifecycle},
year = {2013},
isbn = {9781450326032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Mobile application usage and development is experiencing exponential growth. According to Gartner, by 2016 more than 300 billion applications will be downloaded annually. The mobile domain presents new challenges to software engineering. Mobile platforms are rapidly changing, including diverse capabilities as GPS, sensors, and input modes. Applications must be omnichannel and work on all platforms. Activated on mobile platforms, modern applications must be elastic and scale on demand according to the hardware abilities. Applications often need to support and use third-party services. Therefore, during development, security and authorization processes for the dataflow must be applied. Bring your own device (BYOD) policies and bring new security data leaks challenges. Developing such applications requires suitable practices and tools e.g., architecture techniques that relate to the complexity at hand; improved refactoring tools for hybrid applications using dynamic languages and polyglot development and applications; and testing techniques for applications that run on different devices. This workshop aims at establishing a community of researchers and practitioners to share their work and lead to further research in the mobile software engineering. The workshop has several goals. First, we want to develop relationships to create a vibrant research community in the area of mobile software development. Second, we want to identify the most important research problems for mobile software development.We have two distinguished keynote speakers, invited talks, and papers of mobile software engineering. We welcome you to work with us on these topics and define the next research directions in mobile software engineering.Mobile software engineering presents new challenges and directions. Among others, we observe the following five areas of interest: Management of the mobile applications. This refers to the technical capabilities to create, deploy, and manage a suite of applications for multiple heterogeneous devices (e.g., iOS, Android, BlackBerry, Windows) that connect securely to enterprise back-end servers.Hybrid applications versus native applications. A native application is an application designed to run in a specific environment written in a specific language. A hybrid mobile application, however, is developed using web technologies such as HTML, CSS, and JavaScript activated by a native wrapper. Building native applications requires comprehensive knowledge in the specific environment, such as Objective C (iOS), Java (Android), and C# (Windows mobile and BlackBerry). However, hybrid applications based on web technologies require more common knowledge.User experience. Applications must be developed that provide different user experiences depending on the target environment. For example, an iOS application provides a different user experience than an Android application, even though the functionality of the application must be the same.Battery life. How can developers write software that uses up as little battery life as possible?Migrations to mobile. As more users access and use mobile-based tools, developers need to enable and support migration from legacy software such as web applications to mobile.Mobile security. Mobile devices have strong networking capabilities. Hence security of personal information and businesses data become very important. Employees use their smartphones to access sensitive information. The operating system of those devices collect sensitive data that may be visible to a third-party application. Hence vulnerabilities from both the web browser and operating system must be considered.Moreover, the development of mobile applications includes the following aspects that extend existing software engineering practices: Software characteristics. 1) Software is distributed on several platforms that link between them over the network. For example, one part of an application could be on mobile phone browsers, another part might be on the cloud, and both of them are reading data from some legacy systems. 2) Mobile applications need to be elastic and scale on demand according to their environments' abilities. Functionalities need to be easily removed, added, or moved to or from the cloud. 3) Many hardware platforms exist for an application and the platforms are rapidly changing, including flexible capabilities such as GPS, sensors, and input modes. Development, however, should be for all platforms.Architecture. Mobile application development also includes several architectural challenges, such as how to support omni-channel communications and how to support new application data updates from the server, e.g., notifications about new mail or software updates. Applications must be able to easily communicate with new systems. Traditional solutions enable software to be easily designed and modified to communicate with new environments. However, the environments with which applications need to communicate are rapidly changing. As a result, traditional solutions do not fit modern software and we cannot modify applications using traditional architectural approaches to support all channels.Testing. Another aspect of mobile application development concerns software testing. How can applications be tested on arbitrary and unknown hardware? And how can we develop test-driven software without being able to run the test itself?},
location = {Indianapolis, Indiana, USA}
}

@inproceedings{10.1145/2695664.2695929,
author = {Krutz, Daniel E. and Malachowsky, Samuel A. and Shihab, Emad},
title = {Examining the Effectiveness of Using Concolic Analysis to Detect Code Clones},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695929},
doi = {10.1145/2695664.2695929},
abstract = {During the initial construction and subsequent maintenance of an application, duplication of functionality is common, whether intentional or otherwise. This replicated functionality, known as a code clone, has a diverse set of causes and can have moderate to severe adverse effects on a software project in a variety of ways. A code clone is defined as multiple code fragments that produce similar results when provided the same input. While there is an array of powerful clone detection tools, most suffer from a variety of drawbacks including, most importantly, the inability to accurately and reliably detect the more difficult clone types.This paper presents a new technique for detecting code clones based on concolic analysis, which uses a mixture of concrete and symbolic values to traverse a large and diverse portion of the source code. By performing concolic analysis on the targeted source code and then examining the holistic output for similarities, code clone candidates can be consistently identified. We found that concolic analysis was able to accurately and reliably discover all four types of code clones with an average precision of .8, recall of .91, F-score of .85 and an accuracy of .99.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {1610–1615},
numpages = {6},
keywords = {concolic analysis, code clones, software engineering},
location = {Salamanca, Spain},
series = {SAC '15}
}

@inproceedings{10.1145/2978192.2978208,
author = {Blair, Jean and Sobiesk, Edward and Ekstrom, Joseph J. and Parrish, Allen},
title = {What is Information Technology's Role in Cybersecurity?},
year = {2016},
isbn = {9781450344524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2978192.2978208},
doi = {10.1145/2978192.2978208},
abstract = {This panel will discuss and debate what role(s) the information technology discipline should have in cybersecurity. Diverse viewpoints will be considered including current and potential ACM curricular recommendations, current and potential ABET and NSA accreditation criteria, the emerging cybersecurity discipline(s), consideration of government frameworks, the need for a multi-disciplinary approach to cybersecurity, and what aspects of cybersecurity should be under information technology's purview.},
booktitle = {Proceedings of the 17th Annual Conference on Information Technology Education},
pages = {46–47},
numpages = {2},
keywords = {multi-discipline cybersecurity education, cybersecurity roles},
location = {Boston, Massachusetts, USA},
series = {SIGITE '16}
}

@inproceedings{10.1145/2676723.2677268,
author = {Hooshangi, Sara and Weiss, Richard and Cappos, Justin},
title = {Can the Security Mindset Make Students Better Testers?},
year = {2015},
isbn = {9781450329668},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676723.2677268},
doi = {10.1145/2676723.2677268},
abstract = {Writing secure code requires a programmer to think both as a defender and an attacker. One can draw a parallel between this model of thinking and techniques used in test-driven development, where students learn by thinking about how to effectively test their code and anticipate possible bugs. In this study, we analyzed the quality of both attack and defense code that students wrote for an assignment given in an introductory security class of 75 (both graduate and senior undergraduate levels) at NYU. We made several observations regarding students' behaviors and the quality of both their defensive and offensive code. We saw that student defensive programs (i.e., assignments) are highly unique and that their attack programs (i.e., test cases) are also relatively unique. In addition, we examined how student behaviors in writing defense programs correlated with their attack program's effectiveness. We found evidence that students who learn to write good defensive programs can write effective attack programs, but the converse is not true. While further exploration of causality is needed, our results indicate that a greater pedagogical emphasis on defensive security may benefit students more than one that emphasizes offense.},
booktitle = {Proceedings of the 46th ACM Technical Symposium on Computer Science Education},
pages = {404–409},
numpages = {6},
keywords = {security, python, testing, access control},
location = {Kansas City, Missouri, USA},
series = {SIGCSE '15}
}

@inproceedings{10.1145/800039.808637,
author = {Ulema, Mehmet and Larsen, Jack},
title = {Planning for In-House Software Engineering Education},
year = {1984},
isbn = {0897911261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800039.808637},
doi = {10.1145/800039.808637},
abstract = {In summary, a rapidly changing technology, a tremendous growth of software based systems, a need to retrain current technical staff, the issue of programmer productivity, the lack of established educational programs in software engineering at local colleges, and the integration of theory with practical requirements are among the major factors which force us to implement an in-house educational program in software engineering.It was learned from personal interviews and several surveys that there is a general consensus among Hazeltine management that there is a need to establish a uniform approach to the software development process, and that education and training are essential parts in any effort to improve our software capabilities. This article describes a long term plan to meet the education and training needs.Analysis of the personal interviews, surveys of managers and engineers, and a literature search have made possible the identification of company needs and requirements and target populations. A three-part program is proposed, a system approach to meet the diverse needs of executives, managers, and engineers.The Executive Program, which will cover topics such as the nature of software related project management and development and its critical or “risky” aspects, consists of an intensive one day seminar for corporate executives annually.The Management Program, which will help managers to understand and apply procedures and techniques necessary to the cost effective development of high quality embedded software products, will consist of up to six seminar/workshops each year.The Engineering Program, which will deal mainly with teaching engineers how to make effective use of the modern tools and techniques employed in the software development process, will consist of a combination of workshops, in-house courses and recommended graduate courses at local universities, taking advantage of the existing tuition reimbursment program.},
booktitle = {Proceedings of the Fifteenth SIGCSE Technical Symposium on Computer Science Education},
pages = {130–136},
numpages = {7},
series = {SIGCSE '84}
}

@article{10.1145/952980.808637,
author = {Ulema, Mehmet and Larsen, Jack},
title = {Planning for In-House Software Engineering Education},
year = {1984},
issue_date = {February 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {0097-8418},
url = {https://doi.org/10.1145/952980.808637},
doi = {10.1145/952980.808637},
abstract = {In summary, a rapidly changing technology, a tremendous growth of software based systems, a need to retrain current technical staff, the issue of programmer productivity, the lack of established educational programs in software engineering at local colleges, and the integration of theory with practical requirements are among the major factors which force us to implement an in-house educational program in software engineering.It was learned from personal interviews and several surveys that there is a general consensus among Hazeltine management that there is a need to establish a uniform approach to the software development process, and that education and training are essential parts in any effort to improve our software capabilities. This article describes a long term plan to meet the education and training needs.Analysis of the personal interviews, surveys of managers and engineers, and a literature search have made possible the identification of company needs and requirements and target populations. A three-part program is proposed, a system approach to meet the diverse needs of executives, managers, and engineers.The Executive Program, which will cover topics such as the nature of software related project management and development and its critical or “risky” aspects, consists of an intensive one day seminar for corporate executives annually.The Management Program, which will help managers to understand and apply procedures and techniques necessary to the cost effective development of high quality embedded software products, will consist of up to six seminar/workshops each year.The Engineering Program, which will deal mainly with teaching engineers how to make effective use of the modern tools and techniques employed in the software development process, will consist of a combination of workshops, in-house courses and recommended graduate courses at local universities, taking advantage of the existing tuition reimbursment program.},
journal = {SIGCSE Bull.},
month = {jan},
pages = {130–136},
numpages = {7}
}

@article{10.1145/2560016,
author = {Kuttal, Sandeep K. and Sarma, Anita and Rothermel, Gregg},
title = {On the Benefits of Providing Versioning Support for End Users: An Empirical Study},
year = {2014},
issue_date = {February 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {1073-0516},
url = {https://doi.org/10.1145/2560016},
doi = {10.1145/2560016},
abstract = {End users with little formal programming background are creating software in many different forms, including spreadsheets, web macros, and web mashups. Web mashups are particularly popular because they are relatively easy to create, and because many programming environments that support their creation are available. These programming environments, however, provide no support for tracking versions or provenance of mashups. We believe that versioning support can help end users create, understand, and debug mashups. To investigate this belief, we have added versioning support to a popular wire-oriented mashup environment, Yahoo! Pipes. Our enhanced environment, which we call “Pipes Plumber,” automatically retains versions of pipes and provides an interface with which pipe programmers can browse histories of pipes and retrieve specific versions. We have conducted two studies of this environment: an exploratory study and a larger controlled experiment. Our results provide evidence that versioning helps pipe programmers create and debug mashups. Subsequent qualitative results provide further insights into the barriers faced by pipe programmers, the support for reuse provided by our approach, and the support for debugging provided.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = {feb},
articleno = {9},
numpages = {43},
keywords = {programming barriers, End-user software engineering, Mashups, Yahoo! Pipes, reuse, debugging, versioning}
}

@inproceedings{10.1145/3491102.3517474,
author = {Balayn, Agathe and Rikalo, Natasa and Lofi, Christoph and Yang, Jie and Bozzon, Alessandro},
title = {How Can Explainability Methods Be Used to Support Bug Identification in Computer Vision Models?},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517474},
doi = {10.1145/3491102.3517474},
abstract = { Deep learning models for image classification suffer from dangerous issues often discovered after deployment. The process of identifying bugs that cause these issues remains limited and understudied. Especially, explainability methods are often presented as obvious tools for bug identification. Yet, the current practice lacks an understanding of what kind of explanations can best support the different steps of the bug identification process, and how practitioners could interact with those explanations. Through a formative study and an iterative co-creation process, we build an interactive design probe providing various potentially relevant explainability functionalities, integrated into interfaces that allow for flexible workflows. Using the probe, we perform 18 user-studies with a diverse set of machine learning practitioners. Two-thirds of the practitioners engage in successful bug identification. They use multiple types of explanations, e.g. visual and textual ones, through non-standardized sequences of interactions including queries and exploration. Our results highlight the need for interactive, guiding, interfaces with diverse explanations, shedding light on future research directions. },
booktitle = {CHI Conference on Human Factors in Computing Systems},
articleno = {184},
numpages = {16},
keywords = {user interface, machine learning model debugging, machine learning explainability, computer vision},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1109/ICSSP.2019.00027,
author = {Duarte, Carlos Henrique C.},
title = {The Quest for Productivity in Software Engineering: A Practitioners Systematic Literature Review},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSSP.2019.00027},
doi = {10.1109/ICSSP.2019.00027},
abstract = {Software productivity is perceived by practitioners as one of the most important subjects of Software Engineering (SE), because it establishes a connection between technical and economic concerns. Nonetheless, software processes are complex and productivity means different things to different people. In order to realize the full contribution of productivity research to the practice of SE, the compilation and analysis of the diverse practitioner viewpoints and concerns is required. In this paper, we develop a systematic literature review to confirm the existence of different empirical perceptions of productivity from the distinct business sectors and knowledge areas covered in practice by SE, identifying also commonalities that may exist. This review was compiled by analyzing 73 papers on empirical studies published from 1987 to 2017. The review found great variability of study findings, particularly concerning the impacts of agile and hybrid development practices on software productivity, and research gaps that could be investigated in the future.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {145–154},
numpages = {10},
keywords = {empirical studies, software productivity, systematic literature reviews},
location = {Montreal, Quebec, Canada},
series = {ICSSP '19}
}

@inproceedings{10.5555/3351736.3351774,
author = {Gogolla, Martin and Vallecillo, Antonio and Burgue\~{n}o, Loli and Hilken, Frank},
title = {Employing Classifying Terms for Testing Model Transformations},
year = {2015},
isbn = {9781467369084},
publisher = {IEEE Press},
abstract = {This contribution proposes a new technique for developing test cases for UML and OCL models. The technique is based on an approach that automatically constructs object models for class models enriched by OCL constraints. By guiding the construction process through so-called classifying terms, the built test cases in form of object models are classified into equivalence classes. A classifying term can be an arbitrary OCL term on the class model that calculates for an object model a characteristic value. From each equivalence class of object models with identical characteristic values one representative is chosen. The constructed test cases behave significantly different with regard to the selected classifying term. By building few diverse object models, properties of the UML and OCL model can be explored effectively. The technique is applied for automatically constructing relevant source model test cases for model transformations between a source and target metamodel.},
booktitle = {Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems},
pages = {312–321},
numpages = {10},
location = {Ottawa, Ontario, Canada},
series = {MODELS '15}
}

@inproceedings{10.5555/1030453.1030545,
author = {Balci, Osman and Nance, Richard E. and Arthur, James D. and Ormsby, William F.},
title = {Improving the Model Development Process: Expanding Our Horizons in Verification, Validation, and Accreditation Research and Practice},
year = {2002},
isbn = {0780376153},
publisher = {Winter Simulation Conference},
abstract = {Many different types of modeling and simulation (M&amp;S) applications, consisting of a combination of software, hardware, and humanware, are used in dozens of disciplines under diverse objectives including acquisition, analysis, education, entertainment, research, and training. Certification of sufficient accuracy of an M&amp;S application by conducting verification, validation, and accreditation (VV&amp;A) requires multifaceted knowledge and experience, and poses substantial technical and managerial challenges for researchers, practitioners, and managers. The challenges can only be met by using a very broad spectrum of approaches and expanding our horizons in VV&amp;A. This paper presents 13 strategic directions to meet those challenges. The strategic directions provide guidelines for successful VV&amp;A research and practice.},
booktitle = {Proceedings of the 34th Conference on Winter Simulation: Exploring New Frontiers},
pages = {653–663},
numpages = {11},
location = {San Diego, California},
series = {WSC '02}
}

@inproceedings{10.1145/3511430.3511467,
author = {Kumar, Kuldeep and Suri, Bharti and Wadhwa, Bimlesh},
title = {A Report on the Fifth Workshop on Software Engineering Education (SEED 2022)},
year = {2022},
isbn = {9781450396189},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511430.3511467},
doi = {10.1145/3511430.3511467},
abstract = { The 5th International Workshop on Software Engineering Education (SEED 2022), co-located with the 15th Innovations in Software Engineering Conference (ISEC 2022), aims to provide a unique forum to bring together researchers, educators, students, and practitioners to report on their experiences and their ongoing efforts in meeting the recent demands of remote teaching and learning in Software Engineering. The theme of SEED 2022 is Software Engineering Education amid a global pandemic - How can software engineering teaching meet the challenge of the sudden shift to online education triggered by the COVID-19 pandemic? Strategies for project-based learning, hybrid learning, blended learning, use of tools in teaching and learning are specifically targeted in this workshop. Further, it aims to provide a unique opportunity to Software Engineering educators and practitioners to come together and build collaborations for Software Engineering education research and practice.},
booktitle = {15th Innovations in Software Engineering Conference},
articleno = {40},
numpages = {2},
keywords = {Teaching software development, Software engineering education, Online learning},
location = {Gandhinagar, India},
series = {ISEC 2022}
}

