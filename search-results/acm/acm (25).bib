@inbook{10.1145/3368089.3409761,
author = {Wang, Zan and Yan, Ming and Chen, Junjie and Liu, Shuang and Zhang, Dongdi},
title = {Deep Learning Library Testing via Effective Model Generation},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409761},
abstract = {Deep learning (DL) techniques are rapidly developed and have been widely adopted in practice. However, similar to traditional software systems, DL systems also contain bugs, which could cause serious impacts especially in safety-critical domains. Recently, many research approaches have focused on testing DL models, while little attention has been paid for testing DL libraries, which is the basis of building DL models and directly affects the behavior of DL systems. In this work, we propose a novel approach, LEMON, to testing DL libraries. In particular, we (1) design a series of mutation rules for DL models, with the purpose of exploring different invoking sequences of library code and hard-to-trigger behaviors; and (2) propose a heuristic strategy to guide the model generation process towards the direction of amplifying the inconsistent degrees of the inconsistencies between different DL libraries caused by bugs, so as to mitigate the impact of potential noise introduced by uncertain factors in DL libraries. We conducted an empirical study to evaluate the effectiveness of LEMON with 20 release versions of 4 widely-used DL libraries, i.e., TensorFlow, Theano, CNTK, MXNet. The results demonstrate that LEMON detected 24 new bugs in the latest release versions of these libraries, where 7 bugs have been confirmed and one bug has been fixed by developers. Besides, the results confirm that the heuristic strategy for model generation indeed effectively guides LEMON in amplifying the inconsistent degrees for bugs.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {788–799},
numpages = {12}
}

@inproceedings{10.1145/2414536.2414553,
author = {Doub\'{e}, Wendy and Beh, Jeanie},
title = {Typing over Autocomplete: Cognitive Load in Website Use by Older Adults},
year = {2012},
isbn = {9781450314381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2414536.2414553},
doi = {10.1145/2414536.2414553},
abstract = {This paper describes an exploration into factors influencing the interaction of cognitive processing with visual and motor skills during website use by older adults. Twenty-eight older adults and 18 younger adults completed an on-line air-ticketing search task. Quantitative and qualitative data was captured from multiple sources, and analysed from the perspective of cognitive load. Compared with the younger control group, older adults took significantly longer and made significantly more errors in reporting the results of the task. Although the mean duration of gaze down at the keyboard and notes was similar for both age groups, the mean duration of screen gaze was significantly longer for older than for younger participants. Older adults also logged a significantly higher number of gazes from keyboard to screen. Their longer task times were associated with actions that increase cognitive load by decreasing spatial and temporal contiguity of information. Unlike their younger counterparts, they did not glance rapidly between screen and keyboard, but focussed their gaze on the keyboard, checking their typing only when they had completed a form field. Accordingly, they typed into autocomplete combo boxes, ignoring preset options, with the unexpected consequence of more expensive fares and a smaller range of results. When participant background information was analysed, task time was correlated with less Internet experience as well as with age. Supported by observation and self-report which did not signal pronounced vision or motor problems, these results suggest that task times could be reduced through automation of repeatable user interface actions with practice, especially with training in screen glancing rather than gazing. Although the number of search reporting errors was correlated with age group and not experience, greater proficiency with the interface could possibly free cognitive resources for improved problem-solving.},
booktitle = {Proceedings of the 24th Australian Computer-Human Interaction Conference},
pages = {97–106},
numpages = {10},
keywords = {interaction styles, graphical user interfaces, usability, software testing, website, ageing},
location = {Melbourne, Australia},
series = {OzCHI '12}
}

@inproceedings{10.1145/1145735.1145744,
author = {Ciupa, Ilinca and Leitner, Andreas and Oriol, Manuel and Meyer, Bertrand},
title = {Object Distance and Its Application to Adaptive Random Testing of Object-Oriented Programs},
year = {2006},
isbn = {159593457X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1145735.1145744},
doi = {10.1145/1145735.1145744},
abstract = {Testing with random inputs can give surprisingly good results if the distribution of inputs is spread out evenly over the input domain; this is the intuition behind Adaptive Random Testing, which relies on a notion of "distance" between test values. Such distances have so far been defined for integers and other elementary inputs; extending the idea to the testing of today's object-oriented programs requires a more general notion of distance, applicable to composite programmer-defined types.We define a notion of object distance, with associated algorithms to compute distances between arbitrary objects, and use it to generalize Adaptive Random Testing to such inputs. The resulting testing strategies open the way for effective automated testing of large, realistic object-oriented programs.},
booktitle = {Proceedings of the 1st International Workshop on Random Testing},
pages = {55–63},
numpages = {9},
keywords = {adaptive random testing, distanced-based testing, object distance, random testing},
location = {Portland, Maine},
series = {RT '06}
}

@article{10.5555/948785.948829,
author = {Rosiene, Joel A. and Pe Rosiene, Carolyn},
title = {Testing in the 'Small'},
year = {2003},
issue_date = {December 2003},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {19},
number = {2},
issn = {1937-4771},
abstract = {Much of software testing is designed to verify and validate large software systems. White-box, black-box, unit, and integration testing [1,2,3] are established mechanisms for testing software also at a larger scale. In this paper, we present a methodology to introduce the CS1 student to testing small programs, hence, "testing in the 'small'".The technique involves gradually introducing CS1 students to the notion of program testing. We devised a three-phase approach where we progress from clear, concise testing instructions to more vague and less precise test case selection guidelines.The technique has been successfully implemented and provides CS1 educators a technique to manage program testing.},
journal = {J. Comput. Sci. Coll.},
month = {dec},
pages = {314–318},
numpages = {5}
}

@inproceedings{10.1145/3071178.3071184,
author = {Xu, Xiong and Zhu, Ziming and Jiao, Li},
title = {An Adaptive Fitness Function Based on Branch Hardness for Search Based Testing},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071184},
doi = {10.1145/3071178.3071184},
abstract = {Search based software testing has received great attention as a means of automating the test data generation, and the goal is to improve various criteria. There are different types of coverage criteria. In this paper, we deal with the path coverage. Concretely, we focus on the path that is the most difficult to cover. One major limitation of search based testing is the inefficient and insufficiently informed fitness function. To address this problem, we propose an adaptive fitness function based on branch hardness. The branch hardness is measured by the expected number of visits of each branch in the program, which is modeled by an absorbing discrete time Markov chain. By tuning the parameters of branch hardness heuristically, the search hardness, evaluated by the variation coefficient of the fitness function, of generating test data can be minimized. Therefore, this new fitness function is more flexible than the traditional counterparts. In addition, we point out that the present definition of branch distance and the use of normalizing functions are problematic, and propose some improvements. Finally, the empirical study reveals the promising result of our proposal in this paper.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1335–1342},
numpages = {8},
keywords = {branch hardness, test data generation, fitness functions, adaptivity, search based software testing},
location = {Berlin, Germany},
series = {GECCO '17}
}

@inproceedings{10.1145/3236454.3236488,
author = {Ardito, Luca and Coppola, Riccardo and Torchiano, Marco and Al\'{e}groth, Emil},
title = {Towards Automated Translation between Generations of GUI-Based Tests for Mobile Devices},
year = {2018},
isbn = {9781450359399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236454.3236488},
doi = {10.1145/3236454.3236488},
abstract = {Market demands for faster delivery and higher software quality are progressively becoming more stringent. A key hindrance for software companies to meet such demands is how to test the software due to to the intrinsic costs of development, maintenance and evolution of testware. Especially since testware should be defined, and aligned, with all layers of system under test (SUT), including all graphical user interface (GUI) abstraction levels. These levels can be tested with different generations of GUI-based test approaches, where 2nd generation, or Layout-based, tests leverage GUI properties and 3rd generation, or Visual, tests make use of image recognition. The two approaches provide different benefits and drawbacks and are seldom used together because of the aforementioned costs, despite growing academic evidence of the complementary benefits.In this work we propose the proof of concept of a novel two-step translation approach for Android GUI testing that we aim to implement, where a translator first creates a technology independent script with actions and elements of the GUI, and then translates it to a script with the syntax chosen by the user. The approach enables users to translate Layout-based to Visual scripts and vice versa, to gain the benefits (e.g. robustness, speed and ability to emulate the user) of both generations, whilst minimizing the drawbacks (e.g. development and maintenance costs). We outline our approach from a technical perspective, discuss some of the key challenges with the realization of our approach, evaluate the feasibility and the advantages provided by our approach on an open-source Android application, and discuss the potential industrial impact of this work.},
booktitle = {Companion Proceedings for the ISSTA/ECOOP 2018 Workshops},
pages = {46–53},
numpages = {8},
location = {Amsterdam, Netherlands},
series = {ISSTA '18}
}

@inproceedings{10.1145/1868630.1868641,
author = {Ramassamy, C\'{e}dric and Fouchal, Hac\`{e}ne and Hunel, Philippe and Vidot, Nicolas},
title = {A Pragmatic Testing Approach for Wireless Sensor Networks},
year = {2010},
isbn = {9781450302753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868630.1868641},
doi = {10.1145/1868630.1868641},
abstract = {Applications over wireless sensor networks are growing quickly. Traditional software development tools are not well adapted to this technology. In particular, adequate testing methodologies are required. Many issues have not been formally addressed as energy-conservation, congestion control, reliability data dissemination, security. In this paper, we present a pragmatic approach to detect some kind of anomalies based on defined scenarios on wireless sensor networks. A scenario is considered as a set of events which should happen on the network in an ordered way. We discuss a formal architecture able to perform these scenarios over the wireless sensor networks and to raise alarms if necessary. This methodology has been implemented on a prototype and has been experimented with various examples. This contribution is a first attempt for a formal testing methodology for wireless sensor networks.},
booktitle = {Proceedings of the 6th ACM Workshop on QoS and Security for Wireless and Mobile Networks},
pages = {55–61},
numpages = {7},
keywords = {runtime monitoring, fault detection, wireless sensor networks, software testing},
location = {Bodrum, Turkey},
series = {Q2SWinet '10}
}

@inproceedings{10.1145/2949550.2949645,
author = {Garg, Rohan and Cao, Jiajun and Arya, Kapil and Cooperman, Gene and Vienne, J\'{e}r\^{o}me},
title = {Extended Batch Sessions and Three-Phase Debugging: Using DMTCP to Enhance the Batch Environment},
year = {2016},
isbn = {9781450347556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2949550.2949645},
doi = {10.1145/2949550.2949645},
abstract = {Batch environments are notoriously unfriendly because it's not easy to interactively diagnose the health of a job. A job may be terminated without warning when it reaches the end of an allotted runtime slot, or it may terminate even sooner due to an unsuspected bug that occurs only at large scale.Two strategies are proposed that take advantage of DMTCP (Distributed MultiThreaded CheckPointing) for system-level checkpointing. First, we describe a three-phase debugging strategy that permits one to interactively debug long-running MPI applications that were developed for non-interactive batch environments. Second, we review how to use the SLURM resource manager capability to easily implement extended batch sessions that overcome the typical limitation of 24 hours maximum for a single batch job on large HPC resources. We argue for greater use of this lesser known capability, as a means to remove the necessity for the application-specific checkpointing found in many long-running jobs.},
booktitle = {Proceedings of the XSEDE16 Conference on Diversity, Big Data, and Science at Scale},
articleno = {42},
numpages = {8},
location = {Miami, USA},
series = {XSEDE16}
}

@inproceedings{10.1145/2631890.2631896,
author = {Tao, Chuanqi and Gao, Jerry},
title = {Modeling Mobile Application Test Platform and Environment: Testing Criteria and Complexity Analysis},
year = {2014},
isbn = {9781450329330},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2631890.2631896},
doi = {10.1145/2631890.2631896},
abstract = { With the rapid advance of mobile computing technology and wireless networking, there is a significant increase of mobile subscriptions. This drives a strong demand on mobile application testing on mobile devices. Since mobile APPs are native to mobile devices, an underlying mobile platform becomes the basic foundation of their test environments. To achieve effective test automation, test solutions must be compatible, deployable, and executable on different mobile platforms, devices, network, and appliance APIs. This paper is written to provide an approach to modeling mobile test environments based on a Mobile Test Environment Semantic Tree (MTE_ST). Based on this model, the paper discusses test complexity evaluation methods for test environment. Furthermore, some case study results are reported to demonstrate and analyze the proposed testing models. },
booktitle = {Proceedings of the 2014 Workshop on Joining AcadeMiA and Industry Contributions to Test Automation and Model-Based Testing},
pages = {28–33},
numpages = {6},
keywords = {test modeling and analysis, mobile APP testing, mobile test environment, mobile testing},
location = {San Jose, CA, USA},
series = {JAMAICA 2014}
}

@inproceedings{10.1145/3236454.3236511,
author = {Pontes, Pedro Martins and Lima, Bruno and Faria, Jo\~{a}o Pascoal},
title = {<i>Izinto</i>: A Pattern-Based IoT Testing Framework},
year = {2018},
isbn = {9781450359399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236454.3236511},
doi = {10.1145/3236454.3236511},
abstract = {The emergence of Internet of Things (IoT) technology is expected to offer new promising solutions in various domains and, consequently, impact many aspects of everyday life. However, the development and testing of software applications and services for IoT systems encompasses several challenges that existing solutions have not yet properly addressed. Particularly, the difficulty to test IoT systems - due to their heterogeneous and distributed nature -, and the importance of testing in the development process give rise to the need for an efficient way to implement automated testing in IoT. Although there are already several tools that can be used in the testing of IoT systems, a number of issues can be pointed out, such as focusing on a specific platform, language, or standard, limiting the possibility of improvement or extension, and not providing out-of-the-box functionalities. This paper describes Izinto, a pattern-based test automation framework for integration testing of IoT systems. The framework implements in a generic way a set of test patterns specific to the IoT domain which can be easily instantiated for concrete IoT scenarios. It was validated in a number of test cases, within a concrete application scenario in the domain of Ambient Assisted Living (AAL).},
booktitle = {Companion Proceedings for the ISSTA/ECOOP 2018 Workshops},
pages = {125–131},
numpages = {7},
keywords = {test patterns, internet of things, testing framework},
location = {Amsterdam, Netherlands},
series = {ISSTA '18}
}

@inproceedings{10.1109/ASE.2019.00161,
author = {Yu, Shengcheng},
title = {Crowdsourced Report Generation via Bug Screenshot Understanding},
year = {2019},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00161},
doi = {10.1109/ASE.2019.00161},
abstract = {Quality control is a challenge of crowdsourcing, especially in software testing. As some unprofessional workers involved, low-quality yieldings may hinder crowdsourced testing from satisfying requesters' requirements. Therefore, it is in demand to assist crowdworkers to raise bug report quality. In this paper, we propose a novel auxiliary method, namely CroReG, to generate crowdsourcing bug reports by analyzing bug screenshots uploaded by crowdworkers with image understanding techniques.The preliminary experiment results show that CroReG can effectively generate bug reports containing accurate screenshot captions and providing positive guidance for crowdworkers.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1277–1279},
numpages = {3},
keywords = {bug report generation, crowdsourced testing, mobile app testing},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1109/ICSE.2017.56,
author = {Bertolino, Antonia and Miranda, Breno and Pietrantuono, Roberto and Russo, Stefano},
title = {Adaptive Coverage and Operational Profile-Based Testing for Reliability Improvement},
year = {2017},
isbn = {9781538638682},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2017.56},
doi = {10.1109/ICSE.2017.56},
abstract = {We introduce covrel, an adaptive software testing approach based on the combined use of operational profile and coverage spectrum, with the ultimate goal of improving the delivered reliability of the program under test. Operational profile-based testing is a black-box technique that selects test cases having the largest impact on failure probability in operation; as such, it is considered well suited when reliability is a major concern. Program spectrum is a characterization of a program's behavior in terms of the code entities (e.g., branches, statements, functions) that are covered as the program executes. The driving idea of covrel is to complement operational profile information with white-box coverage measures based on count spectra, so as to dynamically select the most effective test cases for reliability improvement. In particular, we bias operational profile-based test selection towards those entities covered less frequently. We assess the approach by experiments with 18 versions from 4 subjects commonly used in software testing research, comparing results with traditional operational and coverage testing. Results show that exploiting operational and coverage data in a combined adaptive way actually pays in terms of reliability improvement, with covrel overcoming conventional operational testing in more than 80% of the cases.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering},
pages = {541–551},
numpages = {11},
keywords = {test case selection, testing, operational profile, reliability, program count spectrum, operational coverage},
location = {Buenos Aires, Argentina},
series = {ICSE '17}
}

@inproceedings{10.1145/3336294.3336309,
author = {Temple, Paul and Acher, Mathieu and Perrouin, Gilles and Biggio, Battista and Jezequel, Jean-Marc and Roli, Fabio},
title = {Towards Quality Assurance of Software Product Lines with Adversarial Configurations},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336309},
doi = {10.1145/3336294.3336309},
abstract = {Software product line (SPL) engineers put a lot of effort to ensure that, through the setting of a large number of possible configuration options, products are acceptable and well-tailored to customers' needs. Unfortunately, options and their mutual interactions create a huge configuration space which is intractable to exhaustively explore. Instead of testing all products, machine learning is increasingly employed to approximate the set of acceptable products out of a small training sample of configurations. Machine learning (ML) techniques can refine a software product line through learned constraints and a priori prevent non-acceptable products to be derived. In this paper, we use adversarial ML techniques to generate adversarial configurations fooling ML classifiers and pinpoint incorrect classifications of products (videos) derived from an industrial video generator. Our attacks yield (up to) a 100% misclassification rate and a drop in accuracy of 5%. We discuss the implications these results have on SPL quality assurance.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {277–288},
numpages = {12},
keywords = {software product line, quality assurance, machine learning, software variability, software testing},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1109/ICSE.2019.00055,
author = {Cruciani, Emilio and Miranda, Breno and Verdecchia, Roberto and Bertolino, Antonia},
title = {Scalable Approaches for Test Suite Reduction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00055},
doi = {10.1109/ICSE.2019.00055},
abstract = {Test suite reduction approaches aim at decreasing software regression testing costs by selecting a representative subset from large-size test suites. Most existing techniques are too expensive for handling modern massive systems and moreover depend on artifacts, such as code coverage metrics or specification models, that are not commonly available at large scale. We present a family of novel very efficient approaches for similarity-based test suite reduction that apply algorithms borrowed from the big data domain together with smart heuristics for finding an evenly spread subset of test cases. The approaches are very general since they only use as input the test cases themselves (test source code or command line input). We evaluate four approaches in a version that selects a fixed budget B of test cases, and also in an adequate version that does the reduction guaranteeing some fixed coverage. The results show that the approaches yield a fault detection loss comparable to state-of-the-art techniques, while providing huge gains in terms of efficiency. When applied to a suite of more than 500K real world test cases, the most efficient of the four approaches could select B test cases (for varying B values) in less than 10 seconds.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {419–429},
numpages = {11},
keywords = {software testing, random projection, test suite reduction, clustering, similarity-based testing},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1145/3360581,
author = {Marcozzi, Micha\"{e}l and Tang, Qiyi and Donaldson, Alastair F. and Cadar, Cristian},
title = {Compiler Fuzzing: How Much Does It Matter?},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {OOPSLA},
url = {https://doi.org/10.1145/3360581},
doi = {10.1145/3360581},
abstract = {Despite much recent interest in randomised testing (fuzzing) of compilers, the practical impact of fuzzer-found compiler bugs on real-world applications has barely been assessed. We present the first quantitative and qualitative study of the tangible impact of miscompilation bugs in a mature compiler. We follow a rigorous methodology where the bug impact over the compiled application is evaluated based on (1) whether the bug appears to trigger during compilation; (2) the extent to which generated assembly code changes syntactically due to triggering of the bug; and (3) whether such changes cause regression test suite failures, or whether we can manually find application inputs that trigger execution divergence due to such changes. The study is conducted with respect to the compilation of more than 10 million lines of C/C++ code from 309 Debian packages, using 12% of the historical and now fixed miscompilation bugs found by four state-of-the-art fuzzers in the Clang/LLVM compiler, as well as 18 bugs found by human users compiling real code or as a by-product of formal verification efforts. The results show that almost half of the fuzzer-found bugs propagate to the generated binaries for at least one package, in which case only a very small part of the binary is typically affected, yet causing two failures when running the test suites of all the impacted packages. User-reported and formal verification bugs do not exhibit a higher impact, with a lower rate of triggered bugs and one test failure. The manual analysis of a selection of the syntactic changes caused by some of our bugs (fuzzer-found and non fuzzer-found) in package assembly code, shows that either these changes have no semantic impact or that they would require very specific runtime circumstances to trigger execution divergence.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {155},
numpages = {29},
keywords = {LLVM, software testing, fuzzing, bug impact, Clang, compilers}
}

@inproceedings{10.1109/ASE.2011.6100082,
author = {Alshahwan, Nadia and Harman, Mark},
title = {Automated Web Application Testing Using Search Based Software Engineering},
year = {2011},
isbn = {9781457716386},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2011.6100082},
doi = {10.1109/ASE.2011.6100082},
abstract = {This paper introduces three related algorithms and a tool, SWAT, for automated web application testing using Search Based Software Testing (SBST). The algorithms significantly enhance the efficiency and effectiveness of traditional search based techniques exploiting both static and dynamic analysis. The combined approach yields a 54% increase in branch coverage and a 30% reduction in test effort. Each improvement is separately evaluated in an empirical study on 6 real world web applications.},
booktitle = {Proceedings of the 2011 26th IEEE/ACM International Conference on Automated Software Engineering},
pages = {3–12},
numpages = {10},
series = {ASE '11}
}

@article{10.1145/1541822.1541824,
author = {Tappenden, Andrew F. and Miller, James},
title = {Cookies: A Deployment Study and the Testing Implications},
year = {2009},
issue_date = {June 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
issn = {1559-1131},
url = {https://doi.org/10.1145/1541822.1541824},
doi = {10.1145/1541822.1541824},
abstract = {The results of an extensive investigation of cookie deployment amongst 100,000 Internet sites are presented. Cookie deployment is found to be approaching universal levels and hence there exists an associated need for relevant Web and software engineering processes, specifically testing strategies which actively consider cookies. The semi-automated investigation demonstrates that over two-thirds of the sites studied deploy cookies. The investigation specifically examines the use of first-party, third-party, sessional, and persistent cookies within Web-based applications, identifying the presence of a P3P policy and dynamic Web technologies as major predictors of cookie usage. The results are juxtaposed with the lack of testing strategies present in the literature. A number of real-world examples, including two case studies are presented, further accentuating the need for comprehensive testing strategies for Web-based applications. The use of antirandom test case generation is explored with respect to the testing issues discussed. Finally, a number of seeding vectors are presented, providing a basis for testing cookies within Web-based applications.},
journal = {ACM Trans. Web},
month = {jul},
articleno = {9},
numpages = {49},
keywords = {Web technologies, Internet browser, Web engineering, software testing, Cookies}
}

@article{10.1145/2347696.2347701,
author = {Babu, P. Arun and Kumar, C. Senthil and Murali, N. and Jayakumar, T.},
title = {An Intuitive Approach to Determine Test Adequacy in Safety-Critical Software},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2347696.2347701},
doi = {10.1145/2347696.2347701},
abstract = {Safety-critical software must adhere to stringent quality standards and is expected to be thoroughly tested. However, exhaustive testing of software is usually impractical. The two main challenges faced by a software testing team are generation of effective test cases and demonstration of testing adequacy.This paper proposes an intuitive and conservative approach to determine the test adequacy in safety-critical software. The approach is demonstrated through a case study: the core temperature monitoring system of a nuclear reactor. We combine conservative test coverage of unique execution path test cases, and the results from mutation testing to determine the test adequacy.Although mutation testing is a powerful technique, the difficulty in identifying equivalent mutants has limited its practical utility. To gain confidence on the computed test adequacy: (i) faults during mutation testing must be induced at all possible execution paths of the code, (ii) properties of unkilled mutants must be studied, and (iii) all equivalent mutants must be detected. In this regard; results of static, dynamic and coverage analysis of the mutants is presented, and a technique to identify the likely equivalent mutants is proposed.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {sep},
pages = {1–10},
numpages = {10},
keywords = {mutation testing, equivalent mutant, safety critical software, higher order mutation, test adequacy}
}

@inproceedings{10.1145/1808266.1808283,
author = {Papadakis, Mike and Malevris, Nicos and Kallia, Maria},
title = {Towards Automating the Generation of Mutation Tests},
year = {2010},
isbn = {9781605589701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1808266.1808283},
doi = {10.1145/1808266.1808283},
abstract = {Automating software testing activities can increase the quality and drastically decrease the cost of software development. Towards this direction various automated test data generation tools have been developed. The majority of them aim at branch testing, while a quite limited number aim at a higher level of testing thoroughness such as mutation. In this paper an automated framework that makes a joint use of diverse techniques and tools is introduced in the context of automating mutation based test generation. The motivation behind this work is the use of existing techniques and tools such as symbolic execution and evolutionary testing towards automating the test input generation activity according to the weak mutation testing criterion. The proposed framework integrates existing automated tools for branch testing in order to effectively generate mutation test data. To fulfill this suggestion three automated tools are used for illustration purposes and preliminary results are obtained by applying the proposed framework to a set of java program units indicating the applicability and effectiveness of the proposed approach.},
booktitle = {Proceedings of the 5th Workshop on Automation of Software Test},
pages = {111–118},
numpages = {8},
keywords = {genetic algorithms, concolic execution, automated test case generation, symbolic execution, mutation testing},
location = {Cape Town, South Africa},
series = {AST '10}
}

@article{10.1145/3533314,
author = {Sun, Chang-ai and Dai, Hepeng and Liu, Huai and Chen, Tsong Yueh},
title = {Feedback-Directed Metamorphic Testing},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3533314},
doi = {10.1145/3533314},
abstract = {Over the past decade, metamorphic testing has gained rapidly increasing attention from both academia and industry, particularly thanks to its high efficacy on revealing real-life software faults in a wide variety of application domains. On the basis of a set of metamorphic relations among multiple software inputs and their expected outputs, metamorphic testing not only provides a test case generation strategy by constructing new (or follow-up) test cases from some original (or source) test cases, but also a test result verification mechanism through checking the relationship between the outputs of source and follow-up test cases. Many efforts have been made to further improve the cost-effectiveness of metamorphic testing from different perspectives. Some studies attempted to identify “good” metamorphic relations, while other studies were focused on applying effective test case generation strategies especially for source test cases. In this paper, we propose improving the cost-effectiveness of metamorphic testing by leveraging the feedback information obtained in the test execution process. Consequently, we develop a new approach, namely feedback-directed metamorphic testing, which makes use of test execution information to dynamically adjust the selection of metamorphic relations and selection of source test cases. We conduct an empirical study to evaluate the proposed approach based on four laboratory programs, one GNU program, and one industry program. The empirical results show that feedback-directed metamorphic testing can use fewer test cases and take less time than the traditional metamorphic testing for detecting the same number of faults. It is clearly demonstrated that the use of feedback information about test execution does help enhance the cost-effectiveness of metamorphic testing. Our work provides a new perspective to improve the efficacy and applicability of metamorphic testing as well as many other software testing techniques.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
keywords = {test execution, adaptive partition testing, random testing, metamorphic relation, feedback control, metamorphic testing}
}

