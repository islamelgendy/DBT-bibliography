@inproceedings{10.1145/2362536.2362545,
author = {Lee, Jihyun and Kang, Sungwon and Lee, Danhyung},
title = {A Survey on Software Product Line Testing},
year = {2012},
isbn = {9781450310949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2362536.2362545},
doi = {10.1145/2362536.2362545},
abstract = {Software product line (SPL) testing consists of two separate but closely related test engineering activities: domain testing and application testing. Various software product line testing approaches have been developed over the last decade, and surveys have been conducted on them. However, thus far none of them deeply addressed the questions of what researches have been conducted in order to overcome the challenges posed by the two separate testing activities and their relationships. Thus, this paper surveys the current software product line testing approaches by defining a reference SPL testing processes and identifying, based on them, key research perspectives that are important in SPL testing. Through this survey, we identify the researches that addressed the challenges and also derive open research opportunities from each perspective.},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
pages = {31–40},
numpages = {10},
keywords = {software testing, software product line engineering, software product line testing},
location = {Salvador, Brazil},
series = {SPLC '12}
}

@inproceedings{10.1145/3183440.3183468,
author = {Segura, Sergio and Zhou, Zhi Quan},
title = {Metamorphic Testing 20 Years Later: A Hands-on Introduction},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183468},
doi = {10.1145/3183440.3183468},
abstract = {Two of the key challenges in software testing are the automated generation of test cases, and the identification of failures by checking test outputs. Both challenges are effectively addressed by metamorphic testing (MT), a software testing technique where failures are not revealed by checking an individual concrete output, but by checking the relations among the inputs and outputs of multiple executions of the software under test. Two decades after its introduction, MT is becoming a fully-fledged testing paradigm with successful applications in multiple domains including, among others, big data engineering, simulation and modeling, compilers, machine learning programs, autonomous cars and drones, and cybersecurity. This technical briefing will provide an introduction to MT from a double perspective. First, we will present the technique and the results of a novel survey outlining its main trends and lessons learned. Then, we will go deeper and present some of the successful applications of the technique, as well as challenges and opportunities on the topic. The briefing will be complemented with practical exercises on testing real web applications and APIs.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {538–539},
numpages = {2},
keywords = {metamorphic testing, tutorial},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/2934466.2934472,
author = {Temple, Paul and Galindo, Jos\'{e} A. and Acher, Mathieu and J\'{e}z\'{e}quel, Jean-Marc},
title = {Using Machine Learning to Infer Constraints for Product Lines},
year = {2016},
isbn = {9781450340502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2934466.2934472},
doi = {10.1145/2934466.2934472},
abstract = {Variability intensive systems may include several thousand features allowing for an enormous number of possible configurations, including wrong ones (e.g. the derived product does not compile). For years, engineers have been using constraints to a priori restrict the space of possible configurations, i.e. to exclude configurations that would violate these constraints. The challenge is to find the set of constraints that would be both precise (allow all correct configurations) and complete (never allow a wrong configuration with respect to some oracle). In this paper, we propose the use of a machine learning approach to infer such product-line constraints from an oracle that is able to assess whether a given product is correct. We propose to randomly generate products from the product line, keeping for each of them its resolution model. Then we classify these products according to the oracle, and use their resolution models to infer cross-tree constraints over the product-line. We validate our approach on a product-line video generator, using a simple computer vision algorithm as an oracle. We show that an interesting set of cross-tree constraint can be generated, with reasonable precision and recall.},
booktitle = {Proceedings of the 20th International Systems and Software Product Line Conference},
pages = {209–218},
numpages = {10},
keywords = {software product lines, machine learning, constraints and variability mining, variability modeling, software testing},
location = {Beijing, China},
series = {SPLC '16}
}

@inproceedings{10.1145/2501553.2501556,
author = {Machado, Pedro and Campos, Jos\'{e} and Abreu, Rui},
title = {MZoltar: Automatic Debugging of Android Applications},
year = {2013},
isbn = {9781450323123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2501553.2501556},
doi = {10.1145/2501553.2501556},
abstract = { Automated diagnosis of errors and/or failures detected during software testing can greatly improve the efficiency of the debugging process, and thus help to make applications more reliable. In this paper, we propose an approach, dubbed MZoltar, offering dynamic analysis (namely, spectrum-based fault localization) of mobile apps that produces a diagnostic report to help identifying potential defects quickly. The approach also offers a graphical representation of the diagnostic report, making it easier to understand. Our experimental results show that the approach requires low runtime overhead (5.75% on average), while the tester needs to inspect 5 components (statements in this paper) on average to find the fault. },
booktitle = {Proceedings of the 2013 International Workshop on Software Development Lifecycle for Mobile},
pages = {9–16},
numpages = {8},
keywords = {fault detection, automated debugging, Mobile software},
location = {Saint Petersburg, Russia},
series = {DeMobile 2013}
}

@inproceedings{10.1145/2799979.2799988,
author = {Wang, Xuefei and Ma, Hengtai and Jing, Lisha},
title = {A Dynamic Marking Method for Implicit Information Flow in Dynamic Taint Analysis},
year = {2015},
isbn = {9781450334532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2799979.2799988},
doi = {10.1145/2799979.2799988},
abstract = {Dynamic taint analysis is an important technique for tracking information flow in software and it has been widely applied in the field of software testing, debugging and vulnerability detection. However, most of the dynamic taint analysis tools only handle explicit information flow, while ignoring the implicit information flow, resulting in a large number of false negative errors. Considering this situation, we present a dynamic marking method for implicit information flow, to handle a specific type of control-dependence. The method can identify and propagate implicit data during runtime, thus increasing the coverage of the tested program. we also propose pipeline, integrating our method in the process of dynamic taint analysis. Pipeline is implemented on the base of the dynamic taint analysis framework avalanche, and is designed to detect vulnerabilities in binary programs. In the studies, we applied the tool to 5 applications from some open-source projects, and it has effectively located and propagated the specific kind of implicit information flow.},
booktitle = {Proceedings of the 8th International Conference on Security of Information and Networks},
pages = {275–282},
numpages = {8},
keywords = {control dependence, dynamic taint analysis, implicit information flow, dynamic taint analysis framework},
location = {Sochi, Russia},
series = {SIN '15}
}

@proceedings{10.1145/1390832,
title = {TAV-WEB '08: Proceedings of the 2008 Workshop on Testing, Analysis, and Verification of Web Services and Applications},
year = {2008},
isbn = {9781605580531},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The last decade has seen the explosive growth of interactive Web software applications in a diverse set of domains including retail, electronic commerce, wikis, blogs, social network services, etc. This explosive growth is likely to accelerate further by adoption of the service oriented computing paradigm that enables interactions among Web accessible software components. Challenges in developing Web accessible software have inspired a new wave of languages, standards, and tools that have not yet become part of the mainstream software engineering research and education. On the other hand, an increasingly large number of software developers work exclusively on Web software development.TAV-WEB 2008 is the third in a series of workshops that focus on testing, analysis and verification of web software. The scope of TAV-WEB 2008 has been extended (from the web service scope of previous workshops TAV-WEB 2004 and TAV-WEB 2006) to include all Web software. The goal of these workshops has been to bring together researchers from academic, research, and industrial communities interested in the emerging area of dependable Web software development, to present and discuss their recent research results.The TAV-WEB 2008 program consists of seven technical papers and an invited tool demonstration reporting recent research results on testing, analysis and verification of web software.},
location = {Seattle, Washington}
}

@inproceedings{10.1145/3194810.3194812,
author = {Renzullo, Joseph and Weimer, Westley and Moses, Melanie and Forrest, Stephanie},
title = {Neutrality and Epistasis in Program Space},
year = {2018},
isbn = {9781450357531},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194810.3194812},
doi = {10.1145/3194810.3194812},
abstract = {Neutral networks in biology often contain diverse solutions with equal fitness, which can be useful when environments (requirements) change over time. In this paper, we present a method for studying neutral networks in software. In these networks, we find multiple solutions to held-out test cases (latent bugs), suggesting that neutral software networks also exhibit relevant diversity. We also observe instances of positive epistasis between random mutations, i.e. interactions that collectively increase fitness. Positive epistasis is rare as a fraction of the total search space but significant as a fraction of the objective space: 9% of the repairs we found to look (and 4.63% across all programs analyzed) were produced by positive interactions between mutations. Further, the majority (62.50%) of unique repairs are instances of positive epistasis.},
booktitle = {Proceedings of the 4th International Workshop on Genetic Improvement Workshop},
pages = {1–8},
numpages = {8},
keywords = {software evolution, automated software engineering, biological networks, software testing and debugging, network science},
location = {Gothenburg, Sweden},
series = {GI '18}
}

@inproceedings{10.1145/3468264.3468612,
author = {Yan, Ming and Chen, Junjie and Zhang, Xiangyu and Tan, Lin and Wang, Gan and Wang, Zan},
title = {Exposing Numerical Bugs in Deep Learning via Gradient Back-Propagation},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468612},
doi = {10.1145/3468264.3468612},
abstract = {Numerical computation is dominant in deep learning (DL) programs. Consequently, numerical bugs are one of the most prominent kinds of defects in DL programs. Numerical bugs can lead to exceptional values such as NaN (Not-a-Number) and INF (Infinite), which can be propagated and eventually cause crashes or invalid outputs. They occur when special inputs cause invalid parameter values at internal mathematical operations such as log(). In this paper, we propose the first dynamic technique, called GRIST, which automatically generates a small input that can expose numerical bugs in DL programs. GRIST piggy-backs on the built-in gradient computation functionalities of DL infrastructures. Our evaluation on 63 real-world DL programs shows that GRIST detects 78 bugs including 56 unknown bugs. By submitting them to the corresponding issue repositories, eight bugs have been confirmed and three bugs have been fixed. Moreover, GRIST can save 8.79X execution time to expose numerical bugs compared to running original programs with its provided inputs. Compared to the state-of-the-art technique DEBAR (which is a static technique), DEBAR produces 12 false positives and misses 31 true bugs (of which 30 bugs can be found by GRIST), while GRIST only misses one known bug in those programs and no false positive. The results demonstrate the effectiveness of GRIST.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {627–638},
numpages = {12},
keywords = {Search-based Software Testing, Numerical Bug, Deep Learning Testing, Gradient Back-propagation},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3397125.3397137,
author = {Waheed, Fatima and Azam, Farooque and Anwar, Muhammad Waseem and Rasheed, Yawar},
title = {Model Driven Approach for Automatic Script Generation in Stress Testing of Web Applications},
year = {2020},
isbn = {9781450377492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397125.3397137},
doi = {10.1145/3397125.3397137},
abstract = {Mostly, software systems operate satisfactory under normal operating condition. However, if abnormal conditions are encountered i.e in the event of extraordinary load conditions, the response of the software systems may also become abnormal. Due to this reason, Stress Testing is considered an important part of testing that is used to determine the behaviour of software in extraordinary load conditions. Most of the research work that has been done in the domain of stress testing focuses on development of systems using traditional approaches of programming/coding. In this manuscript, we have anticipated an innovative approach for automatic script generation in stress testing of web applications. The proposed approach includes a meta model that may be extended for automation and model based development of such a system/ tool that may generate test scripts for stress testing of web applications using concepts of IFML.},
booktitle = {Proceedings of the 2020 6th International Conference on Computer and Technology Applications},
pages = {46–50},
numpages = {5},
keywords = {Metamodel, UML Profile, Software testing, Model Driven software engineering, IFML, Model Driven Testing},
location = {Antalya, Turkey},
series = {ICCTA '20}
}

@article{10.1145/2659118.2659136,
author = {Zhou, Jingang and Yin, Kun},
title = {Automated Web Testing Based on Textual-Visual UI Patterns: The UTF Approach},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2659118.2659136},
doi = {10.1145/2659118.2659136},
abstract = {Automated software testing is the only resort for delivering quality software, since there are usually large test suites to be executed, especially for regression testing. Though many automated testing tools and techniques have been developed, they still do not solve all problems like cost and maintenance, and they can even be brittle in some situations, thus confining their adoption. To address these issues, we develop a pattern-based automated testing framework, called UTF (User-oriented Testing Framework), for Web applications. UTF encodes textual-visual information about and relationships between widgets into a domain specific language for test scripts based on the underlying invariant structural patterns in the DOM, which allows test scripts to be easily created and maintained. In addition, UTF provides flexible extension and customization capabilities to make it adaptable for various Web-application scenarios. Our experiences show UTF can greatly reduce the cost of adopting automated testing and facilitate its institutionalization.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {sep},
pages = {1–6},
numpages = {6},
keywords = {domain-specific language, web application, automated testing, user-interface pattern}
}

@inproceedings{10.1145/2420950.2420997,
author = {Collberg, Christian and Martin, Sam and Myers, Jonathan and Nagra, Jasvir},
title = {Distributed Application Tamper Detection via Continuous Software Updates},
year = {2012},
isbn = {9781450313124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2420950.2420997},
doi = {10.1145/2420950.2420997},
abstract = {We present a new general technique for protecting clients in distributed systems against Remote Man-at-the-end (R-MATE) attacks. Such attacks occur in settings where an adversary has physical access to an untrusted client device and can obtain an advantage from tampering with the hardware itself or the software it contains.In our system, the trusted server overwhelms the analytical abilities of the untrusted client by continuously and automatically generating and pushing to him diverse client code variants. The diversity subsystem employs a set of primitive code transformations that provide an ever-changing attack target for the adversary, making tampering difficult without this being detected by the server.},
booktitle = {Proceedings of the 28th Annual Computer Security Applications Conference},
pages = {319–328},
numpages = {10},
keywords = {diversity, defense-in-depth, tamperproofing, distributed systems, software protection, security, renewability, obfuscation},
location = {Orlando, Florida, USA},
series = {ACSAC '12}
}

@article{10.1145/43857.43860,
author = {Donnelly, K. F. and Gluck, K. A.},
title = {A Case Study in Test Environment Evolution},
year = {1988},
issue_date = {Jan. 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/43857.43860},
doi = {10.1145/43857.43860},
abstract = {As the demand for increasingly complex software systems grows, and our software development environments become increasingly sophisticated in response, our testing technology must keep pace. This paper describes the evolution of one software testing environment and the genesis of its logical successor.pastel (PICS Automated System Testing Environment for Leap) originated over a decade ago, with an interpreter for a simple testing language used on a single project by a group of about ten people. As the demands of testing very large systems grew, pastel's functionality expanded. Today's pastel includes facilities for creating a test by simply exercising the system under test, for running the test in a variety of modes, and for capturing and automatically analyzing test results. pastel allows application experts to create tests easily; no sophisticated programming skill is required. pastel is now used by projects throughout the Software Technology and Systems Area of Bell Communications Research.pastel is a relatively mature product, an adequate testing system for the monolithic database systems it was intended to exercise. astra, its successor, is now being designed to test systems of interacting systems built on different sizes and flavors of hardware. This paper reviews the evolution of pastel and the preliminary design work and unifying concepts underlying astra.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jan},
pages = {22–28},
numpages = {7}
}

@inproceedings{10.1145/3501409.3501564,
author = {Chen, Zhuo and Wang, Yongjun},
title = {JFD: Automatic Java Fuzz Driver Generation},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501409.3501564},
doi = {10.1145/3501409.3501564},
abstract = {Java is widely used in many areas. There have been a lot of works on improving the security of Java. In the industry, fuzzing is the most efficient software testing technique to discover real-world vulnerabilities and improve software security. Recent efforts are seen to make library fuzzing more automatically and have performed well in general library fuzzing. However, these tools cannot solve problems in Java library fuzzing appropriately. In this paper, we present JFD, an automatic Java fuzz driver generation system, which can generate fuzz drivers based on consumer programs, that utilize target library programs. Our approach consists of three parts: a static-analysis-based method to analyze call dependencies graphs of target Java library, a value-set-based method to analyze argument dependencies graphs of target Java library, and a method to synthesize fuzz drivers in the style of JQF. We then evaluate JFD on JVM native libraries. JFD can generate appropriate fuzz drivers.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {862–867},
numpages = {6},
keywords = {software security, JQF, fuzz driver generation, fuzzing, Java},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/64135.65018,
author = {Clarke, Lori A. and Richardson, Debra J. and Zeil, Steven J.},
title = {TEAM: A Support Environment for Testing, Evaluation, and Analysis},
year = {1988},
isbn = {089791290X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/64135.65018},
doi = {10.1145/64135.65018},
abstract = {Current research indicates that software reliability needs to be achieved through the careful integration of a number of diverse testing and analysis techniques. To address this need, the TEAM environment has been designed to support the integration of and experimentation with an ever growing number of software testing and analysis tools. To achieve this flexibility, we exploit three design principles: component technology so that common underlying functionality is recognized; generic realizations so that these common functions can be instantiated as diversely as possible; and language independence so that tools can work on multiple languages, even allowing some tools to be applicable to different phases of the software lifecycle. The result is an environment that contains building blocks for easily constructing and experimenting with new testing and analysis techniques. Although the first prototype has just recently been implemented, we feel it demonstrates how modularity, genericity, and language independence further extensibility and integration.},
booktitle = {Proceedings of the Third ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments},
pages = {153–162},
numpages = {10},
location = {Boston, Massachusetts, USA},
series = {SDE 3}
}

@article{10.1145/64140.65018,
author = {Clarke, Lori A. and Richardson, Debra J. and Zeil, Steven J.},
title = {TEAM: A Support Environment for Testing, Evaluation, and Analysis},
year = {1988},
issue_date = {Feb. 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {2},
issn = {0362-1340},
url = {https://doi.org/10.1145/64140.65018},
doi = {10.1145/64140.65018},
abstract = {Current research indicates that software reliability needs to be achieved through the careful integration of a number of diverse testing and analysis techniques. To address this need, the TEAM environment has been designed to support the integration of and experimentation with an ever growing number of software testing and analysis tools. To achieve this flexibility, we exploit three design principles: component technology so that common underlying functionality is recognized; generic realizations so that these common functions can be instantiated as diversely as possible; and language independence so that tools can work on multiple languages, even allowing some tools to be applicable to different phases of the software lifecycle. The result is an environment that contains building blocks for easily constructing and experimenting with new testing and analysis techniques. Although the first prototype has just recently been implemented, we feel it demonstrates how modularity, genericity, and language independence further extensibility and integration.},
journal = {SIGPLAN Not.},
month = {nov},
pages = {153–162},
numpages = {10}
}

@article{10.1145/64137.65018,
author = {Clarke, Lori A. and Richardson, Debra J. and Zeil, Steven J.},
title = {TEAM: A Support Environment for Testing, Evaluation, and Analysis},
year = {1988},
issue_date = {November 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/64137.65018},
doi = {10.1145/64137.65018},
abstract = {Current research indicates that software reliability needs to be achieved through the careful integration of a number of diverse testing and analysis techniques. To address this need, the TEAM environment has been designed to support the integration of and experimentation with an ever growing number of software testing and analysis tools. To achieve this flexibility, we exploit three design principles: component technology so that common underlying functionality is recognized; generic realizations so that these common functions can be instantiated as diversely as possible; and language independence so that tools can work on multiple languages, even allowing some tools to be applicable to different phases of the software lifecycle. The result is an environment that contains building blocks for easily constructing and experimenting with new testing and analysis techniques. Although the first prototype has just recently been implemented, we feel it demonstrates how modularity, genericity, and language independence further extensibility and integration.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {nov},
pages = {153–162},
numpages = {10}
}

@inproceedings{10.1145/1062455.1062556,
author = {Berner, Stefan and Weber, Roland and Keller, Rudolf K.},
title = {Observations and Lessons Learned from Automated Testing},
year = {2005},
isbn = {1581139632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1062455.1062556},
doi = {10.1145/1062455.1062556},
abstract = {This report addresses some of our observations made in a dozen of projects in the area of software testing, and more specifically, in automated testing. It documents, analyzes and consolidates what we consider to be of interest to the community. The major findings can be summarized in a number of lessons learned, covering test strategy, testability, daily integration, and best practices.The report starts with a brief description of five sample projects. Then, we discuss our observations and experiences and illustrate them with the sample projects. The report concludes with a synopsis of these experiences and with suggestions for future test automation endeavors.},
booktitle = {Proceedings of the 27th International Conference on Software Engineering},
pages = {571–579},
numpages = {9},
keywords = {software test, automated testing, test management},
location = {St. Louis, MO, USA},
series = {ICSE '05}
}

@inproceedings{10.5555/2093889.2093904,
author = {King, Tariq M. and Ganti, Annaji S. and Froslie, David},
title = {Enabling Automated Integration Testing of Cloud Application Services in Virtualized Environments},
year = {2011},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software development under the cloud computing model brings the advantage that new applications can be rapidly constructed by tailoring existing services. However, the use of Internet-based services as software components, leads to the development of applications in which some building blocks are hosted remotely, rather than locally in a controlled environment. This aspect of cloud-based development, when coupled with factors such as service autonomy, complexity, and high dependability criteria, make software testing of the cloud especially challenging.In this paper we present a novel approach to support integration testing of applications that depend on remotely-hosted cloud services. Our approach seeks to reuse elements of the test automation, typically built to validate a cloud service prior to its deployment, for the realization of Test Support-as-a-Service (TSaaS). TSaaS provides developers with a set of functions that enable integration testing of cloud services using controlled virtual environments. To facilitate continued evaluation of our approach, we have implemented a prototype of TSaaS that is compatible with the Windows Azure platform.},
booktitle = {Proceedings of the 2011 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {120–132},
numpages = {13},
location = {Toronto, Ontario, Canada},
series = {CASCON '11}
}

@inproceedings{10.1145/2739482.2764716,
author = {Boussaa, Mohamed and Barais, Olivier and Sunye, Gerson and Baudry, Benoit},
title = {A Novelty Search-Based Test Data Generator for Object-Oriented Programs},
year = {2015},
isbn = {9781450334884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739482.2764716},
doi = {10.1145/2739482.2764716},
abstract = {In search-based structural testing, meta-heuristic search techniques have been frequently used to automate test data generation. In this paper, we introduce the use of novelty search algorithm to the test data generation problem based on statement-covered criterion. In this approach, we seek to explore the search space by considering diversity as the unique objective function to be optimized. In fact, instead of having a fitness-based selection, we select test cases based on a novelty score showing how different they are compared to all other solutions evaluated so far.},
booktitle = {Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {1359–1360},
numpages = {2},
keywords = {structural coverage, novelty search, automated test data generation, search-based software testing, genetic algorithm},
location = {Madrid, Spain},
series = {GECCO Companion '15}
}

@inproceedings{10.1145/3402842.3407158,
author = {Sun, Jun and Yang, Zijiang},
title = {ObjSim: Efficient Testing of Cyber-Physical Systems},
year = {2020},
isbn = {9781450380324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3402842.3407158},
doi = {10.1145/3402842.3407158},
abstract = {Cyber-physical systems (CPSs) play a critical role in automating public infrastructure and thus attract wide range of attacks. Assessing the effectiveness of defense mechanisms is challenging as realistic sets of attacks to test them against are not always available. In this short paper, we briefly describe smart fuzzing, an automated, machine learning guided technique for systematically producing test suites of CPS network attacks. Our approach uses predictive ma- chine learning models and meta-heuristic search algorithms to guide the fuzzing of actuators so as to drive the CPS into different unsafe physical states. The approach has been proven effective on two real-world CPS testbeds.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Testing, Analysis, and Verification of Cyber-Physical Systems and Internet of Things},
pages = {1–2},
numpages = {2},
keywords = {machine learning, fuzzing, network, cyber-physical system, testing},
location = {Virtual Event, USA},
series = {TAV-CPS/IoT 2020}
}

@inproceedings{10.1145/2134243.2134249,
author = {Groce, Alex},
title = {(Quickly) Testing the Tester via Path Coverage},
year = {2009},
isbn = {9781605586564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2134243.2134249},
doi = {10.1145/2134243.2134249},
abstract = {The configuration complexity and code size of an automated testing framework may grow to a point that the tester itself becomes a significant software artifact, prone to poor configuration and implementation errors. Unfortunately, testing the tester by using old versions of the software under test (SUT) may be impractical or impossible: test framework changes may have been motivated by interface changes in the tested system, or fault detection may become too expensive in terms of computing time to justify running until errors are detected on older versions of the software. We propose the use of path coverage measures as a "quick and dirty" method for detecting many faults in complex test frameworks. We also note the possibility of using techniques developed to diversify state-space searches in model checking to diversify test focus, and an associated classification of tester changes into focus-changing and non-focus-changing modifications.},
booktitle = {Proceedings of the Seventh International Workshop on Dynamic Analysis},
pages = {22–28},
numpages = {7},
keywords = {regression testing, test frameworks, evaluation of test systems},
location = {Chicago, Illinois},
series = {WODA '09}
}

@inproceedings{10.1145/1866210.1866214,
author = {Qi, Yao and Nir-Buchbinder, Yarden and Farchi, Eitan and Das, Raja and Luo, Zhi Da and Gan, Zhi},
title = {Unit Testing for Concurrent Business Code},
year = {2010},
isbn = {9781450301367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866210.1866214},
doi = {10.1145/1866210.1866214},
abstract = {Performing unit testing on concurrent programs is a known challenge. Several solutions have been proposed for the challenges, that provide only a partial answer. We argue that there are two kinds of concurrent code writing, namely concurrency protocols and concurrent "business code", and that they are different not only in the coding itself, but also in the way unit testing should be done for them. We show that the current solutions to concurrent unit testing only give a satisfactory answer to concurrency protocols, but not to concurrent business code. We have designed and implemented a unit testing framework suitable for concurrent business code, as part of the IBM Multicore Software Development Kit. This paper presents the distinction between the types of concurrent programming, and describes the new framework.},
booktitle = {Proceedings of the 8th Workshop on Parallel and Distributed Systems: Testing, Analysis, and Debugging},
pages = {37–47},
numpages = {11},
keywords = {business code, concurrency, unit testing},
location = {Trento, Italy},
series = {PADTAD '10}
}

