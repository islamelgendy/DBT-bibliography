@inproceedings{10.1145/2884781.2884797,
author = {Matinnejad, Reza and Nejati, Shiva and Briand, Lionel C. and Bruckmann, Thomas},
title = {Automated Test Suite Generation for Time-Continuous Simulink Models},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884797},
doi = {10.1145/2884781.2884797},
abstract = {All engineering disciplines are founded and rely on models, although they may differ on purposes and usages of modeling. Interdisciplinary domains such as Cyber Physical Systems (CPSs) seek approaches that incorporate different modeling needs and usages. Specifically, the Simulink modeling platform greatly appeals to CPS engineers due to its seamless support for simulation and code generation. In this paper, we propose a test generation approach that is applicable to Simulink models built for both purposes of simulation and code generation. We define test inputs and outputs as signals that capture evolution of values over time. Our test generation approach is implemented as a meta-heuristic search algorithm and is guided to produce test outputs with diverse shapes according to our proposed notion of diversity. Our evaluation, performed on industrial and public domain models, demonstrates that: (1) In contrast to the existing tools for testing Simulink models that are only applicable to a subset of code generation models, our approach is applicable to both code generation and simulation Simulink models. (2) Our new notion of diversity for output signals outperforms random baseline testing and an existing notion of signal diversity in revealing faults in Simulink models. (3) The fault revealing ability of our test generation approach outperforms that of the Simulink Design Verifier, the only testing toolbox for Simulink.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {595–606},
numpages = {12},
keywords = {search-based software testing, time-continuous behaviors, output diversity, structural coverage, Simulink Design Verifier (SLDV), software testing, simulink models, signal features},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2889160.2889162,
author = {Matinnejad, Reza and Nejati, Shiva and Briand, Lionel C. and Bruckmann, Thomas},
title = {SimCoTest: A Test Suite Generation Tool for Simulink/Stateflow Controllers},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889162},
doi = {10.1145/2889160.2889162},
abstract = {We present SimCoTest, a tool to generate small test suites with high fault revealing ability for Simulink/Stateflow controllers. SimCoTest uses meta-heuristic search to (1) maximize the likelihood of presence of specific failure patterns in output signals (failure-based test generation), and to (2) maximize diversity of output signal shapes (output diversity test generation). SimCoTest has been evaluated on industrial Simulink models and has been systematically compared with Simuilnk Design Verifier (SLDV), an alternative commercial Simulink testing tool. Our results show that the fault revealing ability of SimCoTest outperforms that of SLDV. Further, in contrast to SLDV, SimCoTest is applicable to Simulink/Stateflow models in their entirety. A video describing the main features of SimCoTest is available at: https://youtu.be/YnXgveiGXEA},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {585–588},
numpages = {4},
keywords = {simulink/stateflow models, simulink design verifier (SLDV), software testing, failure-based test generation, search-based software testing, output diversity},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1109/SBST.2019.00010,
author = {Panichella, Annibale},
title = {Beyond Unit-Testing in Search-Based Test Case Generation: Challenges and Opportunities},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SBST.2019.00010},
doi = {10.1109/SBST.2019.00010},
abstract = {Over the last decades, white-box search-based techniques have been applied to automate the design and the execution of test cases. While most of the research effort has been devoted to unit-level testing, integration-level test case generation requires to solve several open challenges, such as the combinatorial explosion of conditions or pre-condition failures. This paper summarizes these challenges in white-box testing and highlights possible research directions to overcome them.},
booktitle = {Proceedings of the 12th International Workshop on Search-Based Software Testing},
pages = {7–8},
numpages = {2},
keywords = {search-based software testing, white-box testing, test case generation, integration testing},
location = {Montreal, Quebec, Canada},
series = {SBST '19}
}

@inproceedings{10.1145/2483760.2483789,
author = {Kifetew, Fitsum M. and Panichella, Annibale and De Lucia, Andrea and Oliveto, Rocco and Tonella, Paolo},
title = {Orthogonal Exploration of the Search Space in Evolutionary Test Case Generation},
year = {2013},
isbn = {9781450321594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2483760.2483789},
doi = {10.1145/2483760.2483789},
abstract = { The effectiveness of evolutionary test case generation based on Genetic Algorithms (GAs) can be seriously impacted by genetic drift, a phenomenon that inhibits the ability of such algorithms to effectively diversify the search and look for alternative potential solutions. In such cases, the search becomes dominated by a small set of similar individuals that lead GAs to converge to a sub-optimal solution and to stagnate, without reaching the desired objective. This problem is particularly common for hard-to-cover program branches, associated with an extremely large solution space. In this paper, we propose an approach to solve this problem by integrating a mechanism for orthogonal exploration of the search space into standard GA. The diversity in the population is enriched by adding individuals in orthogonal directions, hence providing a more effective exploration of the solution space. To the best of our knowledge, no prior work has addressed explicitly the issue of evolution direction based diversification in the context of evolutionary testing. Results achieved on 17 Java classes indicate that the proposed enhancements make GA much more effective and efficient in automating the testing process. In particular, effectiveness (coverage) was significantly improved in 47% of the subjects and efficiency (search budget consumed) was improved in 85% of the subjects on which effectiveness remains the same. },
booktitle = {Proceedings of the 2013 International Symposium on Software Testing and Analysis},
pages = {257–267},
numpages = {11},
keywords = {orthogonal exploration, test case generation, genetic algorithms, genetic drift, Search based testing},
location = {Lugano, Switzerland},
series = {ISSTA 2013}
}

@inproceedings{10.1145/3361242.3361259,
author = {Lei, Cheng and Hu, Benlin and Wang, Dong and Zhang, Shu and Chen, Zhenyu},
title = {A Preliminary Study on Data Augmentation of Deep Learning for Image Classification},
year = {2019},
isbn = {9781450377010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361242.3361259},
doi = {10.1145/3361242.3361259},
abstract = {Deep learning models have a large number of free parameters that need to be calculated by effective training of the models on a great deal of training data to improve their generalization performance. However, data obtaining and labeling is expensive in practice. Data augmentation is one of the methods to alleviate this problem. In this paper, we conduct a preliminary study on how four variables (augmentation method, augmentation rate, size of basic dataset per label, and method combination) can affect the accuracy of deep learning for image classification. The study provides some guidelines: (1) altering the geometry of the images is not always better than those just lighting and color. (2) 2-3 times augmentation rate is good enough for training. (3) the combination of two geometry methods degrade the performance, while combinations with at least one photometric method, will improve the performance, especially when one method is a photometric method and another is a geometry method. (4) the sequence of methods in combination has little effect on the performance.},
booktitle = {Proceedings of the 11th Asia-Pacific Symposium on Internetware},
articleno = {20},
numpages = {6},
keywords = {data quality, quality assurance, model quality, Data augmentation},
location = {Fukuoka, Japan},
series = {Internetware '19}
}

@inproceedings{10.1145/3092282.3092314,
author = {Babic, Domagoj},
title = {SunDew: Systematic Automated Security Testing (Keynote)},
year = {2017},
isbn = {9781450350778},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3092282.3092314},
doi = {10.1145/3092282.3092314},
abstract = { SunDew is a new automated test generation framework developed at Google, focused on finding security bugs in C/C++ code. It combines the strengths of multiple test generation techniques under a single cohesive platform. It leverages the vast amount of computational resources available at Google to massively parallelize the automated test generation and triage. By using a portfolio of test generation techniques, SunDew aims to overcome the coverage saturation (or plateau) that occurs with any individual technique. This saturation manifests as the inability of the technique to discover unexplored parts of a program after a certain number of generated tests. A portfolio of techniques, on the other hand, provides a diversity of test generation strategies that complement each other. SunDew embeds the most recent advances in automated test case generation, which provide precision and thoroughness. For example, symbolic execution uses powerful constraint solvers to generate tests that precisely follow desired program branches. This approach allows symbolic execution to reach code executed under very specific input preconditions that would be difficult to discover randomly. At the same time, recent improvements to coverage guided automated fuzzing, such as AFL or LibFuzzer, generates tests faster than symbolic execution. Thus, SunDew alternates these approaches by using coverage-guided fuzzing to quickly bring the coverage to a first saturation level, then using symbolic execution to refine the search for harder-to-reach code. This, in turn, may provide additional inputs for coverage-guided fuzzers, etc. As part of SunDew, we also developed a number of format-aware fuzzers, that rely on, amongst other things, machine learning to generate language-aware fuzzers. The SunDew architecture follows a distributed continuous pipeline pattern. It allows a performance-based dynamic resource allocation for the various test generation techniques. This allows us to maximize the combined output of the test suite generation and avoid long plateaus in the coverage growth of the test suite. We discuss the application of SunDew on a variety of fuzzing targets of interest. },
booktitle = {Proceedings of the 24th ACM SIGSOFT International SPIN Symposium on Model Checking of Software},
pages = {10},
numpages = {1},
keywords = {vulnerabilities, symbolic execution, Software testing},
location = {Santa Barbara, CA, USA},
series = {SPIN 2017}
}

@inproceedings{10.1145/3194718.3194721,
author = {Pietrantuono, Roberto and Russo, Stefano},
title = {Search-Based Optimization for the Testing Resource Allocation Problem: Research Trends and Opportunities},
year = {2018},
isbn = {9781450357418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194718.3194721},
doi = {10.1145/3194718.3194721},
abstract = {This paper explores the usage of search-based techniques for the Testing Resource Allocation Problem (TRAP). We focus on the analysis of the literature, surveying the research proposals where search-based techniques are exploited for different formulations of the TRAP. Three dimensions are considered: the model formulation, solution, and validation. The analysis allows to derive several observations, and finally outline some new research directions towards better (namely, closer to real-world settings) modelling and solutions, highlighting the most promising areas of investigation.},
booktitle = {Proceedings of the 11th International Workshop on Search-Based Software Testing},
pages = {6–12},
numpages = {7},
keywords = {testing resource allocation, test prioritization, search-based software testing, reliability allocation},
location = {Gothenburg, Sweden},
series = {SBST '18}
}

@inproceedings{10.1145/1083231.1083236,
author = {Chen, T. Y. and Kuo, F.-C. and Zhou, Zhi Quan},
title = {An Effective Testing Method for End-User Programmers},
year = {2005},
isbn = {1595931317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083231.1083236},
doi = {10.1145/1083231.1083236},
abstract = {End-user programmers do not have extensive knowledge of various software testing methodologies used by professional testers. While they are creating the vast majority of software today, errors are pervasive in the programs due to the lack of testing techniques readily adoptable by end-user programmers. In this article we argue that the technique of metamorphic testing is both practical and effective for end-user programmers.},
booktitle = {Proceedings of the First Workshop on End-User Software Engineering},
pages = {1–5},
numpages = {5},
keywords = {end-user software engineering, software testing, metamorphic testing},
location = {St. Louis, Missouri},
series = {WEUSE I}
}

@article{10.1145/1082983.1083236,
author = {Chen, T. Y. and Kuo, F.-C. and Zhou, Zhi Quan},
title = {An Effective Testing Method for End-User Programmers},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1083236},
doi = {10.1145/1082983.1083236},
abstract = {End-user programmers do not have extensive knowledge of various software testing methodologies used by professional testers. While they are creating the vast majority of software today, errors are pervasive in the programs due to the lack of testing techniques readily adoptable by end-user programmers. In this article we argue that the technique of metamorphic testing is both practical and effective for end-user programmers.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {may},
pages = {1–5},
numpages = {5},
keywords = {software testing, end-user software engineering, metamorphic testing}
}

@inproceedings{10.1145/3395363.3397386,
author = {Abdessalem, Raja Ben and Panichella, Annibale and Nejati, Shiva and Briand, Lionel C. and Stifter, Thomas},
title = {Automated Repair of Feature Interaction Failures in Automated Driving Systems},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3397386},
doi = {10.1145/3395363.3397386},
abstract = {In the past years, several automated repair strategies have been proposed to fix bugs in individual software programs without any human intervention. There has been, however, little work on how automated repair techniques can resolve failures that arise at the system-level and are caused by undesired interactions among different system components or functions. Feature interaction failures are common in complex systems such as autonomous cars that are typically built as a composition of independent features (i.e., units of functionality). In this paper, we propose a repair technique to automatically resolve undesired feature interaction failures in automated driving systems (ADS) that lead to the violation of system safety requirements. Our repair strategy achieves its goal by (1) localizing faults spanning several lines of code, (2) simultaneously resolving multiple interaction failures caused by independent faults, (3) scaling repair strategies from the unit-level to the system-level, and (4) resolving failures based on their order of severity. We have evaluated our approach using two industrial ADS containing four features. Our results show that our repair strategy resolves the undesired interaction failures in these two systems in less than 16h and outperforms existing automated repair techniques.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {88–100},
numpages = {13},
keywords = {Search-based Software Testing, Feature Interaction Problem, Automated Software Repair, Automated Driving Systems},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inproceedings{10.1145/2338965.2336763,
author = {Groce, Alex and Zhang, Chaoqiang and Eide, Eric and Chen, Yang and Regehr, John},
title = {Swarm Testing},
year = {2012},
isbn = {9781450314541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2338965.2336763},
doi = {10.1145/2338965.2336763},
abstract = { Swarm testing is a novel and inexpensive way to improve the diversity of test cases generated during random testing. Increased diversity leads to improved coverage and fault detection. In swarm testing, the usual practice of potentially including all features in every test case is abandoned. Rather, a large “swarm” of randomly generated configurations, each of which omits some features, is used, with configurations receiving equal resources. We have identified two mechanisms by which feature omission leads to better exploration of a system’s state space. First, some features actively prevent the system from executing interesting behaviors; e.g., “pop” calls may prevent a stack data structure from executing a bug in its overflow detection logic. Second, even when there is no active suppression of behaviors, test features compete for space in each test, limiting the depth to which logic driven by features can be explored. Experimental results show that swarm testing increases coverage and can improve fault detection dramatically; for example, in a week of testing it found 42% more distinct ways to crash a collection of C compilers than did the heavily hand-tuned default configuration of a random tester. },
booktitle = {Proceedings of the 2012 International Symposium on Software Testing and Analysis},
pages = {78–88},
numpages = {11},
location = {Minneapolis, MN, USA},
series = {ISSTA 2012}
}

@inproceedings{10.5555/3105427.3105436,
author = {Sakti, Abdelilah and Pesant, Gilles and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l},
title = {JTeXpert at the SBST 2017 Tool Competition},
year = {2017},
isbn = {9781538627891},
publisher = {IEEE Press},
abstract = {JTeXpert is a software testing tool that automatically generates a whole test suite to satisfy the branch-coverage criterion. It takes as inputs a Java source code and its dependencies and automatically produces a test-case suite in JUnit format. In this paper, we summarize our results for the Unit Testing Tool Competition held at the fifth SBST Contest, where JTeXpert received 849 points and was ranked second. We also analyze our tool's performance.},
booktitle = {Proceedings of the 10th International Workshop on Search-Based Software Testing},
pages = {43–46},
numpages = {4},
keywords = {test-case generation, random testing, classes testing, unit testing, static analysis},
location = {Buenos Aires, Argentina},
series = {SBST '17}
}

@inproceedings{10.1145/3213846.3213870,
author = {Just, Ren\'{e} and Parnin, Chris and Drosos, Ian and Ernst, Michael D.},
title = {Comparing Developer-Provided to User-Provided Tests for Fault Localization and Automated Program Repair},
year = {2018},
isbn = {9781450356992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213846.3213870},
doi = {10.1145/3213846.3213870},
abstract = {To realistically evaluate a software testing or debugging technique, it must be run on defects and tests that are characteristic of those a developer would encounter in practice. For example, to determine the utility of a fault localization or automated program repair technique, it could be run on real defects from a bug tracking system, using real tests that are committed to the version control repository along with the fixes. Although such a methodology uses real tests, it may not use tests that are characteristic of the information a developer or tool would have in practice. The tests that a developer commits after fixing a defect may encode more information than was available to the developer when initially diagnosing the defect.  This paper compares, both quantitatively and qualitatively, the developer-provided tests committed along with fixes (as found in the version control repository) versus the user-provided tests extracted from bug reports (as found in the issue tracker). It provides evidence that developer-provided tests are more targeted toward the defect and encode more information than user-provided tests. For fault localization, developer-provided tests overestimate a technique’s ability to rank a defective statement in the list of the top-n most suspicious statements. For automated program repair, developer-provided tests overestimate a technique’s ability to (efficiently) generate correct patches—user-provided tests lead to fewer correct patches and increased repair time. This paper also provides suggestions for improving the design and evaluation of fault localization and automated program repair techniques.},
booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {287–297},
numpages = {11},
keywords = {Fault localization, Automated program repair, Test effectiveness},
location = {Amsterdam, Netherlands},
series = {ISSTA 2018}
}

@inproceedings{10.1145/3356317.3356318,
author = {Mendon\c{c}a, Willian D. F. and Assun\c{c}\~{a}o, Wesley K. G. and Vergilio, Silvia R.},
title = {Reusing Test Cases on Graph Product Line Variants: Results from a State-of-the-Practice Test Data Generation Tool},
year = {2019},
isbn = {9781450376488},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3356317.3356318},
doi = {10.1145/3356317.3356318},
abstract = {Software testing is an essential activity for quality assurance, but, it is an error-prone and effort consuming task when conducted manually. Because of this, the use of automated tools is fundamental, as well as, the evaluation of these tools in practice. However, there is not so much evidence on how such tools perform on highly-configurable systems. Highly-configurable systems are commonly observed in industry as an approach to develop families of products, where products have different configuration options to meet customer needs. To fulfill such a gap, this paper reports results on the use of the tool Randoop, which is widely used in industry, to test variants of the Graph Product Line (GPL) family of products. Our goal is to evaluate reusability of a test data set generated by Randoop for one product when reused for testing other GPL products. Besides, we also investigate the impact of using different values of runtime, the main Randoop parameter, on the number of reused test data. The results show that the used value for runtime in general does not contribute to increase the coverage of test data reused in different products. Furthermore, similarity among products does not ensure a greater reusability.},
booktitle = {Proceedings of the IV Brazilian Symposium on Systematic and Automated Software Testing},
pages = {52–61},
numpages = {10},
keywords = {Highly-configurable systems, Test Data Generation, Test Coverage, Family of Products, Software Reuse},
location = {Salvador, Brazil},
series = {SAST 2019}
}

@inproceedings{10.1109/SBST.2019.000-2,
author = {Yoo, Shin},
title = {SBST in the Age of Machine Learning Systems: Challenges Ahead},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SBST.2019.000-2},
doi = {10.1109/SBST.2019.000-2},
abstract = {Machine Learning, and especially Deep Neural Network (DNN), is being rapidly adopted by various software systems, including applications in safety-critical systems such as autonomous driving and medical imaging. This calls for an urgent need to test these AI/ML techniques as part of larger systems. However, this task can be very different from testing of traditional software systems. We will briefly examine the fundamentals of software testing as well as the state of the art in Search Based Software Testing (SBST), and try to outline the challenges ahead while highlighting areas where SBST can shine.},
booktitle = {Proceedings of the 12th International Workshop on Search-Based Software Testing},
pages = {2},
numpages = {1},
location = {Montreal, Quebec, Canada},
series = {SBST '19}
}

@inbook{10.1145/3482909.3482917,
author = {Bonif\'{a}cio, Bruno and Ekwoge, Oswald and Bernardon, Camila and Souto, Thiago},
title = {How Do Testers Feel It? An Experience Report on Evaluating TX in an Industrial Context},
year = {2021},
isbn = {9781450385039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3482909.3482917},
abstract = {Background: Software development is almost always performed by teams. Consequently, several factors such as environment, human aspects, and technologies adopted are likely to affect individual and team performance. Method: Motivated by this context, we conducted a survey with 27 testers of the SIDIA Institute of Science and Technology. The goal was to understand how human and technological aspects can affect test effectiveness, by considering the practitioners’ perspective on their homologation testing review practices with respect three aspects: the testing infrastructure, how they perceive the value of their contribution, and how they feel about their work. Qualitative and quantitative analyses of testers’ perception using the Tester Experience (TX) approach was conducted. Results: Our results show that by using scenarios, the testers’ perceptions with respect to the value of their contribution and how they feel about their work were clearly the highest rated factors. Conclusion: This work can serve as a basis for other companies in their testing teams to evaluate how the use of testing artifacts and how testing activities can improve TX.},
booktitle = {Brazilian Symposium on Systematic and Automated Software Testing},
pages = {55–63},
numpages = {9}
}

@inproceedings{10.1145/3395363.3404363,
author = {Guo, Chao and He, Tieke and Yuan, Wei and Guo, Yue and Hao, Rui},
title = {Crowdsourced Requirements Generation for Automatic Testing via Knowledge Graph},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3404363},
doi = {10.1145/3395363.3404363},
abstract = {Crowdsourced testing provides an effective way to deal with the problem of Android system fragmentation, as well as the application scenario diversity faced by Android testing. The generation of test requirements is a significant part of crowdsourced testing. However, manually generating crowdsourced testing requirements is tedious, which requires the issuers to have the domain knowledge of the Android application under test. To solve these problems, we have developed a tool named KARA, short for Knowledge Graph Aided Crowdsourced Requirements Generation for Android Testing. KARA first analyzes the result of automatic testing on the Android application, through which the operation sequences can be obtained. Then, the knowledge graph of the target application is constructed in a manner of pay-as-you-go. Finally, KARA utilizes knowledge graph and the automatic testing result to generate crowdsourced testing requirements with domain knowledge. Experiments prove that the test requirements generated by KARA are well understandable, and KARA can improve the quality of crowdsourced testing. The demo video can be found at https://youtu.be/kE-dOiekWWM.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {545–548},
numpages = {4},
keywords = {Android GUI Testing, Crowdsourced Requirements, Knowledge Graph},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@article{10.1145/3491038,
author = {Marculescu, Bogdan and Zhang, Man and Arcuri, Andrea},
title = {On the Faults Found in REST APIs by Automated Test Generation},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3491038},
doi = {10.1145/3491038},
abstract = {RESTful web services are often used for building a wide variety of enterprise applications. The diversity and increased number of applications using RESTful APIs means that increasing amounts of resources are spent developing and testing these systems. Automation in test data generation provides a useful way of generating test data in a fast and efficient manner. However, automated test generation often results in large test suites that are hard to evaluate and investigate manually.This article proposes a taxonomy of the faults we have found using search-based software testing techniques applied on RESTful APIs. The taxonomy is a first step in understanding, analyzing, and ultimately fixing software faults in web services and enterprise applications. We propose to apply a density-based clustering algorithm to the test cases evolved during the search to allow a better separation between different groups of faults. This is needed to enable engineers to highlight and focus on the most serious faults.Tests were automatically generated for a set of eight case studies, seven open-source and one industrial. The test cases generated during the search are clustered based on the reported last executed line and based on the error messages returned, when such error messages were available. The tests were manually evaluated to determine their root causes and to obtain additional information.The article presents a taxonomy of the faults found based on the manual analysis of 415 faults in the eight case studies and proposes a method to support the classification using clustering of the resulting test cases.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {mar},
articleno = {41},
numpages = {43},
keywords = {evolutionary Algorithms, Search-based software testing, automated Software Testing, automated Test Generation}
}

@inproceedings{10.1109/ASE.2009.79,
author = {Wang, Huai and Chan, W. K.},
title = {Weaving Context Sensitivity into Test Suite Construction},
year = {2009},
isbn = {9780769538914},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2009.79},
doi = {10.1109/ASE.2009.79},
abstract = {Context-aware applications capture environmental changes as contexts and self-adapt their behaviors dynamically. Existing testing research has not explored context evolutions or their patterns inherent to individual test cases when constructing test suites. We propose the notation of context diversity as a metric to measure how many changes in contextual values of individual test cases. In this paper, we discuss how this notion can be incorporated in a test case generation process by pairing it with coverage-based test data selection criteria},
booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated Software Engineering},
pages = {610–614},
numpages = {5},
keywords = {context-aware programe, context diversity, software testing},
series = {ASE '09}
}

@inproceedings{10.1145/3361242.3361248,
author = {Cao, Jiawei and Wang, Xingya and Li, Zixin and Gu, Qiqi and Chen, Zhenyu},
title = {The Evolution of Open-Source Blockchain Systems: An Empirical Study},
year = {2019},
isbn = {9781450377010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361242.3361248},
doi = {10.1145/3361242.3361248},
abstract = {Blockchain enjoys a rapid development over current years, penetrating multiple areas of application. However, despite the active evolvement of blockchain systems, no special attention is attached to such a hot spot. To gain a clear image of their evolution process, we conducted an empirical study on six open-source blockchain projects with long life span, covering a total of 504 versions. We attempted to verify whether Lehman's Laws are still applicable to blockchain applications over the passage of time with multiple metrics, and found that there do exist laws like declining quality are not confirmed. We raised our new findings---the centralized trends of revisions and non-smooth growth based on the experimental results as well. By this paper, we hope to provide future researcher on blockchain with an overview of its evolution and reveals the points on which special effort should pay during the periods of development and maintenance.},
booktitle = {Proceedings of the 11th Asia-Pacific Symposium on Internetware},
articleno = {10},
numpages = {10},
keywords = {blockchain system, software evolution, lehman's laws},
location = {Fukuoka, Japan},
series = {Internetware '19}
}

@inbook{10.1145/3387940.3392215,
author = {Feldt, Robert and Yoo, Shin},
title = {Flexible Probabilistic Modeling for Search Based Test Data Generation},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392215},
abstract = {While Search-Based Software Testing (SBST) has improved significantly in the last decade we propose that more flexible, probabilistic models can be leveraged to improve it further. Rather than searching for an individual, or even sets of, test case(s) or datum(s) that fulfil specific needs the goal can be to learn a generative model tuned to output a useful family of values. Such generative models can naturally be decomposed into a structured generator and a probabilistic model that determines how to make non-deterministic choices during generation. While the former constrains the generation process to produce valid values the latter allows learning and tuning to specific goals. SBST techniques differ in their level of integration of the two but, regardless of how close it is, we argue that the flexibility and power of the probabilistic model will be a main determinant of success. In this short paper, we present how some existing SBST techniques can be viewed from this perspective and then propose additional techniques for flexible generative modelling the community should consider. In particular, Probabilistic Programming languages (PPLs) and Genetic Programming (GP) should be investigated since they allow for very flexible probabilistic modelling. Benefits could range from utilising the multiple program executions that SBST techniques typically require to allowing the encoding of high-level test strategies.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {537–540},
numpages = {4}
}

