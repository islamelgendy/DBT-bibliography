@inproceedings{10.1145/3460120.3485364,
author = {Jiang, Zhiyuan and Jiang, Xiyue and Hazimeh, Ahmad and Tang, Chaojing and Zhang, Chao and Payer, Mathias},
title = {Igor: Crash Deduplication Through Root-Cause Clustering},
year = {2021},
isbn = {9781450384544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460120.3485364},
doi = {10.1145/3460120.3485364},
abstract = {Fuzzing has emerged as the most effective bug-finding technique. The output of a fuzzer is a set of proof-of-concept (PoC) test cases for all observed "unique'' crashes. It costs developers substantial efforts to analyze each crashing test case. This, mostly manual, process has lead to the number of reported crashes out-pacing the number of bug fixes. Automatic crash deduplication techniques, which mostly rely on coverage profiles and stack hashes, are supposed to alleviate these pressures. However, these techniques both inflate actual bug counts and falsely conflate unrelated bugs. This hinders, rather than helps, developers, and calls for more accurate techniques.The highly-stochastic nature of fuzzing means that PoCs commonly exercise many program behaviors that are orthogonal to the crash's underlying root cause. This diversity in program behaviors manifests as a diversity in crashes, contributing to bug-count inflation and conflation. Based on this insight, we develop Igor, an automated dual-phase crash deduplication technique. By minimizing each PoC's execution trace, we obtain pruned test cases that exercise the critical behavior necessary for triggering a bug. Then, we use a graph similarity comparison to cluster crashes based on the control-flow graph of the minimized execution traces, with each cluster mapping back to a single, unique root cause.We evaluate Igor against 39 bugs resulting from 254,000 PoCs, distributed over 10 programs. Our results show that Igor accurately groups these crashes into 48 uniquely identifiable clusters, while other state-of-the-art methods yield bug counts at least one order of magnitude larger.},
booktitle = {Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3318–3336},
numpages = {19},
keywords = {fuzzing, crash grouping},
location = {Virtual Event, Republic of Korea},
series = {CCS '21}
}

@inproceedings{10.5555/2818754.2818809,
author = {Avgustinov, Pavel and Baars, Arthur I. and Henriksen, Anders S. and Lavender, Greg and Menzel, Galen and de Moor, Oege and Sch\"{a}fer, Max and Tibble, Julian},
title = {Tracking Static Analysis Violations over Time to Capture Developer Characteristics},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Many interesting questions about the software quality of a code base can only be answered adequately if fine-grained information about the evolution of quality metrics over time and the contributions of individual developers is known. We present an approach for tracking static analysis violations (which are often indicative of defects) over the revision history of a program, and for precisely attributing the introduction and elimination of these violations to individual developers. As one application, we demonstrate how this information can be used to compute "fingerprints" of developers that reflect which kinds of violations they tend to introduce or to fix. We have performed an experimental study on several large open-source projects written in different languages, providing evidence that these fingerprints are well-defined and capture characteristic information about the coding habits of individual developers.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {437–447},
numpages = {11},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/2745802.2745807,
author = {Zhou, Bo and Neamtiu, Iulian and Gupta, Rajiv},
title = {Predicting Concurrency Bugs: How Many, What Kind and Where Are They?},
year = {2015},
isbn = {9781450333504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2745802.2745807},
doi = {10.1145/2745802.2745807},
abstract = {Concurrency bugs are difficult to find and fix. To help with finding and fixing concurrency bugs, prior research has mostly focused on static or dynamic analyses for finding specific classes of bugs. We present an approach whose focus is understanding the differences between concurrency and non-concurrency bugs, the differences among various concurrency bug classes, and predicting bug quantity, type, and location, from patches, bug reports and bug-fix metrics. First, we show that bug characteristics and bug-fixing processes vary significantly among different kinds of concurrency bugs and compared to non-concurrency bugs. Next, we build a quantitative predictor model to estimate concurrency bugs appearance in future releases. Then, we build a qualitative predictor that can predict the type of concurrency bug for a newly-filed bug report. Finally, we build a bug location predictor to indicate the likely source code location for newly-reported bugs. We validate the effectiveness of our approach on three popular projects, Mozilla, KDE, and Apache.},
booktitle = {Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {6},
numpages = {10},
location = {Nanjing, China},
series = {EASE '15}
}

@article{10.1145/2656201,
author = {Li, Kaituo and Reichenbach, Christoph and Csallner, Christoph and Smaragdakis, Yannis},
title = {Residual Investigation: Predictive and Precise Bug Detection},
year = {2014},
issue_date = {December 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/2656201},
doi = {10.1145/2656201},
abstract = {We introduce the concept of residual investigation for program analysis. A residual investigation is a dynamic check installed as a result of running a static analysis that reports a possible program error. The purpose is to observe conditions that indicate whether the statically predicted program fault is likely to be realizable and relevant. The key feature of a residual investigation is that it has to be much more precise (i.e., with fewer false warnings) than the static analysis alone, yet significantly more general (i.e., reporting more errors) than the dynamic tests in the program's test suite that are pertinent to the statically reported error. That is, good residual investigations encode dynamic conditions that, when considered in conjunction with the static error report, increase confidence in the existence or severity of an error without needing to directly observe a fault resulting from the error.We enhance the static analyzer FindBugs with several residual investigations appropriately tuned to the static error patterns in FindBugs, and apply it to nine large open-source systems and their native test suites. The result is an analysis with a low occurrence of false warnings (false positives) while reporting several actual errors that would not have been detected by mere execution of a program's test suite.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {dec},
articleno = {7},
numpages = {32},
keywords = {RFBI, existing test cases, False warnings}
}

@article{10.1145/2530290,
author = {Khan, Mohammad Maifi Hasan and Le, Hieu Khac and Ahmadi, Hossein and Abdelzaher, Tarek F. and Han, Jiawei},
title = {Troubleshooting Interactive Complexity Bugs in Wireless Sensor Networks Using Data Mining Techniques},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/2530290},
doi = {10.1145/2530290},
abstract = {This article presents a tool for uncovering bugs due to interactive complexity in networked sensing applications. Such bugs are not localized to one component that is faulty, but rather result from complex and unexpected interactions between multiple often individually nonfaulty components. Moreover, the manifestations of these bugs are often not repeatable, making them particularly hard to find, as the particular sequence of events that invokes the bug may not be easy to reconstruct. Because of the distributed nature of failure scenarios, our tool looks for sequences of events that may be responsible for faulty behavior, as opposed to localized bugs such as a bad pointer in a module. We identified several challenges in applying discriminative sequence mining for root cause analysis when the system fails to perform as expected and presented our solutions to those challenges. We also present two alternative schemes, namely, two-stage mining and the progressive discriminative sequence mining to address the scalability challenge. An extensible framework is developed where a front-end collects runtime data logs of the system being debugged and an offline back-end uses frequent discriminative pattern mining to uncover likely causes of failure. We provided several case studies where we applied our tool successfully to troubleshoot the cause of the problem. We uncovered a kernel-level race condition bug in the LiteOS operating system and a protocol design bug in the directed diffusion protocol. We also presented a case study of debugging a multichannel MAC protocol that was found to exhibit corner cases of poor performance (worse than single-channel MAC). The tool helped to uncover event sequences that lead to a highly degraded mode of operation. Fixing the problem significantly improved the performance of the protocol. We also evaluated the extensions presented in this article. Finally, we provided a detailed analysis of tool overhead in terms of memory requirements and impact on the running application.},
journal = {ACM Trans. Sen. Netw.},
month = {jan},
articleno = {31},
numpages = {35},
keywords = {wireless sensor networks, Distributed protocol debugging}
}

@inproceedings{10.1145/2740908.2741699,
author = {Chasins, Sarah and Phothilimthana, Phitchaya Mangpo},
title = {Dicer: A Framework for Controlled, Large-Scale Web Experiments},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2741699},
doi = {10.1145/2740908.2741699},
abstract = {As dynamic, complex, and non-deterministic webpages proliferate, running controlled web experiments on live webpages is becoming increasingly difficult. To compare algorithms that take webpages as inputs, an experimenter must worry about ever-changing webpages, and also about scalability. Because webpage contents are constantly changing, experimenters must intervene to hold webpages constant, in order to guarantee a fair comparison between algorithms. Because webpages are increasingly customized and diverse, experimenters must test web algorithms over thousands of webpages, and thus need to implement their experiments efficiently. Unfortunately, no existing testing frameworks have been designed for this type of experiment. We introduce Dicer, a framework for running large-scale controlled experiments on live webpages. Dicer's programming model allows experimenters to easily 1) control when to enforce a same-page guarantee and 2) parallelize test execution. The same-page guarantee ensures that all loads of a given URL produce the same response. The framework utilizes a specialized caching proxy server to enforce this guarantee. We evaluate tool on a dataset of 1,000 real webpages, and find it upholds the same-page guarantee with little overhead.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {1321–1326},
numpages = {6},
keywords = {javascript, testing framework, web algorithm testing},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/1868321.1868327,
author = {Di Marco, Antinisca and Bertolino, Antonia and Di Giandomenico, Felicita and Masci, Paolo and Sabetta, Antonino},
title = {Metrics for QoS Analysis in Dynamic, Evolving and Heterogeneous Connected Systems},
year = {2010},
isbn = {9781450301374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868321.1868327},
doi = {10.1145/1868321.1868327},
abstract = {Dynamic, evolving systems pose new challenges from the point of view of Quality of Service (QoS) analysis, calling for techniques able to combine traditional offline methods with new ones applied at run-time. Tracking the evolution and updating the assessment consistently with such system evolution require not only advanced analysis methods, but also appropriate metrics well representative of QoS properties in the addressed context. The ongoing European project Connect addresses systems evolution, and aims at bridging technological gaps arising from heterogeneity of networked systems, by synthesising on-the-fly interoperability connectors. Moving from such ambitious goal, in this paper we present a metrics framework, whereby classical dependability/QoS metrics can be refined and combined to characterise Connect applications and to support their monitoring and analysis.},
booktitle = {Proceedings of the Eighth International Workshop on Dynamic Analysis},
pages = {32–37},
numpages = {6},
location = {Trento, Italy},
series = {WODA '10}
}

@article{10.1145/1745312.1745314,
author = {Jeffrey, Dennis and Nagarajan, Vijay and Gupta, Rajiv},
title = {Execution Suppression: An Automated Iterative Technique for Locating Memory Errors},
year = {2008},
issue_date = {May 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {5},
issn = {0164-0925},
url = {https://doi.org/10.1145/1745312.1745314},
doi = {10.1145/1745312.1745314},
abstract = {By studying the behavior of several programs that crash due to memory errors, we observed that locating the errors can be challenging because significant propagation of corrupt memory values can occur prior to the point of the crash. In this article, we present an automated approach for locating memory errors in the presence of memory corruption propagation. Our approach leverages the information revealed by a program crash: when a crash occurs, this reveals a subset of the memory corruption that exists in the execution. By suppressing (nullifying) the effect of this known corruption during execution, the crash is avoided and any remaining (hidden) corruption may then be exposed by subsequent crashes. The newly exposed corruption can then be suppressed in turn. By iterating this process until no further crashes occur, the first point of memory corruption—and the likely root cause of the program failure—can be identified. However, this iterative approach may terminate prematurely, since programs may not crash even when memory corruption is present during execution. To address this, we show how crashes can be exposed in an execution by manipulating the relative ordering of particular variables within memory. By revealing crashes through this variable re-ordering, the effectiveness and applicability of the execution suppression approach can be improved. We describe a set of experiments illustrating the effectiveness of our approach in consistently and precisely identifying the first points of memory corruption in executions that fail due to memory errors. We also discuss a baseline software implementation of execution suppression that incurs an average overhead of 7.2x, and describe how to reduce this overhead to 1.8x through hardware support.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {may},
articleno = {17},
numpages = {36},
keywords = {hardware support, Execution suppression, memory errors, memory corruption propagation, fault localization, variable re-ordering}
}

@inproceedings{10.1145/2591062.2591173,
author = {Bird, Christian and Ranganath, Venkatesh-Prasad and Zimmermann, Thomas and Nagappan, Nachiappan and Zeller, Andreas},
title = {Extrinsic Influence Factors in Software Reliability: A Study of 200,000 Windows Machines},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591173},
doi = {10.1145/2591062.2591173},
abstract = { Reliability of software depends not only on intrinsic factors such as its code properties, but also on extrinsic factors—that is, the properties of the environment it operates in. In an empirical study of more than 200,000 Windows users, we found that the reliability of individual applications is related to whether and which other applications are in-stalled: While games and file-sharing applications tend to decrease the reliability of other applications, security applications tend to increase it. Furthermore, application reliability is related to the usage profiles of these applications; generally, the more an application is used, the more likely it is to have negative impact on reliability of others. As a conse-quence, software testers must be careful to investigate and control these factors. },
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {205–214},
numpages = {10},
keywords = {Windows},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@inproceedings{10.1145/3456727.3463767,
author = {Roessler, Nick and Chien, Yi and Atayde, Lucas and Yang, Peiru and Palmer, Imani and Gray, Lily and Dautenhahn, Nathan},
title = {Lossless Instruction-to-Object Memory Tracing in the Linux Kernel},
year = {2021},
isbn = {9781450383981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3456727.3463767},
doi = {10.1145/3456727.3463767},
abstract = {The lack of visibility into Linux's behavior makes it hard to refactor and maintain. To peer inside the box, we present Memorizer, a self-contained, low-level tracing framework that tracks (most) object allocations, data accesses, and function calls within the kernel. The core insight is a low-level object-centric representation that records detailed lifetime information while linking each operation (call/read/write) with its intended target. We evaluate Memorizer using extensive input programs and demonstrate its value by showing how Memorizer can (1) aid in refactoring, (2) extend code coverage with object coverage to improve testing and analysis, and (3) identify leaky abstractions. We also release a large data set, visualization tools, and Memorizer's source. This generic, object-centric approach is the first to provide loss-less instruction-to-object tracing, adding an essential software engineering capability to the overly complex Linux kernel.},
booktitle = {Proceedings of the 14th ACM International Conference on Systems and Storage},
articleno = {2},
numpages = {12},
location = {Haifa, Israel},
series = {SYSTOR '21}
}

@inproceedings{10.4108/ICST.SIMUTOOLS2010.8833,
author = {Leye, Stefan and Uhrmacher, Adelinde M.},
title = {A Flexible and Extensible Architecture for Experimental Model Validation},
year = {2010},
isbn = {9789639799875},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/ICST.SIMUTOOLS2010.8833},
doi = {10.4108/ICST.SIMUTOOLS2010.8833},
abstract = {With the rising number and diversity of validation methods, the need for a tool supporting an easy exploitation of those methods emerges. We introduce FAMVal, a validation architecture that supports the seamless integration of different validation techniques. We structure a validation experiment into the tasks specification of requirements, configuration of the model, model execution, observation, analysis, and evaluation. This structuring improves the flexibility of the approach, by facilitating the combination of methods for different tasks. In addition to the overall architecture, basic components and their interactions are presented. The usage of FAMVal is illuminated by several validation experiments with a small chemical model. The architecture has been realized using the plug-in based design of the modeling and simulation framework JAMES II.},
booktitle = {Proceedings of the 3rd International ICST Conference on Simulation Tools and Techniques},
articleno = {65},
numpages = {10},
keywords = {experiment, simulation experiment, model validation, validation, analysis, software, flexibility},
location = {Torremolinos, Malaga, Spain},
series = {SIMUTools '10}
}

@article{10.1145/3379984,
author = {Lappas, Theodoros},
title = {Mining Career Paths from Large Resume Databases: Evidence from IT Professionals},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1556-4681},
url = {https://doi.org/10.1145/3379984},
doi = {10.1145/3379984},
abstract = {The emergence of online professional platforms, such as LinkedIn and Indeed, has led to unprecedented volumes of rich resume data that have revolutionized the study of careers. One of the most prevalent problems in this space is the extraction of prototype career paths from a workforce. Previous research has consistently relied on a two-step approach to tackle this problem. The first step computes the pairwise distances between all the career sequences in the database. The second step uses the distance matrix to create clusters, with each cluster representing a different prototype path. As we demonstrate in this work, this approach faces two significant challenges when applied on large resume databases. First, the overwhelming diversity of job titles in the modern workforce prevents the accurate evaluation of distance between career sequences. Second, the clustering step of the standard approach leads to highly heterogeneous clusters, due to its inability to handle categorical sequences and sensitivity to outliers. This leads to non-representative centroids and spurious prototype paths that do not accurately represent the actual groups in the workforce. Our work addresses these two challenges and has practical implications for the numerous researchers and practitioners working on the analysis of career data across domains.},
journal = {ACM Trans. Knowl. Discov. Data},
month = {may},
articleno = {37},
numpages = {38},
keywords = {Career data, data mining, career paths, clustering}
}

@article{10.1145/1965724.1965743,
author = {Ball, Thomas and Levin, Vladimir and Rajamani, Sriram K.},
title = {A Decade of Software Model Checking with SLAM},
year = {2011},
issue_date = {July 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/1965724.1965743},
doi = {10.1145/1965724.1965743},
abstract = {SLAM is a program-analysis engine used to check if clients of an API follow the API's stateful usage rules.},
journal = {Commun. ACM},
month = {jul},
pages = {68–76},
numpages = {9}
}

@inproceedings{10.1145/3338906.3338938,
author = {Jia, Zhouyang and Li, Shanshan and Yu, Tingting and Liao, Xiangke and Wang, Ji},
title = {Automatically Detecting Missing Cleanup for Ungraceful Exits},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338938},
doi = {10.1145/3338906.3338938},
abstract = {Software encounters ungraceful exits due to either bugs in the interrupt/signal handler code or the intention of developers to debug the software. Users may suffer from ”weird” problems caused by leftovers of the ungraceful exits. A common practice to fix these problems is rebooting, which wipes away the stale state of the software. This solution, however, is heavyweight and often leads to poor user experience because it requires restarting other normal processes. In this paper, we design SafeExit, a tool that can automatically detect and pinpoint the root causes of the problems caused by ungraceful exits, which can help users fix the problems using lightweight solutions. Specifically, SafeExit checks the program exit behaviors in the case of an interrupted execution against its expected exit behaviors to detect the missing cleanup behaviors required for avoiding the ungraceful exit. The expected behaviors are obtained by monitoring the program exit under a normal execution. We apply SafeExit to 38 programs across 10 domains. SafeExit finds 133 types of cleanup behaviors from 36 programs and detects 2861 missing behaviors from 292 interrupted executions. To predict missing behaviors for unseen input scenarios, SafeExit trains prediction models using a set of sampled input scenarios. The results show that SafeExit is accurate with an average F-measure of 92.5%.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {751–762},
numpages = {12},
keywords = {Software signal, Missing cleanup, Ungraceful exit},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/2786805.2786821,
author = {Parameshwaran, Inian and Budianto, Enrico and Shinde, Shweta and Dang, Hung and Sadhu, Atul and Saxena, Prateek},
title = {Auto-Patching DOM-Based XSS at Scale},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786821},
doi = {10.1145/2786805.2786821},
abstract = { DOM-based cross-site scripting (XSS) is a client-side code injection vulnerability that results from unsafe dynamic code generation in JavaScript applications, and has few known practical defenses. We study dynamic code evaluation practices on nearly a quarter million URLs crawled starting from the the Alexa Top 1000 websites. Of 777,082 cases of dynamic HTML/JS code generation we observe, 13.3% use unsafe string interpolation for dynamic code generation — a well-known dangerous coding practice. To remedy this, we propose a technique to generate secure patches that replace unsafe string interpolation with safer code that utilizes programmatic DOM construction techniques. Our system transparently auto-patches the vulnerable site while incurring only 5.2 − 8.07% overhead. The patching mechanism requires no access to server-side code or modification to browsers, and thus is practical as a turnkey defense. },
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {272–283},
numpages = {12},
keywords = {Auto-patching, DOM-based XSS, Web Security, Taint Analysis},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/2645791.2645796,
author = {Stroggylos, Kostantinos and Mitropoulos, Dimitris and Tzermias, Zacharias and Papadopoulos, Panagiotis and Rafailidis, Fotios and Spinellis, Diomidis and Ioannidis, Sotiris and Katsaros, Panagiotis},
title = {Securing Legacy Code with the TRACER Platform},
year = {2014},
isbn = {9781450328975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2645791.2645796},
doi = {10.1145/2645791.2645796},
abstract = {Software vulnerabilities can severely affect an organization's infrastructure and cause significant financial damage to it. A number of tools and techniques are available for performing vulnerability detection in software written in various programming platforms, in a pursuit to mitigate such defects. However, since the requirements for running such tools and the formats in which they store and present their results vary wildly, it is difficult to utilize many of them in the scope of a project. By simplifying the process of running a variety of vulnerability detectors and collecting their results in an efficient, automated manner during development, the task of tracking security defects throughout the evolution history of software projects is bolstered. In this paper we present tracer, a software framework and platform to support the development of more secure applications by constantly monitoring software projects for vulnerabilities. The platform allows the easy integration of existing tools that statically detect software vulnerabilities and promotes their use during software development and maintenance. To demonstrate the efficiency and usability of the platform, we integrated two popular static analysis tools, FindBugs and Frama-c as sample implementations, and report on preliminary results from their use.},
booktitle = {Proceedings of the 18th Panhellenic Conference on Informatics},
pages = {1–6},
numpages = {6},
keywords = {Static Analysis, Legacy software, Software Security, Trusted Applications},
location = {Athens, Greece},
series = {PCI '14}
}

@inproceedings{10.1145/3127041.3127049,
author = {Fellner, Andreas and Krenn, Willibald and Schlick, Rupert and Tarrach, Thorsten and Weissenbacher, Georg},
title = {Model-Based, Mutation-Driven Test Case Generation via Heuristic-Guided Branching Search},
year = {2017},
isbn = {9781450350938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127041.3127049},
doi = {10.1145/3127041.3127049},
abstract = {This work introduces a heuristic-guided branching search algorithm for model-based, mutation-driven test case generation. The algorithm is designed towards the efficient and computationally tractable exploration of discrete, non-deterministic models with huge state spaces. Asynchronous parallel processing is a key feature of the algorithm. The algorithm is inspired by the successful path planning algorithm Rapidly exploring Random Trees (RRT). We adapt RRT in several aspects towards test case generation. Most notably, we introduce parametrized heuristics for start and successor state selection, as well as a mechanism to construct test cases from the data produced during search.We implemented our algorithm in the existing test case generation framework MoMuT. We present an extensive evaluation of our heuristics and parameters based on a diverse set of demanding models obtained in an industrial context. In total we continuously utilized 128 CPU cores on three servers for two weeks to gather the experimental data presented. Using statistical methods we determine which heuristics are performing well on all models. With our new algorithm, we are now able to process models consisting of over 2300 concurrent objects. To our knowledge there is no other mutation driven test case generation tool that is able to process models of this magnitude.},
booktitle = {Proceedings of the 15th ACM-IEEE International Conference on Formal Methods and Models for System Design},
pages = {56–66},
numpages = {11},
keywords = {test case generation, search-based testing, parallel search, heuristics, mutation testing, model-based testing},
location = {Vienna, Austria},
series = {MEMOCODE '17}
}

@inproceedings{10.1145/3452021.3458333,
author = {Meel, Kuldeep S. and Vinodchandran, N.V. and Chakraborty, Sourav},
title = {Estimating the Size of Union of Sets in Streaming Models},
year = {2021},
isbn = {9781450383813},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452021.3458333},
doi = {10.1145/3452021.3458333},
abstract = {In this paper we study the problem of estimating the size of the union of sets $S_1, dots, S_M$ where each set $S_i subseteq \O{}mega$ (for some discrete universe $\O{}mega$) is implicitly presented and comes in a streaming fashion. We define the notion of Delphic sets to capture class of streaming problems where membership, sampling, and counting calls to the sets are efficient. In particular, we show our notion of Delphic sets capture three well known problems: Klee's measure problem (discrete version), test coverage estimation, and model counting of DNF formulas. The Klee's measure problem corresponds to computation of volume of multi-dimension axis aligned rectangles, i.e., every d-dimension axis-aligned rectangle can be defined as $[a_1,b_1] times [a_2,b_2] times \l{}dots times [a_d, b_d]$. The problem of test coverage estimation focuses on the computation of coverage measure for a given testing array in the context of combinatorial testing, which is a fundamental technique in the context of hardware and software testing. Finally, given a DNF formula $varphi = T_1 vee T_2 vee \l{}dots vee T_M$, the problem of model counting seeks to compute the number of satisfying assignments of $varphi$. The primary contribution of our work is a simple and efficient sampling-based algorithm, called hybrid, for estimating the of union of sets in streaming setting. Our algorithm has the space complexity of $O(R\l{}og |\O{}mega|)$ and update time is $O(R\l{}og R cdot \l{}og(M/δ) cdot \l{}og|\O{}mega|)$ where, $R = O\l{}eft(\l{}og (M/δ)cdot varepsilon^2 right).$ Consequently, our algorithm provides the first algorithm with linear dependence on d for Klee's measure problem in streaming setting for $d&gt;1$, thereby settling the open problem of Tirthpura and Woodruff (PODS-12). Furthermore, a straightforward application of our algorithm lends to an efficient algorithm for coverage estimation problem in streaming setting. We then investigate whether the space complexity for coverage estimation can be further improved, and in this context, we present another streaming algorithm that uses near-optimal $O(t\l{}og n/varepsilon^2)$ space complexity but uses an update algorithm that is in $rm P ^rm NP $, thereby showcasing an interesting time vs space trade-off in the streaming setting. Finally, we demonstrate the generality of our Delphic sets by obtaining a streaming algorithm for model counting of DNF formulas. It is worth remarking that we view a key strength of our work is the simplicity of both the algorithm and its theoretical analysis, which makes it amenable to practical implementation and easy adoption.},
booktitle = {Proceedings of the 40th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
pages = {126–137},
numpages = {12},
keywords = {streaming algorithms, dnf counting, klee's measure problem},
location = {Virtual Event, China},
series = {PODS'21}
}

@inproceedings{10.1145/337180.337358,
author = {Keidar, Idit and Khazan, Roger and Lynch, Nancy and Shvartsman, Alex},
title = {An Inheritance-Based Technique for Building Simulation Proofs Incrementally},
year = {2000},
isbn = {1581132069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/337180.337358},
doi = {10.1145/337180.337358},
abstract = {This paper presents a technique for incrementally constructing safety specifications, abstract algorithm descriptions, and simulation proofs showing that algorithms meet their specifications.The technique for building specifications (and algorithms) allows a child specification (or algorithm) to inherit from its parent by two forms of incremental modification: (a) interface extension, where new forms of interaction are added to the parent's interface, and (b) specialization (subtyping), where new data, restrictions, and effects are added to the parent's behavior description. The combination of interface extension and specialization constitutes a powerful and expressive incremental modification mechanism for describing changes that do not override the behavior of the parent, although it may introduce new behavior.Consider the case when incremental modification is applied to both a parent specification S and a parent algorithm A. A proof that the child algorithm A′ implements the child specification S′ can be built incrementally upon simulation proof that algorithm A implements specification S. The new work required involves reasoning about the modifications, but does not require repetition of the reasoning in the original simulation proof.The paper presents the technique mathematically, in terms of automata. The technique has already been used to model and validate a full-fledged group communication system (see [26]); the methodology and results of that experiment are summarized in this paper.},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering},
pages = {478–487},
numpages = {10},
keywords = {specialization by inheritance, interface extension, system modeling/verification, refinement, simulation},
location = {Limerick, Ireland},
series = {ICSE '00}
}

@inproceedings{10.1145/3301293.3302363,
author = {Ma, Yun and Huang, Yangyang and Hu, Ziniu and Xiao, Xusheng and Liu, Xuanzhe},
title = {Paladin: Automated Generation of Reproducible Test Cases for Android Apps},
year = {2019},
isbn = {9781450362733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3301293.3302363},
doi = {10.1145/3301293.3302363},
abstract = {Automated-test-generation tools generate test cases to enable dynamic analysis of Android apps, such as functional testing. These tools build a GUI model to describe the app states during the app execution, and generate a script that performs actions on UI widgets to form a test case. However, when the test cases are re-executed, the apps under analysis often do not behave consistently. The major reasons for such limited reproducibility are due to (1) backend-service dependencies that cause non-determinism in app behaviors and (2) the severe fragmentation of Android platform (i.e., the alarming number of different Android OS versions in vendor-customized devices). To address these challenges, we design and implement Paladin, a novel system that generates reproducible test cases for Android apps. The key insight of Paladin is to provide a GUI model that leverages the structure of the GUI view tree to identify equivalent app states, since the structure can tolerate the changes on the UI contents for an app behavior performed in different test executions. Based on the model, Paladin can search the view tree to locate the desired UI widgets to trigger events and drive the app exploration to reach the desired app states, making the test cases reproducible. Evaluation results on real apps show that Paladin could reach a much higher reproduction ratio than the state-of-the-art tools when the generated test cases are re-executed across different device configurations. In addition, benefiting from the reproducible capability, Paladin is able to cover more app behaviors compared with the existing tools.},
booktitle = {Proceedings of the 20th International Workshop on Mobile Computing Systems and Applications},
pages = {99–104},
numpages = {6},
keywords = {automated test generation, reproducible, android app},
location = {Santa Cruz, CA, USA},
series = {HotMobile '19}
}

