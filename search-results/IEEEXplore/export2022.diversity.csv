"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Teaching software testing methods based on diversity principles","Z. Chen; J. Zhang; B. Luo","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, China, Software Institute, Nanjing University, Nanjing 210093, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, China, Software Institute, Nanjing University, Nanjing 210093, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, China, Software Institute, Nanjing University, Nanjing 210093, China","2011 24th IEEE-CS Conference on Software Engineering Education and Training (CSEE&T)","16 Jun 2011","2011","","","391","395","Software testing is the primary approach to support software quality assurance. Many novel software testing methods have been proposed to achieve various tasks in recent years. It is a challenge to teach these new testing methods and classical testing methods within limited time. This paper reports our work in progress on the new teaching approach to software testing methods based on diversity principles.","2377-570X","978-1-4577-0348-5","10.1109/CSEET.2011.5876111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5876111","","Software testing;Education;Software;Subspace constraints;Industries;Diversity methods","program testing;software quality","software testing method;diversity principle;software quality","","3","","15","","16 Jun 2011","","","IEEE","IEEE Conferences"
"Locating where faults will be [software testing]","T. J. Ostrand; E. J. Weyuker; R. M. Bell","Res., AT&T Labs, Florham Park, NJ, USA; Res., AT&T Labs, Florham Park, NJ, USA; Res., AT&T Labs, Florham Park, NJ, USA","2005 Richard Tapia Celebration of Diversity in Computing Conference","10 Jan 2006","2005","","","48","50","The goal of this research is to allow software developers and testers to become aware of which files in the next release of a large software system are likely to contain the largest numbers of faults or the highest fault densities in the next release, thereby allowing testers to focus their efforts on the most fault-prone files. This is done by developing a negative binomial regression model to help predict characteristics of new releases of a software system, based on information collected about prior releases and the new release under development. The same prediction model was also used to allow a tester to select the files of a new release that collectively contain any desired percentage of the faults. The benefit of being able to make these sorts of predictions accurately should be clear: if we know where to look for bugs, we should be able to target our testing efforts there and, as a result, find problems more quickly and therefore more economically. Two case studies using large industrial software systems are summarized. The first study used seventeen consecutive releases of a large inventory system, representing more than four years of field exposure. The second study used nine releases of a service provisioning system with two years of field experience.","","1-59593-257-7","10.1145/1095242.1095262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1570876","Experimentation;software faults;fault-prone;prediction;regression model;empirical study;software testing","Predictive models;Software testing;Software systems;System testing;Permission;Fault diagnosis;Software engineering;Software debugging;Computer bugs;Economic forecasting","program testing;regression analysis;program debugging","fault awareness;negative binomial regression;software fault;service provisioning system;software testing","","2","","3","","10 Jan 2006","","","IEEE","IEEE Conferences"
"Fundamentals of test case selection: Diversity, diversity, diversity","T. Y. Chen","Centre for Software Analysis and Testing, Swinburne University of Technology, Hawthorn 3122 VIC, Australia","The 2nd International Conference on Software Engineering and Data Mining","9 Aug 2010","2010","","","723","724","Our recent investigations in software testing reveal that diversity constitutes the underlying foundation in many test case selection strategies. This talk attempts to provide an overview of the concept of diversity in test case selection through two families of test case selection strategies, namely, random testing and partition testing. We also present some areas of software testing where the application of data mining techniques shows great potential in identifying key aspects of diversity in various forms.","","978-89-88678-22-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5542825","Adaptive Random Testing;Partition Testing;Proportional Sampling Strategy;Software Testing","Testing;Entropy;Game theory;Counting circuits;Fuzzy sets;Mechatronics;Data analysis;Decision theory;Uncertainty;Fuzzy systems","data mining;program testing","test case selection strategy;software testing;diversity concept;random testing;partition testing;data mining techniques","","","","7","","9 Aug 2010","","","IEEE","IEEE Conferences"
"DDF: Diversity Dragonfly Algorithm for cost-aware test suite minimization approach for software testing","S. R. Sugave; S. H. Patil; B. E. Reddy","MIT College of Engineering, Pune, MH, India; Bharati Vidyapeeth University College of Engineering, Pune, MH, India; JNTUA College of Engineering, Kalikiri, Chittor District, AP, India","2017 International Conference on Intelligent Computing and Control Systems (ICICCS)","11 Jan 2018","2017","","","701","707","The test suite minimization approach is a major research topic that it requires huge attention from the researchers as the traditional methods used for performing the test suite minimization is concentrated on the cost of regression testing but the requirements were not satisfied. To solve the problem of satisfying requirements, researchers proposed greedy algorithms, optimization algorithms, and so on. In this paper, a novel optimization algorithm is proposed termed as the Diversity Dragonfly Algorithm (DDF) algorithm that concentrates on the cost and quality of the test suite. The diversification included in the standard Dragonfly algorithm forms the DDF that uses three bitwise operators for diversification. The DDF algorithm determines the best suite based on the hunting mechanism of the dragonfly using a minimum objective function such that the selected test suite satisfies all the requirements. The experiment is carried out using five subject programs and the performance analysis of the proposed DDF is carried out and compared with the existing methods. It is found that the reduction capability of the DDF is better than existing methods and the cost of the proposed DDF is low ensuring a quality test suite reduction.","","978-1-5386-2745-7","10.1109/ICCONS.2017.8250554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8250554","Test suite reduction;DDF optimization algorithm;cost constraint;Software testing;Diversity function","Software;Minimization;Optimization;Software algorithms;Software testing;Linear programming","greedy algorithms;optimisation;program testing;regression analysis","cost-aware test suite minimization approach;software testing;regression testing;greedy algorithms;optimization algorithms;Diversity Dragonfly Algorithm algorithm;diversification;standard Dragonfly algorithm;DDF algorithm;quality test suite reduction;minimum objective function","","7","","15","","11 Jan 2018","","","IEEE","IEEE Conferences"
"Using mutation testing to measure behavioural test diversity","F. G. d. O. Neto; F. Dobslaw; R. Feldt","Chalmers and the University of Gothenburg,Dept. of Computer Science and Engineering,Gothenburg,Sweden; Chalmers and the University of Gothenburg,Dept. of Computer Science and Engineering,Gothenburg,Sweden; Chalmers and the University of Gothenburg,Dept. of Computer Science and Engineering,Gothenburg,Sweden","2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2020","2020","","","254","263","Diversity has been proposed as a key criterion to improve testing effectiveness and efficiency. It can be used to optimise large test repositories but also to visualise test maintenance issues and raise practitioners' awareness about waste in test artefacts and processes. Even though these diversitybased testing techniques aim to exercise diverse behavior in the system under test (SUT), the diversity has mainly been measured on and between artefacts (e.g., inputs, outputs or test scripts). Here, we introduce a family of measures to capture behavioural diversity (b-div) of test cases by comparing their executions and failure outcomes. Using failure information to capture the SUT behaviour has been shown to improve effectiveness of history-based test prioritisation approaches. However, historybased techniques require reliable test execution logs which are often not available or can be difficult to obtain due to flaky tests, scarcity of test executions, etc. To be generally applicable we instead propose to use mutation testing to measure behavioral diversity by running the set of test cases on various mutated versions of the SUT. Concretely, we propose two specific b-div measures (based on accuracy and Matthew's correlation coefficient, respectively) and compare them with artefact-based diversity (a-div) for prioritising the test suites of 6 different open-source projects. Our results show that our b-div measures outperform a-div and random selection in all of the studied projects. The improvement is substantial with an average increase in average percentage of faults detected (APFD) of between 19% to 31% depending on the size of the subset of prioritised tests.","","978-1-7281-1075-2","10.1109/ICSTW50294.2020.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155915","diversity-based testing;test prioritisation;test selection;empirical study","Testing;Fault detection;Reliability;Optimization;Atmospheric measurements;Particle measurements;Diversity reception","fault diagnosis;program testing","reliable test execution logs;flaky tests;test executions;mutation testing;b-div measures;artefact-based diversity;test suites;prioritised tests;behavioural test diversity;testing effectiveness;test repositories;diversity-based testing techniques;open-source projects;random selection;history-based test;SUT behaviour;failure outcomes;test scripts;diverse behavior;test artefacts;test maintenance issues","","","","31","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Visualizing Test Diversity to Support Test Optimisation","F. G. De Oliveira Neto; R. Feldt; L. Erlenhov; J. B. D. S. Nunes","Dept. of Comput. Sci. & Eng., Univ. of Gothenburg, Gothenburg, Sweden; Dept. of Comput. Sci. & Eng., Univ. of Gothenburg, Gothenburg, Sweden; Dept. of Comput. Sci. & Eng., Univ. of Gothenburg, Gothenburg, Sweden; Dept. of Comput. Syst., Fed. Univ. of Campina Grande, Campina Grande, Brazil","2018 25th Asia-Pacific Software Engineering Conference (APSEC)","23 May 2019","2018","","","149","158","Diversity has been used as an effective criteria to optimise test suites for cost-effective testing. Particularly, diversity-based (alternatively referred to as similarity-based) techniques have the benefit of being generic and applicable across different Systems Under Test (SUT), and have been used to automatically select or prioritise large sets of test cases. However, there is a challenge in how to present diversity information to developers and testers since results are typically many-dimensional. Furthermore, the generality of diversity-based approaches makes it harder to choose when and where to apply them. In this paper we address these challenges by investigating: i) what are the trade-offs in using different sources of diversity (e.g., diversity of test requirements or test scripts) to optimise large test suites, and ii) how visualisation of test diversity data can assist testers for test optimisation and improvement. We perform a case study on three industrial projects and present quantitative results on the fault detection capabilities and redundancy levels of different sets of test cases. Our key result is that test similarity maps, based on pair-wise diversity calculations, helped industrial practitioners identify issues with their test repositories and decide on actions to improve. We conclude that the visualisation of diversity information can assist testers in their maintenance and optimisation activities.","2640-0715","978-1-7281-1970-0","10.1109/APSEC.2018.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719537","Software Testing;Diversity;Search based Software Testing;Empirical Study","Optimization;Testing;Indexes;Data visualization;Fault detection;Maintenance engineering;Subspace constraints","data visualisation;fault diagnosis;program testing","test optimisation;test suites;cost-effective testing;test cases;diversity information;diversity-based approaches;test requirements;test scripts;test diversity data;test similarity maps;pair-wise diversity calculations;test repositories;maintenance;optimisation activities","","4","","25","","23 May 2019","","","IEEE","IEEE Conferences"
"An experimental framework for the evaluation of cooperative diversity","G. J. Bradford; J. N. Laneman","Department of Electrical Engineering, University of Notre Dame, Indiana 46556, USA; Department of Electrical Engineering, University of Notre Dame, Indiana 46556, USA","2009 43rd Annual Conference on Information Sciences and Systems","2 Jun 2009","2009","","","641","645","Cooperative diversity is the result of relaying among nodes to achieve space diversity in multipath environments that offer limited time and frequency diversity. Although there is now substantial literature covering specification and analysis of cooperative communication strategies based upon models of wireless environments, there is much less work addressing experiments with real-world radio hardware and propagation channels. This work describes the construction of a three node, experimental testbed based upon a network of software-defined radios for development and verification of cooperative protocols. Several decode-and-forward relay protocols have been implemented and evaluated in terms of their diversity gains as measured from experimental curves of bit-error rate versus average signal-to-noise ratio. In contrast to the few other implementation efforts reported, the experimental setup maintains the relative node geometry while moving the network to induce fading, and the experimental results exhibit diversity benefits.","","978-1-4244-2733-8","10.1109/CISS.2009.5054797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5054797","","Relays;Protocols;Frequency diversity;Hardware;Software testing;Decoding;Diversity methods;Gain measurement;Bit error rate;Signal to noise ratio","channel coding;decoding;diversity reception;fading channels;multipath channels;protocols;radiowave propagation;software radio","cooperative diversity;experimental evaluation framework;multipath environment;wireless environment;radio hardware;propagation channel;software-defined radio;decode-and-forward relay protocol;fading channel","","27","","17","","2 Jun 2009","","","IEEE","IEEE Conferences"
"Test Set Diameter: Quantifying the Diversity of Sets of Test Cases","R. Feldt; S. Poulding; D. Clark; S. Yoo","Software Eng. Res. Lab., Blekinge Inst. of Technol., Karlskrona, Sweden; Software Eng. Res. Lab., Blekinge Inst. of Technol., Karlskrona, Sweden; Dept. of Comput. Sci., Univ. Coll. London, London, UK; Sch. of Comput., KAIST, Daejeon, South Korea","2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)","21 Jul 2016","2016","","","223","233","A common and natural intuition among software testers is that test cases need to differ if a software system is to be tested properly and its quality ensured. Consequently, much research has gone into formulating distance measures for how test cases, their inputs and/or their outputs differ. However, common to these proposals is that they are data type specific and/or calculate the diversity only between pairs of test inputs, traces or outputs. We propose a new metric to measure the diversity of sets of tests: the test set diameter (TSDm). It extends our earlier, pairwise test diversity metrics based on recent advances in information theory regarding the calculation of the normalized compression distance (NCD) for multisets. A key advantage is that TSDm is a universal measure of diversity and so can be applied to any test set regardless of data type of the test inputs (and, moreover, to other test-related data such as execution traces). But this universality comes at the cost of greater computational effort compared to competing approaches. Our experiments on four different systems show that the test set diameter can help select test sets with higher structural and fault coverage than random selection even when only applied to test inputs. This can enable early test design and selection, prior to even having a software system to test, and complement other types of test automation and analysis. We argue that this quantification of test set diversity creates a number of opportunities to better understand software quality and provides practical ways to increase it.","","978-1-5090-1827-7","10.1109/ICST.2016.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515474","Software testing;Information theory;Test selection;Empirical study","Measurement;Complexity theory;Software testing;Electronic mail;Software systems","program testing;software fault tolerance;software metrics;software quality","software quality;test set diversity;fault coverage;NCD;normalized compression distance;pairwise test diversity metrics;TSDm;software system;software testers;test cases;test set diameter","","41","","41","","21 Jul 2016","","","IEEE","IEEE Conferences"
"Using Exploration Focused Techniques to Augment Search-Based Software Testing: An Experimental Evaluation","B. Marculescu; R. Feldt; R. Torkar","Sch. of Comput. Karlskrona, Blekinge Inst. of Technologv, Karlskrona, Sweden; Sch. of Comput. Karlskrona, Blekinge Inst. of Technologv, Karlskrona, Sweden; Sch. of Comput. Karlskrona, Blekinge Inst. of Technologv, Karlskrona, Sweden","2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)","21 Jul 2016","2016","","","69","79","Search-based software testing (SBST) often uses objective-based approaches to solve testing problems. There are, however, situations where the validity and completeness of objectives cannot be ascertained, or where there is insufficient information to define objectives at all. Incomplete or incorrect objectives may steer the search away from interesting behavior of the software under test (SUT) and from potentially useful test cases. This papers investigates the degree to which exploration-based algorithms can be used to complement an objective-based tool we have previously developed and evaluated in industry. In particular, we would like to assess how exploration-based algorithms perform in situations where little information on the behavior space is available a priori. We have conducted an experiment comparing the performance of an exploration-based algorithm with an objective-based one on a problem with a high-dimensional behavior space. In addition, we evaluate to what extent that performance degrades in situations where computational resources are limited. Our experiment shows that exploration-based algorithms are useful in covering a larger area of the behavior space and result in a more diverse solution population. Typically, of the candidate solutions that exploration-based algorithms propose, more than 80% were not covered by their objective-based counterpart. This increased diversity is present in the resulting population even when computational resources are limited. We conclude that exploration-focused algorithms are a useful means of investigating high-dimensional spaces, even in situations where limited information and limited resources are available.","","978-1-5090-1827-7","10.1109/ICST.2016.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515460","search-based software testing;objective-based algorithms;exploration-focused;controlled experiment","Conferences;Software testing","program testing","search-based software testing;SBST;objective-based approaches;software under test;SUT;exploration-based algorithms;high-dimensional behavior space","","5","","17","","21 Jul 2016","","","IEEE","IEEE Conferences"
"Searching for Cognitively Diverse Tests: Towards Universal Test Diversity Metrics","R. Feldt; R. Torkar; T. Gorschek; W. Afzal","Dept. of Syst. & Software Eng., Blekinge Inst. of Technol., Ronneby; Dept. of Syst. & Software Eng., Blekinge Inst. of Technol., Ronneby; Dept. of Syst. & Software Eng., Blekinge Inst. of Technol., Ronneby; Dept. of Syst. & Software Eng., Blekinge Inst. of Technol., Ronneby","2008 IEEE International Conference on Software Testing Verification and Validation Workshop","16 Jul 2008","2008","","","178","186","Search-based software testing (SBST) has shown a potential to decrease cost and increase quality of testing- related software development activities. Research in SBST has so far mainly focused on the search for isolated tests that are optimal according to a fitness function that guides the search. In this paper we make the case for fitness functions that measure test fitness in relation to existing or previously found tests; a test is good if it is diverse from other tests. We present a model for test variability and propose the use of a theoretically optimal diversity metric at variation points in the model. We then describe how to apply a practically useful approximation to the theoretically optimal metric. The metric is simple and powerful and can be adapted to a multitude of different test diversity measurement scenarios. We present initial results from an experiment to compare how similar to human subjects, the metric can cluster a set of test cases. To carry out the experiment we have extended an existing framework for test automation in an object-oriented, dynamic programming language.","","978-0-7695-3388-9","10.1109/ICSTW.2008.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4567005","","Software testing;System testing;Humans;Object oriented modeling;Automatic testing;Software measurement;Software engineering;Isolation technology;Costs;Programming","object-oriented programming;program testing;software metrics","universal test diversity metrics;search-based software testing;software development;optimal diversity metric;dynamic programming language;object-oriented programming","","32","","22","","16 Jul 2008","","","IEEE","IEEE Conferences"
"A Preliminary Study on Factors Affecting Software Testing Team Performance","T. Kanij; R. Merkel; J. Grundy","Swinburne Univ. of Technol., Hawthorn, VIC, Australia; Monash Univ., Clayton, VIC, Australia; Swinburne Univ. of Technol., Hawthorn, VIC, Australia","2011 International Symposium on Empirical Software Engineering and Measurement","1 Dec 2011","2011","","","359","362","With the growth of the software testing industry, many in-house testing groups and outsourcing testing companies have been established. Underlying the success of these testing groups and companies are team(s) of testers. This research investigates the importance of different factors, diversity and experience on building a successful testing team. We collected the opinions of testing practitioners on these factors via a survey. The outcome strongly indicates the relative importance of different factors and that diversity is helpful for a testing team. The results also support the importance of suitable team experience.","1949-3789","978-1-4577-2203-5","10.1109/ESEM.2011.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6092588","testing team;rank;diversity;experience","Software measurement;Software engineering","program testing;software development management","software testing team performance;outsourcing testing companies;suitable team experience;software testing industry","","10","","11","","1 Dec 2011","","","IEEE","IEEE Conferences"
"Objective Re-weighting to Guide an Interactive Search Based Software Testing System","B. Marculescu; R. Feldt; R. Torkar","Sch. of Comput., Blekinge Inst. of Technol., Karlskrona, Sweden; Sch. of Comput., Blekinge Inst. of Technol., Karlskrona, Sweden; Sch. of Comput., Blekinge Inst. of Technol., Karlskrona, Sweden","2013 12th International Conference on Machine Learning and Applications","10 Apr 2014","2013","2","","102","107","Even hardware-focused industries today develop products where software is both a large and important component. Engineers tasked with developing and integrating these products do not always have a software engineering background. To ensure quality, tools are needed that automate and support software testing while allowing these domain specialists to leverage their knowledge and experience. Search-based testing could be a key aspect in creating an automated tool for supporting testing activities. However, domain specific quality criteria and trade-offs make it difficult to develop a general fitness function a priori, so interaction between domain specialists and such a tool would be critical to its success. In this paper we present a system for interactive search-based software testing and investigate a way for domain specialists to guide the search by dynamically re-weighting quality goals. Our empirical investigation shows that objective re-weighting can help a human domain specialist interactively guide the search, without requiring specialized knowledge of the system and without sacrificing population diversity.","","978-0-7695-5144-9","10.1109/ICMLA.2013.113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786089","search based software testing;interactive search based software engineering;user centered;embedded software;industrial experience","Software;Software testing;Search problems;Software engineering;Context;Sociology","automatic testing;interactive systems;program testing;software quality","software engineering background;automated testing tool;interactive search- based software testing;quality goals;objective reweighting;human domain specialist;population diversity","","5","","12","","10 Apr 2014","","","IEEE","IEEE Conferences"
"Using the 5W+1H Model in Reporting Systematic Literature Review: A Case Study on Software Testing for Cloud Computing","C. Jia; Y. T. Yu","Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China; Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China","2013 13th International Conference on Quality Software","23 Sep 2013","2013","","","222","229","This paper documents a case study of using the 5W+1H model for reporting systematic literature review on software testing for cloud computing. To our knowledge, this is the first systematic literature review that applies the 5W+1H model, which is widely used in the journalism domain, to report the full picture of the research area in both software engineering and services computing. Existing guidelines on systematic literature review heavily rely on the researcher to pose the right research questions, and the review results are tightly focused on these research questions. For researchers new to a field, defining the right research questions that are effective in revealing the critical issues in the field can be challenging. Our case study demonstrates that the 5W+1H model provides an easy aid for the researcher to get over such initial challenges. As the researcher becomes more familiar with the field, he/she may then refine the research questions by adding more topic-specific contexts. In this way, the 5W+1H model serves to provide an exploratory framework to shape a systematic literature review. Applying to software testing for cloud computing, we are able to synthesize a comprehensive picture of recent researches on the field, including publication pattern, article citation immediacy, research topic diversity, research ideas for addressing testing challenges at different cloud service architectural layers. Based on the case study, we summarize the lessons learned on using the 5W+1H model in reporting systematic literature review.","2332-662X","978-0-7695-5039-8","10.1109/QSIC.2013.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6605931","5W+1H;cloud-based application;software testing;systematic literature review","Software testing;Cloud computing;Computational modeling;Software as a service;Systematics","cloud computing;program testing;software engineering","cloud service architectural layers;research ideas;research topic diversity;article citation immediacy;publication pattern;topic specific contexts;services computing;software engineering;cloud computing;software testing;case study;reporting systematic literature review","","2","","29","","23 Sep 2013","","","IEEE","IEEE Conferences"
"Initial results from the 12, 20, and 30 GHz OLYMPUS propagation experiment in Blacksburg, Virginia","W. L. Stutzman; P. W. Remaklus; T. Pratt; A. Safaai-Jazi; R. Nealy","Bradley Dept. of Electr. Eng., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; Bradley Dept. of Electr. Eng., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; Bradley Dept. of Electr. Eng., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; Bradley Dept. of Electr. Eng., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; Bradley Dept. of Electr. Eng., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA","IEEE Antennas and Propagation Society International Symposium 1992 Digest","6 Aug 2002","1992","","","736","739 vol.2","The OLYMPUS satellite has frequency coherent propagation beacons at 12.5, 19.77, and 29.66 GHz. These beacons are visible from Blacksburg, at an elevation angle of 14 degrees . Five receivers were developed: one at each frequency plus a second portable terminal with 20 and 30 GHz receivers for short-baseline diversity measurements. This experiment not only provided valuable data over the 10 to 30 GHz frequency range, but has provided a test bed for hardware and software approaches for the future ACTS (Advanced Communications Technology Satellite) program at 20/30 GHz. The authors present initial results from analysis of early data that shows that radiometer-derived attenuation agrees with beacon-measured attenuation to the fractional decibel level for fading up to 10 dB. Small baseline diversity, as expected, offers no improvement to rain fading, but does for scintillation events. Simple uplink power control algorithms were developed.<<ETX>></ETX>","","0-7803-0730-5","10.1109/APS.1992.221827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=221827","","Satellite broadcasting;Attenuation;Frequency diversity;Frequency measurement;Software testing;Hardware;Communications technology;Artificial satellites;Data analysis;Radiometry","diversity reception;fading;radiowave propagation;satellite relay systems;tropospheric electromagnetic wave propagation","radiowave propagation;diversity measurements;SHF;OLYMPUS satellite;frequency coherent propagation beacons;Blacksburg;attenuation;fading;uplink power control algorithms;12.5 GHz;19.77 GHz;29.66 GHz","","2","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Diversity-Aware Mutation Adequacy Criterion for Improving Fault Detection Capability","D. Shin; S. Yoo; D. -H. Bae","Sch. of Comput., KAIST, Daejeon, South Korea; Sch. of Comput., KAIST, Daejeon, South Korea; Sch. of Comput., KAIST, Daejeon, South Korea","2016 IEEE Ninth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2016","2016","","","122","131","Many existing testing techniques adopt diversity as an important criterion for the selection and prioritization of tests. However, mutation adequacy has been content with simply maximizing the number of mutants that have been killed. We propose a novel mutation adequacy criterion that considers the diversity in the relationship between tests and mutants, as well as whether mutants are killed. Intuitively, the proposed criterion is based on the notion that mutants can be distinguished by the sets of tests that kill them. A test suite is deemed adequate by our criterion if the test suite distinguishes all mutants in terms of their kill patterns. Our hypothesis is that, simply by using a stronger adequacy criterion, it is possible to improve fault detection capabilities of mutation-adequate test suites. The empirical evaluation selects tests for real world applications using the proposed mutation adequacy criterion to test our hypothesis. The results show that, for real world faults, test suites adequate to our criterion can increase the fault detection success rate by up to 76.8 percentage points compared to test suites adequate to the traditional criterion.","","978-1-5090-3674-5","10.1109/ICSTW.2016.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528954","Mutation testing;adequacy criteria;diversity","Fault detection;Conferences;Software testing;Electronic mail;Pathology;Subspace constraints","fault diagnosis;fault tolerant computing;program testing","diversity-aware mutation adequacy criterion;fault detection capability;mutants;kill patterns;mutation-adequate test suites;fault detection success rate","","6","","29","","4 Aug 2016","","","IEEE","IEEE Conferences"
"Implementation of cooperative communications using software defined radios","M. Knox; E. Erkip","Department of Electrical and Computer Engineering, Polytechnic Institute of New York University, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, Polytechnic Institute of New York University, Brooklyn, NY, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","28 Jun 2010","2010","","","5618","5621","Cooperative communications leverages the spatial diversity available in a wireless network enabling multiple radio nodes work together to improve the overall system performance. When a destination receiver combines the signal from an originating source with the associated signals from relay nodes, significant improvements in the bit error rate performance can be achieved. This paper details the measured bit error rate performance of a three-node cooperative communication system operating in a software defined radio testbed. The measured performances of several types of cooperative physical layer protocols are compared to similar systems operating over a single wireless link. The measured results include cooperative systems operating with a maximum ratio combining technique and two cooperative coded systems using hard decision decoding.","2379-190X","978-1-4244-4295-9","10.1109/ICASSP.2010.5495252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5495252","cooperative communications;cooperative coding;software defined radio;WARP;WARPLAB","Software radio;Bit error rate;Diversity reception;Wireless networks;System performance;Receivers;Relays;Software measurement;Software testing;System testing","cooperative systems;decoding;diversity reception;error statistics","cooperative communications;software defined radios;spatial diversity;wireless network;relay nodes;bit error rate;cooperative systems;maximum ratio;hard decision decoding","","5","","11","","28 Jun 2010","","","IEEE","IEEE Conferences"
"Covering arrays: Evaluating coverage and diversity in the presence of disallowed combinations","J. Morgan; R. Lekivetz; T. Donnelly","JMP Division, SAS Institute Incorporated, Cary, NC, USA; JMP Division, SAS Institute Incorporated, Cary, NC, USA; JMP Division, SAS Institute Incorporated, Cary, NC, USA","2017 IEEE 28th Annual Software Technology Conference (STC)","25 Dec 2017","2017","","","1","4","Test engineers are often faced with the challenge of selecting test cases that maximize the chance of discovering faults while working with a limited budget. Combinatorial testing is an effective test case selection strategy to address this challenge. The basic idea is to select test cases that ensure that all possible combinations of settings from two (or more) inputs are accounted for, regardless of which subset of two (or more) inputs are selected. Currently, combinatorial testing usually implies a covering array as the underlying mathematical construct. Yet, despite their demonstrated utility, practitioners sometimes encounter challenges that impede their use. For example, given a covering array with constraints on allowed combinations of settings for some subset of inputs, it is often unclear how to assess the coverage and diversity [2] properties of the resulting covering array.","","978-1-5386-1088-6","10.1109/STC.2017.8234455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8234455","covering array;software testing;systems testing;disallowed combinations;forbidden configurations","Measurement;Synthetic aperture sonar;Software testing;System testing;Control systems;Face","program testing","combinatorial testing;disallowed combinations;effective test case selection strategy;covering array","","1","","5","","25 Dec 2017","","","IEEE","IEEE Conferences"
"A Theoretical and Empirical Study of Diversity-Aware Mutation Adequacy Criterion","D. Shin; S. Yoo; D. Bae","KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea","IEEE Transactions on Software Engineering","14 Oct 2018","2018","44","10","914","931","Diversity has been widely studied in software testing as a guidance towards effective sampling of test inputs in the vast space of possible program behaviors. However, diversity has received relatively little attention in mutation testing. The traditional mutation adequacy criterion is a one-dimensional measure of the total number of killed mutants. We propose a novel, diversity-aware mutation adequacy criterion called distinguishing mutation adequacy criterion, which is fully satisfied when each of the considered mutants can be identified by the set of tests that kill it, thereby encouraging inclusion of more diverse range of tests. This paper presents the formal definition of the distinguishing mutation adequacy and its score. Subsequently, an empirical study investigates the relationship among distinguishing mutation score, fault detection capability, and test suite size. The results show that the distinguishing mutation adequacy criterion detects 1.33 times more unseen faults than the traditional mutation adequacy criterion, at the cost of a 1.56 times increase in test suite size, for adequate test suites that fully satisfies the criteria. The results show a better picture for inadequate test suites; on average, 8.63 times more unseen faults are detected at the cost of a 3.14 times increase in test suite size.","1939-3520","","10.1109/TSE.2017.2732347","Information & communications Technology Promotion (IITP); Korea government (MSIP)(grant numbers:R0126-17-1101); Software R&D for Model-based Analysis and Verification of Higher-order Large Complex System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7994647","Mutation testing;test adequacy criteria;diversity","Fault detection;Software engineering;Software testing;Correlation;Indexes;Subspace constraints","fault diagnosis;program testing;software engineering","empirical study;diversity-aware mutation adequacy criterion;software testing;test inputs;mutation testing;distinguishing mutation score;distinguishing mutation adequacy criterion;adequate test suites;inadequate test suites;theoretical study;program behaviors;killed mutants;fault detection capability","","13","","58","IEEE","27 Jul 2017","","","IEEE","IEEE Journals"
"A Framework for Automated Software Testing on the Cloud","G. Savio de Oliveira; A. Duarte","Informatics Centre, Federal University of Paraiba, Joao Pessoa, Brazil; Informatics Centre, Federal University of Paraiba, Joao Pessoa, Brazil","2013 International Conference on Parallel and Distributed Computing, Applications and Technologies","22 Sep 2014","2013","","","344","349","This work presents the framework Cloud Testing, a solution to parallelize the execution of a test suite over a distributed cloud infrastructure. The use of a cloud as runtime environment for automated software testing provides a more efficient and effective solution when compared to traditional methods regarding the exploration of diversity and heterogeneity for testing coverage. The objective of this work is evaluate our solution regarding the performance gains achieved with the use of the framework showing that it is possible to improve the software testing process with very little configuration overhead and low costs.","2379-5352","978-1-4799-2419-6","10.1109/PDCAT.2013.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6904278","software testing;cloud computing","Software testing;Cloud computing;Standards;Hardware;Random access memory","cloud computing;program testing","automated software testing coverage;cloud computing;cloudtesting;distributed cloud infrastructure","","5","","17","","22 Sep 2014","","","IEEE","IEEE Conferences"
"Random Border Mirror Transform: A Diversity Based Approach to an Effective and Efficient Mirror Adaptive Random Testing","M. Omari; J. Chen; P. Kwaku Kudjo; H. Ackah-Arthur; R. Huang",Jiangsu University; Jiangsu University; Jiangsu University; Jiangsu University; Jiangsu University,"2019 IEEE 19th International Conference on Software Quality, Reliability and Security (QRS)","3 Oct 2019","2019","","","54","61","Mirror Adaptive random testing (MART) is an overhead reduction strategy for adaptive random testing methods. Theoretically speaking, MART's advantage over ordinary ARTs is determined by the mirroring scheme selected. Incidentally, an inherent problem with MART relates to the difficulty in the choice of a scheme for any testing task. This is because a higher scheme (larger mirror domains) does not necessarily guarantee efficient utilization of testing resources due to lack of diversity of mirror generated test cases. The culprit has been identified as the mapping functions used as substitutes to complex ART methods. In this paper, we present a new method for generating diversified mirror test cases by randomly displacing the mirror partitions upon which the mapping functions of MART operates. The result of simulations and experiments conducted shows remarkable improvement over MART's effectiveness and efficiency across MART schemes, especially where program failures are unrelated to one or more input parameters.","","978-1-7281-3927-2","10.1109/QRS.2019.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854699","Adaptive random testing;software testing;mirror adaptive random testing;test case diversity","Mirrors;Subspace constraints;Software;Power capacitors;Software testing;Software reliability","program testing;random processes;transforms","mapping functions;Mirror Adaptive random testing;overhead reduction strategy;adaptive random testing methods;MART;random border mirror transform;ART methods;software testing","","","","24","","3 Oct 2019","","","IEEE","IEEE Conferences"
"Contributions and Perspectives in Architectures of Software Testing Environments","E. Y. Nakagawa; J. C. Maldonado","Dept. of Comput. Syst., Univ. of Sao Paulo, Sao Carlos, Brazil; Dept. of Comput. Syst., Univ. of Sao Paulo, Sao Carlos, Brazil","2011 25th Brazilian Symposium on Software Engineering","3 Nov 2011","2011","","","66","71","Producing high quality software systems has been one of the most important software development concerns. In this perspective, Software Architecture and Software Testing are two important research areas that have contributed in that direction. The attention given to the software architecture has played a significant role in determining the success of software systems. Otherwise, software testing has been recognized as a fundamental activity for assuring the software quality; however, it is an expensive, error-prone, and time consuming activity. For this reason, a diversity of testing tools and environments has been developed; however, they have been almost always designed without an adequate attention to their evolution, maintenance, reuse, and mainly to their architectures. Thus, this paper presents our main contributions to systematize the development of testing tools and environments, aiming at improving their quality, reuse, and productivity. In particular, we have addressed architectures for software testing tools and environments and have also developed and made available testing tools. We also state perspectives of research in this area, including open research issues that must be treated, considering the unquestionable relevance of testing automation to the testing activity.","","978-1-4577-2187-8","10.1109/SBES.2011.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065147","","Computer architecture;Software testing;Software;Software architecture;Context","program testing;software architecture;software quality;software tools","software testing environment architecture;high quality software systems;software development;software testing tools;testing automation;testing activity","","2","","48","","3 Nov 2011","","","IEEE","IEEE Conferences"
"Collision resolution based on pulse shape diversity","X. Liu; S. Oymak; A. P. Petropulu; K. R. Dandekar","Electrical and Computer Engineering Department, Drexel University, Philadelphia 19104, USA; Electrical and Computer Engineering Department, Drexel University, Philadelphia 19104, USA; Electrical and Computer Engineering Department, Drexel University, Philadelphia 19104, USA; Electrical and Computer Engineering Department, Drexel University, Philadelphia 19104, USA","2009 IEEE 10th Workshop on Signal Processing Advances in Wireless Communications","10 Jul 2009","2009","","","409","413","A two-user wireless uplink scenario is considered, in which the users transmit simultaneously over the same channel. In the networking literature the result of such transmission is referred to as collision. It has been recently shown that small user delays and carrier frequency offsets (CFO) between the users allow for blind collision resolution based on the measurements of a single receive antenna. This is achieved by oversampling the collision signal, and exploiting the information on the collided packets that is contained in the signal's polyphase components. In this paper, user pulse-shape diversity is investigated for separating collided users even when delays and CFOs are small. In particular, an iterative pulse shape design is proposed that enforces several desirable characteristics to each user's pulse shape function. The proposed approach is tested on a software defined radio testbed and also via simulations. Both simulations and testbed evaluation suggest that the proposed approach can be very successful in resolving the users under realistic signal-to-noise ratio scenarios. Resolving collisions can significantly improve throughput in wireless networks.","1948-3252","978-1-4244-3695-8","10.1109/SPAWC.2009.5161817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5161817","collision resolution;pulse shape diversity;blind user separation;successive interference cancelation;software defined radio.","Pulse shaping methods;Shape;Signal resolution;Delay;Software testing;Antenna measurements;Frequency measurement;Receiving antennas;Software radio;Signal to noise ratio","diversity reception;iterative methods;signal sampling;wireless channels","blind collision resolution;iterative pulse shape diversity;two-user wireless uplink scenario;wireless channel;carrier frequency offset;collision signal oversampling;signal polyphase component","","3","","14","","10 Jul 2009","","","IEEE","IEEE Conferences"
"Crowdsourced Test Report Prioritization Based on Text Classification","Y. Yang; X. Chen","School of Computer Science, Hangzhou Dianzi University.; School of Computer Science, Hangzhou Dianzi University. (e-mail: chenxin4391@hdu.edu.cn)","IEEE Access","","2021","PP","99","1","1","In crowdsourced testing, crowd workers from different places help developers conduct testing and submit test reports for the observed abnormal behaviors. Developers manually inspect each test report and make an initial decision for the potential bug. However, due to the poor quality, test reports are handled extremely slowly. Meanwhile, due to the limitation of resources, some test reports are not handled at all. Therefore, some researchers attempt to resolve the problem of test report prioritization and have proposed many methods. However, these methods do not consider the impact of duplicate test reports. In this paper, we focus on the problem of test report prioritization and present a new method named DivClass by combining a diversity strategy and a classification strategy. First, we leverage Natural Language Processing (NLP) techniques to preprocess crowdsourced test reports. Then, we build a similarity matrix by introducing an asymmetric similarity computation strategy. Finally, we combine the diversity strategy and the classification strategy to determine the inspection order of test reports. To validate the effectiveness of DivClass, experiments are conducted on five crowdsourced test report datasets. Experimental results show that DivClass achieves 0.8887 in terms of APFD (Average Percentage of Fault Detected) and improves the state-of-the-art technique DivRisk by 14.12% on average. The asymmetric similarity computation strategy can improve DivClass by 4.82% in terms of APFD on average. In addition, empirical results show that DivClass can greatly reduce the number of inspected test reports.","2169-3536","","10.1109/ACCESS.2021.3128726","National Natural Science Foundation of China(grant numbers:61902096); Science and Technology of Zhejiang Province(grant numbers:LY21F020020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9617598","Crowdsourced testing;test report prioritization;text classification;diversity strategy;asymmetric similarity","Computer bugs;Diversity reception;Software;Inspection;Task analysis;Software testing;Smart phones","","","","","","","CCBY","16 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Test Case Selection Method for Emergency Changes","F. d. Farzat","Postgrad. Inf. Syst. Program, UNIRIO, Rio de Janeiro, Brazil","2nd International Symposium on Search Based Software Engineering","11 Nov 2010","2010","","","31","35","Software testing is an expensive task that significantly contributes to the total cost of a software development project. Among the many strategies available to test a software project, the creation of automated test cases that can be enacted after building a release or resolving a defect is increasingly used in the industry. However, certain defects found in the system operation may block major business operations. These critical defects are sometimes resolved directly in the production environment under such a restricted deadline that there is not enough time to run the complete set of automated test cases upon the patched version of the software. Declining to run the test case suite allows a quicker release of the software to production, but also allows other defects to be introduced into the system. This paper presents a heuristic approach to select test cases that might support emergency changes aiming to maximize the coverage and diversity of the testing activity under a strict time constraint and given the priority of the features that were changed.","","978-1-4244-8341-9","10.1109/SSBSE.2010.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635168","Software Testing;Genetic Algorithm;Time Constraint;Process development;Risk Management","Software;Testing;Optimization;History;Companies;Time factors;Industries","program testing;software engineering","test case selection method;emergency changes;software testing;software development project;test case suite","","2","","11","","11 Nov 2010","","","IEEE","IEEE Conferences"
"Modeling the effects of combining diverse software fault detection techniques","B. Littlewood; P. T. Popov; L. Strigini; N. Shryane","Centre for Software Reliability, City Univ., London, UK; NA; NA; NA","IEEE Transactions on Software Engineering","6 Aug 2002","2000","26","12","1157","1167","Considers what happens when several different fault-finding techniques are used together. The effectiveness of such multi-technique approaches depends upon a quite subtle interplay between their individual efficacies. The modeling tool we use to study this problem is closely related to earlier work on software design diversity which showed that it would be unreasonable even to expect software versions that were developed truly independently to fail independently of one another. The key idea was a ""difficulty function"" over the input space. Later work extended these ideas to introduce a notion of ""forced"" diversity. In this paper, we show that many of these results for design diversity have counterparts in diverse fault detection in a single software version. We define measures of fault-finding effectiveness and diversity, and show how these might be used to give guidance for the optimal application of different fault-finding procedures to a particular program. The effects on reliability of repeated applications of a particular fault-finding procedure are not statistically independent; such an incorrect assumption of independence will always give results that are too optimistic. For diverse fault-finding procedures, it is possible for effectiveness to be even greater than it would be under an assumption of statistical independence. Diversity of fault-finding procedures is a good thing and should be applied as widely as possible. The model is illustrated using some data from an experimental investigation into diverse fault-finding on a railway signalling application.","1939-3520","","10.1109/32.888629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=888629","","Diversity reception;Fault detection;Software design;Application software;Redundancy;Hardware;Aerospace control;Battery powered vehicles;Software engineering;Particle measurements","system recovery;program diagnostics;software reliability;signalling;railways","software fault detection techniques;multi-technique approach;modeling tool;software design diversity;independently developed software versions;system failure;difficulty function;forced diversity;fault-finding effectiveness;repeated application reliability;diverse fault-finding procedures;statistical independence;railway signalling application;fault removal;software testing;software reliability growth","","32","","15","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Wireless field trial results of a high hopping rate FHSS-FSK testbed","D. Cabric; A. M. Eltawil; H. Zou; S. Mohan; B. Daneshrad","Electr. Eng. & Comput. Sci. Dept., Univ. of California, Berkeley, CA, USA; NA; NA; NA; NA","IEEE Journal on Selected Areas in Communications","2 May 2005","2005","23","5","1113","1122","This paper presents a complete study and characterization of a real-time frequency-hopped, frequency shift-keyed testbed capable of transmitting data at 160 kb/s, with hopping rates of up to 80 Khops/s operating in the 900 MHz band. The system provides the highest hopping rate reported to date and sets a new trend for FHSS communications with superior low probability of interception/detection and anti-jamming (LPI/LPD/AJ) capabilities. The architecture features a direct digital frequency synthesizer to enable high-rate hopping, and a frequency correlator-based demodulator, plus all digital timing and frequency recovery algorithms to minimize complexity. Furthermore, single sideband modulation was used to achieve spectral efficiency. The testbed is software configured and provides the user with full control over the diversity combining techniques, symbol interleaving, packet structure, and acquisition protocols. A total of 5850 independent experiments were carried out under various receiver configurations and wireless environments. The results underscore the dramatic potential for a system that optimally combines high-rate hopping, interleaving, and equal gain combining to combat severe propagation conditions, including multipath fading and intentional jamming.","1558-0008","","10.1109/JSAC.2005.845437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1425653","Direct digital frequency synthesizer (DDFS);diversity combining;equal gain combining (EGC);frequency hopping;frequency shift-keying","Frequency synthesizers;Diversity reception;Interleaved codes;Computer architecture;Spread spectrum communication;Demodulation;Timing;Software testing;Protocols;Fading","frequency shift keying;diversity reception;protocols;direct digital synthesis;correlation theory;data communication;probability;frequency hop communication;demodulators","wireless field trial;high hopping rate;FHSS-FSK testbed;real-time frequency-hop;frequency shift-keyed testbed;data transmission;interception probability;antijamming;DDFS;direct digital frequency synthesizer;frequency correlator-based demodulator;digital timing;frequency recovery algorithm;single sideband modulation;spectral efficiency;diversity combining technique;symbol interleave;acquisition protocol;EGC;equal gain combining;160 Kbit/s;900 MHz","","5","","16","IEEE","2 May 2005","","","IEEE","IEEE Journals"
"Prioritization of Metamorphic Relations Based on Test Case Execution Properties","M. Srinivasan","Gianforte Sch. of Comput., Montana State Univ., Bozeman, MT, USA","2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)","18 Nov 2018","2018","","","162","165","A test oracle is essential for software testing. In certain complex systems, it is hard to distinguish between correct and incorrect behavior. Metamorphic testing is one of the solution to solve the test oracle problem. In metamorphic testing, metamorphic relations (MRs) are derived based on the properties exhibited by the program under test (PUT). These MRs play a major role in the generation of test data for conducting MT. The effectiveness of MRs can be determined based on the ability to detect considerable faults for the given PUT. Many metamorphic relations with different fault finding capability can be used to test the PUT and it is important to identify and prioritize the MRs based on its fault finding effectiveness. In order to answer this challenge, we propose to prioritize the MRs based on the diversity in the execution path of the source and follow-up test cases of the MRs. We propose four metrics to capture different levels of diversity in the execution behavior of the test cases for each of the derived MRs. The total weight calculated for each of the MRs using the metrics is used to prioritize the MRs.","","978-1-5386-9443-5","10.1109/ISSREW.2018.000-5","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539189","Metamorphic Testing, Metamorphic Relations, Test case diversity, MR Prioritization","Measurement;Complexity theory;Indexes;Correlation;Tools;Software testing","program testing;software fault tolerance","metamorphic relations;test case execution properties;software testing;metamorphic testing;test oracle problem;test data;fault finding effectiveness;fault finding capability;program under test;fault detection","","1","","13","","18 Nov 2018","","","IEEE","IEEE Conferences"
"The Effectiveness of Software Diversity in a Large Population of Programs","M. J. P. van der Meulen; M. A. Revilla","Det Norske Veritas, Høvik; University of Valladolid, Valladolid","IEEE Transactions on Software Engineering","12 Dec 2008","2008","34","6","753","764","In this paper, we first present an exploratory analysis of the aspects of multiple-version software diversity using 36,123, programs written to the same specification. We do so within the framework of the theories of Eckhardt and Lee and Littlewood and Miller. We analyse programming faults made, explore failure regions and difficulty functions, show how effective 1-out-of-2 diversity is and how language diversity increases this effectiveness. The second part of the paper generalizes the findings about 1-out-of-2 diversity, and its special case language diversity by performing statistical analyses of 89,402 programs written to 60 specifications. Most observations in the exploratory analysis are confirmed; however, although the benefit of language diversity can be observed, its effectiveness appears to be low.","1939-3520","","10.1109/TSE.2008.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4604670","Programming Techniques;Protection mechanisms;Design concepts;Quality analysis and evaluation;Software and System Safety;Reliability;Reliability;Performance measures;Programming Techniques;Protection mechanisms;Design concepts;Quality analysis and evaluation;Software and System Safety;Reliability;Reliability;Performance measures","Statistical analysis;Software reliability;Failure analysis;Functional programming;Fault tolerance;Software testing;Java;Algorithm design and analysis;Reliability engineering","software fault tolerance;statistical analysis","software diversity;exploratory analysis;programming fault;software failure;language diversity;1-out-of-2 diversity;statistical analysis;software reliability","","22","","12","","22 Aug 2008","","","IEEE","IEEE Journals"
"Grey-box Fuzzing With Deep Reinforcement Learning And Process Trace Back","C. Chen","Anhui University,Institutes of Physical Science and Information Technology,Hefei,China","2021 4th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","19 Aug 2021","2021","","","1167","1171","Grey-box fuzzing, as a software testing technique, can find possible program bugs such as memory leaks, assertion failures and invalid input by generate random data then input it into a program, and monitor program exceptions. With program running, grey-box fuzzing collected the branch information in order to guide choosing next seeds. In this paper, we try to use the concept of Markov decision processes to formalize grey-box fuzzing as a deep reinforcement learning problem, and use process trace back(Intel Process Trace) to collect branch information in order to improve its efficiency toward binary programs. The experiments show this approach can outperform baseline random fuzzing and gain performance improvement.","","978-1-6654-1596-5","10.1109/AEMCSE51986.2021.00238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9512987","component;fuzzing;deep reinforcement learning;Intel PT;software testing","Computers;Software algorithms;Diversity reception;Reinforcement learning;Fuzzing;Markov processes;Tools","deep learning (artificial intelligence);fuzzy set theory;Markov processes;program debugging;program diagnostics;program testing","Intel Process Trace;baseline random fuzzing;grey-box fuzzing;program bugs;program running;program exception monitoring;deep reinforcement learning;process trace back;Markov decision processes;software testing","","","","12","","19 Aug 2021","","","IEEE","IEEE Conferences"
"Fostering the Diversity of Exploratory Testing in Web Applications","J. Leveau; X. Blanc; L. Réveillère; J. Falleri; R. Rouvoy","Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI,Talence,France,UMR5800, F-33400; Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI,Talence,France,UMR5800, F-33400; Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI,Talence,France,UMR5800, F-33400; Univ. Bordeaux, Bordeaux INP, CNRS, LaBRI,Talence,France,UMR5800, F-33400; Univ. Lille / Inria,France","2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)","5 Aug 2020","2020","","","164","174","Exploratory testing (ET) is a software testing approach that complements automated testing by leveraging business expertise. It has gained momentum over the last decades as it appeals testers to exploit their business knowledge to stress the system under test (SUT). Exploratory tests, unlike automated tests, are defined and executed on-the-fly by testers. Testers who perform exploratory tests may be biased by their past experience and therefore may miss anomalies or unusual interactions proposed by the SUT. This is even more complex in the context of web applications, which typically expose a huge number of interaction paths to their users. As testers of these applications cannot remember all the sequences of interactions they performed, they may fail to deeply explore the application scope. This paper therefore introduces a new approach to assist testers in widely exploring any web application. In particular, our approach monitors the online interactions performed by the testers to suggest in real-time the probabilities of performing next interactions. Looking at these probabilities, we claim that the testers who favour interactions that have a low probability (because they were rarely performed), will increase the diversity of their explorations. Our approach defines a prediction model, based on ${n}$-grams, that encodes the history of past interactions and that supports the estimation of the probabilities. Integrated within a web browser extension, it automatically and transparently injects feedback within the application itself. We conduct a controlled experiment and a qualitative study to assess our approach. Results show that it prevents testers to be trapped in already tested loops, and succeeds to assist them in performing deeper explorations of the SUT.","2159-4848","978-1-7281-5778-8","10.1109/ICST46399.2020.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159101","test;Exploratory test;n-gram;web applications","Predictive models;Computational modeling;Monitoring;Software testing;Buildings;Context modeling","","","","","","26","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Cloud based mobile application testing","L. Murugesan; P. Balasubramanian","School of Computing Science and Engineering, VIT University, Chennai, India; School of Computing Science and Engineering, VIT University, Chennai, India","2014 IEEE/ACIS 13th International Conference on Computer and Information Science (ICIS)","29 Sep 2014","2014","","","287","289","The testing of a mobile application is a difficult task keeping in mind the diversity in mobile devices and the runtime environment. Also the need of resources to test a mobile application varies from mobile phones to tablet. At present there are tools which can simulate the mobile environment to test mobile applications. These stimulators simulate only the functionality of a particular operating system but not the processor cores, speed, memory, cache size of the mobile device. In order to overcome the above short comings we move to cloud testing. In cloud computing we can easily allocate the required resources using virtualization and also it is easy to scale up our resources anytime without affecting the entire system. The major advantage in cloud is that it is cost-effective. In this paper we define a cloud based mobile testing model which can test application for different mobile environments and platforms.","","978-1-4799-4860-4","10.1109/ICIS.2014.6912148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6912148","Cloud Testing;Software Testing;Mobile Application Testing;Cloud Computing","Mobile communication;Mobile handsets;Cloud computing;Runtime environment;Computational modeling;Software testing","cloud computing;mobile computing;operating systems (computers);program testing;virtualisation","software testing;cloud computing;virtualization;operating system;tablet;mobile phones;runtime environment;mobile devices;cloud based mobile application testing","","11","","16","","29 Sep 2014","","","IEEE","IEEE Conferences"
"A software fault tolerance experiment for space applications","D. Simon; C. Hourtolle; H. Biondi; J. Bernelas; P. Duverneuil; S. Gallet; P. Vielcanet; S. De Viguerie; F. Gsell; J. N. Chelotti","Centre Nat. d'Etudes Spatiales, Toulouse, France; Centre Nat. d'Etudes Spatiales, Toulouse, France; Centre Nat. d'Etudes Spatiales, Toulouse, France; NA; NA; NA; NA; NA; NA; NA","[1990] Digest of Papers. Fault-Tolerant Computing: 20th International Symposium","6 Aug 2002","1990","","","28","35","The aim of the experiment described was to implement and assess fault-tolerant software within an industrial framework. Another significant aspect was to adapt the classical software engineering life cycle to this type of project. Two complementary techniques are considered: fault avoidance through the use of higher level language and strict development process; and fault tolerance by using techniques based on design diversity, such as N-version programming and recovery blocks, and exception handling. Starting from the specification of an existing spacecraft orbit and attitude control system, a 3-version software was developed, coded in Ada, and assessed in a fault-tolerant experimental testbed. The authors describe the experiment development and the main study results (on development efforts, observed diversity, and methodology aspects).<<ETX>></ETX>","","0-8186-2051-X","10.1109/FTCS.1990.89363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=89363","","Fault tolerance;Application software;Computer industry;Software engineering;Space vehicles;Software systems;Fault tolerant systems;Software testing;System testing;Diversity methods","aerospace computing;fault tolerant computing;software engineering","software fault tolerance experiment;space applications;classical software engineering life cycle;fault avoidance;design diversity;N-version programming;recovery blocks;exception handling;spacecraft orbit;attitude control system;Ada;methodology aspects","","2","1","13","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Assessment of Data Diversity Methods for Software Fault Tolerance Based on Mutation Analysis","G. Gallardo; J. May; J. C. Gallardo","University of Bristol, UK; University of Bristol, UK; Research Associate at the SSRC","Second Workshop on Mutation Analysis (Mutation 2006 - ISSRE Workshops 2006)","2 Apr 2007","2006","","","6","6","One of the main concerns in safety-critical software is to ensure sufficient reliability because proof of the absence of systematic failures has proved to be an unrealistic goal. fault-tolerance (FT) is one method for improving reliability claims. It is reasonable to assume that some software FT techniques offer more protection than others, but the relative effectiveness of different software FT schemes remains unclear. We present the principles of a method to assess the effectiveness of FT using mutation analysis. The aim of this approach is to observe the power of FT directly and use this empirical process to evolve more powerful forms of FT. We also investigate an approach to FT that integrates data diversity (DD) assertions and TA. This work is part of a longer term goal to use FT in quantitative safety arguments for safety critical systems.","","0-7695-2897-X","10.1109/MUTATION.2006.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4144725","","Diversity methods;Fault tolerance;Genetic mutations;Software safety;Redundancy;Software testing;Fault tolerant systems;Software systems;Failure analysis;System testing","safety-critical software;software fault tolerance;software reliability","data diversity methods;software fault tolerance;mutation analysis;safety-critical software;reliability","","","","17","","2 Apr 2007","","","IEEE","IEEE Conferences"
"Space-time processing TDMA wireless testbed","H. Sampath; A. Paulraj","Inf. Syst. Lab., Stanford Univ., CA, USA; NA","1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)","6 Aug 2002","1999","4","","2203","2206 vol.4","The paper describes the architecture of the Stanford University (SU) TDMA standalone testbed. The testbed was developed to evaluate space-time processing (STP) algorithms for diversity, co-channel interference (CCI) and intersymbol interference (ISI) mitigation, array gain and space-time coding. It operates in both uplink and downlink modes and uses a hybrid (combining a real and simulated) channel environment. A description of transmit and receive schemes implemented on the testbed is presented.","1520-6149","0-7803-5041-3","10.1109/ICASSP.1999.758373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=758373","","Time division multiple access;Radio frequency;System testing;Radiofrequency interference;Software testing;Intersymbol interference;GSM;Computer architecture;Hardware;Transmitters","time division multiple access;space-time adaptive processing;diversity reception;cochannel interference;encoding;radio links;telecommunication channels;intersymbol interference;transmitting antennas;receiving antennas;interference suppression;parallel architectures","TDMA wireless testbed;space-time processing;Stanford University;space-time processing algorithms;diversity;co-channel interference;CCI;intersymbol interference;ISI;array gain;space-time coding;uplink;downlink;hybrid channel environment;simulated channel;real channel;transmit scheme;receive scheme;parallel DSP architecture","","2","1","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Increasing Diversity in Coverage Test Suites Using Model Checking","G. Fraser; F. Wotawa","Inst. for Software Technol., Graz Univ. of Technol., Graz, Austria; Inst. for Software Technol., Graz Univ. of Technol., Graz, Austria","2009 Ninth International Conference on Quality Software","15 Jan 2010","2009","","","211","218","Automated test case generation often results in test suites containing significant redundancy such as test cases that are duplicates, prefixes of other test cases, or cover the same test requirements. In this paper we consider the fact that items described by a coverage criterion can be covered in different ways. We introduce a technique where each created test case is guaranteed to cover a test requirement in a new way, even if it has previously been covered. This increases the diversity of how test objectives are satisfied, thus reducing the redundancy in test suites, improving their fault detection ability, and usually also decreasing the number of test cases generated. This approach is based in a scenario of specification based testing using model checkers as test case generation tools, and evaluation is performed on three different case study specifications.","2332-662X","978-1-4244-5913-1","10.1109/QSIC.2009.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5381459","test case generation;specification based testing;model checking;test coverage;test redundancy;test diversity","Logic testing;Automatic testing;Software testing;Redundancy;Fault detection;Software quality;Performance evaluation;Programming;Monitoring;Encoding","fault diagnosis;formal specification;program testing;program verification","coverage test suite diversity;model checking;automated test case generation;coverage criterion;test requirement;fault detection;specification based testing","","1","","21","","15 Jan 2010","","","IEEE","IEEE Conferences"
"Augmenting test suites effectiveness by increasing output diversity","N. Alshahwan; M. Harman","CREST Centre, University College London Malet Place, London, WC1E 6BT, U.K.; CREST Centre, University College London Malet Place, London, WC1E 6BT, U.K.","2012 34th International Conference on Software Engineering (ICSE)","28 Jun 2012","2012","","","1345","1348","The uniqueness (or otherwise) of test outputs ought to have a bearing on test effectiveness, yet it has not previously been studied. In this paper we introduce a novel test suite adequacy criterion based on output uniqueness. We propose 4 definitions of output uniqueness with varying degrees of strictness. We present a preliminary evaluation for web application testing that confirms that output uniqueness enhances fault-finding effectiveness. The approach outperforms random augmentation in fault finding ability by an overall average of 280% in 5 medium sized, real world web applications.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227083","SBSE;HTML output;Web applications","HTML;Testing;Educational institutions;Databases;Web pages;Instruments;Cloning","Internet;program testing;software fault tolerance","test suite adequacy criterion;augment test suites effectiveness;Web application testing;fault-finding effectiveness;real world Web applications;output diversity;software testing","","19","","9","","28 Jun 2012","","","IEEE","IEEE Conferences"
"On the role of diversity measures for multi-objective test case selection","A. De Lucia; M. Di Penta; R. Oliveto; A. Panichella","University of Salerno, via Ponte don Melillo, Fisciano (SA), 84084, Italy; University of Sannio, Palazzo ex Poste, Via Traiano, 82100 Benevento, Italy; University of Molise, Contrada Fonte Lappone, 86090 Pesche (IS), Italy; University of Salerno, via Ponte don Melillo, Fisciano (SA), 84084, Italy","2012 7th International Workshop on Automation of Software Test (AST)","2 Jul 2012","2012","","","145","151","Test case selection has been recently formulated as multi-objective optimization problem trying to satisfy conflicting goals, such as code coverage and computational cost. This paper introduces the concept of asymmetric distance preserving, useful to improve the diversity of non-dominated solutions produced by multi-objective Pareto efficient genetic algorithms, and proposes two techniques to achieve this objective. Results of an empirical study conducted over four programs from the SIR benchmark show how the proposed technique (i) obtains non-dominated solutions having a higher diversity than the previously proposed multi-objective Pareto genetic algorithms; and (ii) improves the convergence speed of the genetic algorithms.","","978-1-4673-1822-8","10.1109/IWAST.2012.6228983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228983","Search-based Software Testing;Test Case Selection;Niched Genetic Algorithms;Empirical Studies","Genetic algorithms;Optimization;Minimization;Testing;Convergence;Measurement;Search problems","convergence;genetic algorithms;Pareto optimisation;program testing","diversity measure;multiobjective test case selection;multiobjective optimization problem;conflicting goal satisfaction;code coverage;computational cost;asymmetric distance preserving;multiobjective Pareto efficient genetic algorithm;SIR benchmark;nondominated solution;convergence speed;software testing","","14","","20","","2 Jul 2012","","","IEEE","IEEE Conferences"
"Exploring Test Suite Diversification and Code Coverage in Multi-Objective Test Case Selection","D. Mondal; H. Hemmati; S. Durocher","Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada; Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada; Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada","2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)","7 May 2015","2015","","","1","10","Test case selection is a classic testing technique to choose a subset of existing test cases for execution, due to the limited budget and tight deadlines. While `code coverage' is the state of practice among test case selection heuristics, recent literature has shown that `test case diversity' is also a very promising approach. In this paper, we first compare these two heuristics for test case selection in several real-world case studies (Apache Ant, Derby, JBoss, NanoXML and Math). The results show that neither of the two techniques completely dominates the other, but they can potentially be complementary. Therefore, we next propose a novel approach that maximizes both code coverage and diversity among the selected test cases using NSGA-II multi- objective optimization, and the results show a significant improvement in fault detection rate. Specifically, sometimes this novel approach detects up to 16\%(Ant), 10\%(JBoss), and 14\% (Math) more faults compared to either of coverage or diversity-based approaches, when the testing budget is less than 20\% of the entire test suite execution cost.","2159-4848","978-1-4799-7125-1","10.1109/ICST.2015.7102588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102588","","Optimization;Testing;Fault detection;Linear programming;Shape;Diversity reception;Hamming distance","genetic algorithms;program testing;software fault tolerance","test suite diversification;multiobjective test case selection;testing technique;code coverage;test case selection heuristics;test case diversity;Apache Ant;Derby;JBoss;NanoXML;Math;code diversity;NSGA-II multiobjective optimization;fault detection rate;testing budget;test suite execution cost;genetic algorithm","","31","","29","","7 May 2015","","","IEEE","IEEE Conferences"
"Frenetic at the SBST 2021 Tool Competition","E. Castellano; A. Cetinkaya; C. H. Thanh; S. Klikovits; X. Zhang; P. Arcaini","National Institute of Informatics,Tokyo,Japan; National Institute of Informatics,Tokyo,Japan; National Institute of Informatics,Tokyo,Japan; National Institute of Informatics,Tokyo,Japan; National Institute of Informatics,Tokyo,Japan; National Institute of Informatics,Tokyo,Japan","2021 IEEE/ACM 14th International Workshop on Search-Based Software Testing (SBST)","13 Jul 2021","2021","","","36","37","Frenetic is a genetic approach that leverages a curvature-based road representation. Given an autonomous driving agent, the goal of Frenetic is to generate roads where the agent fails to stay within its lane. In other words, Frenetic tries to minimize the “out of bound distance”, which is the distance between the car and either edge of the lane if the car is within the lane, and proceeds to negative values once the car drives off. This work resembles classic aspects of genetic algorithms such as mutations and crossover, but introduces some nuances aiming at improving diversity of the generated roads.","","978-1-6654-4571-9","10.1109/SBST52555.2021.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476234","","Software testing;Roads;Conferences;Tools;Drives;Genetics;Automobiles","automatic testing;driver information systems;genetic algorithms;Java;program testing;road traffic;road vehicles","SBST 2021 tool competition;Frenetic;genetic approach;curvature-based road representation;autonomous driving agent;lane;bound distance;car drives;genetic algorithms;generated roads","","2","","3","","13 Jul 2021","","","IEEE","IEEE Conferences"
"Dynamic white-box software testing using a recursive hybrid evolutionary strategy/genetic algorithm","A. Panchapakesan; R. Abielmona; E. Petriu","School of EECS, University of Ottawa, Canada; Research & Engineering, Larus Technologies Corporation, Ottawa, Canada; School of EECS, University of Ottawa, Canada","2013 IEEE Congress on Evolutionary Computation","15 Jul 2013","2013","","","2525","2532","Software testing is an important and time consuming part of the software development cycle. While automated testing frameworks do help in reducing the amount of programmer time that testing requires, the onus is still upon the programmer to provide such a framework with the inputs on which the software must be tested. This requires static analysis of the source code, which is more effective when performed as a peer review exercise and is highly dependent on the skills of the programmers performing the analysis. Thus, it demands the allocation of precious time of highly skilled programmers. An algorithm that automatically generates inputs to satisfy test coverage criteria for the software being tested would therefore be valuable, as it would imply that the programmer no longer needs to analyze code to generate the relevant test cases. This paper explores a hybrid evolutionary strategy with an evolutionary algorithm to discover such test case synthesis, in an improvement over previous methods which overly focus their search without maintaining the diversity required to cover the entire search space efficiently.","1941-0026","978-1-4799-0454-9","10.1109/CEC.2013.6557873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6557873","Software testing;black-box testing;white-box testing;static white-box testing;dynamic white-box testing;evolutionary algorithm;genetic algorithm;evolutionary strategy;control flow graph","Testing;Biological cells;Sociology;Statistics;Genetic algorithms;Software;Evolutionary computation","automatic test software;flow graphs;program diagnostics;program testing;search problems;source coding","dynamic white-box software testing;recursive hybrid evolutionary strategy;genetic algorithm;software development cycle;automated testing frameworks;source code;static analysis;peer review exercise;highly skilled programmers;evolutionary algorithm;search space","","1","","14","","15 Jul 2013","","","IEEE","IEEE Conferences"
"DAC: Distributed Asynchronous Cooperation for Wireless Relay Networks","X. Zhang; K. G. Shin","Dept. of Electr. Eng. & Comput. Sci., Univ. of Michigan, Ann Arbor, MI, USA; Dept. of Electr. Eng. & Comput. Sci., Univ. of Michigan, Ann Arbor, MI, USA","2010 Proceedings IEEE INFOCOM","6 May 2010","2010","","","1","9","Cooperative relay is a communication paradigm that aims to realize the capacity of multi-antenna arrays in a distributed manner. However, the symbol-level synchronization requirement among distributed relays limits its use in practice. We propose to circumvent this barrier with a cross-layer protocol called Distributed Asynchronous Cooperation (DAC). With DAC, multiple relays can schedule concurrent transmissions with packet-level (hence coarse) synchronization. The receiver then extracts multiple versions of each relayed packet via a collision-resolution algorithm, thus realizing the diversity gain of cooperative communication. We demonstrate the feasibility of DAC by prototyping and testing it on the GNURadio/USRP software radio platform. To explore its relevance at the network level, we introduce a DAC-based MAC, and a generic approach to integrate the DAC MAC/PHY layer into a typical routing algorithm. Considering the use of DAC for multiple network flows, we analyze the fundamental tradeoff between the improvement in diversity gain and the reduction in multiplexing opportunities. DAC is shown to improve the throughput and delay performance of lossy networks with medium-level link quality. Our analytical results are also confirmed by network-level simulation in ns-2.","0743-166X","978-1-4244-5838-7","10.1109/INFCOM.2010.5461940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461940","","Relays;Diversity methods;Protocols;Receivers;Software prototyping;Software testing;Software radio;Physical layer;Routing;Throughput","access protocols;antenna arrays;diversity reception;radio receivers;software radio;telecommunication network routing;wireless channels","distributed asynchronous cooperation;wireless relay networks;cooperative relay;communication paradigm;multiantenna arrays;symbol-level synchronization;cross-layer protocol;packet-level synchronization;radio receiver;diversity gain;cooperative communication;GNURadio/USRP software radio platform;MAC protocol;DAC MAC/PHY layer;routing algorithm;medium-level link quality;ns-2 network-level simulation","","17","","25","","6 May 2010","","","IEEE","IEEE Conferences"
"Automated Test Suite Generation for Time-Continuous Simulink Models","R. Matinnejad; S. Nejati; L. C. Briand; T. Bruckmann","SnT Centre, Univ. of Luxembourg, Luxembourg, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg, Luxembourg; Delphi Automotive Syst., Luxembourg","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","3 Apr 2017","2016","","","595","606","All engineering disciplines are founded and rely on models, although they may differ on purposes and usages of modeling. Interdisciplinary domains such as Cyber Physical Systems (CPSs) seek approaches that incorporate different modeling needs and usages. Specifically, the Simulink modeling platform greatly appeals to CPS engineers due to its seamless support for simulation and code generation. In this paper, we propose a test generation approach that is applicable to Simulink models built for both purposes of simulation and code generation. We define test inputs and outputs as signals that capture evolution of values over time. Our test generation approach is implemented as a meta-heuristic search algorithm and is guided to produce test outputs with diverse shapes according to our proposed notion of diversity. Our evaluation, performed on industrial and public domain models, demonstrates that: (1) In contrast to the existing tools for testing Simulink models that are only applicable to a subset of code generation models, our approach is applicable to both code generation and simulation Simulink models. (2) Our new notion of diversity for output signals outperforms random baseline testing and an existing notion of signal diversity in revealing faults in Simulink models. (3) The fault revealing ability of our test generation approach outperforms that of the Simulink Design Verifier, the only testing toolbox for Simulink.","1558-1225","978-1-4503-3900-1","10.1145/2884781.2884797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886937","Simulink models;Software testing;Time-continuous behaviors;Search-based software testing;Output diversity;Signal features;Structural coverage;Simulink Design Verifier (SLDV)","Software packages;Computational modeling;Fuels;Testing;Mathematical model;Shape","automatic testing;program compilers;program testing;search problems","automated test suite generation;time-continuous Simulink models;code generation;test inputs;test outputs;meta-heuristic search algorithm;industrial domain models;public domain models;simulation Simulink models;signal diversity;fault revealing ability","","17","","61","","3 Apr 2017","","","IEEE","IEEE Conferences"
"Research on an autonomous and controllable portable universal interface test platform","Y. Xu; B. Liu; X. Wang; H. Zhang; Z. Zhang","Jiangsu Automation Research Institute,Lianyungang,Jiangsu,China; Jiangsu Automation Research Institute,Lianyungang,Jiangsu,China; Jiangsu Automation Research Institute,Lianyungang,Jiangsu,China; Jiangsu Automation Research Institute,Lianyungang,Jiangsu,China; Jiangsu Automation Research Institute,Lianyungang,Jiangsu,China","2021 3rd International Conference on Industrial Artificial Intelligence (IAI)","30 Nov 2021","2021","","","1","5","Industrial software testing including software development and debugging depends on the external input interface. The development, debugging and adaptation of interface software simulation consumes a lot of time. The process of software evaluation and self-test lack a portable general software testing equipment suitable for the industrial field, in order to greatly improve the testing efficiency, test integrity and adequacy. Therefore, it is urgent for the general interface generation platform to be transformed into high performance such as hardware, distributed, hardware interface adaptation, test task load and high real-time. In this paper, the overall design framework of portable general software test equipment is carried out, which includes the design and software development of the execution host, the software transformation of general control host and other research contents. At the same time, a portable general software testing equipment for complex industrial system software and multiple interfaces is developed. This platform can satisfy the diversity of complex industrial software system interfaces and the real-time requirements of special systems. It is expected to further promote the development of interface testing automation.","","978-1-6654-3517-8","10.1109/IAI53119.2021.9619437","Nature; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619437","","Software testing;Debugging;Tools;Software systems;Software;Real-time systems;Hardware","program debugging;program testing;software engineering;user interfaces","interface software simulation;software evaluation;self-test;portable general software testing equipment;testing efficiency;test integrity;general interface generation platform;hardware interface adaptation;test task load;portable general software test equipment;software transformation;complex industrial software system interfaces;interface testing automation;autonomous interface test platform;controllable portable universal interface test platform;industrial software testing;external input interface;debugging;software development","","","","10","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Efficient and Effective Generation of Test Cases for Pedestrian Detection - Search-based Software Testing of Baidu Apollo in SVL","H. Ebadi; M. H. Moghadam; M. Borg; G. Gay; A. Fontes; K. Socha","Infotiv AB,Gothenburg,Sweden; RISE Research Institutes of Sweden,Västerås,Sweden; RISE Research Institutes of Sweden,Lund,Sweden; Chalmers and the University of Gothenburg,Gothenburg,Sweden; Chalmers and the University of Gothenburg,Gothenburg,Sweden; RISE Research Institutes of Sweden,Lund,Sweden","2021 IEEE International Conference on Artificial Intelligence Testing (AITest)","14 Oct 2021","2021","","","103","110","With the growing capabilities of autonomous vehicles, there is a higher demand for sophisticated and pragmatic quality assurance approaches for machine learning-enabled systems in the automotive AI context. The use of simulation-based prototyping platforms provides the possibility for early-stage testing, enabling inexpensive testing and the ability to capture critical corner-case test scenarios. Simulation-based testing properly complements conventional on-road testing. However, due to the large space of test input parameters in these systems, the efficient generation of effective test scenarios leading to the unveiling of failures is a challenge. This paper presents a study on testing pedestrian detection and emergency braking system of the Baidu Apollo autonomous driving platform within the SVL simulator. We propose an evolutionary automated test generation technique that generates failure-revealing scenarios for Apollo in the SVL environment. Our approach models the input space using a generic and flexible data structure and benefits a multi-criteria safety-based heuristic for the objective function targeted for optimization. This paper presents the results of our proposed test generation technique in the 2021 IEEE Autonomous Driving AI Test Challenge. In order to demonstrate the efficiency and effectiveness of our approach, we also report the results from a baseline random generation technique. Our evaluation shows that the proposed evolutionary test case generator is more effective at generating failure-revealing test cases and provides higher diversity between the generated failures than the random baseline.","","978-1-6654-3481-2","10.1109/AITEST52744.2021.00030","ECSEL Joint Undertaking(grant numbers:876852); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564347","Search-Based Test Generation;Evolutionary Algorithm;Advanced Driver Assistance Systems;Pedestrian Detection;Automotive Simulators","Software testing;Quality assurance;Web and internet services;Software algorithms;Test pattern generators;Artificial intelligence;Autonomous vehicles","data structures;evolutionary computation;learning (artificial intelligence);program testing","software testing;growing capabilities;autonomous vehicles;higher demand;sophisticated quality assurance approaches;pragmatic quality assurance approaches;machine learning-enabled systems;automotive AI context;simulation-based;early-stage testing;inexpensive testing;critical corner-case test scenarios;on-road testing;test input parameters;effective test scenarios;testing pedestrian detection;Baidu Apollo autonomous driving platform;SVL simulator;evolutionary automated test generation technique;failure-revealing scenarios;SVL environment;approach models;flexible data structure;multicriteria safety-based;2021 IEEE Autonomous Driving AI Test Challenge;baseline random generation technique;evolutionary test case generator;failure-revealing test cases;generated failures","","","","24","","14 Oct 2021","","","IEEE","IEEE Conferences"
"SimCoTest: A Test Suite Generation Tool for Simulink/Stateflow Controllers","R. Matinnejad; S. Nejati; L. C. Briand; T. Bruckmann","SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; Delphi Automotive Syst., Luxembourg, Luxembourg","2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)","23 Mar 2017","2016","","","585","588","We present SimCoTest, a tool to generate small test suites with high fault revealing ability for Simulink/Stateflow controllers. SimCoTest uses meta-heuristic search to (1) maximize the likelihood of presence of specific failure patterns in output signals (failure-based test generation), and to (2) maximize diversity of output signal shapes (output diversity test generation). SimCoTest has been evaluated on industrial Simulink models and has been systematically compared with Simuilnk Design Verifier (SLDV), an alternative commercial Simulink testing tool. Our results show that the fault revealing ability of SimCoTest outperforms that of SLDV. Further, in contrast to SLDV, SimCoTest is applicable to Simulink/Stateflow models in their entirety. A video describing the main features of SimCoTest is available at: https://youtu.be/YnXgveiGXEA.","","978-1-4503-4205-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883346","Simulink/Stateflow models;Software testing;Search-based software testing;Output diversity;Failure-based test generation;Simulink Design Verifier (SLDV)","Software packages;Mathematical model;Computational modeling;Testing;Data models;Adaptation models;Shape","optimisation;program testing;search problems;software tools","SimCoTest;test suite generation tool;Simulink/stateflow controllers;high fault revealing ability;metaheuristic search;specific failure pattern presence maximization;failure-based test generation;diversity maximization;industrial Simulink models;Simuilnk design verifier;SLDV;Simulink testing tool","","","","14","","23 Mar 2017","","","IEEE","IEEE Conferences"
"Validation, verification, and testing: diversity rules","B. Kitchenham; S. Linkman","Keele Univ., UK; NA","IEEE Software","6 Aug 2002","1998","15","4","46","49","Many software project managers try to decide whether to enhance reliability by performing detailed inspections or by doing execution-based testing using operational profiles. The authors regard this as a false choice. Operational-profile-based testing is an important method, but it is not a simple, cost-effective panacea. Instead, they suggest a better approach: a diverse validation, verification, and testing strategy that includes inspections and execution-based testing. Such an approach addresses the more appropriate question of what selection of W and T techniques should a project employ to achieve the functionality and quality that the product requires?.","1937-4194","","10.1109/52.687944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=687944","","System testing;Software testing;Software systems;Aircraft;Printers;Research and development;Boundary conditions;Reliability engineering","software development management;project management;software reliability;program testing;program verification;software quality","verification;validation;software project management;reliability;inspections;execution-based testing;quality;functionality","","3","","","IEEE","6 Aug 2002","","","IEEE","IEEE Magazines"
"Diversity of interaction in a quality assurance course","M. Ardis; C. Dugas","Dept. of Comput. Sci. & Software Eng., Rose-Hulman Inst. of Technol., Terre Haute, IN, USA; NA","Proceedings Frontiers in Education 35th Annual Conference","3 Apr 2006","2005","","","F1G","13","All software engineering courses face a daunting task: how to recreate within the classroom the environment of software engineering as it is practiced. There are three major difficulties to overcome: providing the cultural environment of professional software engineering, providing opportunities for learning by observation and imitation, and providing opportunities for constructive feedback from teammates. Each of these difficulties can be addressed, but some creativity may be required to solve them within the traditional classroom setting","2377-634X","0-7803-9077-6","10.1109/FIE.2005.1612028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1612028","Quality assurance;situated learning;software engineering;usability testing;Vygotsky","Quality assurance;Software engineering;Software quality;Application software;Software testing;Automatic testing;System testing;Computer science;Software design;Software performance","educational courses;quality assurance;software quality","quality assurance course;software engineering courses;professional software engineering","","","","5","","3 Apr 2006","","","IEEE","IEEE Conferences"
"Real-world design diversity: a case study on cost","K. Kanoun",LAAS,"IEEE Software","7 Aug 2002","2001","18","4","29","33","","1937-4194","","10.1109/MS.2001.936214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=936214","","Computer aided software engineering;Costs;System testing;Software testing;Software design;Programming;Formal languages;Assembly;Performance evaluation;Process design","","","","6","","15","","7 Aug 2002","","","IEEE","IEEE Magazines"
"Metamorphic relations to improve the test accuracy of Multi Precision Arithmetic software applications","C. Aruna; R. S. R. Prasad","Department of Computer Science and Engineering, KKR & KSR Institute of Technology and Sciences, Guntur, Andhra Pradesh, India; Department of CSE, Acharya Nagarjuna University, Guntur, Andhra Pradesh, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","1 Dec 2014","2014","","","2244","2248","Recent advances in computing technologies are increasing the expectations of high accuracy and reliability from sophisticated arithmetic programs. Multi Precision Arithmetic (MPA) plays a vital role in majority of scientific applications, where the accuracy levels are more considerable and even a small mistake may misguide the downstream experimental results. Normal testing strategies rely on test oracles to predict the expected output to compare with target output. Testing of MPA programs is a crucial work with normal testing strategies, due to the complexity of generating oracles to verify the correctness of test outputs. In this paper we propose a novel software testing technique called Metamorphic Testing (MT), to test the non-testable MPA programs with the help of Metamorphic Relations (MRs) to alleviate the oracle problem.MT uses the data diversity technique to generate the follow-up test cases based on the existed successful test cases, which are low cost, scalable, efficient and leads to ‘N-Version Programming’. Experimental results are showing that our approach is identifying the hidden errors and improving the testing accuracy by finding more mutants.","","978-1-4799-3080-7","10.1109/ICACCI.2014.6968586","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968586","Software Testing;Metamorphic Testing;Metamorphic relations;Follow-up test cases;Multi Precision Arithmetic","Accuracy;Software;Software testing;Complexity theory;Programming;Standards","program testing;software quality;software reliability","software reliability;data diversity technique;nontestable MPA programs;oracles;N-version programming;metamorphic testing;sophisticated arithmetic programs;multiprecision arithmetic;software testing;metamorphic relations","","2","","19","","1 Dec 2014","","","IEEE","IEEE Conferences"
"Weaving Context Sensitivity into Test Suite Construction","H. Wang; W. K. Chan","Dept. of Comput. Sci., Univ. of Hong Kong, Hong Kong, China; Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China","2009 IEEE/ACM International Conference on Automated Software Engineering","18 Mar 2010","2009","","","610","614","Context-aware applications capture environmental changes as contexts and self-adapt their behaviors dynamically. Existing testing research has not explored context evolutions or their patterns inherent to individual test cases when constructing test suites. We propose the notation of context diversity as a metric to measure how many changes in contextual values of individual test cases. In this paper, we discuss how this notion can be incorporated in a test case generation process by pairing it with coverage-based test data selection criteria.","1938-4300","978-1-4244-5259-0","10.1109/ASE.2009.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5431725","context diversity;software testing;context-aware programe","Weaving;Software testing;Computer science;Application software;Software engineering;Automatic testing;Middleware;Physics computing;Working environment noise;Programming profession","program testing;ubiquitous computing","context sensitivity weaving;test suite construction;context-aware applications;context diversity;test case generation process;coverage-based test data selection criteria","","12","","15","","18 Mar 2010","","","IEEE","IEEE Conferences"
"Effectively Sampling Higher Order Mutants Using Causal Effect","S. Oh; S. Lee; S. Yoo","School of Computing KAIST,Daejeon,Republic of Korea; School of Computing KAIST,Daejeon,Republic of Korea; School of Computing KAIST,Daejeon,Republic of Korea","2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","28 May 2021","2021","","","19","24","Higher Order Mutation (HOM) has been proposed to avoid equivalent mutants and improve the scalability of mutation testing, but generating useful HOMs remain an expensive search problem on its own. We propose a new approach to generate Strongly Subsuming Higher Order Mutants (SSHOM) using a recently introduced Causal Program Dependence Analysis (CPDA). CPDA itself is based on program mutation, and provides quantitative estimation of how often a change of the value of a program element will cause a value change of another program element. Our SSHOM generation approach chooses pairs of program elements using heuristics based on CPDA analysis, performs First Order Mutation to the chosen pairs, and generates an HOM by combining two FOMs.","","978-1-6654-4456-9","10.1109/ICSTW52544.2021.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440150","higher order mutant;mutation testing;causal inference;causal program dependence analysis","Software testing;Measurement;Conferences;Scalability;Diversity reception;Estimation;Benchmark testing","program testing;search problems","mutation testing;expensive search problem;program mutation;program element;value change;SSHOM generation approach;CPDA analysis;HOM;causal effect;higher order mutation;equivalent mutants;higher order mutant sampling;first order mutation;causal program dependence analysis;strongly subsuming higher order mutants;quantitative estimation;heuristics","","","","12","","28 May 2021","","","IEEE","IEEE Conferences"
"Generation of All-Paths Unit Test with Function Calls","P. Mouy; B. Marre; N. Williams; P. Le Gall","CEA/LIST, LSL, Gif-sur-Yvette; CEA/LIST, LSL, Gif-sur-Yvette; CEA/LIST, LSL, Gif-sur-Yvette; NA","2008 1st International Conference on Software Testing, Verification, and Validation","6 Jun 2008","2008","","","32","41","Structural testing is usually restricted to unit tests and based on some clear definition of source code coverage. In particular, the all-paths criterion, which requires at least one test-case per feasible path of the function under test, is recognised as offering a high level of software reliability. This paper deals with the difficulties of using structural unit testing to test functions which call other functions. To limit the resulting combinatorial explosion in the number of paths, we choose to abstract the called functions by their specification. We incorporate the functional information on the called functions within the structural information on the function under test, given as a control flow graph (CFG). This representation combining functional and structural descriptions may be viewed as an extension of the classic CFG and allows us to characterise test selection criteria ensuring the coverage of the source code of the function under test. Two new criteria will be proposed. The first criterion corresponds to the coverage of all the paths of this new representation, including all the paths arising from the functional description of the called functions. The second criterion covers all the feasible paths of the function under test only. We describe how we automate test-data generation with respect to such grey-box (combinations of black- box and white-box) test selection strategies, and we apply the resulting extension of our PathCrawler tool to examples coded in the C language.","2159-4848","978-0-7695-3127-4","10.1109/ICST.2008.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4539530","unit test;structural testing;all-paths unit test;automatic generation;constraint solving;unit test with function calls;testing C programs","Automatic testing;Software testing;Explosions;Software reliability;Flow graphs;Diversity reception;Embedded software;Linear approximation;Application software","formal specification;program control structures;program testing;software reliability;structured programming","all-paths unit test;function calls;all-paths criterion;software reliability;structural unit testing;control flow graph;test-data generation;grey-box test selection;PathCrawler;C language","","11","","23","","6 Jun 2008","","","IEEE","IEEE Conferences"
"Security testing and resilience","A. Rosa Cavalli",Montimaqe,"2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","28 May 2021","2021","","","1","1","Testing techniques are used to check if a given system implementation satisfies its specification or some predefined properties. In the last years an important research activity has taken place concerning the definition of testing techniques for security. Resilience has also become a crucial issue to guarantee the security and robustness of systems. Resilience is the capability of a system to continue to function properly with minimal degradation of performance, despite intrusions and attacks. In this lecture, we will present the main features of security testing and resilience. Regarding security testing, we will focus on model-based security testing, penetration testing and fuzzing testing. Regarding resilience, we will present a formal methodology that is based on three techniques: modelling, diversification and reflection. To implement this methodology, we first developed an approach of resilience that leverages model-level diversity. With this aim, we define a model of the system and derive more robust variants that can replace the first one in case of attack. To avoid manually deriving the variants and to increase the level of diversity, we propose a second complementary approach. The latter approach also consists in having different variants of ones services; but unlike the first, we have a single model and the implementations differ at the language, source code and binaries levels. To conclude we propose a formal Web service testing framework by incorporating these complementary mechanisms in order to take advantage of the benefits provided by each.","","978-1-6654-4456-9","10.1109/ICSTW52544.2021.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440162","Security testing;Penetration testing;Monitoring;Root Cause Analysis;Resilience","Root cause analysis;Runtime;Web services;Conferences;Safety;Security;System implementation","fuzzy set theory;program testing;security of data;Web services","testing techniques;system implementation;model-level diversity;formal Web service testing framework;fuzzing testing;penetration testing;model-based security testing","","","","0","","28 May 2021","","","IEEE","IEEE Conferences"
"Implementing design diversity to achieve fault tolerance","J. P. J. Kelly; T. I. McVittie; W. I. Yamamoto","Dept. of Electr. & Comput. Eng., California Univ., Santa Barbara, CA, USA; Dept. of Electr. & Comput. Eng., California Univ., Santa Barbara, CA, USA; Dept. of Electr. & Comput. Eng., California Univ., Santa Barbara, CA, USA","IEEE Software","6 Aug 2002","1991","8","4","61","71","The software faults that are particularly significant in a real-time concurrent system are identified, and the use of design diversity to prevent their occurrence is examined. Two approaches to enforced diversity, recovery-block software and multiversion software, are discussed. The recovery-block scheme combines N diverse software versions arranged (conceptually, at least) in sequential order, although the versions may also be organized to execute concurrently. The multiversion-software approach excuses all N versions in parallel, taking advantage of the redundant processors likely to be available in any system that must tolerate hardware and software faults. Although different, both approaches require sufficiently diverse development environments and that faults in the specification do not lead to similar errors.<<ETX>></ETX>","1937-4194","","10.1109/52.300038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=300038","","Fault tolerance;Real time systems;Hardware;Fault tolerant systems;Application software;Fault detection;Timing;Software testing;Life testing;System testing","fault tolerant computing;multiprocessing programs;multiprocessing systems;real-time systems;software reliability","fault tolerant computing;hardware faults;software faults;real-time concurrent system;design diversity;recovery-block software;multiversion software","","41","1","12","IEEE","6 Aug 2002","","","IEEE","IEEE Magazines"
"Using Program Data-State Diversity in Test Data Search","M. Alshraideh; L. Bottaci","The University Of Hull, UK; Dept. of Comput. Sci., Hull Univ.","Testing: Academic & Industrial Conference - Practice And Research Techniques (TAIC PART'06)","16 Oct 2006","2006","","","107","114","Search-based automatic software test data generation for structural testing depends on the instrumentation of the test goal to construct a many-valued function which is then optimised. The method encounters difficulty when the search is in a region in which the function is not able to discriminate between different candidate test cases because it returns a constant value. A typical example of this problem arises in the instrumentation of branch predicates that depend on the value of a boolean-valued (flag) variable. Existing transformation techniques can solve many cases of the problem but there are situations for which transformation techniques are inadequate. This paper presents a technique for directing the search when the function that instruments the test goal is not able to discriminate candidate test inputs. The new technique depends on introducing program data-state diversity as an additional search goal. The search is guided by a new evaluation (cost) function made up of two parts, one depends on the conventional instrumentation of the test goal, the other depends on the diversity of the data-states produced during execution of the program under test. The method is demonstrated for a number of example programs for which existing methods are inadequate.","","0-7695-2672-1","10.1109/TAIC-PART.2006.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1691676","","Automatic testing;Instruments;Cost function;Software testing;Computer science;Search methods;Genetic algorithms","data flow analysis;optimising compilers;program control structures;program testing;search problems","program data-state diversity;search-based automatic software test data generation;structural testing;many-valued function construction;branch predicates;Boolean-valued variable;program transformation technique","","1","","18","","16 Oct 2006","","","IEEE","IEEE Conferences"
"Alternatives to achieve software diversity in common channel signaling networks","N. L. Hung; A. R. Jacob; S. E. Makris","Bellcore, Raritan, NJ, USA; NA; NA","IEEE Journal on Selected Areas in Communications","6 Aug 2002","1994","12","3","533","538","With the increasing amount of software deployed in the common channel signaling networks (CCSNs) and its increasing complexity, software and its failure effects on the CCSNs have become a major concern. The software error contributing to the 1991 CCSN outages, which affected a large number of customer lines, has underscored the vulnerability of the CCSNs to software failures. The current mated pair signaling transfer point (STP) implementations in the CCSNs, with both STPs from the same supplier having the same software, make this architecture susceptible to common-cause software failure modes that might result in failures of both STPs simultaneously. To address these concerns, ways have been considered to achieve software diversity in the CCSNs by ensuring software failure mode independence among network nodes. Four potential alternatives are identified here: (i) multiple software developments in STPs; (ii) different software generics for backup; (iii) mixed-supplier STP pairs; and (iv) E-link sets to different supplier STPs. The advantages and disadvantages of these alternatives to ensure software diversity are examined in this paper and should be weighed by individual telecommunications network providers. concerns expressed in this paper are not exhaustive listings, but rather catalysts for further studies and discussions.<<ETX>></ETX>","1558-0008","","10.1109/49.285295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=285295","","Intelligent networks;Software testing;Fault tolerance;Software reliability;Jacobian matrices;Computer architecture;Programming;Telecommunication services;Software engineering;Guidelines","software reliability;telecommunication signalling;telecommunications computing;software quality;electrical engineering computing","common channel signaling networks;software error;software failures;signaling transfer point;STP;software diversity;network nodes;multiple software developments;software generics;telecommunications network providers;E-links;software reliability","","4","1","8","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Boundary Value Exploration for Software Analysis","F. Dobslaw; F. G. de Oliveira Neto; R. Feldt","Chalmers and the University of Gothenburg,Dept. of Computer Science and Engineering,Gothenburg,Sweden; Chalmers and the University of Gothenburg,Dept. of Computer Science and Engineering,Gothenburg,Sweden; Chalmers and the University of Gothenburg,Dept. of Computer Science and Engineering,Gothenburg,Sweden","2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)","4 Aug 2020","2020","","","346","353","For software to be reliable and resilient, it is widely accepted that tests must be created and maintained alongside the software itself. One safeguard from vulnerabilities and failures in code is to ensure correct behavior on the boundaries between subdomains of the input space. So-called boundary value analysis (BVA) and boundary value testing (BVT) techniques aim to exercise those boundaries and increase test effectiveness. However, the concepts of BVA and BVT themselves are not generally well defined, and it is not clear how to identify relevant sub-domains, and thus the boundaries delineating them, given a specification. This has limited adoption and hindered automation. We clarify BVA and BVT and introduce Boundary Value Exploration (BVE) to describe techniques that support them by helping to detect and identify boundary inputs. Additionally, we propose two concrete BVE techniques based on information-theoretic distance functions: (i) an algorithm for boundary detection and (ii) the usage of software visualization to explore the behavior of the software under test and identify its boundary behavior. As an initial evaluation, we apply these techniques on a much used and well-tested date handling library. Our results reveal questionable behavior at boundaries highlighted by our techniques. In conclusion, we argue that the boundary value exploration that our techniques enable is a step towards automated boundary value analysis and testing, which can foster their wider use and improve test effectiveness and efficiency.","","978-1-7281-1075-2","10.1109/ICSTW50294.2020.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155629","boundary value analysis;boundary value testing;test diversity","Software;Tools;Software testing;Visualization;Measurement;Heating systems","boundary-value problems;data visualisation;program testing","software visualization;boundary behavior;boundary value exploration;automated boundary value analysis;test effectiveness;software analysis;boundary inputs;boundary detection","","","","28","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Elimination by Linear Association: An Effective and Efficient Static Mirror Adaptive Random Testing","M. Omari; J. Chen; H. Ackah-Arthur; P. Kwaku Kudjo","School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China","IEEE Access","10 Jun 2019","2019","7","","71038","71060","Adaptive random testing (ART) is a software testing method which combines randomness with even distribution of test cases within the input domain of a program with the aim of improving the effectiveness of random testing (RT). It was established right from the onset that, ART is considerably less efficient compared to RT due to the overhead cost involved in filtering randomly generated test cases in order to achieve the even spread objective. Again, it has been observed that over-concentration on achieving better effectiveness at the expense of efficiency will make ART advantage over RT a superficial one. Besides, the ART is close to its theoretical bound in terms of effectiveness. Various algorithms have therefore emerged that seeks to minimize the efficiency deficit incurred by the ART. One of such strategies is mirror adaptive random testing (MART). Unfortunately, the MART's performance is generally unstable due to the lack of diversity in mirror generated test cases. The culprit has been identified as the mirroring functions used in place of complex ART computations. In this paper, we present elimination (E) by linear association (E-MART) as a solution to the problem of the MART that guarantees diversity in all dimension(s) of mirror test cases. By partitioning the source domain into multiple subdomains, we systematically isolate mirror partitions which are linearly associated with the source domains. The source domain is then iteratively partitioned whiles forgetting strategy is applied to select test cases. The simulations and experimental studies conducted indicate that the EMART has a more stable performance compared to the MART and compares favorably in terms of efficiency by reducing the quadratic time of the MART to linear.","2169-3536","","10.1109/ACCESS.2019.2919160","National Natural Science Foundation of China(grant numbers:U1836116,61502205,61872167); Graduate Research Innovation Project of Jiangsu Province(grant numbers:KYCX171807); Six Talent Peaks Project in Jiangsu Province(grant numbers:XYDXXJS-016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725470","Adaptive random testing;ART overhead challenge;software testing;mirror adaptive random testing","Subspace constraints;Mirrors;Software testing;Software;Partitioning algorithms;Power capacitors","program testing","linear association;software testing method;randomly generated test cases;ART advantage;efficiency deficit;MART;mirroring functions;mirror test cases;mirror partitions;ART computations;static mirror adaptive random testing","","3","","40","OAPA","29 May 2019","","","IEEE","IEEE Journals"
"Ubiquitous Application Testing on Cloud","A. I. Khan; A. Al-Badi","Department of Information Systems, Sultan Qaboos University, Muscat, Oman; Department of Information Systems, Sultan Qaboos University, Muscat, Oman","2018 International Conference on Smart Computing and Electronic Enterprise (ICSCEE)","18 Nov 2018","2018","","","1","4","Nowadays desktop-based application are continuously evolving into pervasive or ubiquitous applications. There are millions of ubiquitous applications developed and used, but the testing of these applications are very complex tasks due to diversity in ubiquitous devices. Cloud computing is the future which has brought cost reduction, improved business, and processes in organizations through minimum management efforts. Software testing is a process to make sure the software is of acceptable quality. The traditional testing processes are incompatible with the changing technology and environment such as in ubiquitous applications. The availability of 5G network has reduced the data streaming dependence on the network. Thus under the presence of 5 G network cloud based testing can be successfully carried out for ubiquitous applications. Therefore, this research proposes a testing process for ubiquitous applications on cloud consisting of five steps. The testing on cloud would include stress testing, performance testing, compatibility testing, functional testing, web browser testing, load testing, and latency testing etc. The research mainly relate to ubiquitous application testing.","","978-1-5386-4838-4","10.1109/ICSCEE.2018.8538412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8538412","cloud computing;cloud based testing;cloud testing;ubiquitous application;ubiquitous devices;pervasive application;mobile application","Cloud computing;Software;Business;Software testing;Browsers;Conferences","cloud computing;program testing;ubiquitous computing","ubiquitous applications;ubiquitous application testing;ubiquitous devices;software testing;desktop-based application;cloud computing;5G network","","2","","36","","18 Nov 2018","","","IEEE","IEEE Conferences"
"Data diversity: an approach to software fault tolerance","P. E. Ammann; J. C. Knight","Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA; Dept. of Comput. Sci., Virginia Univ., Charlottesville, VA, USA","IEEE Transactions on Computers","6 Aug 2002","1988","37","4","418","425","Data diversity is described, and the results of a pilot study are presented. The regions of the input space that cause failure for certain experimental programs are discussed, and data reexpression, the way in which alternate input data sets can be obtained, is examined. A description is given of the retry block which is the data-diverse equivalent of the recovery block, and a model of the retry block, together with some empirical results is presented. N-copy programming which is the data-diverse equivalent of N-version programming is considered, and a simple model and some empirical results are also given.<<ETX>></ETX>","1557-9956","","10.1109/12.2185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=2185","","Fault tolerance;System testing;Application software;Buildings;Computer applications;Software testing;Redundancy;Software algorithms;NASA;Computer science","fault tolerant computing","data diversity;software fault tolerance;data reexpression;retry block;N-copy programming;N-version programming","","220","6","12","","6 Aug 2002","","","IEEE","IEEE Journals"
"Evaluation and Comparison of Agent-Oriented Methodologies: A Software Engineering Viewpoint","K. Slhoub; M. Carvalho; F. Nembhard","College of Engineering and Sciences, Florida Institute of Technology, Melbourne, Florida, USA; College of Engineering and Sciences, Florida Institute of Technology, Melbourne, Florida, USA; College of Engineering and Sciences, Florida Institute of Technology, Melbourne, Florida, USA","2019 IEEE International Systems Conference (SysCon)","16 Sep 2019","2019","","","1","8","Numerous agent-oriented methodologies that offer a rich pool of resources to support developers of agent-based systems have been proposed. However, the use of existing methodologies in industrial settings is still limited due to the large volume of methodologies, diversity of covered scopes, ambiguity in concepts, and lack of maturity. This makes it difficult for agent technology practitioners to choose the appropriate methodology that best fits their given development context. To eliminate such agent-based development bottleneck, it is important to introduce suitable methods for evaluating, comparing, and classifying agent-oriented methodologies in order to leverage their usage among practitioners. Having systems to evaluate methodologies can effectively help developers better understand existing methodologies, realize their benefits, outline their pros and cons, and assist practitioners with selecting the best-fit methodology for a specific agent-based project. In response, this paper proposes a novel criteria-based evaluation that is influenced by software engineering practices to assess and compare agentoriented methodologies. The proposed evaluation is derived from the software engineering body of knowledge (SWEBOK) and provides a simplified method to assess the coverage degree of an agent-oriented methodology with respect to major software knowledge areas such as the requirements and testing phases. We demonstrate the applicability of the proposed evaluation by applying it to three agent-oriented methodologies (PASSI, MaSE, and Prometheus) in the software engineering requirements and testing phases.","2472-9647","978-1-5386-8396-5","10.1109/SYSCON.2019.8836962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836962","Agent-Oriented Methodologies;AgentOriented Software Engineering;Multi-Agent Systems;Software Requirements;Software Testing;SWEBOK;AOSE","Software engineering;Software;Knowledge engineering;Software testing;Tools;Diversity methods","multi-agent systems;object-oriented programming;program testing;project management;software agents;software development management;software engineering","agent-based systems;agent-based development bottleneck;agent-oriented methodologies;agent-based project;software engineering body of knowledge;SWEBOK;PASSI;MaSE;Prometheus;software engineering requirements;testing phases","","2","","39","","16 Sep 2019","","","IEEE","IEEE Conferences"
"ATE self test","A. M. Greenspan",NA,"IEEE Automatic Testing Conference.The Systems Readiness Technology Conference. Automatic Testing in the Next Decade and the 21st Century. Conference Record.","6 Aug 2002","1989","","","284","288","The ability of automatic test equipment (ATE) to introspectively assess its own well-being as well as assess the well-being of the UUTs (units under test) external to itself has long been understood to be a major advantage of offline ATE. The author argues that this inherent potential ATE system capability has not been used effectively. It has been treated as an afterthought and implemented by the most prosaic of methods. The results of this inadequate and inappropriate treatment of ATE self-test has been stagnation in improved MTBF of new ATE systems and regression in MTTR. The maintenance and training problems for new and modern ATE have been exacerbated rather than reduced. The author contends that this situation is a result of neglect and apathy on the part of ATE systems developers who have failed to be innovative or attentive to modern system techniques in the design of self-test for their ATE. The author proposes a five-phase ATE self-test approach that he hopes can resolve the above-mentioned problems. The phases are: pre-ATE planning; ATE planning; self-test implementation; self-test maturity and evaluation; and self-test feedback/archiving.<<ETX>></ETX>","","","10.1109/AUTEST.1989.81135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=81135","","Automatic testing;Software testing;System testing;Cost function;Footwear;Test equipment;Design for testability;Design optimization;Diversity reception;Trademarks","automatic test equipment;maintenance engineering","maintenance engineering;ATE self test;automatic test equipment;units under test;MTBF;MTTR;maintenance;training","","","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"An Improved Test Case Generation Method of Pair-Wise Testing","Q. Feng-an; J. Jian-hui","Tongji University, Shanghai 201804,China; Tongji University, Shanghai 201804,China","16th Asian Test Symposium (ATS 2007)","21 Nov 2007","2007","","","149","154","Pair-wise testing is a testing criterion based on specification, which requires that for each pair of parameters, every combination of their valid value should be covered by at least one test case in the test set. This paper presents an improved method based on AETG. Experimental results show that the size of test set produced by our method is relatively small. In addition, the method can be easily implemented.","2377-5386","978-0-7695-2890-8","10.1109/ATS.2007.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4388001","","System testing;Software testing;Laboratories;Embedded system;Embedded computing;Computer science education;Computer science;Educational technology;Diversity reception;Costs","automatic test pattern generation;logic testing","test case generation method;pair-wise testing;AETG","","4","","13","","21 Nov 2007","","","IEEE","IEEE Conferences"
"ALOHA with Collision Resolution: Physical layer description and software defined radio implementation","X. Liu; J. Kountouriotis; A. P. Petropulu; K. R. Dandekar","Electrical & Computer Engineering Department, Drexel University, Philadelphia PA, USA; Electrical & Computer Engineering Department, Drexel University, Philadelphia PA, USA; Electrical & Computer Engineering Department, Drexel University, Philadelphia PA, USA; Electrical & Computer Engineering Department, Drexel University, Philadelphia PA, USA","2010 IEEE International Conference on Acoustics, Speech and Signal Processing","28 Jun 2010","2010","","","3330","3333","A cross-layer scheme, namely ALOHA with Collision Resolution (ALOHA-CR), is proposed for high throughput wireless communications in a cellular scenario. Transmissions occur in a time-slotted ALOHA-type fashion but with an important difference: simultaneous transmissions of two users can be successful. The physical layer required to achieve this functionality is described and the statistical properties of the user delays are determined so that the probability of user separation is maximized. An implementation of ALOHA-CR on the Wireless Open Access Research Platform (WARP) testbed containing software defined radio nodes is discussed and experimental results are presented.","2379-190X","978-1-4244-4295-9","10.1109/ICASSP.2010.5496007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5496007","multi-user system;blind source separation;MIMO systems;collision resolution;software defined radio","Physical layer;Software radio;Delay;Throughput;Diversity reception;Software testing;System testing;Wireless networks;Bandwidth;Frequency diversity","multi-access systems;protocols;software radio","collision resolution;physical layer description;software defined radio implementation;high throughput wireless communication;cellular scenario;time slotted ALOHA;wireless open access research platform","","1","","11","","28 Jun 2010","","","IEEE","IEEE Conferences"
"ALOHA with Collision Resolution: MAC layer analysis and software defined radio implementation","J. Kountouriotis; X. Liu; A. P. Petropulu; K. R. Dandekar","Electrical & Computer Engineering Department, Drexel University, Philadelphia PA, USA; Electrical & Computer Engineering Department, Drexel University, Philadelphia PA, USA; Electrical & Computer Engineering Department, Drexel University, Philadelphia PA, USA; Electrical & Computer Engineering Department, Drexel University, Philadelphia PA, USA","2010 44th Annual Conference on Information Sciences and Systems (CISS)","13 May 2010","2010","","","1","6","A cross-layer scheme, namely ALOHA with Collision Resolution (ALOHA-CR), is proposed for high throughput wireless communications in a cellular scenario. Transmissions occur in a time-slotted ALOHA-type fashion but with an important difference: simultaneous transmissions of two users can be successful. In this paper, throughput and service delay analysis is provided and the analytical results are validated on the Wireless Open Access Research Platform (WARP) testbed containing software defined radio (SDR) testbed. Both analysis and experiments indicate that ALOHA-CR leads to significant increase in throughput and reduction of service delays.","","978-1-4244-7417-2","10.1109/CISS.2010.5464810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5464810","multi-user system;blind source separation;MIMO systems;collision resolution;software defined radio","Software radio;Throughput;Delay;Software testing;Road accidents;Wireless networks;Bandwidth;Frequency diversity;Diversity reception;Time division multiple access","cellular radio;software radio","ALOHA;collision resolution;MAC layer analysis;software defined radio implementation;high throughput wireless communications;cellular communications;wireless open access research platform","","1","","15","","13 May 2010","","","IEEE","IEEE Conferences"
"Automatic generation of software test data based on hybrid particle swarm genetic algorithm","Rui Ding; Xianbin Feng; Shuping Li; Hongbin Dong","Computer department, Mudanjiang Normal University, China; Computer department, Mudanjiang Normal University, China; Computer department, Mudanjiang Normal University, China; National Science Park, Harbin Engineering University, China","2012 IEEE Symposium on Electrical & Electronics Engineering (EEESYM)","6 Aug 2012","2012","","","670","673","A hybrid particle swarm genetic algorithm is purposed to apply in software testing using case automated generations. On the basis of classical genetic algorithm, the algorithm divided the population into “families”, influencing the convergence efficiency by crossover in family, keeping the diversity of the population by crossover between families; meanwhile, enhancing the speed of convergence by the PSO crossover (commixed the thought of PSO in genetic algorithm) According to the characteristics of software testing problems, we designed the corresponding fitness function and the encoding method. The results of data experiment were given to illustrate the effectiveness of the algorithm.","","978-1-4673-2365-9","10.1109/EEESym.2012.6258748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6258748","Genetic Algorithm;Particle Swarm Optimization;Software Testing;Case Automatically Generates","Reliability;Genetics","encoding;genetic algorithms;particle swarm optimisation;program testing","software test data automatic generation;hybrid particle swarm genetic algorithm;convergence efficiency;population diversity;PSO crossover;fitness function;encoding method","","5","","12","","6 Aug 2012","","","IEEE","IEEE Conferences"
"Adaptive Random Test Case Generation Based on Multi-objective Evolutionary Search","C. Mao; L. Wen; T. Y. Chen","Jiangxi University of Finance and Economics, China; Jiangxi University of Finance and Economics, China; Swinburne University of Technology, Australia","2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","9 Feb 2021","2020","","","46","53","Diversity is the key factor for test cases to detect program failures. Adaptive random testing (ART) is one of the effective methods to improve the diversity of test cases. Being an ART algorithm, the evolutionary adaptive random testing (eAR) only increases the distance between test cases to enhance its failure detection ability. This paper presents a new ART algorithm, MoesART, based on multi-objective evolutionary search. In this algorithm, in addition to the dispersion diversity, two other new diversities (or optimization objectives) are designed from the perspectives of the balance and proportionality of test cases. Then, the Pareto optimal solution returned by the NSGA-II framework is used as the next test case. In the experiments, the typical block failure pattern in the cases of two-dimensional and three-dimensional input domains is used to validate the effectiveness of the proposed MoesART algorithm. The experimental results show that MoesART exhibits better failure detection ability than both eAR and the fixed-sized-candidate-set ART (FSCS-ART), especially for the programs with three-dimensional input domain.","2324-9013","978-1-6654-0392-4","10.1109/TrustCom50675.2020.00020","NSFC(grant numbers:61762040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9343017","software testing;adaptive random testing;multi objective evolutionary search;test case;diversity","Privacy;Subspace constraints;Ear;Software;Power capacitors;Security;Testing","evolutionary computation;genetic algorithms;Pareto optimisation;program testing;search problems","multiobjective evolutionary search;diversities;failure detection ability;adaptive random test case generation;ART algorithm;evolutionary adaptive random testing","","","","35","","9 Feb 2021","","","IEEE","IEEE Conferences"
"A software radio testbed for two-transmitter two-receiver space-time coding OFDM wireless LAN","Weidong Xiang; T. Pratt; Xudong Wang","Georgia Inst. of Technol., Atlanta, GA, USA; Georgia Inst. of Technol., Atlanta, GA, USA; NA","IEEE Communications Magazine","14 Jun 2004","2004","42","6","S20","S28","A real-time testbed based on the technology of software radio is adopted to efficiently evaluate cutting-edge technologies in wireless communications, and thus becomes a valuable tool for both academic research and system prototyping. In this article we describe a software radio testbed, established in the software radio laboratory at Georgia Institute of Technology, used to implement a physical layer similar to IEEE 802.11a space-time coded orthogonal frequency-division multiplexing. The testbed consists of a 2 x 2 multiple-input multiple-output configuration with powerful digital signal processor chains, high-speed data exchange interfaces, and many advanced subsystem modules, such as high-speed high-resolution analog-to-digital and digital-to-analog converters, digital up/downconverters, and wideband RF transmit and receive front-ends with synchronous channels and programmable settings. The design methodology and implementation for key algorithms, such as time, sampling, and frequency synchronization, and channel estimation and compensation are discussed. The experimental data obtained from a typical indoor environment demonstrates that the prototype is capable of providing 30 Mb/s peak data rate, operating at the central frequency of 2.435 GHz with a spectral occupancy of 6.25 MHz. Spatial-temporal diversity gain associated with space-time coding is verified by the experimental results.","1558-1896","","10.1109/MCOM.2004.1304228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1304228","","Software radio;Software testing;OFDM;Wireless LAN;Space technology;Real time systems;System testing;Communications technology;Wireless communication;Software prototyping","software radio;telecommunication equipment testing;radio transmitters;radio receivers;space-time codes;OFDM modulation;modulation coding;wireless LAN;signal processing;analogue-digital conversion;digital-analogue conversion;channel estimation;indoor radio;diversity reception","software radio testbed;transmitter;receiver;space-time coding OFDM wireless LAN;wireless communications;orthogonal frequency-division multiplexing;multiple-input multiple-output configuration;digital signal processor chains;data exchange interfaces;analog-to-digital converters;digital-to-analog converters;digital downconverters;digital upconverters;wideband RF transmit front-end;wideband RF receive front-end;synchronous channels;programmable settings;frequency synchronization;channel estimation;indoor environment;peak data rate;spatial-temporal diversity gain;30 Mbit/s;2.435 GHz;6.25 MHz","","22","2","8","","14 Jun 2004","","","IEEE","IEEE Magazines"
"Topology Insensitive Location Determination Using Independent Estimates Through Semi-Directional Antennas","C. -l. Yang; S. Bagchi; W. J. Chappell","Electr. & Comput. Eng. Dept., Purdue Univ., West Lafayette, IN; NA; NA","IEEE Transactions on Antennas and Propagation","13 Nov 2006","2006","54","11","3458","3472","We demonstrate the effect of using multiple estimations from independent single wireless motes in order to decrease network topology dependence on location estimation in a wireless sensor network. A method of determining the location of a target by using multiple compact semi-directional antennas is shown to give an independent estimate of location from each sensor mote in a network, each estimate not relying on the data from neighboring motes as in the case of traditional triangulation. We begin by demonstrating a method of using angular diversity through multiple semi-directional antennas in order to ascertain the location of a target. The estimation of both range and angle is demonstrated in the presence of a noisy and/or faded channel. An efficient and fast algorithm on a wireless sensor mote is presented through a Taylor series expansion of the simulated antenna pattern. Furthermore, using the results from the location estimation from a single node, location determination in a realistic network is explored through both theory and simulation. The results indicate that our proposed algorithm depends significantly less on the topology (spatial arrangement) of the anchor nodes. While network planning for a variety of topologies of anchor nodes is shown to be necessary when using triangulation, our proposed algorithm is insensitive to the deployments of the anchor nodes. A testbed was created in order to experimentally demonstrate that the predictions are accurate even in triangulation-adverse topologies. The experimental testbed shows that a linear arrangement of closely spaced sensors can reduce the location error to one-fourth of the location error using triangulation","1558-2221","","10.1109/TAP.2006.884294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4012482","Directional antennas;location determination;sensor networks;topology;triangulation","Wireless sensor networks;Network topology;Application software;Testing;Computer applications;Protocols;Taylor series;Nanotechnology;Computerized monitoring;Condition monitoring","antenna radiation patterns;directive antennas;diversity reception;fading channels;radio direction-finding;telecommunication network planning;telecommunication network topology;wireless sensor networks","location estimation;wireless sensor network;target location;multiple compact semidirectional antennas;angular diversity;fading channel;Taylor series expansion;antenna pattern simulation;network planning;triangulation-adverse topology;linear arrangement","","3","","20","","13 Nov 2006","","","IEEE","IEEE Journals"
"Simulation for Robotics Test Automation: Developer Perspectives","A. Afzal; D. S. Katz; C. Le Goues; C. S. Timperley","Carnegie Mellon University,Pittsburgh,PA; Carnegie Mellon University,Pittsburgh,PA; Carnegie Mellon University,Pittsburgh,PA; Carnegie Mellon University,Pittsburgh,PA","2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)","24 May 2021","2021","","","263","274","Robotics simulation plays an important role in the design, development, and verification and validation of robotics systems. Simulation represents a potentially cheaper, safer, and more reliable alternative to the widely used practice of manual field testing, and introduces valuable opportunities for extensive test automation. The goal of this paper is to develop a principled understanding of the ways robotics developers use simulation in their testing processes and the challenges they face in doing so. This understanding can guide the improvement of simulators and testing techniques for modern robotics development.To that end, we conduct a survey of 82 robotics developers from a diversity of backgrounds, addressing the current capabilities and limits of simulation in practice. We find that simulation is used by 84% of our participants for testing, and that many participants want to use simulation as part of their test automation. Using qualitative and quantitative research methods, we identify 10 high-level challenges that impede developers from using simulation for manual and automated testing and in general. These challenges include the gap between simulation and reality, a lack of reproducibility, and considerable resource costs associated with simulation. Finally, we outline ways in which simulators can be improved for use as a means of verification and validation and ways that the software engineering community can contribute to these improvements.","2159-4848","978-1-7281-6836-4","10.1109/ICST49551.2021.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9438553","robotics simulation challenges;robotics testing;simulation testing;testing challenges;empirical study;practitioner survey","Software testing;Automation;Manuals;Tools;Reproducibility of results;Reliability;Robots","control engineering computing;mobile robots;program testing;software engineering","robotics test automation;robotics simulation;robotics systems;testing processes;testing techniques;modern robotics development;robotics developers;qualitative research methods;quantitative research methods;high-level challenges;automated testing","","1","","76","","24 May 2021","","","IEEE","IEEE Conferences"
"SBST Tool Competition 2021","S. Panichella; A. Gambi; F. Zampetti; V. Riccio","Zurich University of Applied Science (ZHAW),Zurich,Switzerland; University of Passau,Passau,Germany; University of Sannio,Benevento,Italy; Software Institute - USI,Lugano,Switzerland","2021 IEEE/ACM 14th International Workshop on Search-Based Software Testing (SBST)","13 Jul 2021","2021","","","20","27","We report on the organization, challenges, and results of the ninth edition of the Java Unit Testing Competition as well as the first edition of the Cyber-Physical Systems Testing Tool Competition. Java Unit Testing Competition. This year, five tools, Randoop, UtBot, Kex, Evosuite, and EvosuiteDSE, were executed on a benchmark with (i) new classes under test, selected from three open-source software projects, and (ii) the set of classes from three projects considered in the eighth edition. We relied on an improved Docker infrastructure to execute the tools and the subsequent coverage and mutation analysis. Given the high number of participants, we considered only two time budgets for test case generation: thirty seconds and two minutes. Cyber- Physical Systems Testing Tool Competition. Five tools, Deeper, Frenetic, GABExplore, GAB Exploit, and Swat, competed on testing self-driving car software by generating simulation-based tests using our new testing infrastructure. We considered two experimental settings to study test generators' transitory and asymptotic behaviors and evaluated the tools' test generation effectiveness and the exposed failures' diversity. This paper describes our methodology, the statistical analysis of the results together with the contestant tools, and the challenges faced while running the competition experiments.","","978-1-6654-4571-9","10.1109/SBST52555.2021.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476243","Competition;Tools;Unit Testing;Simulation based Testing;Java;Self driving car software;Automated Test Generation","Software testing;Java;System testing;Statistical analysis;Organizations;Tools;Cyber-physical systems","benchmark testing;Java;program testing;public domain software;statistical analysis","SBST Tool Competition;Java Unit Testing Competition;Cyber-Physical Systems;open-source software projects;test case generation;cyber-physical systems;self-driving car software;simulation-based tests;testing infrastructure;statistical analysis","","","","36","","13 Jul 2021","","","IEEE","IEEE Conferences"
"Test Data Generation Using Annealing Immune Genetic Algorithm","X. B. Tan; C. Longxin; X. Xiumei","Inst. of Comput., Foshan Vocational & Tech. Coll., Guangzhou, China; Inst. of Policy & Manage., Chinese Acad. of Sci., Beijing, China; Comput. & Inf. Technol., Beijing Jiaotong Univ., Beijing, China","2009 Fifth International Joint Conference on INC, IMS and IDC","13 Nov 2009","2009","","","344","348","With the development of software technology and the expansion of software project scale, software testing appears to be more crucial. And test data selection is one of the nodi during software structure testing because the suitability of test data may directly affect error detection. Notwithstanding existence of several methods to generate test data automatically, such an algorithm overcoming disadvantages of the existing methods in practice hasn't been brought out, that some errors still have to be detected by engineering experience. Therefore, this paper analyzes the characteristics and shortcomings of simple genetic algorithm, simulated annealing genetic algorithm as well as immune algorithm respectively. Aiming at solving the shortcomings in standard Genetic Algorithm on search efficiency, individual diversity and premature, the Annealing Immune Genetic Algorithm (AIGA) is presented as the core algorithm of test data generation by introducing the mechanism of reproduction rate adjustment of individual concentration of immune algorithm and annealing principium into genetic algorithm. Finally, AIGA mentioned above was applied and verified with a practical software testing example.","","978-1-4244-5209-5","10.1109/NCM.2009.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331701","Software testing;test data generation;genetic algorithm;expectation of reproduction","Genetic algorithms;Software testing;Automatic testing;Simulated annealing;Algorithm design and analysis;Computational modeling;Solid modeling;Electronic mail;Analytical models;Iterative algorithms","genetic algorithms;program testing;simulated annealing","test data generation;annealing immune genetic algorithm;software technology;test data selection;software structure testing;error detection;simulated annealing genetic algorithm;search efficiency;reproduction rate adjustment;annealing principium","","3","","10","","13 Nov 2009","","","IEEE","IEEE Conferences"
"Estimation of software diversity by fault simulation and failure searching","Luping Chen; J. May; G. Hughes","Dept. of Comput. Sci., Bristol Univ., UK; Dept. of Comput. Sci., Bristol Univ., UK; Dept. of Comput. Sci., Bristol Univ., UK","Proceedings 12th International Symposium on Software Reliability Engineering","7 Aug 2002","2001","","","122","131","An important problem for computer-based systems is providing fault tolerance for unknown (at the time of commencement of service) systematic design errors. Such design errors can have a long latency in normal operation and only become apparent under specific conditions associated with particular combinations of input and internal system states. The use of 'diverse' software versions remains a possible approach to prevent coincidental failure, but its potential value has never been quantified. This paper presents the application of data-flow and constant perturbation to simulate the introduction of faults or errors into programs and explores methods to establish the magnitudes and locations of the associated input space failure regions. Used together, these two techniques enable failure behaviour to be described in a quantitative way and provide a method to estimate the diversity of multi-version software. A simple case and a industrial software are studied to illustrate the applications of the approach.","1071-9458","0-7695-1306-9","10.1109/ISSRE.2001.989465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=989465","","Software testing;Computer errors;Software safety;Computational modeling;Computer simulation;Fault tolerant systems;Application software;Software quality;Software engineering;Fault tolerance","software fault tolerance;program testing;data flow analysis","fault tolerance;systematic design errors;latency;data-flow;failure behaviour;software engineering;fault injection;software fault injection","","1","","28","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Likelihood function-based modulation classification in bandwidth-constrained sensor networks","J. L. Xu; W. Su; M. Zhou","Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ 07102, USA; US Army RDECOM, Communications-Electronics RD&E Center, Fort Monmouth, NJ, 07703, USA; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ 07102, USA","2010 International Conference on Networking, Sensing and Control (ICNSC)","6 May 2010","2010","","","530","533","Automatic modulation classification with a single receiver has been intensively studied for two decades. Enhancing the successful classification probability is a bottleneck in this research field especially with weak signals in a non-cooperative communication environment. A sensor network with distributed classification techniques is expected to achieve technology breakthrough in providing spatial diversity and increasing the classification reliability. In this paper, we developed a distributed likelihood function-based classification method and extend the automatic modulation classification to sensor or radio networks. The classification methods performed in the sensors and primary node associated with theoretical discussion and numerical results are presented.","","978-1-4244-6453-1","10.1109/ICNSC.2010.5461606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461606","Modulation classification;modulation recognition;likelihood ratio test;sensor networks;cognitive radio;software-defined radio;distributed classification;wireless communication","Telecommunication network reliability;Cognitive radio;Intensity modulation;Bayesian methods;Digital modulation;Random variables;Amplitude estimation;Radio network;Software testing;Wireless sensor networks","maximum likelihood estimation;modulation;signal classification;wireless sensor networks","bandwidth-constrained sensor networks;modulation classification;classification probability;noncooperative communication environment;distributed classification;distributed likelihood function;spatial diversity;classification reliability","","9","","15","","6 May 2010","","","IEEE","IEEE Conferences"
"Cautious optimism for the future (codesign research)","P. A. Subrahmanyam","AT&T Bell Lab., Holmdel, NJ, USA","Computer","6 Aug 2002","1993","26","1","84","","The expectations, experimental results, and open issues relating to codesign research are discussed. Codesign refers to the integrated design of systems implemented using both hardware and software components. It is argued that the renewed interest in codesign is largely explained by the increasing diversity and complexity of applications employing embedded systems; the need to decrease the cost of designing and testing such systems; and advances in some key enabling technologies.<<ETX>></ETX>","1558-0814","","10.1109/2.179165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=179165","","Hardware;System testing;Software testing;Software performance;Computational modeling;Application software;Embedded system;Costs;Integrated circuit testing;Integrated circuit synthesis","concurrent engineering;integrated software","codesign research;integrated design of systems;hardware;software components;diversity;complexity","","12","","4","","6 Aug 2002","","","IEEE","IEEE Magazines"
"Implementation of a real-time multiple input multiple output channel estimator on the smart antenna software radio test system platform using the Xilinx Virtex 2 Pro Field Programmable Gate Array","P. J. Green; D. P. Taylor","Dept. of Electr. & Comput. Eng., Canterbury Univ.; NA","2006 IEEE International Conference on Field Programmable Technology","2 Jan 2007","2006","","","257","260","This paper describes the concept, architecture, development and demonstration of a real time, channel estimator system on a Xilinx Virtex 2 Pro field programmable gate array for a 4-transmit 4-receiver multiple input and multiple output (MIMO) wireless test platform. It is designed and developed for research into receiver diversity and MIMO wireless systems. Hardware, firmware, use of the Xilinx Core Generator Intellectual Property modules and experimental verification of the channel estimator are discussed","","0-7803-9728-2","10.1109/FPT.2006.270322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4042444","","Real time systems;MIMO;Software radio;Software testing;System testing;Antenna arrays;Field programmable gate arrays;Computer architecture;Hardware;Microprogramming","adaptive antenna arrays;antenna testing;channel estimation;field programmable gate arrays;MIMO systems","field programmable gate array;channel estimator;receiver diversity;MIMO wireless systems;Xilinx core generator;Xilinx Virtex 2 Pro;intellectual property","","2","","7","","2 Jan 2007","","","IEEE","IEEE Conferences"
"An Empirical Comparison of Combinatorial and Random Testing","L. S. Ghandehari; J. Czerwonka; Y. Lei; S. Shafiee; R. Kacker; R. Kuhn","Dept. of Comput. Sci. & Eng., Univ. of Texas at Arlington, Arlington, TX, USA; Microsoft Res., Redmond, WA, USA; Dept. of Comput. Sci. & Eng., Univ. of Texas at Arlington, Arlington, TX, USA; Dept. of Comput. Sci. & Eng., Univ. of Texas at Arlington, Arlington, TX, USA; Inf. Technol. Lab., Nat. Inst. of Stand. & Technol., Gaithersburg, MD, USA; Inf. Technol. Lab., Nat. Inst. of Stand. & Technol., Gaithersburg, MD, USA","2014 IEEE Seventh International Conference on Software Testing, Verification and Validation Workshops","5 Jun 2014","2014","","","68","77","Some conflicting results have been reported on the comparison between t-way combinatorial testing and random testing. In this paper, we report a new study that applies t-way and random testing to the Siemens suite. In particular, we investigate the stability of the two techniques. We measure both code coverage and fault detection effectiveness. Each program in the Siemens suite has a number of faulty versions. In addition, mutation faults are used to better evaluate fault detection effectiveness in terms of both number and diversity of faults. The experimental results show that in most cases, t-way testing performed as good as or better than random testing. There are few cases where random testing performed better, but with a very small margin. Overall, the differences between the two techniques are not as significant as one would have probably expected. We discuss the practical implications of the results. We believe that more studies are needed to better understand the comparison of the two techniques.","","978-1-4799-5790-3","10.1109/ICSTW.2014.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6825640","Combinatorial Testing;Random Testing;Software Testing","Testing;Fault detection;Schedules;Computational modeling;Measurement;Stability analysis;Standards","program testing;software fault tolerance","t-way combinatorial testing;random testing;Siemens suite;code coverage;fault detection effectiveness;faulty versions","","22","","22","","5 Jun 2014","","","IEEE","IEEE Conferences"
"An empirical study on testing and fault tolerance for software reliability engineering","M. R. Lyu; Zubin Huang; S. K. S. Sze; Xia Cai","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, China","14th International Symposium on Software Reliability Engineering, 2003. ISSRE 2003.","8 Dec 2003","2003","","","119","130","Software testing and software fault tolerance are two major techniques for developing reliable software systems, yet limited empirical data are available in the literature to evaluate their effectiveness. We conducted a major experiment to engage 34 programming teams to independently develop multiple software versions for an industry-scale critical flight application, and collected faults detected in these program versions. To evaluate the effectiveness of software testing and software fault tolerance, mutants were created by injecting real faults occurred in the development stage. The nature, manifestation, detection, and correlation of these faults were carefully investigated. The results show that coverage testing is generally an effective means to detecting software faults, but the effectiveness of testing coverage is not equivalent to that of mutation coverage, which is a more truthful indicator of testing quality. We also found that exact faults found among versions are very limited. This result supports software fault tolerance by design diversity as a creditable approach for software reliability engineering. Finally we conducted domain analysis approach for test case generation, and concluded that it is a promising technique for software testing purpose.","1071-9458","0-7695-2007-3","10.1109/ISSRE.2003.1251036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1251036","","Software testing;Fault tolerance;Software reliability;Reliability engineering;Fault detection;Aerospace engineering;Fault tolerant systems;Software systems;Computer industry;Application software","program testing;software fault tolerance;aerospace computing;software reliability;program diagnostics;fault diagnosis","software testing;software fault tolerance;software reliability engineering;software development;industry-scale critical flight application;fault detection;fault correlation;coverage testing;domain analysis;test case generation","","27","","36","","8 Dec 2003","","","IEEE","IEEE Conferences"
"Modified ACO to maintain diversity in regression test optimization","S. Kumar; P. Ranjan; R. Rajesh","Department of computer science, Central University of South Bihar, India; Department of computer science, Central University of South Bihar, India; Department of computer science, Central University of South Bihar, India","2016 3rd International Conference on Recent Advances in Information Technology (RAIT)","9 Jul 2016","2016","","","619","625","Regression testing is unavoidable maintenance activity that is performed several times in software development life cycle. Optimization of regression test case is required to minimize the test case (which will in-turn reduce the time and cost of testing) and to find the fault in early testing activity. The two widely used regression test case optimization techniques, namely, selection and prioritization are recently found to be integrated with different metaheuristic algorithms for fruitful regression test cases. Among the various meta-heuristic algorithms, Ant colony optimization (ACO) algorithm is most popularly used. ACO will try to find the smallest path out all the test cases and it is not sufficient because it will not cover all the test cases which are needed. In this paper we have proposed a modified ant colony optimization to solve test cases in huge search space. The modified algorithm selects the best test cases that find the maximum fault in minimum time.","","978-1-4799-8579-1","10.1109/RAIT.2016.7507970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7507970","Regresssion testing;Soft computing;Multi-objective optimization;Test case optimization;Nature Based Optimization","Optimization;Software;Ant colony optimization;Software algorithms;Software testing;Maintenance engineering","ant colony optimisation;program testing;regression analysis;search problems;software development management;software maintenance","ACO;maintenance activity;software development life cycle;regression test case optimization techniques;ant colony optimization;search space","","3","","24","","9 Jul 2016","","","IEEE","IEEE Conferences"
"A Novelty Search Approach for Automatic Test Data Generation","M. Boussaa; O. Barais; G. Sunyé; B. Baudry","Inria/IRISA, Rennes, France; Inria/IRISA, Rennes, France; Inria/IRISA, Rennes, France; Inria/IRISA, Rennes, France","2015 IEEE/ACM 8th International Workshop on Search-Based Software Testing","3 Aug 2015","2015","","","40","43","In search-based structural testing, metaheuristic search techniques have been frequently used to automate the test data generation. In Genetic Algorithms (GAs) for example, test data are rewarded on the basis of an objective function that represents generally the number of statements or branches covered. However, owing to the wide diversity of possible test data values, it is hard to find the set of test data that can satisfy a specific coverage criterion. In this paper, we introduce the use of Novelty Search (NS) algorithm to the test data generation problem based on statement-covered criteria. We believe that such approach to test data generation is attractive because it allows the exploration of the huge space of test data within the input domain. In this approach, we seek to explore the search space without regard to any objectives. In fact, instead of having a fitness-based selection, we select test cases based on a novelty score showing how different they are compared to all other solutions evaluated so far.","","978-1-4673-7079-0","10.1109/SBST.2015.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7173590","","Search problems;Testing;Java;Sociology;Statistics;Space exploration;Measurement","data handling;genetic algorithms;program testing","novelty search approach;automatic test data generation;metaheuristic search techniques;search based structural testing;genetic algorithms;GA;objective function;data values;novelty search algorithm;NS algorithm;data generation problem","","8","","11","","3 Aug 2015","","","IEEE","IEEE Conferences"
"The N-Version Approach to Fault-Tolerant Software","A. Avizienis","Department of Computer Science, University of California","IEEE Transactions on Software Engineering","18 Sep 2006","1985","SE-11","12","1491","1501","Evolution of the N-version software approach to the tolerance of design faults is reviewed. Principal requirements for the implementation of N-version software are summarized and the DEDIX distributed supervisor and testbed for the execution of N-version software is described. Goals of current research are presented and some potential benefits of the N-version approach are identified.","1939-3520","","10.1109/TSE.1985.231893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1701972","Design diversity;fault tolerance;multiple computation;N-version programming;N-version software;software reliability;tolerance of design faults","Fault tolerance;Circuit faults;Fault tolerant systems;Hardware;Application software;Humans;Computer science;Computer errors;Software testing;Software reliability","","Design diversity;fault tolerance;multiple computation;N-version programming;N-version software;software reliability;tolerance of design faults","","651","23","53","IEEE","18 Sep 2006","","","IEEE","IEEE Journals"
"A survey on the practices of mobile application testing","I. Santos; J. C. C. Filho; S. R. S. Souza","Institute of Mathematics and Computer Science (ICMC), University of São Paulo (USP),São Carlos,Brazil; Institute of Mathematics and Computer Science (ICMC), University of São Paulo (USP),São Carlos,Brazil; Institute of Mathematics and Computer Science (ICMC), University of São Paulo (USP),São Carlos,Brazil","2020 XLVI Latin American Computing Conference (CLEI)","28 Jun 2021","2020","","","232","241","Context: Mobile devices have become increasingly popular, and mobile applications should guarantee a very high level of reliability and quality. Mobile application testing needs to consider several unique requirements that distinguish it from conventional software testing. Objective: Our study aims to establish an overview of the testing practices conducted in mobile companies, to identify weaknesses that can be improved to make the testing activity more effective. Method: The survey questions were carefully designed using the Goal/Question/Metric method to provide relevant information to the questions raised in our study. Results and Conclusions: Our study outlines that native applications are more common. The testing level more performed is the system test and the positions that perform testing levels and objectives are described. Practices related to testing technique selection in the context of mobile applications are highlighted. In the context of this study, Cucumber and Selenium are the testing tools most used to automate testing activity. Some mobile testing characteristics were outlined to understand how the testing in mobile applications run on different devices, how testers deal with the diversity of operating systems that are constantly updated and whether tests are unified to testing a mobile app that runs in different platforms. Furthermore, we report the main challenges faced by testers during the validation of the mobile app.","","978-1-6654-1560-6","10.1109/CLEI52000.2020.00034","FAPESP (Sao Paulo Research Foundation)(grant numbers:2018/10183-9,2019/06937-0); CNPq(grant numbers:312922/2018-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458347","Survey;Mobile testing;Software testing practices;Software quality","Software testing;Operating systems;Companies;Tools;Mobile handsets;Mobile applications;Software reliability","mobile computing;program testing;software metrics","mobile application testing;mobile devices;mobile applications;testing practices;mobile companies;testing level;system test;testing levels;testing technique selection;testing tools;automate testing activity;mobile testing characteristics;mobile app","","","","21","","28 Jun 2021","","","IEEE","IEEE Conferences"
"Collaborative Testing of Web Services","H. Zhu; Y. Zhang","Oxford Brookes University, Oxford; The National University of Defense Technology, Changsha","IEEE Transactions on Services Computing","1 Mar 2012","2012","5","1","116","130","Software testers are confronted with great challenges in testing Web Services (WS) especially when integrating to services owned by other vendors. They must deal with the diversity of implementation techniques used by the other services and to meet a wide range of test requirements. However, they are in lack of software artifacts, the means of control over test executions and observation on the internal behavior of the other services. An automated testing technique must be developed to be capable of testing on-the-fly nonintrusively and nondisruptively. Addressing these problems, this paper proposes a framework of collaborative testing in which test tasks are completed through the collaboration of various test services that are registered, discovered, and invoked at runtime using the ontology of software testing STOWS. The composition of test services is realized by using test brokers, which are also test services but specialized in the coordination of other test services. The ontology can be extended and updated through an ontology management service so that it can support a wide open range of test activities, methods, techniques, and types of software artifacts. The paper presents a prototype implementation of the framework in semantic WS and demonstrates the feasibility of the framework by running examples of building a testing tool as a test service, developing a service for test executions of a WS, and composing existing test services for more complicated testing tasks. Experimental evaluation of the framework has also demonstrated its scalability.","1939-1374","","10.1109/TSC.2010.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674012","Software engineering;software testing;distributed/internet based software engineering tools and techniques;testing tools;ontology;web services;semantic web services;service composition.","Ontologies;Software;Semantics;Collaboration;Software testing;Insurance","groupware;program testing;Web services","collaborative testing;Web services;software testers;WS;test requirements;software artifacts;internal behavior;automated testing technique;STOWS;ontology management service","","34","","72","","23 Dec 2010","","","IEEE","IEEE Journals"
"Optimal Release Time for Software Systems","M. Jhaa; R. Jha","Citicorp Services India Limited,Pune,India; FIS Solutions (India) Pvt. Ltd.,Pune,India","2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)","23 Apr 2020","2020","","","1155","1160","Testing the lifecycle is a challenge when it comes to maintaining a high layer of software accuracy obtaining the software's optimal release time. The enterprise urgency to understand when to update and break trial to improve the software's reliability, maintaining the software market growth and decrease the price of research. Companies usually put their product on the market sooner, in order to reach the market. Software testing is a mechanism by which corporations update, Troubleshoot or upgrade their software when used as a debugging method, it guarantees optimum product release, increasing software stability while compressing the economic expense of testing. Today, its journey on market is dynamic due to distributed nature and the diversity of the software making patch an intrinsic testing element. A Sew is a chunk of software to repair or support a device program for fixing or improving it. An important issue within the software advanced preparation to complete when to prevent testing and deliver the software to the users. In this paper, the cost optimal release action, which decreases entire normal cost of program, will be addressed. Scientists have been working in the field to reduce entire testing cost, but so far, accuracy has not been studied in the system for optimal time scheduling. In this paper, we discuss accuracy, which is considerable aspect of quality of program. We therefore suggest reliability development, Design software testing to make the software system stable and cost-effective to fix testing cost issues, product delivery time, and acceptable reliability levels. Using real-life failed software dataset, the numeric illustration was implemented.","2575-7288","978-1-7281-5197-7","10.1109/ICACCS48705.2020.9074453","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074453","Testing;SRGM (Software reliability growth models);Reliability;Release failure data set;software cost","Software;Testing;Software reliability;Tools;Biological system modeling;Numerical models","program testing;scheduling;software reliability","software market growth;software stability;cost optimal release action;testing cost;optimal time scheduling;software testing;software system;software dataset;software systems;software accuracy;Sew","","","","17","","23 Apr 2020","","","IEEE","IEEE Conferences"
"DeepEvolution: A Search-Based Testing Approach for Deep Neural Networks","H. Ben Braiek; F. Khomh",Polytechnic Montreal; Polytechnic Montreal,"2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)","5 Dec 2019","2019","","","454","458","The increasing inclusion of Deep Learning (DL) models in safety-critical systems such as autonomous vehicles have led to the development of multiple model-based DL testing techniques. One common denominator of these testing techniques is the automated generation of test cases, e.g., new inputs transformed from the original training data with the aim to optimize some test adequacy criteria. So far, the effectiveness of these approaches has been hindered by their reliance on random fuzzing or transformations that do not always produce test cases with a good diversity. To overcome these limitations, we propose, DeepEvolution, a novel search-based approach for testing DL models that relies on metaheuristics to ensure a maximum diversity in generated test cases. We assess the effectiveness of DeepEvolution in testing computer-vision DL models and found that it significantly increases the neuronal coverage of generated test cases. Moreover, using DeepEvolution, we could successfully find several corner-case behaviors. Finally, DeepEvolution outperformed Tensorfuzz (a coverage-guided fuzzing tool developed at Google Brain) in detecting latent defects introduced during the quantization of the models. These results suggest that search-based approaches can help build effective testing tools for DL systems.","2576-3148","978-1-7281-3094-1","10.1109/ICSME.2019.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919189","Software Testing;Deep Learning;Computer Vision;Search Based Testing;Metamorphic Testing","Computational modeling;Neurons;Quantization (signal);Space exploration;Software testing;Software","learning (artificial intelligence);neural nets;program testing","multiple model-based;testing techniques;automated generation;test adequacy criteria;random fuzzing;DeepEvolution;search-based approach;generated test cases;corner-case behaviors;effective testing tools;deep neural networks;safety-critical systems;deep learning models","","2","","19","","5 Dec 2019","","","IEEE","IEEE Conferences"
"An empirical study on reliability modeling for diverse software systems","Xia Cai; M. R. Lyu","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China","15th International Symposium on Software Reliability Engineering","24 Jan 2005","2004","","","125","136","Reliability and fault correlation are two main concerns for design diversity, yet empirical data are limited in investigating these two. In previous work, we conducted a software project with real-world application for investigation on software testing and fault tolerance for design diversity. Mutants were generated by injecting one single real fault recorded in the software development phase to the final versions. In this paper, we perform more analysis and experiments on these mutants to evaluate and investigate the reliability features in diverse software systems. We apply our project data on two different reliability models and estimate the reliability bounds for evaluation purpose. We also parameterize fault correlations to predict the reliability of various combinations of versions, and compare three different fault-tolerant software architectures.","1071-9458","0-7695-2215-7","10.1109/ISSRE.2004.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383112","","Software systems;Fault tolerance;Application software;Reliability engineering;Software testing;Aerospace electronics;Computer science;Data engineering;Design engineering;Programming","software reliability;software architecture","software reliability modeling;fault correlation;software testing;fault tolerance","","3","","21","","24 Jan 2005","","","IEEE","IEEE Conferences"
"Implementation and Evaluation of Cooperative Communication Schemes in Software-Defined Radio Testbed","J. Zhang; J. Jia; Q. Zhang; E. M. K. Lo","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2010 Proceedings IEEE INFOCOM","6 May 2010","2010","","","1","9","Cooperative communication is a promising technique for future wireless networks, which significantly improves link capacity and reliability by leveraging broadcast nature of wireless medium and exploiting cooperative diversity. However, most of existing works investigate its performance theoretically or by simulation. It has been widely accepted that simulations often fail to faithfully capture many real-world radio signal propagation effects, which can be overcome through developing physical wireless network testbeds. In this work, we build a cooperative testbed based on GNU Radio and Universal Software Radio Peripheral (USRP) platform, which is a promising open-source software-defined radio system. Both single-relay cooperation and multi-relay cooperation can be supported in our testbed. Some key techniques are provided to solve the main challenges during the testbed development: e.g., maximum ratio combine in single-relay transmission and synchronized transmission among multiple relays. Extensive experiments are carried out in the testbed to evaluate performance of various cooperative communication schemes. The results show that cooperative transmission achieves significant performance enhancement in terms of link reliability and end-to-end throughput.","0743-166X","978-1-4244-5838-7","10.1109/INFCOM.2010.5461915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461915","","Software testing;Diversity reception;Relays;Wireless networks;MIMO;Software radio;Throughput;Analytical models;Physical layer;Field programmable gate arrays","software radio;telecommunication network reliability","cooperative communication;software defined radio testbed;GNU radio;universal software radio peripheral;cooperative transmission;link reliability;end-to-end throughput","","45","","20","","6 May 2010","","","IEEE","IEEE Conferences"
"System Testing of Timing Requirements Based on Use Cases and Timed Automata","C. Wang; F. Pastore; L. Briand","SNT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SNT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SNT, Univ. of Luxembourg, Luxembourg City, Luxembourg","2017 IEEE International Conference on Software Testing, Verification and Validation (ICST)","18 May 2017","2017","","","299","309","In the context of use-case centric development and requirements-driven testing, this paper addresses the problem of automatically deriving system test cases to verify timing requirements. Inspired by engineering practice in an automotive software development context, we rely on an analyzable form of use case specifications and augment such functional descriptions with timed automata, capturing timing requirements, following a methodology aiming at minimizing modeling overhead. We automate the generation of executable test cases using a test strategy based on maximizing test suite diversity and building over the UPPAAL model checker. Initial empirical results based on an industrial case study provide evidence of the effectiveness of the approach.","","978-1-5090-6031-3","10.1109/ICST.2017.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927984","Timing Requirements;System Testing;Use cases;Timed Automata","Automata;Software;Timing;Unified modeling language;Testing;Context;Clocks","automata theory;formal specification;program testing;program verification","system testing;timing requirements;timed automata;use-case centric development;requirements-driven testing;automotive software development;use case specifications;test suite diversity;UPPAAL model checker","","7","","33","","18 May 2017","","","IEEE","IEEE Conferences"
"Prioritizing Manual Test Cases in Traditional and Rapid Release Environments","H. Hemmati; Z. Fang; M. V. Mantyla","Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada; Sch. of Software Eng., Tongji Univ., Shanghai, China; Univ. of Oulu, Oulu, Finland","2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)","7 May 2015","2015","","","1","10","Test case prioritization is one of the most practically useful activities in testing, specially for large scale systems. The goal is ranking the existing test cases in a way that they detect faults as soon as possible, so that any partial execution of the test suite detects maximum number of defects for the given budget. Test prioritization becomes even more important when the test execution is time consuming, e.g., manual system tests vs. automated unit tests. Most existing test case prioritization techniques are based on code coverage, which requires access to source code. However, manual testing is mainly done in a black- box manner (manual testers do not have access to the source code). Therefore, in this paper, we first examine the existing test case prioritization techniques and modify them to be applicable on manual black-box system testing. We specifically study a coverage- based, a diversity-based, and a risk driven approach for test case prioritization. Our empirical study on four older releases of Mozilla Firefox shows that none of the techniques are strongly dominating the others in all releases. However, when we study nine more recent releases of Firefox, where the development has been moved from a traditional to a more agile and rapid release environment, we see a very signifiant difference (on average 65% effectiveness improvement) between the risk-driven approach and its alternatives. Our conclusion, based on one case study of 13 releases of an industrial system, is that test suites in rapid release environments, potentially, can be very effectively prioritized for execution, based on their historical riskiness; whereas the same conclusions do not hold in the traditional software development environments.","2159-4848","978-1-4799-7125-1","10.1109/ICST.2015.7102602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102602","","Testing;Manuals;Software;Context;Natural languages;Fault detection;Companies","online front-ends;program testing;software fault tolerance;source code (software)","manual test case prioritization;rapid release environments;large scale systems;fault detection;test execution;code coverage;source code;manual black-box system testing;coverage-based approach;diversity-based approach;risk driven approach;Mozilla Firefox;historical riskiness","","15","","34","","7 May 2015","","","IEEE","IEEE Conferences"
"A dynamic optimization strategy for evolutionary testing","Xiaoyuan Xie; Baowen Xu; Liang Shi; Changhai Nie; Yanxiang He","Dept. of Comput. Sci. & Eng., Southeast Univ., Nanjing, China; Dept. of Comput. Sci. & Eng., Southeast Univ., Nanjing, China; Dept. of Comput. Sci. & Eng., Southeast Univ., Nanjing, China; Dept. of Comput. Sci. & Eng., Southeast Univ., Nanjing, China; NA","12th Asia-Pacific Software Engineering Conference (APSEC'05)","20 Mar 2006","2005","","","8 pp.","","Evolutionary testing (ET) is an efficient technique of automated test case generation. ET uses a kind of metaheuristic search technique, genetic algorithm (GA), to convert the task of test case generation into an optimal problem. The configuration strategies of GA have notable influences upon the performance of ET. In this paper, represent a dynamic self-adaptation strategy for evolutionary structural testing. It monitors evolution process dynamically, detects the symptom of prematurity by analyzing the population, and adjusts the mutation possibility to recover the diversity of the population. The empirical results show that the strategy can greatly improve the performance of the ET in many cases. Besides, some valuable advices are provided for the configuration strategies of ET by the empirical study.","1530-1362","0-7695-2465-6","10.1109/APSEC.2005.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1607196","Software testing;evolutionary testing;structural testing;dynamic optimization","Automatic testing;Software testing;Evolution (biology);Computer science;Software engineering;Genetic algorithms;Genetic mutations;System testing;Delay;Laboratories","program testing;formal verification;genetic algorithms","dynamic optimization strategy;automated test case generation;metaheuristic search technique;genetic algorithm;evolutionary structural testing","","1","1","16","","20 Mar 2006","","","IEEE","IEEE Conferences"
"A Novel Mask-Coding Representation for Set Cover Problems with Applications in Test Suite Minimisation","S. Yoo","Centre for Res. on Search, King's Coll. London, London, UK","2nd International Symposium on Search Based Software Engineering","11 Nov 2010","2010","","","19","28","Multi-Objective Set Cover problem forms the basis of many optimisation problems in software testing because the concept of code coverage is based on the set theory. This paper presents Mask-Coding, a novel representation of solutions for set cover optimisation problems that explores the problem space rather than the solution space. The new representation is empirically evaluated with set cover problems formulated from real code coverage data. The results show that Mask-Coding representation can improve both the convergence and diversity of the Pareto-efficient solution set of the multi-objective set cover optimisation.","","978-1-4244-8341-9","10.1109/SSBSE.2010.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635169","set-cover representation;search-based software engineering;test suite minimisation","Optimization;Space exploration;Search problems;Convergence;Greedy algorithms;Redundancy;Software testing","minimisation;program testing;set theory","mask-coding representation;test suite minimisation;multiobjective set cover problem;optimisation problems;software testing;code coverage;set theory;Pareto-efficient solution set","","13","","24","","11 Nov 2010","","","IEEE","IEEE Conferences"
"Constraint Handling in NSGA-II for Solving Optimal Testing Resource Allocation Problems","G. Zhang; Z. Su; M. Li; F. Yue; J. Jiang; X. Yao","School of Computer and Information, Hefei University of Technology, Hefei, China; School of Computer and Information, Hefei University of Technology, Hefei, China; CERCIA, School of Computer Science, University of Birmingham, Birmingham, U.K.; School of Computer and Information, Hefei University of Technology, Hefei, China; School of Computer and Information, Hefei University of Technology, Hefei, China; Department of Computer Science and Engineering, Shenzhen Key Lab of Computational Intelligence, Southern University of Science and Technology, Shenzhen, China","IEEE Transactions on Reliability","29 Nov 2017","2017","66","4","1193","1212","In software testing, optimal testing resource allocation problems (OTRAPs) are important when seeking a good tradeoff between reliability, cost, and time with limited resources. There have been intensive studies of OTRAPs using multiobjective evolutionary algorithms (MOEAs), but little attention has been paid to the constraint handling. This paper comprehensively investigates the effect of the constraint handling on the performance of nondominated sorting genetic algorithm II (NSGA-II) for solving OTRAPs, from both theoretical and empirical perspectives. The heuristics for individual repairs are first proposed to handle constraint violations in NSGA-II, based on which several properties are derived. Additionally, the Z-score based Euclidean distance is adopted to estimate the difference between solutions. Finally, the above methods are evaluated and the experiments show several results. 1) The developed heuristics for constraint handling are better than the Existing Strategy in terms of the capacity and coverage values. 2) The Z-score operation obtains better diversity values and reduces repeated solutions. 3) The modified NSGA-II for OTRAPs (called NSGA-II-TRA) performs significantly better than the existing MOEAs in terms of capacity and coverage values, which suggests that NSGA-II-TRA could obtain more and higher quality testing-time-allocation schemes, especially for large, complex datasets. 4) NSGA-II-TRA is robust according to the sensitivity analysis results.","1558-1721","","10.1109/TR.2017.2738660","National Natural Science Foundation of China(grant numbers:61573125,61329302,61371155); Engineering and Physical Sciences Research Council(grant numbers:EP/J017515/1); Anhui Provincial Natural Science Foundation(grant numbers:1608085MF131,1508085MF132,1508085QF129); Science and Technology Innovation Committee Foundation of Shenzhen(grant numbers:ZDSYS201703031748284); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8023833","Constraint handling;heuristics;multiobjective optimization;software reliability;testing-resource allocation","Software reliability;Software systems;Resource management;Software testing","constraint handling;genetic algorithms;program testing;resource allocation;software reliability","software testing;optimal testing resource allocation problems;multiobjective evolutionary algorithms;nondominated sorting genetic algorithm II;Z-score based Euclidean distance;NSGA-II-TRA;quality testing-time-allocation schemes;OTRAPs;MOEAs;heuristics;constraint violation handling","","15","","47","IEEE","31 Aug 2017","","","IEEE","IEEE Journals"
"Peer Instruction in Online Synchronous Software Engineering - Findings from fine-grained clicker data","B. Gopal; S. Cooper","University of Nebraska-Lincoln,Computer Science and Engineering,Lincoln,USA; University of Nebraska-Lincoln,Computer Science and Engineering,Lincoln,USA","2021 IEEE Frontiers in Education Conference (FIE)","20 Dec 2021","2021","","","1","8","In this Research Full paper, we present the results of a replication study in a semester-long, sophomore-level software engineering course utilizing Peer Instruction (PI). PI is an active learning pedagogy with roots in STEM Education. In this study, we examine the relationship between student response data from in-class PI correctness and students' performance on quizzes and exams. We worked with a fully remote, synchronous course offered over Zoom. The study we replicated was with an honors cohort of students with a diversity of undergraduate majors, while we focused on a non-honors course containing computing-related majors. Our intervention design included a flipped-classroom approach for each class session with required readings, reading quizzes, followed by PI in class using online breakout rooms for peer discussion. Our course modules were heavily based on industry practices and knowledge from the workforce, across several varied modules that encompass the complete software development lifecycle, and were as follows: Software Process Models (SPM), Software Architecture (SA), Databases (DB), User Interface/user Experience (UI/UX), Software Testing (ST), and Continuous Integration (CI). Our data points for analysis with fine-grained PI student response data were two-fold: scores from weekly online quizzes, and a summative final exam, administered online through a course management system (CMS), at different points during the semester after the PI sessions. The online quizzes and the online exam were timed, closed book/notes, and conducted during class periods. We analyzed and classified individual student responses before and after each question in each module and attempted to create response patterns for each module. We correlated these response patterns with exam and quiz scores using ANOVA techniques, on a variety of questions including Parson's problems. We report overall correctness on each type of vote, track student response patterns from in-class to quizzes and the exam, and quantify absolute percentages of students that demonstrate longer-term learning from the PI process. Our results show that 58% of students exhibited cognitive gains across all modules during PI sessions. Students who learn in class from PI perform well on the quizzes and the final exam, indicating persistence of the knowledge gained during PI several weeks after the actual sessions. We also found that those who fail to learn from the PI process in the class perform worse on quizzes and the final exam. Our results were consistent across all modules. More significantly, we found PI to be an effective way to teach our software engineering course based on student learning before and after PI, in a completely virtual environment, a result unique to our study. Based on our results, we discuss the implications for software engineering education, both in-person and virtual.","2377-634X","978-1-6654-3851-3","10.1109/FIE49875.2021.9637353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637353","Software Engineering Education;Peer Instruction;Active Learning;Online courses;Virtual Instruction;Cognitive gains using Peer Instruction;Fine-grained data analysis;student response data","Software testing;Knowledge engineering;Industries;Software architecture;Education;Virtual environments;Software","cognition;computer science education;educational courses;program testing;software architecture;statistical analysis;STEM;teaching;user interfaces","peer instruction;fine-grained clicker data;sophomore-level software engineering course;in-class PI correctness;fully remote course;synchronous course;nonhonors course;class session;online breakout rooms;course modules;software development lifecycle;software architecture;software testing;data points;fine-grained PI student response data;weekly online quizzes;summative final exam;course management system;PI sessions;online exam;student response patterns;PI process;student learning;software engineering education;online synchronous software engineering;STEM education;flipped-classroom approach;software process models;user interface;user experience;continuous integration;ANOVA techniques","","","","38","","20 Dec 2021","","","IEEE","IEEE Conferences"
"Black-Box String Test Case Generation through a Multi-Objective Optimization","A. Shahbazi; J. Miller","Department of Electrical and Computer Engineering, Edmonton, AB, Canada; Department of Electrical and Computer Engineering, Edmonton, AB, Canada","IEEE Transactions on Software Engineering","14 Apr 2016","2016","42","4","361","378","String test cases are required by many real-world applications to identify defects and security risks. Random Testing (RT) is a low cost and easy to implement testing approach to generate strings. However, its effectiveness is not satisfactory. In this research, black-box string test case generation methods are investigated. Two objective functions are introduced to produce effective test cases. The diversity of the test cases is the first objective, where it can be measured through string distance functions. The second objective is guiding the string length distribution into a Benford distribution based on the hypothesis that the population of strings is right-skewed within its range. When both objectives are applied via a multi-objective optimization algorithm, superior string test sets are produced. An empirical study is performed with several real-world programs indicating that the generated string test cases outperform test cases generated by other methods.","1939-3520","","10.1109/TSE.2015.2487958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7293669","Adaptive random testing;automated test case generation;black-box testing;mutation;random testing;software testing;string distance;string test cases;Adaptive random testing;automated test case generation;black-box testing;mutation;random testing;software testing;string distance;string test cases","Sociology;Statistics;Biological cells;Subspace constraints;Testing;Power capacitors;Genetic algorithms","optimisation;program testing;security of data","black-box string test case generation;security risks;random testing;RT;objective functions;string distance functions;Benford distribution;multiobjective optimization algorithm","","21","","76","IEEE","7 Oct 2015","","","IEEE","IEEE Journals"
"The effect of testing on reliability of fault-tolerant software","P. Popov; B. Littlewood","Centre for Software Reliability, City Univ., London, UK; Centre for Software Reliability, City Univ., London, UK","International Conference on Dependable Systems and Networks, 2004","26 Jul 2004","2004","","","265","274","Previous models have investigated the impact upon diversity - and hence upon the reliability of fault-tolerant software built from 'diverse' versions - of the variation in 'difficulty' of demands over the demand space. These models are essentially static, taking a single snapshot view of the system. In this paper, we consider a generalisation in which the individual versions are allowed to evolve - and their reliability to grow - through debugging. In particular, we examine the trade-off that occurs in testing between, on the one hand, the increasing reliability of individual versions, and on the other hand the possible diminution of diversity.","","0-7695-2052-9","10.1109/DSN.2004.1311896","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311896","","Software testing;Fault tolerance;Fault tolerant systems;Battery powered vehicles;Software reliability;Debugging;Stochastic processes;Parameter estimation;Computer industry;Hardware","program testing;software fault tolerance;reliability;program debugging","reliability testing;fault-tolerant software;software debugging;software testing","","9","","7","","26 Jul 2004","","","IEEE","IEEE Conferences"
"BRIX: meeting the requirements for online second language learning","M. Sawatpanit; D. Suthers; S. Fleming","eSpherical Inc., Washington, DC, USA; NA; NA","37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the","26 Feb 2004","2004","","","10 pp.","","This paper describes the design and evaluation of BRIX, an environment for online learning of second languages. A needs analysis identified specific requirements of online language learning. Commercial course management systems were determined to be inadequate with respect to these requirements. BRIX was developed to address the need for a generic language learning environment that fulfils language educators' requirements focusing on reading, writing, and listening activities and can easily be customized for different language courses. The design of BRIX is based on pedagogic approaches and theories of teaching and learning second languages and on the results of analytic and empirical evaluation of test versions of the software. In this paper, we describe the needs analysis and the design of BRIX, and present an evaluation that compares the use and usability of a Chinese course in BRIX to a previous handcrafted version of the same course.","","0-7695-2056-1","10.1109/HICSS.2004.1265047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1265047","","Natural languages;Writing;Distance learning;Education;Internet;Programming profession;World Wide Web;Software testing;Usability;Diversity reception","educational courses;distance learning","BRIX;online learning;second language learning;course management;language learning environment;language courses;Chinese course","","3","","20","","26 Feb 2004","","","IEEE","IEEE Conferences"
"Mitagation against MAI in a Space Time Spreading Software Defined Radio Test Bed","S. Wee; M. Ros; P. J. Vial","Univ. of Wollongong, Wollongong, NSW; Univ. of Wollongong, Wollongong, NSW; Univ. of Wollongong, Wollongong, NSW","2009 Sixth International Conference on Information Technology: New Generations","10 Jun 2009","2009","","","534","540","A software defined radio test bed using the Gnu Radio project was installed on Unix boxes and modified so that estimates of the channel state coefficients were taken for a multiple input multiple output (MIMO) system to take advantage of space time transmission at a frequency of 2.4 GHz. This system was modified to provide a space time spreading test bed. The test bed was modified so that multiple access interference was experienced by offsetting different users data streams. The Walsh-Hadamard and Wysocki (low correlation) spreading sequences were deployed in the test bed to compare their bit error rate performance. We confirmed that the low cross correlation spreading sequences experienced an improved bit error rate compared to that obtained when using the Walsh-Hadamard spreading sequence for high signal to noise ratios.","","978-1-4244-3770-2","10.1109/ITNG.2009.117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5070674","Gnu Radio;Space Time Spreading;MIMO;Software Defined Radio","Software radio;Software testing;Sociotechnical systems;Multiple access interference;Diversity reception;Receiving antennas;System testing;MIMO;Bit error rate;Fading","error statistics;interference suppression;MIMO communication;software radio;Unix","space time spreading software defined radio test bed;Gnu Radio project;Unix boxes;channel state coefficients;multiple input multiple output system;Walsh-Hadamard spreading sequences;Wysocki spreading sequences;bit error rate;multiple access interference;signal to noise ratios","","2","","16","","10 Jun 2009","","","IEEE","IEEE Conferences"
"The Workflow Trace Archive: Open-Access Data From Public and Private Computing Infrastructures","L. Versluis; R. Mathá; S. Talluri; T. Hegeman; R. Prodan; E. Deelman; A. Iosup","Computer Science, Vrije Universiteit Amsterdam, HV Amsterdam, Netherlands; Institute of Computer Science, Universitat Innsbruck, Innsbruck, Tyrol, Austria; Computer Science, Vrije Universiteit Amsterdam, HV Amsterdam, Netherlands; Computer Science, Vrije Universiteit Amsterdam, HV Amsterdam, Netherlands; Institute of Software Technology, University of Klagenfurt, Klagenfurt am, Austria; Information Sciences Institute, University of Southern California, Los Angeles, CA, USA; Computer Science, Vrije Universiteit Amsterdam, HV Amsterdam, Netherlands","IEEE Transactions on Parallel and Distributed Systems","4 May 2020","2020","31","9","2170","2184","Realistic, relevant, and reproducible experiments often need input traces collected from real-world environments. In this work, we focus on traces of workflows-common in datacenters, clouds, and HPC infrastructures. We show that the state-of-the-art in using workflow-traces raises important issues: (1) the use of realistic traces is infrequent and (2) the use of realistic, open-access traces even more so. Alleviating these issues, we introduce the Workflow Trace Archive (WTA), an open-access archive of workflow traces from diverse computing infrastructures and tooling to parse, validate, and analyze traces. The WTA includes > 48 million workflows captured from > 10 computing infrastructures, representing a broad diversity of trace domains and characteristics. To emphasize the importance of trace diversity, we characterize the WTA contents and analyze in simulation the impact of trace diversity on experiment results. Our results indicate significant differences in characteristics, properties, and workflow structures between workload sources, domains, and fields.","1558-2183","","10.1109/TPDS.2020.2984821","Vidi MagnaData; European Union's Horizon 2020 Research and Innovation Programme(grant numbers:801091); National Science Foundation(grant numbers:1664162); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9066946","Workflow;open-source;open-access;traces;characterization;archive;survey;simulation","Cloud computing;Open source software;Testing;Labeling;Computational modeling;Task analysis;Tools","cloud computing;public domain software;resource allocation;workflow management software","datacenters;clouds infrastructures;workflow trace archive;workflow structures;trace diversity;trace domains;computing infrastructures;open-access traces;HPC infrastructures;open-access data","","6","","60","CCBY","14 Apr 2020","","","IEEE","IEEE Journals"
"Test Generation and Test Prioritization for Simulink Models with Dynamic Behavior","R. Matinnejad; S. Nejati; L. C. Briand; T. Bruckmann","SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; Delphi Automotive Systems, Luxembourg","IEEE Transactions on Software Engineering","17 Sep 2019","2019","45","9","919","944","All engineering disciplines are founded and rely on models, although they may differ on purposes and usages of modeling. Among the different disciplines, the engineering of Cyber Physical Systems (CPSs) particularly relies on models with dynamic behaviors (i.e., models that exhibit time-varying changes). The Simulink modeling platform greatly appeals to CPS engineers since it captures dynamic behavior models. It further provides seamless support for two indispensable engineering activities: (1) automated verification of abstract system models via model simulation, and (2) automated generation of system implementation via code generation. We identify three main challenges in the verification and testing of Simulink models with dynamic behavior, namely incompatibility, oracle and scalability challenges. We propose a Simulink testing approach that attempts to address these challenges. Specifically, we propose a black-box test generation approach, implemented based on meta-heuristic search, that aims to maximize diversity in test output signals generated by Simulink models. We argue that in the CPS domain test oracles are likely to be manual and therefore the main cost driver of testing. In order to lower the cost of manual test oracles, we propose a test prioritization algorithm to automatically rank test cases generated by our test generation algorithm according to their likelihood to reveal a fault. Engineers can then select, according to their test budget, a subset of the most highly ranked test cases. To demonstrate scalability, we evaluate our testing approach using industrial Simulink models. Our evaluation shows that our test generation and test prioritization approaches outperform baseline techniques that rely on random testing and structural coverage.","1939-3520","","10.1109/TSE.2018.2811489","H2020 European Research Council(grant numbers:694277); Delphi Automotive Systems, Luxembourg; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8305644","Simulink models;search-based software testing;test generation;test prioritization;test oracle;output diversity;signal features;structural coverage","Software packages;Testing;Tools;Computational modeling;Vehicle dynamics;Scalability","computer simulation;cyber-physical systems;program compilers;program testing;program verification;search problems","industrial Simulink models;random testing;Simulink modeling platform;dynamic behavior models;abstract system models;code generation;Simulink testing approach;black-box test generation approach;test output signals;CPS domain test oracles;test budget;cyber physical systems;automated verification;automated generation;meta-heuristic search;cost driver;test prioritization approach;structural coverage","","29","","124","IEEE","1 Mar 2018","","","IEEE","IEEE Journals"
"Achieving dependability throughout the development process: a distributed software experiment","J. P. J. Kelly; S. C. Murphy","Dept. of Electr. & Comput. Eng., California Univ., Santa Barbara, CA, USA; NA","IEEE Transactions on Software Engineering","6 Aug 2002","1990","16","2","153","165","Distributed software engineering techniques and methods for improving the specification and testing phases are considered. To examine these issues, an experiment was performed using the design diversity approach in the specification, design, implementation, and testing of distributed software. In the experiment, three diverse formal specifications were used to produce multiple independent implementations of a distributed communication protocol in Ada. The problems encountered in building complex concurrent processing systems in Ada were also studied. Many pitfalls were discovered in mapping the formal specifications into Ada implementations.<<ETX>></ETX>","1939-3520","","10.1109/32.44379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=44379","","Software testing;Automatic testing;Fault tolerance;Software engineering;Formal specifications;Hardware;Fault detection;Software performance;Protocols;Buildings","Ada;computer communications software;data communication systems;distributed processing;formal specification;program testing;protocols","distributed software engineering;B/B testing;automated testing;software testing;dependability;multiple independent implementations;distributed communication protocol;Ada;complex concurrent processing systems","","18","","29","","6 Aug 2002","","","IEEE","IEEE Journals"
"Ate software, whence - whither","R. T. Oishi","RLG Associates, Inc.","International Automatic Testing Conference AUTOTESTCON '78.","10 Dec 2002","1978","","","210","214","Standardization efforts within ATE software have been aimed pri marily at the languages used to prepare test programs. In the future the diversity of computer con figurations available to ATE will increase tremendously. To take full advantage of this diversity in a coherent manner will require some standardization of operating system features. The primary goal of such standardization should be the operator to computer interface. Given such standardization a wide range of possibilities become available without the disadvantages that diverse operator interfaces impose.","","","10.1109/AUTEST.1978.764367","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=764367","","Standardization;Operating systems;System testing;Programming profession;Costs;Control systems;System software;Manufacturing;Software testing;Computer interfaces","","","","","","","","10 Dec 2002","","","IEEE","IEEE Conferences"
"Georgia Tech Software Radio Laboratory","T. G. Pratt","Georgia Institute of Technology, Atlanta, Georgia 30332-0821, USA, thomas.pratt@gtri.gatech.edu","54th ARFTG Conference Digest","12 Mar 2007","2000","36","","1","4","The Georgia Tech Broadband Institute of the Georgia Institute of Technology is establishing a Software Radio Laboratory in the Georgia Center for Advanced Telecommunications Technology (GCATT). The laboratory, which is planned to be operational in early 2000, has been designed as a testbed for research, development, test, and evaluation of software radio concepts. The laboratory consists of waveform generators and communications signal sources, local area networking transceivers, radio frequency (RF) channel emulators with branch diversity and smart antenna emulation capabilities, and a multichannel programmable VME-based software radio platform. The software radio platform incorporates a programmable RF front-end, digital down-converters, and multiple Quad TI-C6x DSP boards to facilitate algorithm development for intermediate frequency (IF), baseband, and bitstream processing. The laboratory promises to have capability for addressing a broad spectrum of problems including the development and test of communications modulation techniques, access methods, traffic types, channel distortion effects, transmitter diversity, receiver signal processing algorithms, coding, power control, and many other diverse topics of research.","","978-1-6654-5036-2","10.1109/ARFTG.1999.327381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4120060","","Software radio;Laboratories;Radio frequency;Software testing;Signal processing algorithms;Signal generators;RF signals;LAN emulation;Transceivers;Digital signal processing","","","","1","","3","","12 Mar 2007","","","IEEE","IEEE Conferences"
"Good Things Come In Threes: Improving Search-based Crash Reproduction With Helper Objectives","P. Derakhshanfar; X. Devroey; A. Zaidman; A. van Deursen; A. Panichella","Delft University of Technology,Delft,The Netherlands; Delft University of Technology,Delft,The Netherlands; Delft University of Technology,Delft,The Netherlands; Delft University of Technology,Delft,The Netherlands; Delft University of Technology,Delft,The Netherlands","2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)","24 Dec 2020","2020","","","211","223","Writing a test case reproducing a reported software crash is a common practice to identify the root cause of an anomaly in the software under test. However, this task is usually labor-intensive and time-taking. Hence, evolutionary intelligence approaches have been successfully applied to assist developers during debugging by generating a test case reproducing reported crashes. These approaches use a single fitness function called Crash Distance to guide the search process toward reproducing a target crash. Despite the reported achievements, these approaches do not always successfully reproduce some crashes due to a lack of test diversity (premature convergence). In this study, we introduce a new approach, called MOHO, that addresses this issue via multi-objectivization. In particular, we introduce two new Helper-Objectives for crash reproduction, namely test length (to minimize) and method sequence diversity (to maximize), in addition to Crash Distance. We assessed MO-HO using five multi-objective evolutionary algorithms (NSGA-II, SPEA2, PESA-II, MOEA/D, FEMO) on 124 non-trivial crashes stemming from open-source projects. Our results indicate that SPEA2 is the best-performing multi-objective algorithm for MO-HO. We evaluated this best-performing algorithm for MO-HO against the state-of-the-art: single-objective approach (Single-Objective Search) and decomposition-based multi-objectivization approach (De-MO). Our results show that MO-HO reproduces five crashes that cannot be reproduced by the current state-of-the-art. Besides, MO-HO improves the effectiveness (+10% and +8% in reproduction ratio) and the efficiency in 34.6% and 36% of crashes (i.e., significantly lower running time) compared to Single-Objective Search and De-MO, respectively. For some crashes, the improvements are very large, being up to +93.3% for reproduction ratio and -92% for the required running time.","2643-1572","978-1-4503-6768-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9285999","crash reproduction;search-based software testing;multi-objective evolutionary algorithms","Evolutionary computation;Writing;Search problems;Computer crashes;Task analysis;Open source software;Software engineering","evolutionary computation;genetic algorithms;Pareto optimisation;program debugging;program testing","test length;helper-objectives;test diversity;target crash;search process;fitness function;evolutionary intelligence approaches;software crash;helper objectives;search-based crash reproduction;reproduction ratio;single-objective search;multiobjective algorithm;nontrivial crashes;SPEA2;multiobjective evolutionary algorithms;MO-HO;crash distance","","","","47","","24 Dec 2020","","","IEEE","IEEE Conferences"
"Making Sense of Software Development and Personality Types","L. F. Capretz; F. Ahmed","University of Western Ontario, Canada; United Arab Emirates University","IT Professional","2 Feb 2010","2010","12","1","6","13","It's common sense to state that the production of any software product involves a human element, at least to some extent. We all have different personality traits, and the way we perceive, plan, and execute any activity is influenced by these characteristics. Typically, software development is a product of teamwork, involving several people performing various tasks. The success and failure of software projects reveal the human factor as one of vital importance. Not everyone can excel at every task, thus better results are achieved if people with particular personality traits are assigned to different aspects of a project, especially the roles best suited to their ability. The authors mapped some opposing psychological traits, such as extroversion-introversion, sensing-intuition, thinking-feeling, and judging-perceiving, to the main stages of a software development life cycle. Consequently, they concluded that assigning a person with specific psychological characteristics to the stage of the software life cycle best suited for his or her traits increases the chances of a successful outcome for the project.","1941-045X","","10.1109/MITP.2010.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5403172","IT workforce;human factors in software engineering;software psychology;personality types;diversity in software development;MBTI","Programming;Software engineering;Psychology;Software testing;Decision making;Teamwork;Production;Human factors","human factors;product life cycle management;project management;psychology;software development management;software reusability","software product;personality traits;teamwork;software projects;human factor;psychological traits;extroversion;introversion;intuition sensing;thinking-feeling;judging-perceiving;software development life cycle","","110","","13","","2 Feb 2010","","","IEEE","IEEE Magazines"
"PODS — A project on diverse software","P. G. Bishop; D. G. Esp; M. Barnes; P. Humphreys; G. Dahll; J. Lahti","Central Electricity Research Laboratories, UK Central Electricity Generating Board, Surrey KT22 7SE, England; Central Electricity Research Laboratories, UK Central Electricity Generating Board, Surrey KT22 7SE, England; UK Atomic Energy Authority; UK Atomic Energy Authority; Institute for Energy; Technical Research Center of Finland","IEEE Transactions on Software Engineering","26 Sep 2012","1986","SE-12","9","929","940","A review of the Project on Diverse Software (PODS), a collaborative software reliability research project, is presented. The purpose of the project was to determine the effect of a number of different software development techniques on software reliability. The main objectives were to evaluate the merits of using diverse software, evaluate the specification language X-SPEX, and compare the productivity and reliability associated with high-level and low-level languages. A secondary objective was to monitor the software development process, with particular reference to the creation and detection of software faults. To achieve these objectives, an experiment was performed which simulated a normal software development process to produce three diverse programs to the same requirement. The requirement was for a reactor over-power protection (trip) system. After careful independent development and testing, the three programs were tested against each other in a special test harness to locate residual faults. The conclusions drawn from this project are discussed.","1939-3520","","10.1109/TSE.1986.6313048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6313048","Fault classification;n-version programming;PODS;programming languages;reactor protection;software diversity;software faults;software reliability;specification languages;X","Software;Testing;Inductors;Specification languages;Software reliability;Documentation;Quality assurance","software reliability;specification languages","diverse software;Project on Diverse Software;PODS;software reliability research project;software development techniques;software reliability;diverse software;specification language X-SPEX;software development process;software faults;reactor over-power protection","","63","","","","26 Sep 2012","","","IEEE","IEEE Journals"
"Architecting Distributed PXI Test Systems","S. Stock","National Instruments, 11500 N Mopac Expwy, Austin, TX 78759 (512)683-5624. spencer.stock@ni.com","2006 IEEE Autotestcon","15 Jan 2007","2006","","","547","551","The popularity of distributed test systems is growing for a number of reasons, which include the distribution of processing among multiple intelligent nodes in order to increase computing power and I/O bandwidth and geographic constraints that prohibit all of the components of a system from residing in a single location. This paper will examine the features of the PXI platform that enable the architecting of distributed test systems. These features include software frameworks that easily interface with both local and distributed hardware, integration resources for PXI systems with a diversity of instruments and hybrid test systems, and hardware synchronization resources that enable distributed synchronization down to the sub- nanosecond level by extending the PXI backplane across multiple distributed PXI systems or synchronization over significant distances with technologies such as GPS. This paper will also examine distributed system design techniques for communication and data transfer between intelligent nodes and discuss dedicated deterministic communication for advanced distributed PXI test systems.","1558-4550","1-4244-0051-1","10.1109/AUTEST.2006.283724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4062437","","System testing;Instruments;Software testing;Hardware;Control systems;Ethernet networks;Software architecture;Application software;Software measurement;Distributed computing","automatic testing;peripheral interfaces;synchronisation","architecting distributed;PXI test systems;distributed test systems;software frameworks;local hardware;distributed hardware;hybrid test systems;hardware synchronization;distributed synchronization;distributed system design;data transfer","","4","","3","","15 Jan 2007","","","IEEE","IEEE Conferences"
"PODS revisited-a study of software failure behaviour","P. G. Bishop; F. D. Pullen","Central Electr. Res. Lab., Leatherhead, UK; Central Electr. Res. Lab., Leatherhead, UK","[1988] The Eighteenth International Symposium on Fault-Tolerant Computing. Digest of Papers","6 Aug 2002","1988","","","2","8","A description is given of an empirical study of the failure characteristics of software defects detected in the programs developed in the Project on Diverse Software (PODS). The results are interpreted in the context of a state machine model of software failure. The results of the empirical study case doubts on the general validity of the assumption of constant software failure probability and the assumption of constant software failure probability and the assumption that all defects have similar failure rates. In addition, an analysis of failure dependency lends support to the use of diversity as a means of minimizing the impact of design-level faults. Here, nonidentical faults exhibited coincident failure characteristics approximately in accord with the independence assumption, and some of the observed positive and negative correlation effects could be explained by failure masking effects, which can be removed by suitable design.<<ETX>></ETX>","","0-8186-0867-6","10.1109/FTCS.1988.5289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5289","","Context modeling;Collaborative software;State-space methods;Predictive models;Kelvin;Failure analysis;Fault detection;Software testing;Software reliability;Real time systems","fault tolerant computing;software reliability","software failure behaviour;Project on Diverse Software;PODS;state machine model;failure dependency;design-level faults","","16","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Are Our Students Prepared for Testing Based Software Development?","V. Bhattacherjee; M. S. Neogi; R. Mahanti","Deptt. of CS & E, Birla Inst. of Technol., Ranchi; Deptt. of lM, Xavier Inst. of Social Service, Ranchi; Tata Consultancy Services, Kolkata","2009 22nd Conference on Software Engineering Education and Training","10 Apr 2009","2009","","","210","211","The pervasive impact of software in systems design as well as its changing character presents immense challenges for the education of software engineers. In the twenty first century, software engineers face the challenges of rapid change and uncertainty along with dependability and diversity. This paper presents the results of a study conducted to assess the pair programmers' as well as individual programmers' ability and eagerness to begin with early testing while writing programs or developing semester projects.","2377-570X","978-1-4244-3431-2","10.1109/CSEET.2009.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812699","","Software testing;Programming profession;Software engineering;Laboratories;Educational technology;Software systems;Educational programs;Systems engineering education;Design engineering;Uncertainty","computer aided instruction;computer science education;programming;software engineering","testing based software development;pair programming","","2","","11","","10 Apr 2009","","","IEEE","IEEE Conferences"
"Test software at Texas Instruments: what SEI level is appropriate?","J. Payne; S. Griffith","Defense Syst. & Electron. Group, Texas Instrum. Inc., Lewisville, TX, USA; Defense Syst. & Electron. Group, Texas Instrum. Inc., Lewisville, TX, USA","Conference Record AUTOTESTCON '95. 'Systems Readiness: Test Technology for the 21st Century'","6 Aug 2002","1995","","","196","203","In 1989, Texas Instruments (TI) as a corporation embarked on an aggressive mission to improve the quality of its internally developed software. As a part of this ongoing effort, the Test Engineering Department of the Defense Systems and Electronics Group (DSEG) evaluated existing test software development practices and procedures. Using the Software Engineering Institute's (SEI) Capability Maturity Model (CMM) to measure software process quality, DSEG Test Engineering Department was internally appraised at SEI Level 2 and is currently working towards Level 3. There were unique challenges and difficulties relative to this achievement due to the wide diversity of test types, development standards, languages and platforms associated with test software. This paper presents the approach, schedule, lessons learned and some of the benefits which resulted from the efforts of the DSEG Test Engineering software quality thrust.","","0-7803-2621-0","10.1109/AUTEST.1995.522673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=522673","","Software testing;Instruments;Electronic equipment testing;Software quality;System testing;Programming;Software engineering;Capability maturity model;Coordinate measuring machines;Current measurement","automatic test software;software quality;configuration management;software standards","test software;Texas Instruments software;software process quality;software development practices;Software Engineering Institute;Capability Maturity Model;Level 2;Level 3","","","","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Software measurement in the U.S. Army","D. S. Lucero","Army Oper. Test & Evaluation Command, USA","Proceedings Twenty-First Annual International Computer Software and Applications Conference (COMPSAC'97)","6 Aug 2002","1997","","","589","590","Many means for organizing software measures have been developed over the years. The Army has found that the larger the organization, the higher in the hierarchy the requirement for software measurement needs to be stated. The reason for this stems from the growing diversity of developers in larger organizations. Small organizations that have a well defined process for developing software, or a common set of software development tools, can require that specific data elements be collected, or specific measurements be taken. If larger organizations attempting to impose such specific requirements on developers are likely to meet some resistance, a tight policy does not allow for variation in development processes and development tools. With software development centers building air defense systems in Huntsville, Alabama; command and control systems in Monmouth, New Jersey; logistics systems in Petersburg, Virginia; personnel systems in Fairfax, Virginia; communications systems in Sierra Vista, Arizona; aviation systems in St. Louis, Missouri, armor systems in Picatinny, New Jersey and Detroit Michigan, and engineering systems at various locations throughout the US, the Army must have a policy for software measurement that puts in place flexible reporting requirements, yet provides training and support tailored to the needs of specific programs.","0730-3157","0-8186-8105-5","10.1109/CMPSAC.1997.625076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=625076","","Software measurement;Software testing;Software metrics;Quality management;Stability;Software quality;Software systems;System testing;Delay systems;Delay effects","military computing;software metrics;software development management","software measurement;US Army;software measures;larger organizations;small organizations;software development tools;software development centers;air defense systems;command and control systems;logistics systems;personnel systems;aviation systems;armor systems;engineering systems;US Army operational test/evaluation command","","","2","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Guideline-based approach for achieving non-functional attributes of software","M. Hneif; Sai Peck Lee","Department of Software Engineering, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Department of Software Engineering, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia","2010 2nd International Conference on Computer Engineering and Technology","17 Jun 2010","2010","6","","V6-305","V6-308","Non-functional attributes of software are considered as major element for improving software quality. However, achieving these attributes in a software system is not a simple task, bearing in mind the relationships between these attributes, and the diversity of software domains. This paper proposes a new guideline-based software development approach that provides the suitable guidelines for the software engineer, throughout the phases of software development for the purpose of achieving a high quality level of non-functional attributes of software.","","978-1-4244-6349-7","10.1109/ICCET.2010.5486233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5486233","non-functional attributes;guideline-based development;software quality;preventive approach","Software quality;Software systems;Programming;Software testing;System testing;Software maintenance;Software engineering;Computer science;Information technology;Guidelines","software quality;software reliability","software quality;guideline based software development;software systems;nonfunctional attributes","","1","","16","","17 Jun 2010","","","IEEE","IEEE Conferences"
"The role of extensibility in software standards for automatic test systems","T. P. Lopes; I. A. Neag; J. E. Ralph","Teradyne Inc., North Reading, MA, USA; NA; NA","IEEE Autotestcon, 2005.","27 Mar 2006","2005","","","367","373","The extension of standardized software interfaces provides a consistent format by which software vendors expose unique functional features of a product, as well as features common with other products, but not supported by existing standards. Extensibility is critical in the field of automatic test systems (ATSs) due to the diversity of existing hardware and software and the need to maintain systems over long periods of time. The paper describes the principle of interface extensibility and shows that, when properly used, extensions do not compromise the interoperability benefits obtained through standardization. Modern software interfacing technologies provide effective support for extensibility. The paper illustrates this support by analyzing the extensibility features of various ATS software standards. This analysis is used to derive a set of rules for designing interface extensions. Extensibility in the emerging automatic test markup language (ATML) standards is presented in detail and illustrated through examples","1558-4550","0-7803-9101-2","10.1109/AUTEST.2005.1609160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1609160","","Software standards;Automatic testing;Software testing;System testing;Application software;Standards development;Electrical resistance measurement;Software maintenance;Standardization;Hardware","automatic test software;software standards;XML","software standards;automatic test systems;software interface extensibility;software interfacing technologies;ATS;automatic test markup language standards;ATML standards","","1","","5","","27 Mar 2006","","","IEEE","IEEE Conferences"
"A New Method for Constructing Decision Tree Based on Rough Set Theory","L. Huang; M. Huang; B. Guo; Z. Zhang","Jiangxi Normal Univ., Jiangxi; Jiangxi Normal Univ., Jiangxi; Jiangxi Normal Univ., Jiangxi; Jiangxi Normal Univ., Jiangxi","2007 IEEE International Conference on Granular Computing (GRC 2007)","17 Dec 2007","2007","","","241","241","One of the keys to constructing decision tree model is to choose standard for testing attribute, for the criteria of selecting test attributes influences the classification accuracy of the tree. There exists diversity choosing standards for testing attribute based on entropy, Bayesian, and so on. In this paper, the degree of dependency of decision attribute on condition attribute, based on rough set theory, is used as a heuristic for selecting the attribute that will best separate the samples into individual classes. The results of example and experiments show that compared with the entropy-based approach, our approach is a better way to select nodes for constructing decision tree.","","978-0-7695-3032-1","10.1109/GrC.2007.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4403102","","Decision trees;Set theory;Information systems;Classification tree analysis;Software testing;Feature extraction;Educational institutions;Software standards;Entropy;Bayesian methods","decision trees;optimisation;pattern classification;rough set theory","rough set theory;decision tree model;testing attribute;classification accuracy;heuristic","","7","","10","","17 Dec 2007","","","IEEE","IEEE Conferences"
"Testing software components using boundary value analysis","Muthu Ramachandran","Sch. of Comput., Leeds Metropolitan Univ., UK","2003 Proceedings 29th Euromicro Conference","15 Sep 2003","2003","","","94","98","Most consumer electronics products today contain complex embedded software. We believe a component-oriented approach is an ideal way to handle the diversity of software complexity. Our earlier work on reusable components has addressed the development of the Koala component model has been developed (as an outcome of the ESPRIT project ARES) to address reuse with concept of late binding. This has been carried out as a part of the research project on 'testing software components'. Our approach to testing components was based on the principles of testing from object models. Therefore we have decomposed a COM-like component into OO models so that various test techniques can be automated. Also we are able to generate a volume of key test cases to study boundary value testing and analysis on component interfaces, which is the key to achieve testability of a reusable software component.","1089-6503","0-7695-1996-2","10.1109/EURMIC.2003.1231572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1231572","","Software reusability;Object oriented programming;Software metrics;Software testing","software reusability;distributed object management;object-oriented programming;software metrics;program testing","software components testing;boundary value analysis;consumer electronic product;complex embedded software;component-oriented approach;software complexity;reusable software component;Koala component model;COM-like component;object-oriented model","","10","","4","","15 Sep 2003","","","IEEE","IEEE Conferences"
"Variability Management in Software Product Line Engineering","A. Metzger; K. Pohl","University of Duisburg-Essen, Germany; University of Duisburg-Essen, Germany; Lero, University of Limerick, Ireland","29th International Conference on Software Engineering (ICSE'07 Companion)","4 Jun 2007","2007","","","186","187","Software product line engineering (SPLE [2], [6]) has proven to be the paradigm for developing a diversity of similar software applications and software-intensive systems at low costs, in short time, and with high quality. Numerous reports document the significant achievements of introducing software product lines in industry [6].","","0-7695-2892-9","10.1109/ICSECOMPANION.2007.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4222738","","Engineering management;Application software;Testing;Design engineering;Software engineering;Software quality;Documentation;Software systems;Systems engineering and theory;Costs","","","","23","1","7","","4 Jun 2007","","","IEEE","IEEE Conferences"
"Location of checkpoints in fault-tolerant software","F. Saglietti","Gesellschaft fuer Reaktorsicherheit mbH Forschungsgelande, Garching, Germany","Proceedings of the 5th Jerusalem Conference on Information Technology, 1990. 'Next Decade in Information Technology'","6 Aug 2002","1990","","","270","277","Information reduction throughout a program is studied, identifying its impact on the effectiveness of checkpoints. The discussion covers failure masking, function classes that reduce information, the impact of information reduction on failure dependence, information reduction for binary values, and location of checkpoints. The conclusions reported and the strategy suggested are intended to support decision-making during the development of fault-tolerant software by identifying which internal variables or intermediate results should be checked by means of diversity in order to optimize fault-tolerance achievement.<<ETX>></ETX>","","0-8186-2078-1","10.1109/JCIT.1990.128295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=128295","","Fault tolerance;Software testing;Parallel programming;Decision making;Fault diagnosis;Software reliability;Reliability engineering;Sequential analysis;Information analysis;Probability","fault tolerant computing;program testing;redundancy;software engineering","fault-tolerant software;failure masking;function classes;failure dependence;information reduction;internal variables;intermediate results","","","","4","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Assessing Diagnostic Techniques for Fault Tolerance in Software","G. Gallardo; J. May; J. C. Gallardo",Bristol Univ.; Bristol Univ.; Bristol Univ.,"2007 Annual Reliability and Maintainability Symposium","12 Mar 2007","2007","","","232","237","One of the main concerns in software safety critical applications is to ensure sufficient reliability if one cannot prove the absence of faults. Fault tolerance (FT) provides a plausible method for improving reliability claims in the presence of systematic failures in software. It is plausible that some software FT techniques offer increased protection than others. However, the extent of claims that can be made for different FT software architectures remains unclear. We investigate an approach to FT that integrates data diversity (DD) assertions and traditional assertions (TA). We also present the principles of a method to assess the effectiveness of the approach. The aim of this approach is to make it possible to evolve more powerful FT and thereby improve reliability. This is a step towards the aim of understanding the effectiveness of FT safety-critical applications and thus making it easier to use FT in safety arguments","0149-144X","0-7803-9766-5","10.1109/RAMS.2007.328122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4126355","","Fault tolerance;Software safety;Redundancy;Fault tolerant systems;Software testing;Fault diagnosis;Microprocessors;Software systems;Application software;Computer architecture","program testing;software fault tolerance","diagnostic techniques;software fault tolerance;software safety critical applications;software systematic failures;data diversity;traditional assertions","","","","17","","12 Mar 2007","","","IEEE","IEEE Conferences"
"Toward a more reliable theory of software reliability","J. A. Whittaker; J. Voas","Dept. of Comput. Sci., Florida Inst. of Technol., Melbourne, FL, USA; NA","Computer","6 Aug 2002","2000","33","12","36","42","The notions of time and the operational profile incorporated into software reliability are incomplete. Reliability should be redefined as a function of application complexity, test effectiveness, and operating environment. We do not yet have a reliability equation that application complexity, test effectiveness, test suite diversity, and a fuller definition of the operational profile. We challenge the software reliability community to consider these ideas in future models. The reward for successfully doing so likely will be the widespread adoption of software reliability prediction by the majority of software publishers.","1558-0814","","10.1109/2.889091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=889091","","Reliability theory;Software reliability;Hardware;Embedded software;Computer industry;Aerospace testing;Software quality;Telecommunications;Software testing;Software measurement","software reliability;software metrics;program testing","reliable theory;software reliability;operational profile;application complexity;test effectiveness;operating environment;reliability equation;test suite diversity;future models;reliability prediction;software publishers","","25","","10","","6 Aug 2002","","","IEEE","IEEE Magazines"
"An Adaptive Random Test Method based on Variable Probability Density Function with Particle Swarm Optimization","S. Wang; J. Chen; J. Xi; H. Chen; J. Chen","School of Computer Science & Communication Engineering, Jiangsu University,Zhenjiang,China,212013; School of Computer Science & Communication Engineering, Jiangsu University,Zhenjiang,China,212013; School of Computer Science & Communication Engineering, Jiangsu University,Zhenjiang,China,212013; School of Computer Science & Communication Engineering, Jiangsu University,Zhenjiang,China,212013; School of Computer Science & Communication Engineering, Jiangsu University,Zhenjiang,China,212013","2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)","1 Apr 2022","2021","","","1157","1158","Adaptive Random Testing (ART) is proposed to enhance the effectiveness of Random Testing (RT) based on the notation that evenly distributing test cases across the whole input domain. Adaptive Random Testing Through Test Profiles (ART-TP) has been considered as one of the most effective ART methods. Generally, the selection of probabilistic function matters significantly in terms of testing effectiveness. In this paper, to achieve better “evenly distributed”, we analyze the effect of concave-convex functions and design a new probabilistic function. Moreover, we take advantage of the particle swarm optimization (PSO) algorithm to advise test case generation and propose a new approach namely Probability Adaptive Random Testing by Particle Swarm Optimization (PART-PSO), so that the the diversity of test cases could be greatly enhanced, thus a better failure detection capability.","2693-9371","978-1-6654-7836-6","10.1109/QRS-C55045.2021.00172","National Key R&D Program of China(grant numbers:2020YFB1005500); National Natural Science Foundation of China (NSFC)(grant numbers:U1836116,62172194); China Postdoctoral Science Foundation(grant numbers:2021M691310); Postdoctoral Science Foundation of Jiangsu Province(grant numbers:2021K636C); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9742091","Software testing;Probability density function;Particle swarm optimization;Adaptive random testing","Conferences;Subspace constraints;Software quality;Probability density function;Probabilistic logic;Software reliability;Security","","","","","","7","","1 Apr 2022","","","IEEE","IEEE Conferences"
"Importance-Driven Deep Learning System Testing","S. Gerasimou; H. F. Eniser; A. Sen; A. Cakan","University of York,York,UK; MPI-SWS,Kaiserslautern,Germany; Bogazici University,Istanbul,Turkey; Bogazici University,Istanbul,Turkey","2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)","1 Dec 2020","2020","","","322","323","Deep Learning (DL) systems are key enablers for engineering intelligent applications. Nevertheless, using DL systems in safety- and security-critical applications requires to provide testing evidence for their dependable operation. We introduce DeepImportance, a systematic testing methodology accompanied by an Importance-Driven (IDC) test adequacy criterion for DL systems. Applying IDC enables to establish a layer-wise functional understanding of the importance of DL system components and use this information to assess the semantic diversity of a test set. Our empirical evaluation on several DL systems and across multiple DL datasets demonstrates the usefulness and effectiveness of DeepImportance.","2574-1926","978-1-4503-7122-3","","Semiconductor Research Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9270311","Deep Neural Networks;Software Testing","Neurons;Testing;Deep learning;Neural networks;Decision making;Training;Systematics","learning (artificial intelligence);program testing;safety-critical software","Importance-driven deep learning system testing;engineering intelligent applications;DL systems;security-critical applications;systematic testing methodology;IDC;layer-wise functional understanding;DL system components;test set;importance-driven test adequacy criterion;DeepImportance;safety-critical applications","","","","6","","1 Dec 2020","","","IEEE","IEEE Conferences"
"Poster: Toward the Development of Richer Properties for Recommender Systems","D. Shriver","Univ. of Nebraska-Lincoln, Lincoln, NE, USA","2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)","30 Aug 2018","2018","","","173","174","The performance of recommender systems is commonly characterized by metrics such as precision and recall. However, these metrics can only provide a coarse characterization of the system, as they offer limited intuition and insights on potential system anomalies, and may fail to provide a developer with an understanding of the strengths and weaknesses of a recommendation algorithm. In this work, we start to describe a model of recommender systems that defines a space of properties. We begin exploring this space by defining templates that relate to the properties of coverage and diversity, and we demonstrate how instantiated characteristics offer complementary insights to precision and recall.","2574-1934","978-1-4503-5663-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449486","software testing;recommender sytems","Recommender systems;Measurement;Collaboration;Filtering algorithms;Prediction algorithms;Space exploration","recommender systems","recommender systems;coarse characterization;potential system anomalies","","","","9","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Who Should Be Selected to Perform a Task in Crowdsourced Testing?","Q. Cui; J. Wang; G. Yang; M. Xie; Q. Wang; M. Li","Lab. for Internet Software Technol., Inst. of Software, Beijing, China; Lab. for Internet Software Technol., Inst. of Software, Beijing, China; Dept. of Comput. Sci., Texas State Univ., San Marcos, TX, USA; Lab. for Internet Software Technol., Inst. of Software, Beijing, China; Lab. for Internet Software Technol., Inst. of Software, Beijing, China; Lab. for Internet Software Technol., Inst. of Software, Beijing, China","2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)","11 Sep 2017","2017","1","","75","84","Crowdsourced testing is an emerging trend in software testing, which relies on crowd workers to accomplish test tasks. Due to the cost constraint, a test task usually involves a limited number of crowd workers. Furthermore, more workers does not necessarily result in detecting more bugs. Different workers, who may have different testing experience and expertise, may make much differences in the test outcomes. For example, some inappropriate workers may miss true bug, introduce false bugs or report duplicated bugs, which decreases the test quality. In current practice, a test task is usually dispatched in a random manner, and the quality of testing cannot be guaranteed. Therefore, it is important to select an appropriate subset of workers to perform a test task to ensure high bug detection rate. This paper introduces ExReDiv, a novel hybrid approach to select a set of workers for a test task. It consists of three key strategies: the experience strategy selects experienced workers, the relevance strategy selects workers with expertise relevant to the given test task, the diversity strategy selects diverse workers to avoid detecting duplicated bugs. We evaluate ExReDiv based on 42 test tasks from one of the largest crowdsourced testing platforms in China, and the experimental results show its effectiveness.","0730-3157","978-1-5386-0367-3","10.1109/COMPSAC.2017.265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029593","","Computer bugs;Testing;Software;Videos;History;Computer science;Market research","crowdsourcing;program debugging;program testing;software quality","crowdsourced testing;software testing;cost constraint;bug detection rate;ExReDiv;hybrid approach;test task;experience strategy;relevance strategy;diversity strategy;China","","9","","19","","11 Sep 2017","","","IEEE","IEEE Conferences"
"Cloud era in mobile application testing","K. Kaur; A. Kaur","School of IT, Apeejay Institute of Management Technical Campus, Jalandhar, India; I.K.G Punjab Technical University, Kapurthala, India","2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)","31 Oct 2016","2016","","","1057","1060","Mobile technology usage is exploding across the world. There are lakhs of mobile applications available which run on various mobile platforms such as Android, RIM, windows Mobile, Apple iOS and all. With this incredible growth of mobile applications, evidently developers are expected to deliver high quality, on time and within budget applications. Mobile application testing is considered as a challenging task because of various reasons such as ever-changing mobile devices, limited computational power, limited storage, limited energy, diversity of devices etc. There are various mobile application testing approaches such as testing on real devices, simulators, emulators and testing on cloud. As with advent of cloud computing technology the entire IT enterprises are providing services on cloud. Cloud testing is a software testing using cloud computing offering various benefits as compared to traditional testing strategies. The focus of this paper is to provide baselines for testing the mobile app on cloud which is currently an emerging field in testing. This paper discusses cloud computing, trend of testing on cloud along with various advantages and challenges confronted in testing of mobile applications on cloud.","","978-9-3805-4421-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7724423","Cloud computing;Cloud services;Cloud testing Challenges;Cloud;Mobile Applications","Decision support systems","cloud computing;mobile computing;program testing","cloud era;mobile application testing;mobile technology usage;mobile platforms;cloud computing technology;IT enterprises;cloud testing;software testing;mobile app testing","","","","6","","31 Oct 2016","","","IEEE","IEEE Conferences"
"Exhaustive Exploration of the Failure-Oblivious Computing Search Space","T. Durieux; Y. Hamadi; Z. Yu; B. Baudry; M. Monperrus","Univ. of Lille & Inria, Lille, France; Ecole Polytech., Palaiseau, France; Univ. of Lille & Inria, Lille, France; R. Inst. of Technol., Stockholm, Sweden; R. Inst. of Technol., Stockholm, Sweden","2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)","28 May 2018","2018","","","139","149","High-availability of software systems requires automated handling of crashes in presence of errors. Failure-oblivious computing is one technique that aims to achieve high availability. We note that failure-obliviousness has not been studied in depth yet, and there is very few study that helps understand why failure-oblivious techniques work. In order to make failure-oblivious computing to have an impact in practice, we need to deeply understand failure-oblivious behaviors in software. In this paper, we study, design and perform an experiment that analyzes the size and the diversity of the failure-oblivious behaviors. Our experiment consists of exhaustively computing the search space of 16 field failures of large-scale open-source Java software. The outcome of this experiment is a much better understanding of what really happens when failure-oblivious computing is used, and this opens new promising research directions.","","978-1-5386-5012-7","10.1109/ICST.2018.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367043","failure oblivious;repair search space;runtime repair","Computer crashes;Java;Software;Space exploration;Fault tolerance;Fault tolerant systems;Computational modeling","failure analysis;Java;program debugging;public domain software","failure-oblivious computing search space;high-availability;high availability;failure-obliviousness;failure-oblivious behaviors;software systems;failure-oblivious techniques;large-scale open-source Java software","","2","","24","","28 May 2018","","","IEEE","IEEE Conferences"
"Dependency-aware Form Understanding","S. Zhang; Y. Li; W. Yan; Y. Guo; X. Chen","Peking University,MOE Key Lab of HCST,Dept of Computer Science,Beijing,China; Microsoft Research,Beijing,China; Beijing University of Posts and Telecommunications,Beijing,China; Peking University,MOE Key Lab of HCST,Dept of Computer Science,Beijing,China; Peking University,MOE Key Lab of HCST,Dept of Computer Science,Beijing,China","2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE)","11 Feb 2022","2021","","","139","149","Form understanding is an important task in many fields such as software testing, AI assistants, and improving accessibility. One key goal of understanding a complex set of forms is to identify the dependencies between form elements. However, it remains a challenge to capture the dependencies accurately due to the diversity of UI design patterns and the variety in development experiences. In this paper, we propose a deep-learning-based approach called DependEX, which integrates convolutional neural networks (CNNs) and transformers to help understand dependencies within forms. DependEX extracts semantic features from UI images using CNN-based models, captures contextual patterns using a multilayer transformer encoder module, and models dependencies between form elements using two embedding layers. We evaluate DependEX with a large-scale dataset from mobile Web applications. Experimental results show that our proposed model achieves over 92% accuracy in identifying dependencies between UI elements, which significantly outperforms other competitive methods, especially for heuristic-based methods. We also conduct case studies on automatic form filling and test case generation from natural language (NL) instructions, which demonstrates the applicability of our approach.","2332-6549","978-1-6654-2587-2","10.1109/ISSRE52982.2021.00026","National Key Research and Development Program(grant numbers:2017YFB1001904); National Natural Science Foundation of China(grant numbers:61772042); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700239","Form understanding;dependencies;deep learning;CNN;automatic form filling","Software testing;Semantics;Natural languages;Transformers;Feature extraction;Nonhomogeneous media;Filling","","","","","","38","","11 Feb 2022","","","IEEE","IEEE Conferences"
"Predicting Cutterhead Torque for TBM based on Different Characteristics and AGA-Optimized LSTM-MLP","S. Zhang; Q. Du; S. Zhao","Tongji University,Master of Software Engineering,Shanghai,China; Tongji University,Faculty of Software Engineering and Software Testing,Shanghai,China; Tongji University,Civil Engineering,Shanghai,China","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","1165","1171","Adaptive adjustment of excavation parameters makes a significant role in the process of tunneling by tunnel boring machine (TBM), which ensures the tunneling carried out safely and efficiently. Though substantial effort has been devoted to this area, there is still a lack of a comprehensive method for TBM data analysis. In this paper, we analyzed the TBM data from different perspectives. The data source is from the Songhua River Water Conveyance Project. In order to facilitate the processing and analysis of the data, we proposed the concepts of rising characteristic interval (RCI) and stable characteristic interval (SCI), which are the first 30 seconds of the rising stage and one sixth of the center part of the stable stage respectively. As a key parameter, the cutterhead torque (T), which reflects the interaction between the cutter and the soil, is selected as our prediction target. In order to forecast the value of T in the SCIs, the time series characteristic and the non time series (mean and variance) characteristic of the important excavation parameters in the RCIs are analyzed. A sequential combination of long short-term memory (LSTM) and multi-layer perceptrons (MLP), LSTM-MLP for short, is used to make a comprehensive analysis of the two characteristics. Notably, adaptive genetic algorithm (AGA) was employed to optimize the topology structure and the hyper parameters of our neural network, which ensures the convergence of the basic genetic algorithm and maintains the diversity of the population at the same time. The experimental results indicate that, LSTM-MLP performs better in comparison with LSTM network and backpropagation neural network (BPNN, a kind of MLP). Our work provides a reference for the control and optimization of TBM’s excavation parameters. To make our results fully reproducible, all the relevant source codes and the preprocessed dataset are publicly available at https://github.com/Dandelionslove/LSTM MLP for TBM.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9659274","Delta; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659274","","Torque;Network topology;Geology;Time series analysis;Neural networks;Tunneling;Excavation","backpropagation;boring machines;construction equipment;data analysis;genetic algorithms;multilayer perceptrons;neural nets;time series;tunnels","time series characteristic;important excavation parameters;short-term memory;adaptive genetic algorithm;hyper parameters;basic genetic algorithm;backpropagation neural network;optimization;TBM's excavation parameters;cutterhead torque;AGA-optimized LSTM-MLP;adaptive adjustment;tunnel boring machine;tunneling;substantial effort;TBM data analysis;data source;Songhua River Water Conveyance Project;stable characteristic interval;30 seconds;rising stage;center part;stable stage;prediction target;time 30.0 s","","","","25","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"Studying the Characteristics of a ""Good"" GUI Test Suite","Q. Xie; A. M. Memon","University of Maryland, College Park, MD; University of Maryland, College Park, MD","2006 17th International Symposium on Software Reliability Engineering","11 Dec 2006","2006","","","159","168","The widespread deployment of graphical-user interfaces (GUIs) has increased the overall complexity of testing. A GUI test designer needs to perform the daunting task of adequately testing the GUI, which typically has very large input interaction spaces, while considering tradeoffs between GUI test suite characteristics such as the number of test cases (each modeled as a sequence of events), their lengths, and the event composition of each test case. There are no published empirical studies on GUI testing that a GUI test designer may reference to make decisions about these characteristics. Consequently, in practice, very few GUI testers know how to design their test suites. This paper takes the first step towards assisting in GUI test design by presenting an empirical study that evaluates the effect of these characteristics on testing cost and fault detection effectiveness. The results show that two factors significantly effect the fault-detection effectiveness of a test suite: (1) the diversity of states in which an event executes and (2) the event coverage of the suite. Test designers need to improve the diversity of states in which each event executes by developing a large number of short test cases to detect the majority of ""shallow"" faults, which are artifacts of modern GUI design. Additional resources should be used to develop a small number of long test cases to detect a small number of ""deep"" faults","2332-6549","0-7695-2684-5","10.1109/ISSRE.2006.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4021981","","Graphical user interfaces;Software testing;Fault detection;Costs;Application software;Packaging;Computer science;Educational institutions;Performance evaluation;Event detection","fault diagnosis;graphical user interfaces;program debugging;program testing","graphical user interface testing;fault detection","","23","","17","","11 Dec 2006","","","IEEE","IEEE Conferences"
"Information technology preparations for the Pluto encounter from mission operations to science retrieval","G. Griffith; P. Hartman","The Johns Hopkins University, Applied Physics Laboratory (APL), Laurel, MD 20723-6099; The Johns Hopkins University, Applied Physics Laboratory (APL), Laurel, MD 20723-6099","2017 IEEE Aerospace Conference","8 Jun 2017","2017","","","1","6","The Space Exploration Sector (SES) of the Johns Hopkins University Applied Physics Laboratory (APL) currently houses the Mission Operations Center (MOC) for the National Aeronautics and Space Administration (NASA) New Horizons mission. In July 2015, New Horizons encountered Pluto. Prior to this encounter, APL had to prepare for its key role in this historic event by refining a number of its information technology (IT) capabilities. Additional redundancy was built into our infrastructure to ensure diversity. A Remote Mission Operations Center (RMOC) was designed, developed, and installed at the Jet Propulsion Laboratory (JPL) to be used in the event of a catastrophic event on the East Coast that would render both the MOC and the Disaster Recovery Control Center (DRCC) unusable. The Emergency Control Center (ECC) at the Goldstone Complex, which serves as the backup to JPL's Deep Space Operations Center (DSOC), was upgraded to support the New Horizons mission. The amount of web traffic in the weeks prior to, during, and in the weeks following the encounter were expected to far exceed the Laboratory's capabilities for handling such traffic. To reduce the risk of web traffic overloading the APL IT security infrastructure and possibly causing a bottleneck in our intrusion detection and intrusion prevention devices, we elected to move our web services for the Pluto encounter data to Akamai. APL modified Internet service provider contracts to allow for burst traffic and established connectivity for regional diversity. APL took cyber preparedness seriously, performing numerous tabletop exercises to prepare response procedures for various cyber events that would minimize the impact on New Horizon operations. The New Horizons Science Team began placing increased demands on APL six months prior to the encounter, holding numerous Operational Readiness Tests. Each team involved in these tests had specific requirements related to space allocations, network configurations, printers, computers, and peripherals that needed to be settled. Enterprise coordination was very important. The many different APL departments worked together, and the Laboratory was ready to host the event well in advance of the encounter. This paper discusses the basic mission architecture, the plan that was developed to support the Pluto encounter, improvements instituted (the network upgrades, addition of the RMOC and ECC, additional redundancy, etc.), scheduling constraints, resolution of unforeseen problems, and lessons learned.","","978-1-5090-1613-6","10.1109/AERO.2017.7943692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7943692","","Servers;Printers;Computer architecture;Software;Testing;Buildings;Pluto","aerospace computing;information technology;Pluto;redundancy;security of data","science retrieval;pluto encounter;information technology preparation;space exploration sector;SES;Johns Hopkins university applied physics laboratory;APL;MOC;National Aeronautics and Space Administration;NASA;new horizons mission;remote mission operations center;RMOC;disaster recovery control center;DRCC;emergency control center;ECC;goldstone complex;deep space operations center;DSOC;web traffic risk reduce;APL IT security infrastructure;intrusion prevention;intrusion detection;Internet service provider;space allocations;network configuration;printer;computer;peripheral;enterprise coordination;scheduling constraints","","","","1","","8 Jun 2017","","","IEEE","IEEE Conferences"
"An Adaptive Software Fault-Tolerant Framework for Ubiquitous Vehicular Technologies","M. Rizwan; A. Nadeem; M. Iqbal; S. Sarwar; M. Safyan; Z. U. Qayyum",NA; NA; NA; NA; NA; NA,"IEEE Communications Standards Magazine","7 Jan 2021","2020","4","4","26","32","The probability of the occurrence of faults increases manifolds when program lines of code exceed a few thousand in ubiquitous applications. Fault mitigation in ubiquitous applications, such as those of autonomous vehicular technologies (VTs), has not been effective even with the use of formal methods. Faults in such applications require exhaustive testing for a timely fix, which seems infeasible computationally. This emphasizes the imperative role of software fault tolerance (SFT) for autonomous applications. Several SFT techniques have been proposed, but failures revealed in VT applications imply that existing SFT techniques need to be fine-tuned. In this article, current replication-based SFT techniques are analyzed and classified with respect to their diversity, adjudication, and adaptivity. Essential parameters (reliability, time, variance, etc.) for adjudication, diversity, and adaptiveness are recorded. The identified parameters are mapped to different techniques (e.g., AFTRC, SCOP, VFT) for observing their shortcomings. Consequently, a generic framework named Diverse Parallel Adjudication for Software Fault Tolerance (DPA-SFT) is proposed. DPA-SFT addresses the shortcomings of existing SFT techniques for VTs with the added value of parallel and diverse adjudication. A prototype implementation of the proposed framework has been developed for assessing the viability of DPA-SFT over modules of VT. An empirical comparison of the proposed framework is performed with prevalent techniques (AFTRC, SCOP, VFT, etc). A thorough evaluation suggests that DPA-SFT performs better than contemporary SFT techniques in VTs due to its parallel and diverse adjudication.","2471-2833","","10.1109/MCOMSTD.001.2000012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316439","","Fault tolerance;Vehicular and wireless technologies;Fault tolerant systems;Prototypes;Software testing;Software reliability","fault tolerant computing;probability;software fault tolerance;traffic engineering computing;ubiquitous computing","ubiquitous vehicular technologies;fault mitigation;autonomous vehicular technologies;software fault tolerance;autonomous applications;VT applications;adaptiveness;DPA-SFT addresses;diverse adjudication;diverse parallel adjudication;replication-based SFT techniques;adaptive software fault-tolerant framework","","","","15","","7 Jan 2021","","","IEEE","IEEE Magazines"
"The ART of Divide and Conquer: An Innovative Approach to Improving the Efficiency of Adaptive Random Testing","C. Chow; T. Y. Chen; T. H. Tse","Univ. of Hong Kong, Hong Kong, China; Swinburne Univ. of Technol., Hawthorn, VIC, Australia; Univ. of Hong Kong, Hong Kong, China","2013 13th International Conference on Quality Software","23 Sep 2013","2013","","","268","275","Test case selection is a prime process in the engineering of test harnesses. In particular, test case diversity is an important concept. In order to achieve an even spread of test cases across the input domain, Adaptive Random Testing (ART) was proposed such that the history of previously executed test cases are taken into consideration when selecting the next test case. This was achieved through various means such as best candidate selection, exclusion, partitioning, and diversity metrics. Empirical studies showed that ART algorithms make good use of the concept of even spreading and achieve 40 to 50% improvement in test effectiveness over random testing in revealing the first failure, which is close to the theoretical limit. However, the computational complexity of ART algorithms may be quadratic or higher, and hence efficiency is an issue when a large number of previously executed test cases are involved. This paper proposes an innovative divide-and-conquer approach to improve the efficiency of ART algorithms while maintaining their performance in effectiveness. Simulation studies have been conducted to gauge its efficiency against two most commonly used ART algorithms, namely, fixed size candidate set and restricted random testing. Initial experimental results show that the divide-and-conquer technique can provide much better efficiency while maintaining similar, or even better, effectiveness.","2332-662X","978-0-7695-5039-8","10.1109/QSIC.2013.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6605937","adaptive random testing;divide and conquer;efficiency;effectiveness;software testing;test harness","Subspace constraints;Power capacitors;Testing;Computational complexity;Algorithm design and analysis;Measurement;Partitioning algorithms","computational complexity;program testing","innovative approach;adaptive random testing;test case selection;computational complexity;ART algorithms;innovative divide-and-conquer approach;fixed size candidate set;restricted random testing","","12","","16","","23 Sep 2013","","","IEEE","IEEE Conferences"
"Similarity-Based Search for Model Checking: A Pilot Study with Java PathFinder","E. Ibrahimov; J. Wang; Z. Q. Zhou","Sch. of Comput. Sci. & Software Eng., Univ. of Wollongong, Wollongong, NSW, Australia; Sch. of Comput. Sci. & Software Eng., Univ. of Wollongong, Wollongong, NSW, Australia; Sch. of Comput. Sci. & Software Eng., Univ. of Wollongong, Wollongong, NSW, Australia","2013 13th International Conference on Quality Software","23 Sep 2013","2013","","","238","244","When a model checker cannot explore the entire state space because of limited resources, model checking becomes a kind of testing with an attempt to find a failure (violation of properties) quickly. We consider two state sequences in model checking: (i) the sequence in which new states are generated, and (ii) the sequence in which the states generated in sequence (i) are checked for property violation. We observe that neighboring states in sequence (i) often have similarities in certain ways. Based on this observation we propose a search strategy, which generates sequence (ii) in such a way that similar states are evenly spread over the sequence. As a result, neighboring states in sequence (ii) can have a higher diversity. A pilot empirical study with Java Path Finder suggests that the proposed strategy can outperform random search in terms of creating equal or smaller number of states to detect a failure.","2332-662X","978-0-7695-5039-8","10.1109/QSIC.2013.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6605933","Model checking;random search;similarity-based search;heuristics;adaptive random sequence;Java PathFinder","Scattering;Java;Subspace constraints;Model checking;Search problems;Random sequences","failure analysis;Java;program testing;program verification","similarity-based search;model checking;Java PathFinder;state space;software testing;software failure;state sequences;software property violation;empirical analysis","","","","6","","23 Sep 2013","","","IEEE","IEEE Conferences"
"Testing of Component-Based Software: A Metamorphic Testing Methodology","X. Lu; Y. Dong; C. Luo","Sch. of Comput. Sci., Northwestern Polytech. Univ., Xi'an, China; Sch. of Comput. Sci., Northwestern Polytech. Univ., Xi'an, China; Sch. of Comput. Sci., Northwestern Polytech. Univ., Xi'an, China","2010 7th International Conference on Ubiquitous Intelligence & Computing and 7th International Conference on Autonomic & Trusted Computing","13 Dec 2010","2010","","","272","276","In the process of testing Component-based software, Oracle problem comes into existence frequently because of the diversity of component running environment and complicated interactions among components. In this paper, we exploit the features of the component-based software and metamorphic testing (MT) to alleviate the issues. The metamorphic class will invoke relevant component to execute test cases and use their metamorphic relations to defect faults. Test cases for the unit test phase are proposed to generate follow-up test cases for the integration test phase. It has potentials to shift the testing effort from the construction of the integration test sets to the development of metamorphic relations.","","978-1-4244-9043-1","10.1109/UIC-ATC.2010.75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5667186","Component testing;Metamorphic Testing;Metamorphic Relation","Testing;Exchange rates;Programming;Software engineering;Conferences;Embedded software","object-oriented programming;program testing","component-based software testing;metamorphic testing methodology;Oracle problem;component running environment;complicated interactions;unit test phase","","7","","12","","13 Dec 2010","","","IEEE","IEEE Conferences"
"A method for developing agent-based models of socio-technical systems","I. Nikolic; A. Ghorbani","Faculty of Technology, Policy and Management, Section Energy and Industry, TU Delft, Postbus 5015, 2600 GA, Delft; Faculty of Technology, Policy and Management, Section Energy and Industry, TU Delft, Postbus 5015, 2600 GA, Delft","2011 International Conference on Networking, Sensing and Control","13 Jun 2011","2011","","","44","49","Agent-based modeling is one of the popular tools for analyzing complex socio-technical systems. Because of the complex nature of such systems a systematic methodology is required to guide the modeling process. By studying the existing methodologies in MAS we distinguished four major differences between MAS and ABM regarding goals, system scale and diversity, level of system understanding and verification and validation concerns. In this paper we take these differences into account and based on more than 25 case studies, we present a methodological framework for developing agent-based models that consists of five general iterative phases. These phases namely: system analysis, model design, detailed design, implementation and evaluation further consists of smaller step that are also addressed in this paper. This methodology provides a tool independent template while respecting the specific requirements for ABM.","","978-1-4244-9573-3","10.1109/ICNSC.2011.5874914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5874914","","Analytical models;Computational modeling;Biological system modeling;Software;Testing;Unified modeling language;Ontologies","iterative methods;large-scale systems;multi-agent systems","agent based modeling;socio-technical systems;general iterative phases;tool independent template","","16","","13","","13 Jun 2011","","","IEEE","IEEE Conferences"
"Probabilistic distribution factors assessment using OptimalPowerPrice Mathematica software, case study: Test 25 buses test power system","O. Pop; D. Paunescu; S. Kilyeni; M. Nemes; A. Kilyeni; C. Barbulescu","""Politehnica"" University, Electrical Power Engineering Department, Timisoara, Romania; ""Politehnica"" University, Department of Mathematics, Timisoara, Romania; ""Politehnica"" University, Electrical Power Engineering Department, Timisoara, Romania; ""Politehnica"" University, Electrical Power Engineering Department, Timisoara, Romania; ""Politehnica"" University, Communication and Foreign Languages Department, Timisoara, Romania; ""Politehnica"" University, Electrical Power Engineering Department, Timisoara, Romania","2009 5th International Symposium on Applied Computational Intelligence and Informatics","26 Jun 2009","2009","","","453","458","Competition within the electric power systems has proven the importance of distribution factors assessment. In addition, load characteristic is unpredictable, leading to a diversity of supply paths. As a result, probabilistic power flow analysis can provide better tools and information for determining the tracing of the generator-consumer path. In this paper, the authors analyze the probabilistic distribution power factors method using the OptimalPowerPrice Mathematica software. Moreover, a correlation between the generalized distribution factors is obtained by means of probabilistic and deterministic methods. The case study in Section IV presents the above approach using a 25 buses test power system.","","978-1-4244-4477-9","10.1109/SACI.2009.5136291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5136291","distribution factors;probabilistic power flow;optimal power price","Software testing;System testing;Power systems;Computational intelligence;Informatics","mathematics computing;power distribution;power engineering computing","probabilistic distribution factors;OptimalPowerPrice Mathematica software;electric power systems;probabilistic power flow analysis;generator-consumer path","","4","","16","","26 Jun 2009","","","IEEE","IEEE Conferences"
"Cecil: a sequencing constraint language for automatic static analysis generation","K. M. Olender; L. J. Osterweil","Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA; Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA","IEEE Transactions on Software Engineering","6 Aug 2002","1990","16","3","268","280","A flexible and general mechanism for specifying problems relating to the sequencing of events and mechanically translating them into dataflow analysis algorithms capable of solving those problems is presented. Dataflow analysis has been used for quite some time in compiler code optimization. Most static analyzers have been custom-built to search for fixed and often quite limited classes of dataflow conditions. It is shown that the range of sequences for which it is interesting and worthwhile to search in actually quite broad and diverse. A formalism for specifying this diversity of conditions is created. It is shown that these conditions can be modeled essentially as dataflow analysis problems for which effective solutions are known. It is also shown how these solutions can be exploited to serve as the basis for mechanical creation of analyzers for these conditions.<<ETX>></ETX>","1939-3520","","10.1109/32.48935","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=48935","","Software quality;Computer science;Data analysis;Software tools;Software testing;Security;Software engineering;Algorithm design and analysis;Optimizing compilers;Automata","automatic programming;parallel programming;program compilers;specification languages","Cecil;sequencing constraint language;automatic static analysis generation;general mechanism;dataflow analysis algorithms;compiler code optimization;custom-built;dataflow conditions;dataflow analysis problems","","63","2","34","","6 Aug 2002","","","IEEE","IEEE Journals"
"The development of a focal plane array data system for component-level characterization and real-time mission simulation testing","R. H. Fugerer; D. J. Hervig; L. L. Holt; C. R. Banks; D. I. Jennings; T. J. Worley","Micro Craft Technol./AEDC Oper., Arnold AFB, TN, USA; Micro Craft Technol./AEDC Oper., Arnold AFB, TN, USA; Micro Craft Technol./AEDC Oper., Arnold AFB, TN, USA; Micro Craft Technol./AEDC Oper., Arnold AFB, TN, USA; Micro Craft Technol./AEDC Oper., Arnold AFB, TN, USA; Micro Craft Technol./AEDC Oper., Arnold AFB, TN, USA","ICIASF '95 Record. International Congress on Instrumentation in Aerospace Simulation Facilities","6 Aug 2002","1995","","","2/1","210","This paper will describe the USAF Arnold Engineering Development Center (AEDC) technology efforts that provide signal processing and data system support for infrared (IR) Focal Plane Array (FPA) testing. The requirements for AEDC space sensor testing range from component-level FPA characterization to advanced mission simulation. The technology efforts underway address these requirements by developing hardware and software that meet AEDC's generic needs for FPA testing. Component-level FPA characterization places unique requirements on system fidelity and bandwidth performance. Diversity in sensor types being tested and levels of sensor integration creates the need for versatility in data handling and sensor interfaces. Mission simulation requirements emphasize the need for extended data storage, system throughput, and data display capabilities. A signal processing system will be presented which addresses AEDC's requirements for component-level sensor operation data acquisition, and flexible interface architectures that can be modified quickly to accommodate different sensor interfaces and data formats. The system will also address the need for high-speed storage of very large data arrays during mission simulation testing. Techniques used to verify and validate system operation will also be presented.","","0-7803-2088-3","10.1109/ICIASF.1995.519108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=519108","","Data systems;Sensor phenomena and characterization;Space technology;Array signal processing;System testing;Sensor systems;Data engineering;Space missions;Hardware;Software testing","focal planes;infrared imaging;aerospace testing;aerospace simulation;data acquisition;calibration","focal plane array data system;component-level characterization;real-time mission simulation testing;USAF Arnold Engineering Development Center;signal processing support;data system support;advanced mission simulation;sensor integration;data handling;system throughput;data acquisition;flexible interface architectures;radiometric calibration;IR imaging","","","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Correspondent computing for software implementation fault tolerance","P. . -N. Lee; J. Blankenship","Dept. of Comput. Sci., Houston Univ., University Park, TX, USA; Dept. of Comput. Sci., Houston Univ., University Park, TX, USA","Proceedings of the 1990 Symposium on Applied Computing","6 Aug 2002","1990","","","12","19","Correspondent computing, which achieves diversity through correspondent operations and uses a decision algorithm which is based on correspondence checking rather than majority voting or assertion checking, is proposed. The significance of this is that multiple diverse software versions are produced from a single algorithm and the assertions used in the correspondence test are more exact and easier to formulate. The ability of the correspondent computing method to generate correspondent versions systematically is further enhanced by the introduction of 'partial' reciprocal operations. Their role in creating reciprocal correspondent program modules tolerant to software implementation faults is explored in an actual program which implements a well-known triangle algorithm.<<ETX>></ETX>","","0-8186-2031-5","10.1109/SOAC.1990.82133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=82133","","Fault tolerance;Fault tolerant systems;Voting;Software algorithms;Programming profession;Software testing;Software systems;Application software;Computer science;Space vehicles","fault tolerant computing;software engineering","software implementation fault tolerance;correspondent operations;decision algorithm;correspondence checking;multiple diverse software versions;correspondence test;correspondent computing method;reciprocal operations;reciprocal correspondent program modules;well-known triangle algorithm","","","","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Enabling the Large-Scale Emulation of Internet of Things Firmware With Heuristic Workarounds","D. Kim; E. Kim; M. Kim; Y. Jang; Y. Kim",Korea Advanced Institute of Science and Technology; Korea Advanced Institute of Science and Technology; Affiliated Institute of the Electronics and Telecommunications Research Institute; Oregon State University; Korea Advanced Institute of Science and Technology,"IEEE Security & Privacy","28 Oct 2021","2021","19","6","26","35","To evaluate Internet of Things device security, researchers have attempted to emulate and dynamically analyze firmware. However, this approach cannot deal with complex hardware/environmental diversities. We show that heuristic workarounds can enable firmware emulation and facilitate the discovery of vulnerabilities.","1558-4046","","10.1109/MSEC.2021.3076226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431371","","Microprogramming;Internet of Things;Computer security;Software testing;Performance evaluation;Wireless communication;Complexity theory;Software engineering;Heuristic algorithms","firmware;Internet of Things;security of data","heuristic workarounds;firmware emulation;large-scale emulation;Internet of Things firmware;Internet of Things device security","","","","15","IEEE","14 May 2021","","","IEEE","IEEE Magazines"
"Evaluating a Training Process in a Handover Context","A. S. Khan; M. Kajko-Mattsson","Sch. of ICT, KTH R. Inst. of Technol., Stockholm, Sweden; Sch. of ICT, KTH R. Inst. of Technol., Stockholm, Sweden","2011 37th EUROMICRO Conference on Software Engineering and Advanced Applications","3 Nov 2011","2011","","","443","450","Although there exist some people management process models related to the education and training of software engineers, there are no process models that are adapted to specific software engineering contexts and processes. In this paper, we suggest a set of education and training activities that are applicable in the context of a handover process. We then evaluate these activities within twenty organizations. Although our results reveal great diversity of using these activities, they still show that they are realistic and appropriately mirror the industrial status within a handover context.","2376-9505","978-1-4577-1027-8","10.1109/SEAA.2011.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6068382","transition;education;knowledge;transfer","Training;Organizations;Maintenance engineering;Materials;Software;Testing;Context","computer science education;software engineering;training","training process;handover context;people management process model;education;software engineers;software engineering context","","","","12","","3 Nov 2011","","","IEEE","IEEE Conferences"
"Automated optimum test case generation using web navigation graphs","A. Shahzad; S. Raza; M. N. Azam; K. Bilal; Inam-ul-Haq; S. Shamail","Department of Computer Science, LUMS, DHA, Lahore; Department of Computer Science, LUMS, DHA, Lahore; Department of Computer Science, LUMS, DHA, Lahore; Department of Computer Science, LUMS, DHA, Lahore; Department of Computer Science, LUMS, DHA, Lahore; Department of Computer Science, LUMS, DHA, Lahore","2009 International Conference on Emerging Technologies","11 Dec 2009","2009","","","427","432","Increased diversity and complexity of software systems derived the need for test automation. Test Automation is the use of software for automatic execution of tests, comparison of results with expected outcome, setting up preconditions for test and test reporting functions. Model based testing is a test automation approach that generates and maintains more useful and flexible tests from explicit descriptions of the application. Graph theory techniques have been an important part of model based testing and several graph theory techniques have been proposed in the literature. We used a famous graph theory technique called maximum network flows for generating minimum number of test cases covering all features of a system. We used a web based case study to describe the working of the proposed optimum path finding algorithm. We found certain constraints on web navigation graph in order to completely reflect the system in the form of a graph. The resulting web navigation graph is given as input to the algorithm that we implemented, that returns the optimal test cases for the web application system. We then graphically showed the optimality and feature coverage of the algorithm with respect to the case study.","","978-1-4244-5630-7","10.1109/ICET.2009.5353134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5353134","","Automatic testing;Navigation;Software testing;System testing;Graph theory;Automation;Application software;Software systems;Computer science;Programming","graph theory;Internet;program testing","optimum test case generation;Web navigation graphs;test automation;model based testing;graph theory techniques;maximum network flows","","","","16","","11 Dec 2009","","","IEEE","IEEE Conferences"
"A viable system perspective on enterprise architecture management","S. Buckl; F. Matthes; C. M. Schweda","Chair for Informatics 19, Technische Universität München (TUM), D-85748, Garching; Chair for Informatics 19, Technische Universität München (TUM), D-85748, Garching; Chair for Informatics 19, Technische Universität München (TUM), D-85748, Garching","2009 IEEE International Conference on Systems, Man and Cybernetics","4 Dec 2009","2009","","","1483","1488","A number of approaches towards enterprise architecture (EA) management is proposed in literature, differing in the underlying understanding of the EA as well as in the description of the function for performing EA management. These plurality of methods and models should be interpreted as an indicator of the low maturity of the research area. In contrast, some researchers see it as inevitable consequence of the diversity of the enterprises under consideration. Staying to this interpretation, we approach the topic of EA management from a cybernetic point of view. Thereby, we elicit constituents, which should be considered in every EA management function based on a viable system perspective on the topic. From this perspective, we further revisit selected EA management approaches and show to which extent they allude to the viable system nature of the EA.","1062-922X","978-1-4244-2793-2","10.1109/ICSMC.2009.5346262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346262","Enterprise Architecture;Cybernetic;Viable System Model;EA management Process;EA management governance","Cybernetics;Conference management;Process planning;Identity management systems;USA Councils;Informatics;Guidelines;Programming;Software testing;Standardization","electronic commerce;information management","enterprise architecture management;cybernetic;EA management function;viable system model","","25","","33","","4 Dec 2009","","","IEEE","IEEE Conferences"
"Continuous Experimentation and A/B Testing: A Mapping Study","R. Ros; P. Runeson","Lund Univ., Lund, Sweden; Lund Univ., Lund, Sweden","2018 IEEE/ACM 4th International Workshop on Rapid Continuous Software Engineering (RCoSE)","30 Aug 2018","2018","","","35","41","Background. Continuous experimentation (CE) has recently emerged as an established industry practice and as a research subject. Our aim is to study the application of CE and A/B testing in various industrial contexts. Objective. We wanted to investigate whether CE is used in different sectors of industry, by how it is reported in academic studies. We also wanted to explore the main topics researched to give an overview of the subject and discuss future research directions. Method. We performed a systematic mapping study of the published literature and included 62 papers, using a combination of database search and snowballing. Results. Most reported software experiments are done online and with software delivered as a service, although varied exemptions exist for e.g., financial software and games. The most frequently researched topics are challenges to conduct experiments and statistical methods for software experiments. Conclusions. The software engineering research on CE is still in its infancy. There are future research opportunities in evaluation research of technical topics and investigations of ethical experimentation. We conclude that the included studies show that A/B testing is applicable to a diversity of software and organisations.","","978-1-4503-5745-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8452106","Continuous experimentation;A/B testing;Mapping study","Software;Testing;Software engineering;Databases;Data mining;Industries;Companies","environmental factors;organisational aspects;software engineering;statistical analysis","ethical experimentation;A/B testing;continuous experimentation;CE;established industry practice;industrial contexts;academic studies;future research directions;systematic mapping study;published literature;database search;software experiments;financial software;frequently researched topics;statistical methods;software engineering research","","","","32","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Efficiently represent diverse system field usage in reliability testing","P. J. M. Sonnemans; A. Balasubramanian; K. Kevrekedis; M. J. Newby","Eindhoven University of Technology, The Netherlands; Eindhoven University of Technology, The Netherlands; Eindhoven University of Technology, The Netherlands; City University London, UK","2008 Annual Reliability and Maintainability Symposium","15 May 2009","2008","","","132","136","This paper addresses the problem how to represent diverse field usage of professional systems in an efficient way, so that field usage can be incorporated in reliability tests. With diverse we mean the variability in system use in the field. Operational Profiles are constructed from system field data to represent system field use. A clustering technique is introduced and applied in a strategic way to reduce the diversity in describing diverse system use in the field. In this way testing effort could be reduced by a factor 87 while maintaining 70 % similarity with the original system field data.","0149-144X","978-1-4244-1460-4","10.1109/RAMS.2008.4925783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4925783","reliability;testing;system use;operational profile;clustering;grouping;field performance","System testing;Biomedical imaging;Medical diagnostic imaging;Hospitals;Software testing;Maintenance;Reliability;Automotive engineering;Manufacturing;Medical services","life testing;reliability theory;statistical analysis","system reliability testing;diverse system field usage;professional systems;clustering technique","","1","","10","","15 May 2009","","","IEEE","IEEE Conferences"
"Manifold for Machine Learning Assurance","T. Byun; S. Rayadurgam","University of Minnesota,Minneapolis,Minnesota; University of Minnesota,Minneapolis,Minnesota","2020 IEEE/ACM 42nd International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)","8 Apr 2021","2020","","","97","100","The increasing use of machine-learning (ML) enabled systems in critical tasks fuels the quest for novel verification and validation techniques yet grounded in accepted system assurance principles. In traditional system development, model-based techniques have been widely adopted, where the central premise is that abstract models of the required system provide a sound basis for judging its implementation. We posit an analogous approach for ML systems using an ML technique that extracts from the high-dimensional training data implicitly describing the required system, a low-dimensional underlying structure-a manifold. It is then harnessed for a range of quality assurance tasks such as test adequacy measurement, test input generation, and runtime monitoring of the target ML system. The approach is built on variational autoencoder, an unsupervised method for learning a pair of mutually near-inverse functions between a given high-dimensional dataset and a low-dimensional representation. Preliminary experiments establish that the proposed manifold-based approach, for test adequacy drives diversity in test data, for test generation yields fault-revealing yet realistic test cases, and for run-time monitoring provides an independent means to assess trustability of the target system's output.","","978-1-4503-7126-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397537","machine learning testing;neural networks;variational autoencoder","Manifolds;Software testing;Training data;Machine learning;Test pattern generators;Task analysis;Monitoring","data handling;learning (artificial intelligence);program testing;software quality","machine learning assurance;model-based techniques;ML systems;high-dimensional training data;quality assurance tasks;low-dimensional representation;manifold-based approach","","2","","16","","8 Apr 2021","","","IEEE","IEEE Conferences"
"Search-Based Testing of Ajax Web Applications","A. Marchetto; P. Tonella","Fondazione Bruno Kessler, IRST, Trento; Fondazione Bruno Kessler, IRST, Trento","2009 1st International Symposium on Search Based Software Engineering","29 May 2009","2009","","","3","12","Ajax is an emerging Web engineering technology that supports advanced interaction features that go beyond Webpage navigation. The Ajax technology is based on asynchronous communication with the Web server and direct manipulation of the GUI, taking advantage of reflection.Correspondingly, new classes of Web faults are associated with Ajax applications.In previous work, we investigated a state-based testing approach, based on semantically interacting events. The main drawback of this approach is that exhaustive generation of semantically interacting event sequences limits quite severely the maximum achievable length, while longer sequences would have higher fault exposing capability. In this paper, we investigate a search-based algorithm for the exploration of the huge space of long interaction sequences, in order to select those that are most promising, based on a measure of test case diversity.","","978-0-7695-3675-0","10.1109/SSBSE.2009.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5033174","Web Testing;Ajax Applications and Search-based Software Engineering","Software engineering;Application software;Automatic testing;Software testing;Web pages;Navigation;Internet;Asynchronous communication;Web server;Graphical user interfaces","graphical user interfaces;Internet;Java;program testing;XML","search-based testing;Web engineering technology;Webpage navigation;Ajax technology;asynchronous communication;Web server;GUI;asynchronous Javascript and XML;graphical user interface","","24","1","13","","29 May 2009","","","IEEE","IEEE Conferences"
"VulDetector: Detecting Vulnerabilities Using Weighted Feature Graph Comparison","L. Cui; Z. Hao; Y. Jiao; H. Fei; X. Yun","Chinese Academy of Science, Institute of Information Engineering, Beijing, China; Chinese Academy of Science, Institute of Information Engineering, Beijing, China; Chinese Academy of Science, Institute of Information Engineering, Beijing, China; Chinese Academy of Science, Institute of Information Engineering, Beijing, China; Chinese Academy of Science, Institute of Information Engineering, Beijing, China","IEEE Transactions on Information Forensics and Security","27 Jan 2021","2021","16","","2004","2017","Code similarity is one promising approach to detect vulnerabilities hidden in software programs. However, due to the complexity and diversity of source code, current methods suffer low accuracy, high false negative and poor performance, especially in analyzing a large program. In this paper, we propose to tackle these problems by presenting VulDetector, a static-analysis tool to detect C/C++ vulnerabilities based on graph comparison at the granularity of function. At the key of VulDetector is a weighted feature graph (WFG) model which characterizes function with a small yet semantically rich graph. It first pinpoints vulnerability-sensitive keywords to slice the control flow graph of a function, thereby reducing the graph size without compromising security-related semantics. Then, each sliced subgraph is characterized using WFG, which provides both syntactic and semantic features in varying degrees of security. As for graph comparison, we take full usage of vulnerability graph and patch graph to improve accuracy. In addition, we propose two optimization methods based on analysis of vulnerabilities. We have implemented VulDetector to automatically detect vulnerabilities in software programs with known vulnerabilities. The experimental results prove the effectiveness and efficiency of VulDetector.","1556-6021","","10.1109/TIFS.2020.3047756","National Natural Science Foundation of China(grant numbers:61972392,62072453); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2020164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309254","Vulnerability detection;code similarity;weighted feature graph","Syntactics;Software;Testing;Semantics;Security;Optimization methods;Lenses","flow graphs;program diagnostics;security of data","vulnerability detection;patch graph;vulnerability graph;semantic features;syntactic features;security-related semantics;control flow graph;vulnerability-sensitive keywords;semantically rich graph;WFG;weighted feature graph model;static-analysis tool;source code;software programs;code similarity;weighted feature graph comparison;VulDetector","","","","53","IEEE","28 Dec 2020","","","IEEE","IEEE Journals"
"Particle Swarm Based Meta-Heuristics for Function Optimization and Engineering Applications","M. Pant; R. Thangaraj; A. Abraham","Dept. of Paper Technol., IIT Roorkee, Roorkee; Dept. of Paper Technol., IIT Roorkee, Roorkee; NA","2008 7th Computer Information Systems and Industrial Management Applications","9 Jul 2008","2008","","","84","90","This paper evaluates the performance of three Particle Swarm Optimization (PSO) algorithms, namely attraction-repulsion based PSO (ATREPSO), Quadratic Interpolation based PSO (QIPSO) and Gaussian Mutation based PSO (GMPSO). Whereas all the algorithms are guided by the diversity of the population to search the global optimal solution of a given optimization problem, GMPSO uses the concept of mutation and QIPSO uses the reproduction operator to generate a new member of the swarm. We tested the variants of PSO on ten standard benchmark functions and compared the results with classical PSO algorithm. Also, the performance of all algorithms is tested on two engineering design problems. The numerical results show that all the algorithms outperform the classical particle swarm optimization by a remarkable difference.","","978-0-7695-3184-7","10.1109/CISIM.2008.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4557839","particle swarm optimization;nature inspired heuristics;Attraction-Repulsion based PSO;Quadratic Interpolation based PSO (QIPSO);Gaussian Mutation based PSO (GMPSO)","Particle swarm optimization;Genetic mutations;Ant colony optimization;Application software;Testing;Stochastic processes;Management information systems;Computer industry;Quality management;Technology management","interpolation;particle swarm optimisation","function optimization;particle swarm optimization algorithms;meta-heuristics;attraction-repulsion;quadratic interpolation;Gaussian mutation;global optimal solution;standard benchmark functions","","9","","20","","9 Jul 2008","","","IEEE","IEEE Conferences"
"An experience in blending the traditional and Agile methodologies to assist in a small software development project","W. Singhto; N. Denwattana","Faculty of Informatics Burapha University Chonburi, Thailand 20131; Faculty of Informatics Burapha University Chonburi, Thailand 20131","2016 13th International Joint Conference on Computer Science and Software Engineering (JCSSE)","21 Nov 2016","2016","","","1","5","Agile methodology has been adopted for many software development projects, due to its ability to deal with changing product requirements, while Traditional methods are better suited to dealing with projects that have clearly defined requirements. Because of the differences in the two methodologies and their diverse approaches to solving development problems, it is necessary to understand their individual approaches in order for the benefits to be compared and synthesized. This study is necessary to understand the differences and diversities of the two methodologies using the checklist table to select and adopt the appropriate methodology for particular development projects. Results of this study not only provide positive answers but also offer suggestions for better integration.","","978-1-5090-2033-1","10.1109/JCSSE.2016.7748914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7748914","Agile;Traditional;Combined Agile and Traditional;Project mangement;SMEs","Software;Testing;Training;Encoding;Organizations;Adaptation models;Computer science","formal specification;project management;software development management;software prototyping","agile methodologies;software development project;product requirements;development problems","","","","13","","21 Nov 2016","","","IEEE","IEEE Conferences"
"Automatically checking an implementation against its formal specification","S. Antoy; D. Hamlet","Dept. of Comput. Sci., Portland State Univ., OR, USA; NA","IEEE Transactions on Software Engineering","6 Aug 2002","2000","26","1","55","69","We propose checking the execution of an abstract data type's imperative implementation against its algebraic specification. An explicit mapping from implementation states to abstract values is added to the imperative code. The form of specification allows mechanical checking of desirable properties such as consistency and completeness, particularly when operations are added incrementally to the data type. During unit testing, the specification serves as a test oracle. Any variance between computed and specified values is automatically detected. When the module is made part of some application, the checking can he removed, or may remain in place for further validating the implementation. The specification, executed by rewriting, can be thought of as itself an implementation with maximum design diversity, and the validation as a form of multiversion-programming comparison.","1939-3520","","10.1109/32.825766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=825766","","Formal specifications;Application software;Java;Mechanical factors;Software testing;Computer languages;Software engineering;Software maintenance;Equations;Software prototyping","algebraic specification;program verification;abstract data types;program testing;object-oriented programming","implementation checking;formal specification;abstract data type;imperative implementation;algebraic specification;imperative code;unit testing;rewriting;multiversion programming;object oriented program testing","","54","1","59","","6 Aug 2002","","","IEEE","IEEE Journals"
"A Unified Test Framework for Continuous Integration Testing of SOA Solutions","H. Liu; Z. Li; J. Zhu; H. Tan; H. Huang","Res. Lab., IBM China, Beijing, China; Res. Lab., IBM China, Beijing, China; Res. Lab., IBM China, Beijing, China; Res. Lab., IBM China, Beijing, China; Res. Lab., IBM China, Beijing, China","2009 IEEE International Conference on Web Services","31 Jul 2009","2009","","","880","887","The quality of service oriented architecture (SOA) solutions is becoming more and more important along with the increasing adoption of SOA. Continuous integration testing (CIT) is an effective technology to discover bugs as early as possible. However, the diversity of programming models used in an SOA solution and the distribution nature of an SOA solution pose new challenges for CIT. Existing testing frameworks more focus on the integration testing of applications developed by a single programming model. In this paper, a unified test framework is proposed to overcome these limitations and enable the CIT of SOA solutions across the whole development lifecycle. This framework is designed following the model driven architecture (MDA). The information of an executable test case is separated into two layers: the behavior layer and the configuration layer. The behavior layer represents the test logic of a test case and is platform independent. The configuration layer contains the platform specific information and is configurable for different programming models. An extensible and pluggable test execution engine is specially designed to execute the integration test cases. A global test case identifier instrumentation approach is used to merge the distributed test case execution traces captured by ITCAM - an IBM integrated management tool. A verification approach supporting Boolean expression and back-end service interaction verification is proposed to verify the test execution result. Initial experiments have shown the effectiveness of this unified test framework.","","978-0-7695-3709-2","10.1109/ICWS.2009.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5175909","continuous integration testing;service oriented architecture","Semiconductor optical amplifiers;Service oriented architecture;Computer bugs;Logic testing;Web services;Life testing;Logic programming;Engines;Instruments;Software testing","program debugging;program testing;program verification;software architecture;software quality;software tools","SOA solutions;service oriented architecture;unified test framework;continuous integration testing;bugs discovery;model driven architecture;distributed test case execution traces;IBM integrated management tool;ITCAM;Boolean expression;back-end service interaction verification","","3","","12","","31 Jul 2009","","","IEEE","IEEE Conferences"
"Understanding Conflict in Virtual Teams: An Experimental Investigation using Content Analysis","S. Paul; P. Seetharaman; I. Samarah; P. Mykytyn",Southern Illinois University at Carbondale; NA; NA; NA,"Proceedings of the 38th Annual Hawaii International Conference on System Sciences","24 Jan 2005","2005","","","44a","44a","Virtual teams are temporally and geographically dispersed groups, which may have members from varied cultures and backgrounds. Such diversity may cause intra-group conflicts in virtual teams. We analyzed the contents of the transcripts of GSS-based virtual teams and identified the conflict episodes and the approaches followed to resolve intra-group conflicts. The conflict episodes that occurred in the early phases of decision-making were separated from those taking place in the choice phase. The results revealed that conflicts in the choice phase of decision-making were detrimental to global virtual teams. We also found that groups following an integrative conflict resolution style had better performance than those following other conflict resolution approaches, such as a distributive style. While the results contribute towards the understanding of conflict in groups, the area warrants further research.","1530-1605","0-7695-2268-8","10.1109/HICSS.2005.647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1385322","","Virtual groups;Decision making;Cultural differences;Performance analysis;Global communication;Data analysis;Information analysis;Information systems;Collaborative software;Testing","","","","7","","40","","24 Jan 2005","","","IEEE","IEEE Conferences"
"DeepRoad: GAN-Based Metamorphic Testing and Input Validation Framework for Autonomous Driving Systems","M. Zhang; Y. Zhang; L. Zhang; C. Liu; S. Khurshid","University of Texas at Austin,USA; Shenzhen Key Laboratory of Computational Intelligence, Southern University of Science and Technology,Department of Computer Science and Engineering,China; University of Texas at Dallas,USA; University of Texas at Dallas,USA; University of Texas at Austin,USA","2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)","17 Feb 2020","2018","","","132","142","While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems, they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems, a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite, e.g., generating new input images transformed from the original ones. However, these techniques are insufficient due to two limitations: first, many such synthetic images often lack diversity of driving scenes, and hence compromise the resulting efficacy and reliability. Second, for machine-learning-based systems, a mismatch between training and application domain can dramatically degrade system accuracy, such that it is necessary to validate inputs for improving system robustness. In this paper, we propose DeepRoad, an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First, DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale, shear and rotation). In particular, DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second, DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third, DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems, and effectively validate input images to potentially enhance the system robustness as well.","2643-1572","978-1-4503-5937-5","10.1145/3238147.3238187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000040","Software testing;Test generation;Input validation;Deep Neural Networks","","feature extraction;learning (artificial intelligence);mobile robots;neural nets;program testing","system robustness;GAN-based metamorphic testing;input validation framework;image-based autonomous driving systems;artificial driving scenes;synthetic images;machine-learning-based systems;unsupervised DNN-based framework;DNN-based autonomous driving systems;diverse driving scenes;image transformation rules;metamorphic testing techniques;Udacity self-driving car challenge;deeproad;deep neural networks;generative adversarial networks","","78","1","45","","17 Feb 2020","","","IEEE","IEEE Conferences"
"Adaptive Random Testing for Multiagent Path Finding Systems","Y. Liu; X. -Y. Zhang","Beihang University, Beijing, China; National Institute of Informatics, Tokyo, Japan","IEEE Transactions on Reliability","2 Mar 2022","2022","71","1","295","308","The multiagent path finding (MAPF) problem identifies the scheduling of multiple agents simultaneously, such that all of them can reach their targets efficiently. To date, MAPF systems have been assigned important tasks such as traffics and warehouses. It is essential to conduct testing for MAPF systems to detect potential failures. Namely, in an MAPF system, a test case is a specific MAPF scenario, including the initial locations of the agents and the environment for these agents to play in. By testing, we intend to find the scenarios (i.e., test cases) whose executions reveal failures. Testing MAPF systems is challenging due to the complexity of its input and the interactions among multiple agents. This article proposes the testing approach based on the adaptive random testing (ART) for MAPF systems. ART aims to generate new test cases far from the already executed ones. Particularly, to calculate the distance between each pair of test cases, we introduce two metrics, the initial density distribution and the destination density distribution, to characterize the distribution of the agents’ initial and destination nodes, respectively. Benefit from ART, the diversity of the information generated during testing can be improved. Experimental results show that compared with the random testing, our approach can detect more diverse failure-revealing scenarios.","1558-1721","","10.1109/TR.2022.3146323","ERATO HASUO Metamathematics for Systems Design(grant numbers:JPMJER1603); JST; Engineerable AI Techniques for the Practical Applications of High-Quality Machine Learning-based Systems(grant numbers:JPMJMI20B8); JST-Mirai; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9725384","Adaptive random testing (ART);density measurement;multiagent path finding (MAPF);multiagent systems;software testing","Measurement;Adaptive systems;Job shop scheduling;Scalability;Subspace constraints;Benchmark testing;Planning","","","","","","49","IEEE","2 Mar 2022","","","IEEE","IEEE Journals"
"Compatibility Testing Service for Mobile Applications","T. Zhang; J. Gao; J. Cheng; T. Uehara","Sch. of Software & Microelectron., Northwest Polytech. Univ., Xi'an, China; Dept. of Comput. Eng., San Jose State Univ., San Jose, CA, USA; Sch. of Software & Microelectron., Northwest Polytech. Univ., Xi'an, China; Software Innovation Labs., Fujitsu Aboratories Ltd., Japan","2015 IEEE Symposium on Service-Oriented System Engineering","25 Jun 2015","2015","","","179","186","As more and more mobile applications are developed, mobile app testing and quality assurance have become very important. Due to the diversity of mobile devices and platforms, compatibility testing for mobile apps has been identified as one urgent and challenging issue. There are two major reasons contributing to this issue. They are: a) the large number of mobile devices with diverse features and platforms which are upgraded frequently, b) a higher cost and complexity in mobile app compatibility testing. This paper proposes one optimized compatibility testing strategy using a statistical approach to reduce test costs, and improve engineer's operation efficiency. The paper provides a solution to generate an optimized compatibility test sequence for mobile apps using the K-Means statistical algorithm. A compatibility testing service has been proposed for mobile apps. Moreover, two case study results are reported to demonstrate its potential application and effectiveness.","","978-1-4799-8356-8","10.1109/SOSE.2015.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7133527","software testing;mobile testing;compatibility testing;clustering algorithm;test coverage","Mobile communication;Testing;Mobile handsets;Servers;Databases;Home appliances;Analytical models","mobile computing;statistical analysis","compatibility testing service;mobile app testing;quality assurance;mobile devices;mobile app compatibility testing;statistical approach;k-means statistical algorithm","","18","","24","","25 Jun 2015","","","IEEE","IEEE Conferences"
"Semantic Annotation and Retrieval Approach for Historical Testcases","J. Hu; Z. Chen; H. Cai; X. Liu; X. Fei; L. Jiang","Sch. of Software, Shanghai Jiao Tong Univ., Shanghai, China; UM-SJTU Joint Inst., Shanghai Jiao Tong Univ., Shanghai, China; Sch. of Software, Shanghai Jiao Tong Univ., Shanghai, China; Jiangsu Hoperun Software Co., Ltd., China; Fac. of Eng. & Comput., Coventry Univ., Coventry, UK; Sch. of Software, Shanghai Jiao Tong Univ., Shanghai, China","2017 IEEE 14th International Conference on e-Business Engineering (ICEBE)","23 Nov 2017","2017","","","54","61","Reusing Historical testcases play a crucial role in ensuring software testing quality. However, the diversity of historical testcases limits their potential uses. As a result, large amounts of human effort is required to write testcases for complex functional testings. In this paper, an effective framework is proposed to integrate and retrieve historical testcase bases with semantic analysis technologies. Firstly, semantic similarity is calculated to integrate the metadata of the inputted semi-structured testcases. Then, testcases are clustered by using similarity measures to eliminate heterogeneity existed in the contents of the testcases. The clustering results are added to the testcases as semantic annotations for the later semantic query. Using the semantic query interface, testers can easily obtain useful testcases without ambiguity. Finally, a case study demonstrates the effectiveness and scalability of this method for testcases retrieval for bank information systems testing.","","978-1-5386-1412-9","10.1109/ICEBE.2017.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119130","testcases reuse;semantic query;information retrieval","Semantics;Testing;Indexes;Software;Metadata;Business","information systems;meta data;ontologies (artificial intelligence);pattern clustering;program testing;query processing;software quality","historical testcases;historical testcase bases;semantic analysis technologies;semantic similarity;semantic query interface;software testing quality.;semantic annotation","","","","15","","23 Nov 2017","","","IEEE","IEEE Conferences"
"Testing DNN-Based Path Planning Algorithms by Metamorphic Testing","S. Lv; B. Yin","Beihang University,School of Automation Science and Electrical Engineering,Beijing,China; Beihang University,School of Automation Science and Electrical Engineering,Beijing,China","2020 7th International Conference on Dependable Systems and Their Applications (DSA)","26 Jan 2021","2020","","","515","526","Deep Neural Networks (DNNs) are increasingly applied to solve path planning problems in recent years. However, unexpected or incorrect behaviors of DNNs greatly threaten the reliability of DNN-based path planning algorithms. Therefore, the reliability should be evaluated through the software testing process. The quality of the training dataset is of great importance to the pre-trained DNN models. The pretrained model may still lack generality by using a randomly generated and insufficient training dataset. And DNN-based system testing is faced with Oracle problems. Because Metamorphic Testing (MT) has been shown considerable effectiveness in alleviating the absence of oracle problems. To increase the reliability of DNN-based path planning algorithms, in this paper, we present a test technique specialized for DNN-based path planning algorithms based on metamorphic testing. We present a framework for systematically designing sixteen metamorphic relations (MRs) by combining input transformations and output relations. And experiments are carried out on an actually released business software system, which demonstrates that our method is effective. The results show that our approach can effectively improve the diversity of test data, the accuracy of the DNN model, and the reliability of the software.","","978-0-7381-2422-3","10.1109/DSA51864.2020.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9331244","deep learning testing;DNN-based path planning algorithm;metamorphic testing;neuron coverage","Training;Software algorithms;Software systems;Path planning;Software reliability;Testing;Business","control engineering computing;convolutional neural nets;deep learning (artificial intelligence);path planning;program testing;software reliability","oracle problems;DNN-based path planning algorithms;metamorphic testing;DNN model;software testing process;pre-trained DNN models;randomly generated training dataset;DNN-based system testing;software reliability;metamorphic relation","","","","29","","26 Jan 2021","","","IEEE","IEEE Conferences"
"Systematic Mapping of the Literature on Secure Software Development","H. Nina; J. A. Pow-Sang; M. Villavicencio","Maestría en Informática, Pontificia Universidad Católica del Perú, Lima, Peru; Maestría en Informática, Pontificia Universidad Católica del Perú, Lima, Peru; Facultad de Ingeniería en Electricidad y Computación, Escuela Superior Politécnica del Litoral, Guayaquil, Ecuador","IEEE Access","8 Mar 2021","2021","9","","36852","36867","The accelerated growth in exploiting vulnerabilities due to errors or failures in the software development process is a latent concern in the Software Industry. In this sense, this study aims to provide an overview of the Secure Software Development trends to help identify topics that have been extensively studied and those that still need to be. Therefore, in this paper, a systematic mapping review with PICo search strategies was conducted. A total of 867 papers were identified, of which only 528 papers were selected for this review. The main findings correspond to the Software Requirements Security, where the Elicitation and Misuse Cases reported more frequently. In Software Design Security, recurring themes are security in component-based software development, threat model, and security patterns. In the Software Construction Security, the most frequent topics are static code analysis and vulnerability detection. Finally, in Software Testing Security, the most frequent topics are vulnerability scanning and penetration testing. In conclusion, there is a diversity of methodologies, models, and tools with specific objectives in each secure software development stage.","2169-3536","","10.1109/ACCESS.2021.3062388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363884","Software development;security;requirements;design;construction;testing;vulnerability;systematic mapping review","Software;Security;Systematics;Market research;Software engineering;Databases;Licenses","DP industry;object-oriented programming;program diagnostics;program testing;security of data;software quality","accelerated growth;software development process;latent concern;Software Industry;Secure Software Development trends;systematic mapping review;PICo search strategies;Software Requirements Security;Software Design Security;component-based software development;security patterns;Software Construction Security;static code analysis;vulnerability detection;Software Testing Security;vulnerability scanning;penetration testing;secure software development stage","","2","","33","CCBY","26 Feb 2021","","","IEEE","IEEE Journals"
"Overcoming challenges to air force satellite ground control automation","M. J. Bentley; A. C. Lin; D. D. Hodson","Air Force Institute of Technology, 2950 Hobson Way, Wright-Patterson AFB, OH 45433; Air Force Institute of Technology, 2950 Hobson Way, Wright-Patterson AFB, OH 45433; Air Force Institute of Technology, 2950 Hobson Way, Wright-Patterson AFB, OH 45433","2017 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)","18 May 2017","2017","","","1","7","US Air Force satellite ground stations require significant manpower to operate. To improve operating efficiencies, the Air Force seeks to incorporate more automation into routine satellite operations. Interaction with autonomous systems includes not only daily operations, but also the development, maintainability, and the extensibility of such systems. This paper presents challenges to Air Force satellite automation: (1) existing architecture of legacy systems, (2) space segment diversity, and (3) unclear definition and scoping of the term “automation.” Using a qualitative case study approach, we survey comparable non-satellite operation domains (Industrial Control Automation and Software Testing) that have successfully integrated automation, and other satellite operation enterprises (NASA Goddard, Naval Research Laboratory, European Ground Station National Institute for Space Research in Brazil) to identify common themes and best practices. From this insight, we recommend that future satellite operation ground stations encourage the use of layered architectures, abstract satellite operation processes, and integrate simulators in future systems as concrete implementations of this common operating platform.","2379-1675","978-1-5090-6380-2","10.1109/COGSIMA.2017.7929585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7929585","automation;case study;satellite;ground control;process mining;simulation","Automation;Satellites;Software;Computer architecture;Aerospace electronics;Space vehicles;Software engineering","military aircraft;satellite ground stations","US Air Force satellite ground station control automation;legacy system architecture;space segment diversity;qualitative analysis;nonsatellite operation domains;satellite operation enterprises;layered architectures;abstract satellite operation process","","1","","16","","18 May 2017","","","IEEE","IEEE Conferences"
"The usage of contextual information to develop data test vectors","I. Stefan; L. Miclea","Automation Department, Technical University of Cluj-Napoca, Romania; Automation Department, Technical University of Cluj-Napoca, Romania","Proceedings of 2012 IEEE International Conference on Automation, Quality and Testing, Robotics","12 Jul 2012","2012","","","302","306","In real-time systems/hybrid systems the quality of the controlling software represents one of the major aspects. Many of these systems allow interaction with the users by a graphical interface having inputs to select or type in. Even where the software does not control an industrial plant, machinery, a car or robot, it is possible to control financial transactions, personal details or electronic patient information. Large amount of financial, time, human resources are allocated toward testing the software. The paper proposes a method to use contextual data from the GUI of applications to create test cases for functional testing. The objective is to enhance the automation in testing by reducing the time allocated to generate the controllable input values. The DOM architecture for Web and .NET resource file for Windows OS applications will be considered as starting points in the development of the method. The discussion remains if the tester inspection is needed in order to choose between the diversity of test cases automatically generated or the tests will be all executed without exception. It will be taken in consideration the required system resources to repeatedly run all the tests in regression testing. In case of applying this method to several user interfaces, by saving the properties extracted and the generated test cases and results, statistical data regarding effective templates to use would emerge.","","978-1-4673-0704-8","10.1109/AQTR.2012.6237721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6237721","test vector;code combination;genetic combination;automated test vector generator","Testing;Vectors;Genetic algorithms;Software;HTML;Genetics;Automation","automatic test software;graphical user interfaces;human resource management;Internet;program compilers;program testing;real-time systems;regression analysis;resource allocation;software quality","contextual information usage;data test vector development;real-time systems;hybrid systems;controlling software quality;financial transaction control;personal details;electronic patient information;human resource allocation;financial resource allocation;time allocation;software testing;GUI;test case creation;functional testing;controllable input value generation;DOM architecture;Web resource file;.NET resource file;Windows OS applications;automatic test case generation;regression testing;graphical user interfaces;statistical data","","","","11","","12 Jul 2012","","","IEEE","IEEE Conferences"
"ISO/IEC/IEEE International Standard - Systems and software engineering -- Vocabulary","",,"ISO/IEC/IEEE 24765:2010(E)","8 Feb 2018","2010","","","1","418","The systems and software engineering disciplines are continuing to mature while information technology advances. This International Standard was prepared to collect and standardize terminology. Its purpose is to identify terms currently in use in the field and standard definitions for these terms. It is intended to serve as a useful reference for those in the Information Technology field, and to encourage the use of systems and software engineering standards prepared by ISO and liaison organizations IEEE Computer Society and Project Management Institute (PMI). This International Standard replaces IEEE Std 610.12-1990, IEEE Standard Glossary of Software Engineering Terminology, which was contributed by the IEEE as a source document. The approach and lexical exactitude of IEEE Std 610.12-1990 served as a model for this International Standard. Nevertheless, approximately two thirds of the definitions in this International Standard are new since IEEE Std 610.12 was last updated in 1990, a reflection of the continued evolution in the field.;ISO/IEC/IEEE 24765:2010 provides a common vocabulary applicable to all systems and software engineering work. It was prepared to collect and standardize terminology. ISO/IEC/IEEE 24765:2010 is intended to serve as a useful reference for those in the information technology field, and to encourage the use of systems and software engineering standards prepared by ISO and liaison organizations IEEE Computer Society and Project Management Institute. ISO/IEC/IEEE 24765:2010 includes references to the active source standards for each definition so that the use of the term can be further explored.","","978-0-7381-6205-8","10.1109/IEEESTD.2010.5733835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5733835","computer;dictionary;information technology;software engineering;systems engineering;terminology;vocabulary","IEEE standards;ISO standards;IEC standards;Software engineering;Dictionaries","IEEE standards;ISO standards;software engineering","systems engineering;International Standard;information technology field;IEEE Computer Society;Project Management Institute;IEEE Std 610.12-1990;IEEE Standard Glossary of Software Engineering Terminology","","29","1","128","","8 Feb 2018","","","IEEE","IEEE Standards"
"Cooperative and human aspects of software engineering (CHASE 2009)","C. de Souza; H. Sharp; Y. Dittrich; J. Singer","UFPA, Brazil; Open University, UK; IT University of Copenhagen, Denmark; NRC, Canada","2009 31st International Conference on Software Engineering - Companion Volume","12 Jun 2009","2009","","","451","452","The CHASE 2009 workshop is concerned with exploring the cooperative and human aspects of software engineering, and providing a forum for discussing high-quality research. Accepted papers reflect the diversity of the field of software engineering - ranging from requirements to testing, and from ethnographic research to experiments. Moreover, the background of attendees reflects the diversity of researchers in this domain, ranging from sociology to psychology, from informatics to software engineering. CHASE 2009 met its goals in presenting high-quality research and building community through a mixture of presentations, discussions, posters, and social activities.","","978-1-4244-3495-4","10.1109/ICSE-COMPANION.2009.5071057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5071057","","Humans;Software engineering;Cultural differences;Collaborative work;Software testing;Psychology;Engineering management;Programming;Software maintenance;Information systems","","","","3","","3","","12 Jun 2009","","","IEEE","IEEE Conferences"
"Some heresy regarding software engineering","R. L. Glass",NA,"IEEE Software","6 Jul 2004","2004","21","4","104","103","Different software application domains require different programming techniques. The author argues that the field should rethink what should be taught to students - and what we ought to methodologize. Let's question some of the historic unquestionables. Let's acknowledge the diversity of application domains and realize that different domains require different techniques. Let's listen both to brilliant academics and equally brilliant practitioners about what works - and what doesn't.","1937-4194","","10.1109/MS.2004.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1309657","software engineering;CMM","Software engineering;Project management;Software development management;Coordinate measuring machines;Application software;Programming;Software testing;System testing;Failure analysis;Performance analysis","","software engineering;CMM","","1","","","","6 Jul 2004","","","IEEE","IEEE Magazines"
